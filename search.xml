<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>G1调优</title>
      <link href="2021/06/04/G1%E8%B0%83%E4%BC%98/"/>
      <url>2021/06/04/G1%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在某些情况下，CMS GC的性能比G1更高，因此一些人推荐在Java8坚持使用CMS，而由于CMS在Java9被启用，切换到另一个GC迫在眉睫，因此转向G1是目前最好的解决方案。</p><h2 id="G1基础"><a href="#G1基础" class="headerlink" title="G1基础"></a>G1基础</h2><p>G1关键设计的目标之一是使垃圾收集导致的stop-the-world暂停持续时间变得可预测和可配置。实际上，G1是一个软实时的垃圾收集器，简单说就是您可以为stop-the-world配置一个毫秒长的时间，G1 GC将尽最大可能实现这个目标。</p><p>为实现stop-the-world的时间可预测，G1将堆分成多个（通常大约2048个）可以容纳对象、大小相等的独立区域（Region），可以通过 -XX:G1HeapRegionSize 配置每个Region大小，每个Region大小可以从1MB到32MB不等，并且必须是 2 的幂。</p><p>每个Region可能是Eden，也可能是Survivor，也可能是Old，所有的Eden和Survivor区逻辑上组成年轻代，所有Old区逻辑上组成老年代。另外Region还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象都被认定为大对象，对于那些超过了整个Region容量的超级大对象，将被存放在多个连续的Humongous Region中。G1进行垃圾回收时，会将Humongous当成老年代回收。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/04/G1%E8%B0%83%E4%BC%98/a1.png"></p><h2 id="stop-the-world"><a href="#stop-the-world" class="headerlink" title="stop-the-world"></a>stop-the-world</h2><p>在垃圾收集期间，有许多事件使整个应用程序暂停，这个被称为stop-the-world事件。在stop-the-world期间，对JVM的任何请求都被暂停。因此，GC调优目标之一就是尽量减少stop-the-world持续时间。Full GC通常stop-the-world暂停时间最长，因为要遍历整个堆，而其他stw暂停可能更短或者在可接受的范围之内。在GC调优过程中，GC日志分析有助于了解暂停的时间以及原因，从而采取纠正措施。</p><h2 id="G1-GC"><a href="#G1-GC" class="headerlink" title="G1 GC"></a>G1 GC</h2><p>G1 GC有3个主要集合：</p><ul><li>Young GC：只清理年轻代，即活动对象从Eden移到Survivor，从一个Survivor移到另一个Survivor，以及达到MaxTenuringThreshold年龄的对象移到Old区。</li><li>Mixed GC：年轻代和老年代中包含垃圾最多的一些区域（可配置）也被清除，这也是Garbage First的名字，即垃圾优先。</li><li>Full GC：当Mixed GC失败，堆中没有足够的空间给复制对象使用，触发单线程的stop-the-world暂停使用“标记整理”算法进行垃圾收集。</li></ul><h2 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h2><p>当JVM分配对象到Eden区域失败时，便会触发stop-the-world暂停多线程并行来进行年轻代的垃圾收集，YGC 将 Eden Region 中存活的对象拷贝到Survivor,或者直接晋升到Old Region中；将Survivor Regin中存活的对象拷贝到新的Survivor或者晋升Old Region。</p><h2 id="Mixed-GC"><a href="#Mixed-GC" class="headerlink" title="Mixed GC"></a>Mixed GC</h2><p>G1收集器很多理念是建立在CMS概念之上。G1并发标记使用Snapshot-At-The-Beginning（SATB或原始快照）方法标记周期开始时处于活动状态的对象，而CMS则采用增量更新。</p><p>当堆的整体占用足够大时，并发标记开始，默认情况下是45%，也可以通过设置 -XX:InitiatingHeapOccupancyPercent 参数进行修改，跟CMS类似，G1的并发标记由许多阶段组成，其中一些是与应用程序线程完全并发的，而另一些则需要停止应用程序线程。</p><h3 id="第一阶段：初始标记"><a href="#第一阶段：初始标记" class="headerlink" title="第一阶段：初始标记"></a>第一阶段：初始标记</h3><p>此阶段标记所有可从GC根直接访问的对象。它需要stop-the-world暂停。可以从日志 Evacuation Pause的“initial-mark”来查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.631: [GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0062656 secs]</span><br></pre></td></tr></table></figure><h3 id="第二阶段：根区域扫描"><a href="#第二阶段：根区域扫描" class="headerlink" title="第二阶段：根区域扫描"></a>第二阶段：根区域扫描</h3><p>这个阶段标记所有可从根区域访问的活动对象，即那些不为空的对象。此阶段与应用程序线程同时运行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.362: [GC concurrent-root-region-scan-start]</span><br><span class="line">1.364: [GC concurrent-root-region-scan-end, 0.0028513 secs]</span><br></pre></td></tr></table></figure><h3 id="第三阶段：并发标记"><a href="#第三阶段：并发标记" class="headerlink" title="第三阶段：并发标记"></a>第三阶段：并发标记</h3><p>这个阶段和CMS并发标记非常相似：遍历整个堆里的对象图，找到要回收的对象，此阶段与应用程序线程同时运行，并发标记时会产生漏标、错标问题，G1使用SATB算法来解决。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.364: [GC concurrent-mark-start]</span><br><span class="line">1.645: [GC concurrent-mark-end, 0.2803470 secs]</span><br></pre></td></tr></table></figure><h3 id="第四阶段：最终标记"><a href="#第四阶段：最终标记" class="headerlink" title="第四阶段：最终标记"></a>第四阶段：最终标记</h3><p>此阶段会stop-the-world暂停，与CMS一样，完成最终的标记。对用户程序线程做短暂的暂停，用于处理并发标记阶段遗留下的SATB记录。</p><h3 id="第五阶段：筛选回收"><a href="#第五阶段：筛选回收" class="headerlink" title="第五阶段：筛选回收"></a>第五阶段：筛选回收</h3><p>此阶段会计算堆中所有的活动对象，根据GC效率对这些区域排序，并按照-XX:MaxGCPauseMillis参数设定的毫秒数对价值最高的区域进行回收。这个阶段某部分是需要stop-the-world暂停的，例如标记初始标记以来所有对象的卡位图（TASM之上的所有对象）、为任何具有一个活动对象的区域标记区域位图、清理没有活动对象的区域RSet集等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.872: [GC cleanup 1357M-&gt;173M(1996M), 0.0015664 secs]</span><br><span class="line">[Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br></pre></td></tr></table></figure><p>某部分是并发的，例如空区域回收和大部分活跃对象计算等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.874: [GC concurrent-cleanup-start]</span><br><span class="line">1.876: [GC concurrent-cleanup-end, 0.0014846 secs]</span><br></pre></td></tr></table></figure><h2 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h2><p>如果Mixed GC在进行GC回收拷贝对象时，没有足够的空Region能够承载拷贝对象就会触发Full GC。Full GC是单线程的stop-the-world暂停，使用“标记整理”算法进行垃圾收集，这个过程是非常耗时的。</p><h2 id="G1-GC调优"><a href="#G1-GC调优" class="headerlink" title="G1 GC调优"></a>G1 GC调优</h2><p>G1 GC的可用JVM选项比CMS少得多，为G1 GC调整jVM的基本策略是设置堆大小和暂停时间，然后让JVM动态修改所需的设置以尝试满足暂停时间目标。</p><h3 id="基本JVM选项"><a href="#基本JVM选项" class="headerlink" title="基本JVM选项"></a>基本JVM选项</h3><h4 id="使用G1垃圾收集器"><a href="#使用G1垃圾收集器" class="headerlink" title="使用G1垃圾收集器"></a>使用G1垃圾收集器</h4><p>在Java8上，默认GC是Parallel GC，而在Java11上默认是G1 GC。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC</span><br></pre></td></tr></table></figure><h4 id="堆大小"><a href="#堆大小" class="headerlink" title="堆大小"></a>堆大小</h4><p>建议将最小和最大堆设置相同值，从而避免在应用程序生命周期中堆的动态收缩和增长。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:InitialHeapSize (最小堆大小)  -XX:MaxHeapSize (最大堆大小)</span><br></pre></td></tr></table></figure><p>-Xms和-Xmx选项是上述选项的快捷方式，因此选用任一搭配都可以。</p><h4 id="暂停目标和年轻代大小"><a href="#暂停目标和年轻代大小" class="headerlink" title="暂停目标和年轻代大小"></a>暂停目标和年轻代大小</h4><p>G1 GC有一个试图满足的暂停时间目标，即软目标。</p><p>在年轻代收集期间，G1 GC会调整年轻代的大小以满足这个目标。出于这个原因，建议设置暂停时间，让GC根据需要自己更改年轻代大小。</p><blockquote><p>特别注意：除非需要，否则不要设置年轻代大小</p></blockquote><p>为了设置暂停时间目标，请设置以下JVM选项：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:MaxGCPauseMillis</span><br></pre></td></tr></table></figure><p>例如，您可以首先将此值设置在200-500之间（单位毫秒）并测试是否满足您的性能要求，默认200ms</p><h4 id="垃圾收集记录"><a href="#垃圾收集记录" class="headerlink" title="垃圾收集记录"></a>垃圾收集记录</h4><p>调优是基于收集前后数据进行对比的迭代过程，因此开启GC日志记录尤为重要，即使在生产环境也是如此。显然需要一个日志记录策略来处理系统上消耗资源的日志。默认日志级别为info。</p><p>建议设置以下JVM选项：</p><ul><li>-Xlog - 这将使用指定选项进行设置</li><li>gc* - 打印所有GC事件</li><li>safepoint - 打印先前使用Java8设置的值</li><li>age* - 在调试级别打印详细信息</li><li>ergo* - 对大多数信息使用调式级别</li><li>time - ISO-8601格式的当前时间和日期</li><li>level - 与日志消息相关的级别</li><li>tags - 与日志消息关联的标签集</li><li>uptime - 自JVM启动以来的时间</li><li>file=filename - 文件名，可选择包含%p或/或%t已包含JVM的PID和启动时间戳</li><li>filesize=size - 设置文件大小</li></ul><p>上面例子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Xlog:gc*,safepoint,age*,ergo*:file&#x3D;&#x2F;opt&#x2F;gclogs&#x2F;gc-%p-%t.log:tags,uptime,time,level:filecount&#x3D;10,filesize&#x3D;50m</span><br></pre></td></tr></table></figure><h3 id="其他JVM选项"><a href="#其他JVM选项" class="headerlink" title="其他JVM选项"></a>其他JVM选项</h3><table><thead><tr><th>JVM选项</th><th>描述</th></tr></thead><tbody><tr><td>-XX:DisableExplicitGC</td><td>建议设置此值以禁用对System.gc()方法调用</td></tr><tr><td>-XX:+UseStringDeduplication</td><td>字符串重复数据删除减少Java堆上String对象的内存占用。默认情况下禁用此功能</td></tr><tr><td>-XX:MaxMetaspaceSize=<size></size></td><td>设置元数据分配的本机最大内存。建议将此值设置为256MB</td></tr><tr><td>-XX:MaxTenuringThreshold=<threshold></threshold></td><td>设置最大对象在年轻代存活年龄阈值。默认为15，对于大部分应用服务器，保持默认即可。</td></tr><tr><td>-XX:+ParallelRefProcEnabled</td><td>建议设置此值以启用并行引用处理。默认情况下，此项处于禁用状态。</td></tr></tbody></table><h3 id="进一步调整"><a href="#进一步调整" class="headerlink" title="进一步调整"></a>进一步调整</h3><p>以下选项没有具体的推荐值，需要基于您的应用程序自行分析设置。</p><h4 id="XX-ParallelGCThreads"><a href="#XX-ParallelGCThreads" class="headerlink" title="-XX:ParallelGCThreads"></a>-XX:ParallelGCThreads</h4><p>指定并行GC线程数，也就是STW期间工作的GC线程数，遵循以下原则：</p><ul><li><p>如果用户指定该值，使用用户指定的值</p></li><li><p>用户未指定时，如果CPU逻辑核数小于8，则ParallelGCThreads为CPU逻辑核数</p></li><li><p>用户未指定，如果CPU逻辑核数大于8，则计算方式为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ParallelGCThreads&#x3D;8 + (N - 8) * 5&#x2F;8</span><br><span class="line">或</span><br><span class="line">ParallelGCThreads&#x3D;8 + (N - 8) * 5&#x2F;16</span><br></pre></td></tr></table></figure><p> JVM会根据实际情况决定到底是乘以5/8还是5/16。</p></li></ul><h4 id="XX-ConcGCThreads"><a href="#XX-ConcGCThreads" class="headerlink" title="-XX:ConcGCThreads"></a>-XX:ConcGCThreads</h4><p>设置并行标记线程的数量。默认情况下设置为并行垃圾收集线程数（ParallelGCThreads）的1/4。例如，具有16个逻辑处理器的系统将默认ParallelGCThreads为16，因此ConcGCThreads为4。您可以增加ConcGCThreads以增加并行标记线程的数量并减少标记期间的暂停时间。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:ConcGCThreads&#x3D;n</span><br></pre></td></tr></table></figure><h4 id="XX-InitiatingHeapOccupancyPercent"><a href="#XX-InitiatingHeapOccupancyPercent" class="headerlink" title="-XX:InitiatingHeapOccupancyPercent"></a>-XX:InitiatingHeapOccupancyPercent</h4><p>该值决定初始标记何时开始，默认为45%。但G1 GC尝试为IHOP寻找最佳值，并且仅在以下情况使用该值：没有足够的信息进行优化或自适应IHOP被覆盖。</p><p>例如，如果由于分配失败而获得Full GC，或者在GC日志中看到Evacuation Pause/Evacuation Failure，这通常意味着无法分配对象，因为没有足够的内存或无法足够快地回收对象，这时您可以通过降低IHOP值提前进行初始标记。为了覆盖自适应行为，您可以设置该 -XX:G1UseAdaptiveIHOP 选项。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:InitiatingHeapOccupancyPercent</span><br></pre></td></tr></table></figure><h4 id="XX-G1MixedGCLiveThresholdPercent"><a href="#XX-G1MixedGCLiveThresholdPercent" class="headerlink" title="-XX:G1MixedGCLiveThresholdPercent"></a>-XX:G1MixedGCLiveThresholdPercent</h4><p>通过设置该值指定被纳入CSet Region地存活空间占比阈值。不同版本默认值不同，有65%和85%。在全局地并发标记阶段，如果一个Region地存活对象空间占比超过该值，那么就会被纳入CSet。该值会直接影响到Mixed GC选择回收地区域。当GC时间较长时，表示GC回收的空间较大，那么可以尝试调低该值，但设置不合理也可能导致垃圾回收不彻底，最终导致Full GC。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:G1MixedGCLiveThresholdPercent&#x3D;85</span><br></pre></td></tr></table></figure><h4 id="XX-G1HeapWastePercent"><a href="#XX-G1HeapWastePercent" class="headerlink" title="-XX:G1HeapWastePercent"></a>-XX:G1HeapWastePercent</h4><p>通过设置该值指定触发Mixed GC的堆垃圾占比，默认值为5%。在全局标记结束后统计出所有CSet内可被回收的垃圾占整个堆的占比，如果超过5%，那么就会触发之后的Mixed GC，如果不超过，那么在之后的某次Young GC中重新执行全局并发标记。可以适当调高此阈值，能够适当降低Mixed GC的频率。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:G1HeapWastePercent&#x3D;5</span><br></pre></td></tr></table></figure><h4 id="XX-G1HeapRegionSize"><a href="#XX-G1HeapRegionSize" class="headerlink" title="-XX:G1HeapRegionSize"></a>-XX:G1HeapRegionSize</h4><p>设置Region大小。默认G1将整个堆分成大约2048个Region，每块大小需要为2的幂次方。Region的大小主要关系到Humongous的判断，当一个对象超过Region大小的一半时，则为巨大对象，那么其会至少独占一个Region，如果一个放不下，会占用连续的多个Region。如果一个Humongous Region放入了巨大对象，可能还有其他空间，但是剩余空间不能用于存放其他对象，就造成了空间浪费。如果你的java应用里有很多大小差不多的巨大对象，可以适当调大Region的大小。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:G1HeapRegionSize&#x3D;2M</span><br></pre></td></tr></table></figure><h4 id="XX-G1NewSizePercent和-XX-G1MaxNewSizePercent"><a href="#XX-G1NewSizePercent和-XX-G1MaxNewSizePercent" class="headerlink" title="-XX:G1NewSizePercent和-XX:G1MaxNewSizePercent"></a>-XX:G1NewSizePercent和-XX:G1MaxNewSizePercent</h4><p>年轻代比例有两个数值指定。-XX:G1NewSizePercent指定年轻代占整个堆的下限占比，默认为5%，-XX:G1MaxNewSizePercent指定年轻代占整个堆的上限占比，默认为60%。G1会根据实际GC情况（STW时间）来动态调整年轻代的大小。需要平衡年轻代和老年代的空间。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:G1NewSizePercent&#x3D;5</span><br><span class="line">-XX:G1MaxNewSizePercent&#x3D;60</span><br></pre></td></tr></table></figure><h4 id="Xmn或-XX-NewSize和-XX-MaxNewSize"><a href="#Xmn或-XX-NewSize和-XX-MaxNewSize" class="headerlink" title="-Xmn或-XX:NewSize和-XX:MaxNewSize"></a>-Xmn或-XX:NewSize和-XX:MaxNewSize</h4><p>G1会根据应用程序的行为动态的调整年轻代。设置这些选项会导致错误的年轻代优化，应该尽量避免设置这些。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMS调优</title>
      <link href="2021/06/04/CMS%E8%B0%83%E4%BC%98/"/>
      <url>2021/06/04/CMS%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="CMS基础"><a href="#CMS基础" class="headerlink" title="CMS基础"></a>CMS基础</h2><p>这个垃圾收集器官方名称是”Mostly Concurrent Mark and Sweep Garbage Collector“。它在年轻代使用”复制”算法，并行进行垃圾回收，在老年代使用并发的“标记清除”算法。</p><p>CMS收集器目标是避免在老年代长时间停顿，它通过两种方式实现。首先，它不压缩老年代空间，而是通过空闲列表来管理回收空间。其次，它与应用程序线程同时完成标记和清理阶段的大部分工作。这意味着垃圾收集器不会显式停止应用程序线程来执行这些阶段，然后这也会导致垃圾回收线程和应用程序线程会竞争CPU时间。</p><h2 id="CMS收集阶段"><a href="#CMS收集阶段" class="headerlink" title="CMS收集阶段"></a>CMS收集阶段</h2><h3 id="第一阶段：初始标记"><a href="#第一阶段：初始标记" class="headerlink" title="第一阶段：初始标记"></a>第一阶段：初始标记</h3><p>该阶段会触发stop-the-world暂停。这个阶段的目标是标记老年代中的所有对象，这些对象要么是直接的GC根，要么是从年轻代中某个活动对象引用的。后者很重要，因为老年代是单独收集的。</p><h3 id="第二阶段：并发标记"><a href="#第二阶段：并发标记" class="headerlink" title="第二阶段：并发标记"></a>第二阶段：并发标记</h3><p>在这个阶段，垃圾收集器会遍历老年代并标记所有活着的对象，从“初始标记”阶段找到的GC根开始。“并发标记”阶段，顾名思义，就是与应用程序线程并发运行，不会停止应用程序线程。请注意，此阶段并不是所有的老年代存活对象都可以被标记，因为应用程序在标记期间会改变引用。</p><h3 id="第三阶段：并发预清理"><a href="#第三阶段：并发预清理" class="headerlink" title="第三阶段：并发预清理"></a>第三阶段：并发预清理</h3><p>这又是一个并发阶段，与应用程序线程并行运行，而不是停止它们。由于前一阶段与应用程序线程同时运行，一些引用已被更改。每当发生这种情况时，JVM会将这些突变对象的区域标记为Dirty Card。</p><p>在预清理阶段，那些能够从Dirty Card区域可达的对象也被标记为存活，当标记完这些对象后，该Dirty Card区域就会消失。</p><h3 id="第四阶段：并发可中断预清理"><a href="#第四阶段：并发可中断预清理" class="headerlink" title="第四阶段：并发可中断预清理"></a>第四阶段：并发可中断预清理</h3><p>与并发预处理清理类似，CMS有两个参数：CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。这两个参数组合起来的意思是预清理后，Eden空间使用超过2M时启动可中断的并发预处理，直到Eden空间使用率达到50%时中断，进入重新标记阶段。</p><h3 id="第五阶段：最终标记"><a href="#第五阶段：最终标记" class="headerlink" title="第五阶段：最终标记"></a>第五阶段：最终标记</h3><p>这是CMS垃圾收集的第二个也是最后一个stop-the-world暂停。这个阶段目标是完成老年代所有活动对象的标记。由于之前的预清理阶段是并发的，它无法跟上应用程序线程的变化速度，需要stop-the-world暂停才能完成。</p><p>通常CMS会在Young Generation尽可能发生后尝试运行“最终标记”阶段，以消除多个stop-the-world暂停。</p><h3 id="第六阶段：并发清理"><a href="#第六阶段：并发清理" class="headerlink" title="第六阶段：并发清理"></a>第六阶段：并发清理</h3><p>无需stop-the-world暂停，与应用程序线程同时运行。该阶段目标是清理未使用的对象并回收它们的空间。</p><h3 id="第七阶段：并发重置"><a href="#第七阶段：并发重置" class="headerlink" title="第七阶段：并发重置"></a>第七阶段：并发重置</h3><p>清理并恢复在CMS GC过程中的各种状态，重新初始化CMS相关数据结构，为下一个垃圾收集做准备。</p><p>总而言之，CMS垃圾收集器通过将大量工作分成不同阶段，在大部分阶段不需要stop-the-world暂停，从而减少延迟。然而，CMS也存在很多缺点，其中最明显的就是由于CMS使用“标记清除”算法清理老年代，所以会产生内存碎片；其次CMS并发清理阶段是和应用程序线程同时进行的，会产生浮动垃圾，CMS无法在当次的收集中处理掉它，只好等到下一次GC去处理；还有CMS并发清理失败后，会使用Serial Old收集器进行Full GC，由于Serial收集器是单线程、存在stop-the-world暂停，会出现长时间的暂停。</p><h2 id="CMS优化"><a href="#CMS优化" class="headerlink" title="CMS优化"></a>CMS优化</h2><h3 id="XX-UseConcMarkSweepGC"><a href="#XX-UseConcMarkSweepGC" class="headerlink" title="-XX:+UseConcMarkSweepGC"></a>-XX:+UseConcMarkSweepGC</h3><p>启用CMS垃圾收集器。默认情况下，Java任何版本都没有将CMS做为默认的垃圾收集器。</p><h3 id="XX-UseParNewGC"><a href="#XX-UseParNewGC" class="headerlink" title="-XX:+UseParNewGC"></a>-XX:+UseParNewGC</h3><p>一般与CMS配合使用，ParNew是年轻代的多线程垃圾收集器，使用“复制”算法收集垃圾。</p><h3 id="XX-CMSConcurrentMTEnabled"><a href="#XX-CMSConcurrentMTEnabled" class="headerlink" title="-XX:+CMSConcurrentMTEnabled"></a>-XX:+CMSConcurrentMTEnabled</h3><p>激活此选项后，允许CMS在并发阶段使用多个线程运行。默认情况下，该选项已激活。</p><h3 id="XX-ConcGCThreads"><a href="#XX-ConcGCThreads" class="headerlink" title="-XX:ConcGCThreads"></a>-XX:ConcGCThreads</h3><p>设置CMS并发阶段的运行线程数。该值取决于ParallelGCThreads，ParallelGCThreads一般默认情况是系统内核数，ConcGCThreads=(ParallelGCThreads+3)/4。</p><h3 id="XX-CMSInitiatingOccupancyFraction"><a href="#XX-CMSInitiatingOccupancyFraction" class="headerlink" title="-XX:CMSInitiatingOccupancyFraction"></a>-XX:CMSInitiatingOccupancyFraction</h3><p>CMS仅在堆已满时才启动GC，即当没有足够的可用空间来存储新分配的对象或提升对象。对于CMS来说，不建议等待这么长时间，CMS收集器需要更早地启动GC。通过设置CMSInitiatingOccupancyFraction阈值提示CMS进行GC。默认值为68%。</p><h3 id="XX-CMSInitiatingOccupancyOnly"><a href="#XX-CMSInitiatingOccupancyOnly" class="headerlink" title="-XX:+CMSInitiatingOccupancyOnly"></a>-XX:+CMSInitiatingOccupancyOnly</h3><p>后台线程ConcurrentMarkSweepThread循环判断（默认2s）是否触发GC，这种现象称为周期性Old GC。如果没有设置CMSInitiatingOccupancyOnly，虚拟机会根据收集的数据决定是否触发GC（建议生产环境带上这个参数）。启用改选项，JVM会为每一个CMS GC使用CMSInitiatingOccupancyFraction做为GC启动的阈值。</p><h3 id="XX-CMSClassUnloadingEnabled"><a href="#XX-CMSClassUnloadingEnabled" class="headerlink" title="-XX:+CMSClassUnloadingEnabled"></a>-XX:+CMSClassUnloadingEnabled</h3><p>CMS是对老年代进行垃圾收集活动的，默认情况下不会对永久代执行GC。激活该选项，CMS会对永久代进行垃圾收集。</p><h3 id="XX-CMSInitiatingPermOccupancyFraction"><a href="#XX-CMSInitiatingPermOccupancyFraction" class="headerlink" title="-XX:CMSInitiatingPermOccupancyFraction"></a>-XX:CMSInitiatingPermOccupancyFraction</h3><p>设置该选项表示当永久代占比达到阈值，就触发CMS GC回收永久代对象，前提是开启CMSClassUnloadingEnabled选项。</p><h3 id="XX-CMSScavengeBeforeRemark"><a href="#XX-CMSScavengeBeforeRemark" class="headerlink" title="-XX:+CMSScavengeBeforeRemark"></a>-XX:+CMSScavengeBeforeRemark</h3><p>激活该选项表示在CMS GC前启动一次Young GC，主要减少Old区对Young区的引用，降低CMS最终标记阶段的开销，减少STW时间。</p><h3 id="XX-CMSIncrementalMode"><a href="#XX-CMSIncrementalMode" class="headerlink" title="-XX:+CMSIncrementalMode"></a>-XX:+CMSIncrementalMode</h3><p>激活该选项表示启用CMS收集器的增量模式。增量模式会定期暂停CMS并发阶段，完全让步给应用程序线程，所以CMS收集器需要更长的时间来完成整个GC。因此只有当CMS GC对应用程序线程影响过多的情况下，启用该选项这更有意义。</p><h3 id="XX-ExplicitGCInvokesConcurrent"><a href="#XX-ExplicitGCInvokesConcurrent" class="headerlink" title="-XX:+ExplicitGCInvokesConcurrent"></a>-XX:+ExplicitGCInvokesConcurrent</h3><p>激活该选项表示避免当应用程序调用System.gc()来显式调用GC。当应用程序调用System.gc()时，会触发Full GC，激活该选项指示JVM运行CMS GC而不是完整的Full GC，从而减少STW暂停时间。</p><h3 id="XX-ExplicitGCInvokesConcurrentAndUnloadsClasses"><a href="#XX-ExplicitGCInvokesConcurrentAndUnloadsClasses" class="headerlink" title="-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses"></a>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses</h3><p>激活该选项表示在调用系统GC时，确保CMS GC将永久代包含进去。</p><h3 id="XX-DisableExplicitGC"><a href="#XX-DisableExplicitGC" class="headerlink" title="-XX:+DisableExplicitGC"></a>-XX:+DisableExplicitGC</h3><p>激活该选项表示忽略系统GC。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Garbage Collection</title>
      <link href="2021/06/03/Garbage-Collection/"/>
      <url>2021/06/03/Garbage-Collection/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="什么是垃圾收集"><a href="#什么是垃圾收集" class="headerlink" title="什么是垃圾收集"></a>什么是垃圾收集</h2><p>从字面意思来说，顾名思义垃圾收集就是处理垃圾。实际上，它的做法恰恰相反，垃圾收集正在追踪所有仍在使用的对象，将其余的对象标记为垃圾。下面我们深入探究 Java 虚拟机实现“垃圾收集”的自动内存回收过程。</p><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>内存管理主要分为手动内存管理和自动内存管理。</p><h3 id="手动内存管理"><a href="#手动内存管理" class="headerlink" title="手动内存管理"></a>手动内存管理</h3><p>在C语言中通过malloc申请内存，通过free释放内存；C++通过new申请对象使用的内存，通过delete释放内存。对于C和C++这种手动管理内存的方式，很容易忘记释放内存，从而造成内存泄漏。因此，更好的方法是自动回收未使用的内存，这种自动化称为垃圾收集（即GC）。</p><h3 id="自动内存管理"><a href="#自动内存管理" class="headerlink" title="自动内存管理"></a>自动内存管理</h3><p>自动内存管理让开发者不再需要考虑自己清理内存，极大地提高了开发效率。但是这种自动内存管理，也就是说自动释放内存，它该如何定位到垃圾呢？</p><h4 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h4><p>Reference Count称为引用计数，为了标记存活对象，引用计数会在每个对象的头上引入一个叫“计数器”的东西，用来记录有多少对象引用了它。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A a &#x3D; new A();</span><br><span class="line">B b &#x3D; new B();</span><br><span class="line">a.ref &#x3D; b;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a1.png"></p><p>对象A的实例在堆中就是一块内存，而a引用了它，所以它的引用就是1，对象B的实例在堆中也是一块内存，首先b引用了它，然后a又引用它一次，所以引用计数就是2。所以通过引用计数就能定位垃圾。但是引用计数有个非常致命的缺点，就是它不能找到循环引用的垃圾，这种情况，这些循环引用的对象是不能被回收的，其实它们是一团垃圾。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a2.png"></p><h4 id="根可达算法"><a href="#根可达算法" class="headerlink" title="根可达算法"></a>根可达算法</h4><p>Root Searching称为根可达算法，java垃圾收集使用的就是根可达算法，即从GC根开始，遍历所有可到达的对象，所有找不到的对象都视为垃圾。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a3.png"></p><p>不太好的事情就是应用程序线程需要停止才能进行，因为如果引用一直发生变化，就无法真正计算引用，当应用程序线程真正停止，垃圾收集线程开始进行GC活动，这种情况称为Stop the World。</p><h2 id="常见的垃圾回收算法"><a href="#常见的垃圾回收算法" class="headerlink" title="常见的垃圾回收算法"></a>常见的垃圾回收算法</h2><h3 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h3><p>在使用上最简单的垃圾回收算法，分为两个阶段，一个是标记阶段，为每个对象更新标记位，检查对象是否死亡；第二个阶段是清除阶段，对死亡的对象进行清除。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a4.png"></p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>实现简单</li><li>不需要移动对象</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>产生内存碎片，清理后的内存可能不连续，容易出现内存很多，但是分配大对象时找不到合适的位置</li><li>效率低，每次都需要遍历整个堆</li></ul><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>将内存一分为二，每次只使用一半，将标记存活的对象复制到另一片内存，然后一下子清空当前内存。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a5.png"></p><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul><li>效率高，主要是标记阶段和复制是可以同时发生的</li><li>不会产生内存碎片</li></ul><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul><li>内存利用率低</li></ul><h3 id="标记整理"><a href="#标记整理" class="headerlink" title="标记整理"></a>标记整理</h3><p>将所有标记存活的对象移动到内存区域的一端，然后再对其他内存进行清理。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a6.png"></p><h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ul><li>不会产生内存碎片</li></ul><h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ul><li>效率低，需要重新更新存活对象的引用地址</li></ul><h2 id="内存池"><a href="#内存池" class="headerlink" title="内存池"></a>内存池</h2><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a7.png"></p><h3 id="Eden"><a href="#Eden" class="headerlink" title="Eden"></a>Eden</h3><p>当对象在创建时会被分配到该区域，由于通常有多个线程创建大量对象，因此Eden被进一步划分为驻留在Eden空间中的一个或多个 Thread Local Allocation Buffer（TLAB），即线程本地分配缓冲区。由于线程之间会存在争抢同一块内存区域，会进行昂贵的线程同步开销，因此JVM允许在相应的TLAB中分配一个线程内的大多数对象。</p><p>由于每个线程分配的TLAB空间有限，当对象无法分配在里面时，JVM会将该对象分配在Eden的其他空间。如果那里也没有足够的空间，就会触发Young Generation来进行垃圾回收以释放更多空间，如果垃圾回收也没有在Eden中产生更多的空间，那么对象会被分配到老年代。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a8.png"></p><p>收集Eden区时，GC会从根遍历所有可到达的对象并将它们标记为活动对象，标记阶段完成后，将Eden中所有活动对象（以及Survivor空间之一未满足年龄的存活对象）复制到Survivor1或者Survivor2。这时清空Eden区和Survivor空间之一，可以重用以分配更多的对象，这种方法称为“复制“算法，简单来说就是标记存活对象，然后复制（而不是移动）到Survivor Spaces。</p><h3 id="Survivor-Spaces"><a href="#Survivor-Spaces" class="headerlink" title="Survivor Spaces"></a>Survivor Spaces</h3><p>Eden区旁边驻留着2个Survivor区称为S1和S2，有的地方也叫from和to，注意的是，两个Survivor空间中的一个必定为空。</p><p>年轻代被收集时，空的Survivor区将开始出现存活对象，因为整个年轻代（Eden区和非空的Survivor区）的所有存活对象都被复制到空的Survivor区。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a9.png"></p><p>当两个Survivor空间之间复制对象的过程重复多次，直到某些对象达到足够的”年龄“，这些对象不在被复制到空的Survivor区，而是进入年老代，在年老代，他们将驻留直到无法访问为止。</p><p>GC会跟踪特定对象存活下来的集合数量，在每一代对象GC结束后，那些仍然存活的对象的年龄会增加，当年龄超过任期阈值时，对象就会被提升到老年代。实际的任期阈值由JVM动态调整，但也可以通过指定 -XX:+MaxTenuringThreshold 为其设置上限，当设置 -XX:+MaxTenuringThreshold=0 时，会导致对象立即进入老年代，不会在Survivor之间进行复制。默认情况下，JVM设置此阈值为15个GC周期，这也是HotSpot中的最大值。</p><p>如果Survivor空间大小不足以容纳年轻代中所有活动对象，那么对象提升年老代也可能会过早发生。</p><h3 id="Old-Generation"><a href="#Old-Generation" class="headerlink" title="Old Generation"></a>Old Generation</h3><p>相比于年轻代，老年代通常空间要大得多，并且老年代GC发生频率低于年轻代。此外，由于大多数对象都存活在老年代，因此不会使用”复制“算法，相反对象会四处移动以最大程度地减少碎片，原则上，老年代垃圾回收步骤如下：</p><ul><li>通过GC根访问所有对象旁边地标记位来标记可达的对象</li><li>清除所有无法访问的对象</li><li>通过将活动对象复制到老年代的边界来整理空间</li></ul><p>从上面描述可以看出，老年代中的GC必须使用”标记整理“算法以避免过度的内存碎片化。</p><h3 id="PermGen"><a href="#PermGen" class="headerlink" title="PermGen"></a>PermGen</h3><p>在 Java8 之前，存在一个称为”永久代“的特殊空间（方法区的一种实现），主要用来存储class相关信息，包括class对象的Method、Field等。永久代使用的是JVM内存，实际上它给java开发人员带来很多麻烦，因为很难预测这些需要多少空间，所以方法区也会出现OOM（java.lang.OutOfMemoryError: Permgen space），对于这种情况只能简单的增加Permgen大小。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:MaxPermSize&#x3D;256m com.mycompany.MyApplication</span><br></pre></td></tr></table></figure><h3 id="Metaspace"><a href="#Metaspace" class="headerlink" title="Metaspace"></a>Metaspace</h3><p>由于预测对元数据空间是一件非常困难的，因此 Java8 中删除了永久代，取而代之的是元空间（方法区的一种实现），两者最大的区别是元空间使用本地内存，而永久代使用的是JVM内存，这样的话默认的类的元数据分配只受本地内存大小的限制，也就是说本地内存剩余多少，理论上Metaspace就可以有多大，这就解决了java.lang.OutOfMemoryError: Permgen space的问题，不过也不可能任其无限大，JVM默认在运行时会根据需要动态的设置其大小。</p><p>如果仍然希望限制Metaspace大小，可以设置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX：MaxMetaspaceSize&#x3D;256m com.mycompany.MyApplication</span><br></pre></td></tr></table></figure><h2 id="Minor-GC-vs-Major-GC-vs-Full-GC"><a href="#Minor-GC-vs-Major-GC-vs-Full-GC" class="headerlink" title="Minor GC vs Major GC vs Full GC"></a>Minor GC vs Major GC vs Full GC</h2><p>清理堆内存的垃圾回收事件通常称为Minor、Major和Full GC。</p><h3 id="Minor-GC"><a href="#Minor-GC" class="headerlink" title="Minor GC"></a>Minor GC</h3><p>从Young区收集垃圾的事件称为Minor GC，但是在处理Minor GC事件时，应该注意以下几点：</p><ul><li>Minor GC总是发生在JVM无法为新对象分配空间时触发，例如Eden区没有足够空间，所以正常来说分配新对象频率越高，Minor GC频率也越高。</li><li>在Minor GC事件期间，老年代会被忽略，从老年代到年轻代的引用会被认为是GC根，在标记阶段，从年轻代到老年代的引用会被简单地忽略。</li><li>Minor GC事件期间，会触发 stop-the-world 暂停，即暂停应用程序线程。对于大多数应用程序，如果Eden中大多数对象都被视为垃圾并且永远不会复制到Surivor/Old空间，那么暂停在延迟方面可以忽略不计。如果情况相反，大多数新生对象都会被复制地话，那么Minor GC暂停会花费更多时间。</li></ul><h3 id="Major-GC-与-Full-GC"><a href="#Major-GC-与-Full-GC" class="headerlink" title="Major GC 与 Full GC"></a>Major GC 与 Full GC</h3><p>应该注意的是，Major GC 和 Full GC还是存在区别的：</p><ul><li>Major GC清理Old空间</li><li>Full GC清理整个Heap，包括Young和Old空间</li></ul><p>但是许多Major GC是由Minor GC触发的，因此许多情况下不能将Major GC和Full GC分开。另一方面，对于像G1这种现代垃圾收集器，回收垃圾只是执行部分垃圾的清理，因此”清理“两字也并不严谨。</p><h2 id="常见的垃圾回收器"><a href="#常见的垃圾回收器" class="headerlink" title="常见的垃圾回收器"></a>常见的垃圾回收器</h2><p>在上面已经介绍了GC算法的核心概念，那么来看看在JVM中的具体实现。首先先认识到一个重要方面是，对于分代模型，需要两种不同的GC算法：一种适用于清理年轻代，另一种适用于清理年老代。以下适用于Java8，对于较久的Java版本，可用的组合略有不同：</p><table><thead><tr><th>年轻代</th><th>老年代</th><th>JVM选项</th></tr></thead><tbody><tr><td>Serial</td><td>Serial Old</td><td>-XX:+UseSerialGC</td></tr><tr><td>Serial</td><td>CMS</td><td>-XX:-UseParNewGC -XX:UseConcMarkSweepGC</td></tr><tr><td>Parallel Scavenge</td><td>Parallel Old</td><td>-XX:+UseParallelGC -XX:+UseParallelOldGC</td></tr><tr><td>Parallel Scavenge</td><td>Serial Old</td><td>-XX:+UseParallelGC -XX:-UseParallelOldGC</td></tr><tr><td>Parallel New</td><td>CMS</td><td>-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</td></tr><tr><td>Parallel New</td><td>Serial Old</td><td>-XX:+UseParNewGC -XX:-UseParallelOldGC</td></tr><tr><td>G1</td><td></td><td>-XX:+UseG1GC</td></tr></tbody></table><p>实际上在真正的使用上，并没有这么多组合，最常用的组合：</p><ul><li>串行：Serial + Serial Old</li><li>并行：Parallel Scavenge + Parallel Old</li><li>年轻代并行新 Parallel New + 老年代并发标记和清除 CMS</li><li>G1 包含Young和Old集合</li></ul><h3 id="Serial-GC"><a href="#Serial-GC" class="headerlink" title="Serial GC"></a>Serial GC</h3><p>Serial收集器是最基本、最悠久的垃圾收集器，JDK1.3之前新生代唯一的选择。</p><p>这个垃圾收集器对年轻代使用”复制“算法，对老年代使用“标记整理”算法。顾名思义，这个垃圾收集器是单线程收集器，无法并行处理任务，并且在GC时，还会触发stop-the-world暂停，即停止所有应用程序线程。</p><p>因此，这个垃圾收集器无法适用于多核CPU。</p><p>为年轻代和老年代启动该垃圾收集器，可以通过下面参数指定：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:+UseSerialGC com.mypackages.MyExecutableClass</span><br></pre></td></tr></table></figure><p>Serial GC仅推荐用于200MB大小的内存，以及具有单个CPU的环境。</p><p>下面来看下Serial GC的日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2015-05-26T14:45:37.987-0200: 151.126: [GC (Allocation Failure) 151.126: [DefNew: 629119K-&gt;69888K(629120K), 0.0584157 secs] 1619346K-&gt;1273247K(2027264K), 0.0585007 secs] [Times: user&#x3D;0.06 sys&#x3D;0.00, real&#x3D;0.06 secs]</span><br><span class="line"></span><br><span class="line">2015-05-26T14:45:59.690-0200: 172.829: [GC (Allocation Failure) 172.829: [DefNew: 629120K-&gt;629120K(629120K), 0.0000372 secs]172.829: [Tenured: 1203359K-&gt;755802K(1398144K), 0.1855567 secs] 1832479K-&gt;755802K(2027264K), [Metaspace: 6741K-&gt;6741K(1056768K)], 0.1856954 secs] [Times: user&#x3D;0.18 sys&#x3D;0.00, real&#x3D;0.18 secs]</span><br></pre></td></tr></table></figure><p>上面日志中发生了两个垃圾回收事件，一个是清理年轻代，另一个是处理整个堆。</p><h4 id="Minor-GC-1"><a href="#Minor-GC-1" class="headerlink" title="Minor GC"></a>Minor GC</h4><blockquote><p>2015-05-26T14:45:37.987-0200 <sup>1</sup>: 151.126 <sup>2</sup>: [GC <sup>3</sup> (Allocation Failure <sup>4</sup>) 151.126: [DefNew <sup>5</sup>: 629119K-&gt;69888K <sup>6</sup>(629120K) <sup>7</sup>, 0.0584157 secs] 1619346K-&gt;1273247K <sup>8</sup>(2027264K) <sup>9</sup>, 0.0585007 secs <sup>10</sup>] [Times: user=0.06 sys=0.00, real=0.06 secs] <sup>11</sup></p></blockquote><ol><li><p>2015-05-26T14:45:37.987-0200 - GC事件开始的时间</p></li><li><p>151.126 - GC事件开始时间，相对于JVM启动时间，以秒为单位</p></li><li><p>GC - 用于区分Minor和Full GC的标志，这是一个Minor GC</p></li><li><p>Allocation Failure - GC发生的原因</p></li><li><p>DefNew - 使用的垃圾收集器名称，这个表示用于清理年轻代的单线程标记复制、stop-the-world 收集器</p></li><li><p>629119K-&gt;69888K - 在收集前后年轻代使用大小</p></li><li><p>(629120K) - 年轻代的总大小</p></li><li><p>1619346K-&gt;1273247K - 收集前后整个堆的使用大小</p></li><li><p>(2027264K) - 整个堆的大小</p></li><li><p>0.0585007 secs - GC事件的持续事件（单位为秒）</p></li><li><p>Times: user=0.06 sys=0.00, real=0.06 secs - GC持续时间，按不同类别衡量：</p><p>user - 垃圾收集器线程在此收集期间消耗的总CPU时间</p><p>sys - 花费在OS调用或等待系统事件上的事件</p><p>real - 应用程序停止的时间，由于串行垃圾收集器总是使用一个线程，因此real时间等于用户时间和系统时间之和</p></li></ol><h4 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h4><blockquote><p>2015-05-26T14:45:59.690-0200 <sup>1</sup>: 172.829 <sup>2</sup>: [GC (Allocation Failure) 172.829: [DefNew: 629120K-&gt;629120K(629120K), 0.0000372 secs <sup>3</sup>]172.829: [Tenured <sup>4</sup>: 1203359K-&gt;755802K <sup>5</sup>(1398144K) <sup>6</sup>, 0.1855567 secs <sup>7</sup>] 1832479K-&gt;755802K <sup>8</sup>(2027264K) <sup>9</sup>, [Metaspace: 6741K-&gt;6741K(1056768K) <sup>10</sup>], 0.1856954 secs] [Times: user=0.18 sys=0.00, real=0.18 secs] <sup>11</sup></p></blockquote><ol><li><p>2015-05-26T14:45:59.690-0200 - GC事件开始的时间</p></li><li><p>172.829 - GC事件开始时间，相对于JVM启动时间，以秒为单位</p></li><li><p>DefNew: 629120K-&gt;629120K(629120K), 0.0000372 secs - 与前面类似，由于分配失败，在此期间发生了年轻代的GC，年轻代总大小629120K，此次GC回收了0K，耗时0.0000372秒</p></li><li><p>Tenured - 用于清理老年代的垃圾收集器名称，名称Tenured表示使用单线程、stop-the-world 收集器</p></li><li><p>1203359K-&gt;755802K - GC前后老年代使用量</p></li><li><p>1398144K - 老年代的总大小</p></li><li><p>0.1855567 secs - 清理老年代所花费的时间</p></li><li><p>1832479K-&gt;755802K - 在年轻代和老年代收集前后整个堆的使用量</p></li><li><p>2027264K - JVM总堆的大小</p></li><li><p>Metaspace: 6741K-&gt;6741K(1056768K - 元空间集合的信息，这次事件没有在Metaspace中收集垃圾</p></li><li><p>Times: user=0.18 sys=0.00, real=0.18 secs - GC持续时间，按不同类别衡量：</p><p>user - 垃圾收集器线程在此收集期间消耗的总CPU时间</p><p>sys - 花费在OS调用或等待系统事件上的事件</p><p>real - 应用程序停止的时间，由于串行垃圾收集器总是使用一个线程，因此real时间等于用户时间和系统时间之和</p></li></ol><h3 id="Parallel-GC"><a href="#Parallel-GC" class="headerlink" title="Parallel GC"></a>Parallel GC</h3><p>Parallel收集器在年轻代采用”复制“算法，在老年代使用”标记整理“算法。同样，Young和Old收集都会触发stop-the-world暂停，停止所有的应用程序线程，Parallel收集器会在GC时使用多个线程进行复制/标记整理，这大大减少了收集时间和stop-the-world时间。</p><p>该收集器使用的线程数可通过命令行参数 -XX:ParallelGCThreads 进行配置，默认值是机器的内核数。</p><p>Parallel GC通过下面任意一个进行开启：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:+UseParallelGC com.mypackages.MyExecutableClass</span><br><span class="line">java -XX:+UseParallelOldGC com.mypackages.MyExecutableClass</span><br><span class="line">java -XX:+UseParallelGC -XX:+UseParallelOldGC com.mypackages.MyExecutable</span><br></pre></td></tr></table></figure><p>相对于Serial单线程收集，Parallel收集器可以提高吞吐量，适用于多核机器。在收集期间，所有内核都在并行进行清理垃圾，从而缩短应用程序线程暂停的时间；但是还是会有长时间暂停的影响，如果延迟是您的主要目标，可以考虑下面的垃圾收集器。</p><p>下面来看下Parallel GC的日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2015-05-26T14:27:40.915-0200: 116.115: [GC (Allocation Failure) [PSYoungGen: 2694440K-&gt;1305132K(2796544K)] 9556775K-&gt;8438926K(11185152K), 0.2406675 secs] [Times: user&#x3D;1.77 sys&#x3D;0.01, real&#x3D;0.24 secs]</span><br><span class="line"></span><br><span class="line">2015-05-26T14:27:41.155-0200: 116.356: [Full GC (Ergonomics) [PSYoungGen: 1305132K-&gt;0K(2796544K)] [ParOldGen: 7133794K-&gt;6597672K(8388608K)] 8438926K-&gt;6597672K(11185152K), [Metaspace: 6745K-&gt;6745K(1056768K)], 0.9158801 secs] [Times: user&#x3D;4.49 sys&#x3D;0.64, real&#x3D;0.92 secs]</span><br></pre></td></tr></table></figure><h4 id="Minor-GC-2"><a href="#Minor-GC-2" class="headerlink" title="Minor GC"></a>Minor GC</h4><blockquote><p>2015-05-26T14:27:40.915-0200 <sup>1</sup>: 116.115 <sup>2</sup>: [GC <sup>3</sup> (Allocation Failure <sup>4</sup>) [PSYoungGen <sup>5</sup>: 2694440K-&gt;1305132K <sup>6</sup>(2796544K) <sup>7</sup>] 9556775K-&gt;8438926K <sup>8</sup>(11185152K) <sup>9</sup>, 0.2406675 secs <sup>10</sup>] [Times: user=1.77 sys=0.01, real=0.24 secs] <sup>11</sup></p></blockquote><ol><li><p>2015-05-26T14:27:40.915-0200 - GC事件开始时间</p></li><li><p>116.115 - GC事件开始时间，相对于JVM启动，以秒为单位</p></li><li><p>GC - 用于区分Minor和Full GC，这是一个Minor GC</p></li><li><p>Allocation Failure - GC事件发生的原因</p></li><li><p>PSYoungGen - 使用的垃圾收集器名称，表示清理年轻代的并行标记复制、stop-the-world 收集器</p></li><li><p>2694440K-&gt;1305132K - GC前后年轻代的使用量</p></li><li><p>2796544K - 年轻代总大小</p></li><li><p>9556775K-&gt;8438926K - GC前后总堆的大小</p></li><li><p>11185152K - 总堆的大小</p></li><li><p>0.2406675 secs - GC事件持续事件（以秒为单位）</p></li><li><p>Times: user=1.77 sys=0.01, real=0.24 secs - GC事件持续事件，按不同类别衡量：</p><p>user - 垃圾收集器线程在此收集期间消耗的总CPU时间</p><p>sys - 花费在OS调用或等待系统事件上的事件</p><p>real - 应用程序停止的时间，对于Parallel GC，这个数字应该接近(user+sys)/垃圾收集器线程数</p></li></ol><h4 id="Full-GC-1"><a href="#Full-GC-1" class="headerlink" title="Full GC"></a>Full GC</h4><blockquote><p>2015-05-26T14:27:41.155-0200 <sup>1</sup>: 116.356 <sup>2</sup>: [Full GC <sup>3</sup> (Ergonomics <sup>4</sup>) [PSYoungGen: 1305132K-&gt;0K(2796544K) <sup>5</sup>] [ParOldGen <sup>6</sup>: 7133794K-&gt;6597672K <sup>7</sup>(8388608K) <sup>8</sup>] 8438926K-&gt;6597672K <sup>9</sup>(11185152K) <sup>10</sup>, [Metaspace: 6745K-&gt;6745K(1056768K) <sup>11</sup>], 0.9158801 secs <sup>12</sup>] [Times: user=4.49 sys=0.64, real=0.92 secs] <sup>13</sup></p></blockquote><ol><li><p>2015-05-26T14:27:41.155-0200 - GC事件开始时间</p></li><li><p>116.356 - GC事件开始时间，相对于JVM启动，以秒为单位</p></li><li><p>Full GC - 用于区分Minor和Full GC，这是一个Full GC</p></li><li><p>Ergonomics - GC事件发生的原因，是由于开启了UseAdaptiveSizePolicy，jvm本身进行自适应调整引起的Full GC</p></li><li><p>PSYoungGen: 1305132K-&gt;0K(2796544K) - 使用的垃圾收集器名称，表示清理年轻代的并行标记复制、stop-the-world 收集器，年轻代总大小2796544K，GC清理后从1305132K缩减到0K</p></li><li><p>ParOldGen - 用于清理老年代的收集器，表示使用清理老年代的并行标记整理、stop-the-world 收集器</p></li><li><p>7133794K-&gt;6597672K - GC前后老年代的使用量</p></li><li><p>8388608K - 老年代总大小</p></li><li><p>8438926K-&gt;6597672K - GC前后总堆的大小</p></li><li><p>11185152K - 总堆的大小</p></li><li><p>Metaspace: 6745K-&gt;6745K(1056768K) - 元空间集合的信息，这次事件没有在Metaspace中收集垃圾</p></li><li><p>0.9158801 secs - GC事件持续事件（以秒为单位）</p></li><li><p>Times: user=4.49 sys=0.64, real=0.92 secs - GC事件持续事件，按不同类别衡量：</p><p>user - 垃圾收集器线程在此收集期间消耗的总CPU时间</p><p>sys - 花费在OS调用或等待系统事件上的事件</p><p>real - 应用程序停止的时间，对于Parallel GC，这个数字应该接近(user+sys)/垃圾收集器线程数</p></li></ol><h3 id="Concurrent-Mark-and-Sweep"><a href="#Concurrent-Mark-and-Sweep" class="headerlink" title="Concurrent Mark and Sweep"></a>Concurrent Mark and Sweep</h3><p>这个垃圾收集器官方名称是”Mostly Concurrent Mark and Sweep Garbage Collector“。它在年轻代使用”复制”算法，并行进行垃圾回收，在老年代使用并发的“标记清除”算法。</p><p>CMS收集器目标是避免在老年代长时间停顿，它通过两种方式实现。首先，它不压缩老年代空间，而是通过空闲列表来管理回收空间。其次，它与应用程序线程同时完成标记和清理阶段的大部分工作。这意味着垃圾收集器不会显式停止应用程序线程来执行这些阶段，然后这也会导致垃圾回收线程和应用程序线程会竞争CPU时间。默认情况下，该收集器的线程数等于机器物理内核数的1/4。</p><p>可以通过在命令行指定以下参数启动此垃圾收集器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:+UseConcMarkSweepGC com.mypackages.MyExecutableClass</span><br></pre></td></tr></table></figure><p>如果您的目标是延迟，那么ParNew + CMS 这种垃圾收集器组合是个不错的选择。</p><p>下面来看看该组合垃圾收集器的日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2015-05-26T16:23:07.219-0200: 64.322: [GC (Allocation Failure) 64.322: [ParNew: 613404K-&gt;68068K(613440K), 0.1020465 secs] 10885349K-&gt;10880154K(12514816K), 0.1021309 secs] [Times: user&#x3D;0.78 sys&#x3D;0.01, real&#x3D;0.11 secs]</span><br><span class="line"></span><br><span class="line">2015-05-26T16:23:07.321-0200: 64.425: [GC (CMS Initial Mark) [1 CMS-initial-mark: 10812086K(11901376K)] 10887844K(12514816K), 0.0001997 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs]</span><br><span class="line">2015-05-26T16:23:07.321-0200: 64.425: [CMS-concurrent-mark-start]</span><br><span class="line">2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-mark: 0.035&#x2F;0.035 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs]</span><br><span class="line">2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-preclean-start]</span><br><span class="line">2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-preclean: 0.016&#x2F;0.016 secs] [Times: user&#x3D;0.02 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line">2015-05-26T16:23:08.446-0200: 65.550: [CMS-concurrent-abortable-preclean: 0.167&#x2F;1.074 secs] [Times: user&#x3D;0.20 sys&#x3D;0.00, real&#x3D;1.07 secs]</span><br><span class="line">2015-05-26T16:23:08.447-0200: 65.550: [GC (CMS Final Remark) [YG occupancy: 387920 K (613440 K)]65.550: [Rescan (parallel) , 0.0085125 secs]65.559: [weak refs processing, 0.0000243 secs]65.559: [class unloading, 0.0013120 secs]65.560: [scrub symbol table, 0.0008345 secs]65.561: [scrub string table, 0.0001759 secs][1 CMS-remark: 10812086K(11901376K)] 11200006K(12514816K), 0.0110730 secs] [Times: user&#x3D;0.06 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">2015-05-26T16:23:08.458-0200: 65.561: [CMS-concurrent-sweep-start]</span><br><span class="line">2015-05-26T16:23:08.485-0200: 65.588: [CMS-concurrent-sweep: 0.027&#x2F;0.027 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.03 secs]</span><br><span class="line">2015-05-26T16:23:08.485-0200: 65.589: [CMS-concurrent-reset-start]</span><br><span class="line">2015-05-26T16:23:08.497-0200: 65.601: [CMS-concurrent-reset: 0.012&#x2F;0.012 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br></pre></td></tr></table></figure><h4 id="Minor-GC-3"><a href="#Minor-GC-3" class="headerlink" title="Minor GC"></a>Minor GC</h4><blockquote><p>2015-05-26T16:23:07.219-0200 <sup>1</sup>: 64.322 <sup>2</sup>: [GC <sup>3</sup> (Allocation Failure <sup>4</sup>) 64.322: [ParNew <sup>5</sup>: 613404K-&gt;68068K <sup>6</sup>(613440K) <sup>7</sup>, 0.1020465 secs <sup>8</sup>] 10885349K-&gt;10880154K <sup>9</sup>(12514816K) <sup>10</sup>, 0.1021309 secs <sup>11</sup>] [Times: user=0.78 sys=0.01, real=0.11 secs] <sup>12</sup></p></blockquote><ol><li><p>2015-05-26T16:23:07.219-0200 - GC事件开始时间</p></li><li><p>64.322 - GC事件开始时间，相对于JVM启动，以秒为单位</p></li><li><p>GC - 用于区分Minor和Full GC，这是一个Minor GC</p></li><li><p>Allocation Failure - GC事件发生的原因</p></li><li><p>ParNew - 使用的垃圾收集器名称，表示清理年轻代的并行标记复制、stop-the-world 收集器</p></li><li><p>613404K-&gt;68068K - GC前后年轻代的使用量</p></li><li><p>613440K - 年轻代总大小</p></li><li><p>0.1020465 secs - 不带最终清理的持续时间</p></li><li><p>10885349K-&gt;10880154K - GC前后总堆的大小</p></li><li><p>12514816K - 总堆的大小</p></li><li><p>0.1021309 secs - GC事件持续事件（以秒为单位）。这包括和CMS收集器的通信开销、对老年代足够老的对象的提升以及在垃圾收集周期结束的一些最终清理</p></li><li><p>Times: user=0.78 sys=0.01, real=0.11 secs - GC事件持续事件，按不同类别衡量：</p><p>user - 垃圾收集器线程在此收集期间消耗的总CPU时间</p><p>sys - 花费在OS调用或等待系统事件上的事件</p><p>real - 应用程序停止的时间，对于Parallel GC，这个数字应该接近(user+sys)/垃圾收集器线程数</p></li></ol><h4 id="Full-GC-2"><a href="#Full-GC-2" class="headerlink" title="Full GC"></a>Full GC</h4><p>CMS在老年代的垃圾收集分为不同阶段首先看这个Full GC日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2015-05-26T16:23:07.321-0200: 64.425: [GC (CMS Initial Mark) [1 CMS-initial-mark: 10812086K(11901376K)] 10887844K(12514816K), 0.0001997 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs]</span><br><span class="line">2015-05-26T16:23:07.321-0200: 64.425: [CMS-concurrent-mark-start]</span><br><span class="line">2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-mark: 0.035&#x2F;0.035 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs]</span><br><span class="line">2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-preclean-start]</span><br><span class="line">2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-preclean: 0.016&#x2F;0.016 secs] [Times: user&#x3D;0.02 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line">2015-05-26T16:23:08.446-0200: 65.550: [CMS-concurrent-abortable-preclean: 0.167&#x2F;1.074 secs] [Times: user&#x3D;0.20 sys&#x3D;0.00, real&#x3D;1.07 secs]</span><br><span class="line">2015-05-26T16:23:08.447-0200: 65.550: [GC (CMS Final Remark) [YG occupancy: 387920 K (613440 K)]65.550: [Rescan (parallel) , 0.0085125 secs]65.559: [weak refs processing, 0.0000243 secs]65.559: [class unloading, 0.0013120 secs]65.560: [scrub symbol table, 0.0008345 secs]65.561: [scrub string table, 0.0001759 secs][1 CMS-remark: 10812086K(11901376K)] 11200006K(12514816K), 0.0110730 secs] [Times: user&#x3D;0.06 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">2015-05-26T16:23:08.458-0200: 65.561: [CMS-concurrent-sweep-start]</span><br><span class="line">2015-05-26T16:23:08.485-0200: 65.588: [CMS-concurrent-sweep: 0.027&#x2F;0.027 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.03 secs]</span><br><span class="line">2015-05-26T16:23:08.485-0200: 65.589: [CMS-concurrent-reset-start]</span><br><span class="line">2015-05-26T16:23:08.497-0200: 65.601: [CMS-concurrent-reset: 0.012&#x2F;0.012 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br></pre></td></tr></table></figure><h5 id="第一阶段：初始标记"><a href="#第一阶段：初始标记" class="headerlink" title="第一阶段：初始标记"></a>第一阶段：初始标记</h5><p>该阶段会触发stop-the-world暂停。这个阶段的目标是标记老年代中的所有对象，这些对象要么是直接的GC根，要么是从年轻代中某个活动对象引用的。后者很重要，因为老年代是单独收集的。</p><blockquote><p>2015-05-26T16:23:07.321-0200: 64.425 <sup>1</sup>: [GC (CMS Initial Mark <sup>2</sup>) [1 CMS-initial-mark: 10812086K <sup>3</sup>(11901376K) <sup>4</sup>] 10887844K <sup>5</sup>(12514816K) <sup>6</sup>, 0.0001997 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]<sup>7</sup></p></blockquote><ol><li>2015-05-26T16:23:07.321-0200: 64.425 - GC事件开始时间，包括时钟时间和相对于JVM启动时间</li><li>CMS Initial Mark - CMS初始标记阶段，即收集所有的GC根</li><li>10812086K - 当前老年代的使用大小</li><li>11901376K - 老年代总大小</li><li>10887844K - 当前堆使用大小</li><li>12514816K - 堆总大小</li><li>Times: user=0.00 sys=0.00, real=0.00 secs - 该阶段持续事件，按不同类别衡量</li></ol><h5 id="第二阶段：并发标记"><a href="#第二阶段：并发标记" class="headerlink" title="第二阶段：并发标记"></a>第二阶段：并发标记</h5><p>在这个阶段，垃圾收集器会遍历老年代并标记所有活着的对象，从“初始标记”阶段找到的GC根开始。“并发标记”阶段，顾名思义，就是与应用程序线程并发运行，不会停止应用程序线程。请注意，此阶段并不是所有的老年代存活对象都可以被标记，因为应用程序在标记期间会改变引用。</p><blockquote><p>2015-05-26T16:23:07.321-0200: 64.425: [CMS-concurrent-mark-start]<br>2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-mark <sup>1</sup>: 0.035/0.035 secs <sup>2</sup>] [Times: user=0.07 sys=0.00, real=0.03 secs] <sup>3</sup></p></blockquote><ol><li>CMS-concurrent-mark - CMS并发标记，遍历老年代并标记所有活着的对象</li><li>0.035/0.035 secs - 阶段持续时间</li><li>Times: user=0.07 sys=0.00, real=0.03 secs - 该阶段时间没有意义，因为是从并发标记开始测量的，不仅仅包括为并发标记所做的工作</li></ol><h5 id="第三阶段：并发预清理"><a href="#第三阶段：并发预清理" class="headerlink" title="第三阶段：并发预清理"></a>第三阶段：并发预清理</h5><p>这又是一个并发阶段，与应用程序线程并行运行，而不是停止它们。由于前一阶段与应用程序线程同时运行，一些引用已被更改。每当发生这种情况时，JVM会将这些突变对象的区域标记为Dirty Card。</p><p>在预清理阶段，那些能够从Dirty Card区域可达的对象也被标记为存活，当标记完这些对象后，该Dirty Card区域就会消失。</p><blockquote><p>2015-05-26T16:23:07.357-0200: 64.460: [CMS-concurrent-preclean-start]<br>2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-preclean <sup>1</sup>: 0.016/0.016 secs <sup>2</sup>] [Times: user=0.02 sys=0.00, real=0.02 secs] <sup>3</sup></p></blockquote><ol><li>CMS-concurrent-preclean - 并发预清理阶段，考虑到在前一阶段更改的引用</li><li>0.016/0.016 secs - 阶段持续时间</li><li>Times: user=0.07 sys=0.00, real=0.03 secs - 该阶段时间没有意义，因为是从并发标记开始测量的</li></ol><h5 id="第四阶段：并发可中断预清理"><a href="#第四阶段：并发可中断预清理" class="headerlink" title="第四阶段：并发可中断预清理"></a>第四阶段：并发可中断预清理</h5><p>与并发预处理清理类似，CMS有两个参数：CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。这两个参数组合起来的意思是预清理后，Eden空间使用超过2M时启动可中断的并发预处理，直到Eden空间使用率达到50%时中断，进入重新标记阶段。</p><blockquote><p>2015-05-26T16:23:07.373-0200: 64.476: [CMS-concurrent-abortable-preclean-start]<br>2015-05-26T16:23:08.446-0200: 65.550: [CMS-concurrent-abortable-preclean <sup>1</sup>: 0.167/1.074 secs <sup>2</sup>] [Times: user=0.20 sys=0.00, real=1.07 secs] <sup>3</sup></p></blockquote><ol><li>CMS-concurrent-abortable-preclean - 并发可中断预清理阶段</li><li>0.167/1.074 secs - 阶段持续时间</li><li>Times: user=0.20 sys=0.00, real=1.07 secs - 该阶段时间没有意义，因为是从并发标记开始测量的</li></ol><h5 id="第五阶段：最终标记"><a href="#第五阶段：最终标记" class="headerlink" title="第五阶段：最终标记"></a>第五阶段：最终标记</h5><p>这是CMS垃圾收集的第二个也是最后一个stop-the-world暂停。这个阶段目标是完成老年代所有活动对象的标记。由于之前的预清理阶段是并发的，它无法跟上应用程序线程的变化速度，需要stop-the-world暂停才能完成。</p><p>通常CMS会在Young Generation尽可能发生后尝试运行“最终标记”阶段，以消除多个stop-the-world暂停。</p><blockquote><p>2015-05-26T16:23:08.447-0200: 65.550<sup>1</sup>: [GC (CMS Final Remark<sup>2</sup>) [YG occupancy: 387920 K (613440 K)<sup>3</sup>]65.550: [Rescan (parallel) , 0.0085125 secs<sup>4</sup>]65.559: [weak refs processing, 0.0000243 secs<sup>5</sup>]65.559: [class unloading, 0.0013120 secs<sup>6</sup>]65.560: [scrub symbol table, 0.0008345 secs]65.561:  [scrub string table, 0.0001759 secs <sup>7</sup>] [1 CMS-remark: 10812086K(11901376K)<sup>8</sup>] 11200006K(12514816K) <sup>9</sup>, 0.0110730 secs<sup>10</sup>] [Times: user=0.06 sys=0.00, real=0.01 secs]<sup>11</sup></p></blockquote><ol><li>2015-05-26T16:23:08.447-0200: 65.550 - GC事件开始时间，包括时钟时间和相对于JVM启动时间</li><li>CMS Final Remark - CMS最终标记阶段，标记老年代所有活动对象，stop-the-world暂停</li><li>YG occupancy: 387920 K (613440 K) - 年轻代使用量和总大小</li><li>Rescan (parallel) , 0.0085125 secs - 重新扫描在应用程序线程停止时完成对活动对象的标记，在这种情况下，重新扫描是并行完成的，耗时0.0085125秒</li><li>weak refs processing, 0.0000243 secs - 处理弱引用持续时间</li><li>class unloading, 0.0013120 secs - 类卸载持续时间</li><li>scrub string table, 0.0001759 secs - 清理类元数据和内部字符串表时间</li><li>CMS-remark: 10812086K(11901376K) - 最终标记阶段后的老年代使用量和总量</li><li>11200006K(12514816K)  - 最终标记阶段后堆的使用量和总量</li><li>0.0110730 secs - 最终标记阶段的持续时间</li><li>Times: user=0.06 sys=0.00, real=0.01 secs - 暂停的持续时间，按不同类别衡量</li></ol><h5 id="第六阶段：并发清理"><a href="#第六阶段：并发清理" class="headerlink" title="第六阶段：并发清理"></a>第六阶段：并发清理</h5><p>无需stop-the-world暂停，与应用程序线程同时运行。该阶段目标是清理未使用的对象并回收它们的空间。</p><blockquote><p>2015-05-26T16:23:08.458-0200: 65.561: [CMS-concurrent-sweep-start]<br>2015-05-26T16:23:08.485-0200: 65.588: [CMS-concurrent-sweep<sup>1</sup>: 0.027/0.027 secs<sup>2</sup>] [Times: user=0.03 sys=0.00, real=0.03 secs]<sup>3</sup></p></blockquote><ol><li>CMS-concurrent-sweep - 并发清理</li><li>0.027/0.027 secs - 阶段的持续时间</li><li>Times: user=0.03 sys=0.00, real=0.03 - 该阶段时间没有意义，因为是从并发标记开始测量的</li></ol><h5 id="第七阶段：并发重置"><a href="#第七阶段：并发重置" class="headerlink" title="第七阶段：并发重置"></a>第七阶段：并发重置</h5><p>清理并恢复在CMS GC过程中的各种状态，重新初始化CMS相关数据结构，为下一个垃圾收集做准备。</p><blockquote><p>2015-05-26T16:23:08.485-0200: 65.589: [CMS-concurrent-reset-start]<br>2015-05-26T16:23:08.497-0200: 65.601: [CMS-concurrent-reset<sup>1</sup>: 0.012/0.012 secs<sup>2</sup>] [Times: user=0.01 sys=0.00, real=0.01 secs]<sup>3</sup></p></blockquote><ol><li>CMS-concurrent-reset - 并发重置</li><li>0.012/0.012 secs - 阶段的持续时间</li><li>Times: user=0.01 sys=0.00, real=0.01 secs - 该阶段时间没有意义，因为是从并发标记开始测量的</li></ol><p>总而言之，CMS垃圾收集器通过将大量工作分成不同阶段，在大部分阶段不需要stop-the-world暂停，从而减少延迟。然而，CMS也存在很多缺点，其中最明显的就是由于CMS使用“标记清除”算法清理老年代，所以会产生内存碎片；其次CMS并发清理阶段是和应用程序线程同时进行的，会产生浮动垃圾，CMS无法在当次的收集中处理掉它，只好等到下一次GC去处理；还有CMS并发清理失败后，会使用Serial Old收集器进行Full GC，由于Serial收集器是单线程、存在stop-the-world暂停，会出现长时间的暂停。</p><h3 id="G1-Garbage-First"><a href="#G1-Garbage-First" class="headerlink" title="G1 - Garbage First"></a>G1 - Garbage First</h3><p>G1关键设计的目标之一是使垃圾收集导致的stop-the-world暂停持续时间变得可预测和可配置。实际上，G1是一个软实时的垃圾收集器，简单说就是您可以为stop-the-world配置一个毫秒长的时间，G1 GC将尽最大可能实现这个目标。</p><h4 id="堆内存划分"><a href="#堆内存划分" class="headerlink" title="堆内存划分"></a>堆内存划分</h4><p>为实现stop-the-world的时间可预测，G1将堆分成多个（通常大约2048个）可以容纳对象、大小相等的独立区域（Region），可以通过 -XX:G1HeapRegionSize 配置每个Region大小，每个Region大小可以从1MB到32MB不等，并且必须是 2 的幂。</p><p>每个Region可能是Eden，也可能是Survivor，也可能是Old，所有的Eden和Survivor区逻辑上组成年轻代，所有Old区逻辑上组成老年代。另外Region还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象都被认定为大对象，对于那些超过了整个Region容量的超级大对象，将被存放在多个连续的Humongous Region中。G1进行垃圾回收时，会将Humongous当成老年代回收。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/06/03/Garbage-Collection/a10.png"></p><p>可以通过在命令行指定以下参数启动此垃圾收集器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:+UseG1GC com.mypackages.MyExecutableClass</span><br></pre></td></tr></table></figure><h4 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h4><p>当JVM分配对象到Eden区域失败时，便会触发stop-the-world暂停多线程并行来进行年轻代的垃圾收集，YGC 将 Eden Region 中存活的对象拷贝到Survivor,或者直接晋升到Old Region中；将Survivor Regin中存活的对象拷贝到新的Survivor或者晋升Old Region。</p><h4 id="Mixed-GC"><a href="#Mixed-GC" class="headerlink" title="Mixed GC"></a>Mixed GC</h4><p>G1收集器很多理念是建立在CMS概念之上。G1并发标记使用Snapshot-At-The-Beginning（SATB或原始快照）方法标记周期开始时处于活动状态的对象，而CMS则采用增量更新。</p><p>当堆的整体占用足够大时，并发标记开始，默认情况下是45%，也可以通过设置 -XX:InitiatingHeapOccupancyPercent 参数进行修改，跟CMS类似，G1的并发标记由许多阶段组成，其中一些是与应用程序线程完全并发的，而另一些则需要停止应用程序线程。</p><h5 id="第一阶段：初始标记-1"><a href="#第一阶段：初始标记-1" class="headerlink" title="第一阶段：初始标记"></a>第一阶段：初始标记</h5><p>此阶段标记所有可从GC根直接访问的对象。它需要stop-the-world暂停。可以从日志 Evacuation Pause的“initial-mark”来查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.631: [GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0062656 secs]</span><br></pre></td></tr></table></figure><h5 id="第二阶段：根区域扫描"><a href="#第二阶段：根区域扫描" class="headerlink" title="第二阶段：根区域扫描"></a>第二阶段：根区域扫描</h5><p>这个阶段标记所有可从根区域访问的活动对象，即那些不为空的对象。此阶段与应用程序线程同时运行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.362: [GC concurrent-root-region-scan-start]</span><br><span class="line">1.364: [GC concurrent-root-region-scan-end, 0.0028513 secs]</span><br></pre></td></tr></table></figure><h5 id="第三阶段：并发标记"><a href="#第三阶段：并发标记" class="headerlink" title="第三阶段：并发标记"></a>第三阶段：并发标记</h5><p>这个阶段和CMS并发标记非常相似：遍历整个堆里的对象图，找到要回收的对象，此阶段与应用程序线程同时运行，并发标记时会产生漏标、错标问题，G1使用SATB算法来解决。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.364: [GC concurrent-mark-start]</span><br><span class="line">1.645: [GC concurrent-mark-end, 0.2803470 secs]</span><br></pre></td></tr></table></figure><h5 id="第四阶段：最终标记"><a href="#第四阶段：最终标记" class="headerlink" title="第四阶段：最终标记"></a>第四阶段：最终标记</h5><p>此阶段会stop-the-world暂停，与CMS一样，完成最终的标记。对用户程序线程做短暂的暂停，用于处理并发标记阶段遗留下的SATB记录。</p><h5 id="第五阶段：筛选回收"><a href="#第五阶段：筛选回收" class="headerlink" title="第五阶段：筛选回收"></a>第五阶段：筛选回收</h5><p>此阶段会计算堆中所有的活动对象，根据GC效率对这些区域排序，并按照-XX:MaxGCPauseMillis参数设定的毫秒数对价值最高的区域进行回收。这个阶段某部分是需要stop-the-world暂停的，例如标记初始标记以来所有对象的卡位图（TASM之上的所有对象）、为任何具有一个活动对象的区域标记区域位图、清理没有活动对象的区域RSet集等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.872: [GC cleanup 1357M-&gt;173M(1996M), 0.0015664 secs]</span><br><span class="line">[Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br></pre></td></tr></table></figure><p>某部分是并发的，例如空区域回收和大部分活跃对象计算等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.874: [GC concurrent-cleanup-start]</span><br><span class="line">1.876: [GC concurrent-cleanup-end, 0.0014846 secs]</span><br></pre></td></tr></table></figure><h4 id="Full-GC-3"><a href="#Full-GC-3" class="headerlink" title="Full GC"></a>Full GC</h4><p>如果Mixed GC在进行GC回收拷贝对象时，没有足够的空Region能够承载拷贝对象就会触发Full GC。Full GC是单线程的stop-the-world暂停，使用“标记整理”算法进行垃圾收集，这个过程是非常耗时的。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes二进制升级</title>
      <link href="2021/05/27/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8D%87%E7%BA%A7/"/>
      <url>2021/05/27/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kubernetes升级比较简单，小版本的升级只需要更新二进制文件即可，大版本升级需要额外关注组件升级的参数变化。</p><blockquote><p>提前准备好二进制包</p></blockquote><h2 id="升级kubectl（master节点）"><a href="#升级kubectl（master节点）" class="headerlink" title="升级kubectl（master节点）"></a>升级kubectl（master节点）</h2><p>备份kubectl：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;bin</span><br><span class="line">mv kubectl kubectl.bak_2021-05-27</span><br></pre></td></tr></table></figure><p>替换下载的二进制包并查看版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master1 bin]# kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;20&quot;, GitVersion:&quot;v1.20.3&quot;, GitCommit:&quot;01849e73f3c86211f05533c2e807736e776fcf29&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-02-17T12:44:29Z&quot;, GoVersion:&quot;go1.15.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;20&quot;, GitVersion:&quot;v1.20.0&quot;, GitCommit:&quot;af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-12-08T17:51:19Z&quot;, GoVersion:&quot;go1.15.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125;</span><br></pre></td></tr></table></figure><p>可以看到Client Version已经是新版本了，Server Version还是老版本，这是因为apiserver还没有升级</p><h2 id="升级master组件（master节点）"><a href="#升级master组件（master节点）" class="headerlink" title="升级master组件（master节点）"></a>升级master组件（master节点）</h2><p>停止master上面的组件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop kube-apiserver</span><br><span class="line">systemctl stop kube-scheduler</span><br><span class="line">systemctl stop kube-controller-manager</span><br><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop kube-proxy</span><br></pre></td></tr></table></figure><p>备份老版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;</span><br><span class="line">mv kube-apiserver kube-apiserver.bak_2021-05-27</span><br><span class="line">mv kube-scheduler kube-scheduler.bak_2021-05-27</span><br><span class="line">mv kube-controller-manager kube-controller-manager.bak_2021-05-27</span><br><span class="line">mv kubelet kubelet.bak_2021-05-27</span><br><span class="line">mv kube-proxy kube-proxy_2021-05-27</span><br></pre></td></tr></table></figure><p>拷贝新版本过来，启动组件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start kube-apiserver</span><br><span class="line">systemctl start kube-scheduler</span><br><span class="line">systemctl start kube-controller-manager</span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl start kube-proxy</span><br></pre></td></tr></table></figure><p>查看组件启动情况和健康状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status kube-apiserver</span><br><span class="line">systemctl status kube-scheduler</span><br><span class="line">systemctl status kube-controller-manager</span><br><span class="line">systemctl status kubelet</span><br><span class="line">systemctl status kube-proxy</span><br><span class="line">kubectl get cs</span><br></pre></td></tr></table></figure><p>查看客户端和服务端版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master1 bin]# kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;20&quot;, GitVersion:&quot;v1.20.3&quot;, GitCommit:&quot;01849e73f3c86211f05533c2e807736e776fcf29&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-02-17T12:44:29Z&quot;, GoVersion:&quot;go1.15.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;20&quot;, GitVersion:&quot;v1.20.3&quot;, GitCommit:&quot;01849e73f3c86211f05533c2e807736e776fcf29&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-02-17T12:35:49Z&quot;, GoVersion:&quot;go1.15.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="升级node组件（node节点）"><a href="#升级node组件（node节点）" class="headerlink" title="升级node组件（node节点）"></a>升级node组件（node节点）</h2><p>停止node上面的组件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop kube-proxy</span><br></pre></td></tr></table></figure><p>备份老版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;</span><br><span class="line">mv kubelet kubelet.bak_2021-05-27</span><br><span class="line">mv kube-proxy kube-proxy_2021-05-27</span><br></pre></td></tr></table></figure><p>拷贝新版本过来，启动组件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start kubelet</span><br><span class="line">systemctl start kube-proxy</span><br></pre></td></tr></table></figure><p>查看组件启动情况和健康状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status kubelet</span><br><span class="line">systemctl status kube-proxy</span><br></pre></td></tr></table></figure><h2 id="验证升级是否成功"><a href="#验证升级是否成功" class="headerlink" title="验证升级是否成功"></a>验证升级是否成功</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看集群状态</span><br><span class="line">[root@master1 bin]# kubectl cluster-info</span><br><span class="line">Kubernetes control plane is running at https:&#x2F;&#x2F;192.168.1.120:6443</span><br><span class="line">CoreDNS is running at https:&#x2F;&#x2F;192.168.1.120:6443&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;kube-dns:dns&#x2F;proxy</span><br><span class="line"></span><br><span class="line">To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.</span><br><span class="line"></span><br><span class="line">[root@master1 bin]# kubectl get node</span><br><span class="line">NAME      STATUS   ROLES    AGE   VERSION</span><br><span class="line">master1   Ready    &lt;none&gt;   42h   v1.20.3</span><br><span class="line">master2   Ready    &lt;none&gt;   23h   v1.20.0</span><br><span class="line">node1     Ready    &lt;none&gt;   41h   v1.20.3</span><br><span class="line">node2     Ready    &lt;none&gt;   41h   v1.20.3</span><br><span class="line"></span><br><span class="line">[root@master1 bin]# kubectl get cs</span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line"></span><br><span class="line">[root@master1 bin]# kubectl get pod -n kube-system</span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-97769f7c7-rc9jg   1&#x2F;1     Running   0          42h</span><br><span class="line">calico-node-fw9fv                         1&#x2F;1     Running   0          42h</span><br><span class="line">calico-node-q2f2w                         1&#x2F;1     Running   0          23h</span><br><span class="line">calico-node-rlzg9                         1&#x2F;1     Running   0          41h</span><br><span class="line">calico-node-v9nhl                         1&#x2F;1     Running   0          42h</span><br><span class="line">coredns-6cc56c94bd-nr96k                  1&#x2F;1     Running   0          41h</span><br><span class="line"></span><br><span class="line"># 验证coredns解析</span><br><span class="line">[root@master1 bin]# kubectl run -it --rm dns-test --image&#x3D;busybox:1.28.4 sh</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line">&#x2F; # nslookup kubernetes</span><br><span class="line">Server:    10.0.0.2</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二进制部署高可用Kubernetes集群</title>
      <link href="2021/05/27/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8Kubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2021/05/27/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8Kubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><blockquote><p>本文所有使用的文件：</p><p>链接：<a href="https://pan.baidu.com/s/1vtDxA6K2BYT8fZYi8CiuQw">https://pan.baidu.com/s/1vtDxA6K2BYT8fZYi8CiuQw</a><br>提取码：sgfw </p></blockquote><table><thead><tr><th>角色</th><th>IP</th><th>组件</th></tr></thead><tbody><tr><td>master1</td><td>192.168.1.120</td><td>kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy、docker、etcd、nginx、keepalived</td></tr><tr><td>master2</td><td>192.168.1.123</td><td>kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy、docker、nginx、keepalived</td></tr><tr><td>node1</td><td>192.168.1.121</td><td>kubelet、kube-proxy、docker、etcd</td></tr><tr><td>node2</td><td>192.168.1.122</td><td>kubelet、kube-proxy、docker、etcd</td></tr><tr><td>负载均衡器</td><td>192.168.1.124<br>192.168.1.100（虚拟vip）</td><td></td></tr></tbody></table><h2 id="初始化配置（master1、master2、node1、node2）"><a href="#初始化配置（master1、master2、node1、node2）" class="headerlink" title="初始化配置（master1、master2、node1、node2）"></a>初始化配置（master1、master2、node1、node2）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 关闭防火墙</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line"># 关闭selinux</span><br><span class="line">sed -i &#39;s&#x2F;enforcing&#x2F;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config #永久</span><br><span class="line">setenforce 0 #临时</span><br><span class="line"># 关闭swap</span><br><span class="line">swapoff -a #临时</span><br><span class="line"># 设置主机名</span><br><span class="line">hostnamectl set-hostname &lt;hostname&gt;</span><br><span class="line"># 添加hosts</span><br><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;hosts &lt;&lt; EOF </span><br><span class="line">192.168.1.120 master1</span><br><span class="line">192.168.1.121 node1</span><br><span class="line">192.168.1.122 node2</span><br><span class="line">192.168.1.123 master2</span><br><span class="line">EOF</span><br><span class="line"># 将桥接的IPv4流量传递到iptables的链</span><br><span class="line">cat &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOF </span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1 </span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1 </span><br><span class="line">EOF</span><br><span class="line">sysctl --system #生效配置</span><br><span class="line"># 修改时区并同步时间</span><br><span class="line">cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure><h2 id="部署Etcd集群（master1、node1、node2）"><a href="#部署Etcd集群（master1、node1、node2）" class="headerlink" title="部署Etcd集群（master1、node1、node2）"></a>部署Etcd集群（master1、node1、node2）</h2><h3 id="准备cfssl证书工具（master1）"><a href="#准备cfssl证书工具（master1）" class="headerlink" title="准备cfssl证书工具（master1）"></a>准备cfssl证书工具（master1）</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mv cfssl-certinfo_linux-amd64 &#x2F;usr&#x2F;bin&#x2F;cfssl-certinfo</span><br><span class="line">mv cfssljson_linux-amd64 &#x2F;usr&#x2F;bin&#x2F;cfssljson</span><br><span class="line">mv cfssl_linux-amd64 &#x2F;usr&#x2F;bin&#x2F;cfssl</span><br></pre></td></tr></table></figure><h3 id="生成Etcd证书（master1）"><a href="#生成Etcd证书（master1）" class="headerlink" title="生成Etcd证书（master1）"></a>生成Etcd证书（master1）</h3><h4 id="自签CA证书"><a href="#自签CA证书" class="headerlink" title="自签CA证书"></a>自签CA证书</h4><p>创建证书目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p ~&#x2F;TLS&#x2F;&#123;etcd,k8s&#125;</span><br><span class="line">cd ~&#x2F;TLS&#x2F;etcd</span><br></pre></td></tr></table></figure><p>自签CA：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;www&quot;: &#123;</span><br><span class="line">         &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">         &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;etcd CA&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;Beijing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br></pre></td></tr></table></figure><h4 id="使用CA签发Etcd-HTTPS证书"><a href="#使用CA签发Etcd-HTTPS证书" class="headerlink" title="使用CA签发Etcd HTTPS证书"></a>使用CA签发Etcd HTTPS证书</h4><p>创建证书申请文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; server-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    &quot;192.168.1.120&quot;,</span><br><span class="line">    &quot;192.168.1.121&quot;,</span><br><span class="line">    &quot;192.168.1.122&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;www server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure><h3 id="部署Etcd集群（master1、node1、node2）-1"><a href="#部署Etcd集群（master1、node1、node2）-1" class="headerlink" title="部署Etcd集群（master1、node1、node2）"></a>部署Etcd集群（master1、node1、node2）</h3><blockquote><p>以下操作均在master1上执行，后面将配置拷到node1、node2</p></blockquote><h4 id="创建目录并解压二进制包"><a href="#创建目录并解压二进制包" class="headerlink" title="创建目录并解压二进制包"></a>创建目录并解压二进制包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line">mkdir &#x2F;opt&#x2F;etcd&#x2F;&#123;bin,cfg,ssl&#125; -p</span><br><span class="line">mv etcd-v3.4.9-linux-amd64&#x2F;&#123;etcd,etcdctl&#125; &#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><h4 id="创建etcd配置文件"><a href="#创建etcd配置文件" class="headerlink" title="创建etcd配置文件"></a>创建etcd配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;etcd&#x2F;cfg&#x2F;etcd.conf &lt;&lt; EOF</span><br><span class="line">#[Member]</span><br><span class="line"># 节点名称</span><br><span class="line">ETCD_NAME&#x3D;&quot;etcd-1&quot;</span><br><span class="line"># 数据目录</span><br><span class="line">ETCD_DATA_DIR&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;default.etcd&quot;</span><br><span class="line"># 集群通信监听地址</span><br><span class="line">ETCD_LISTEN_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2380&quot;</span><br><span class="line"># 客户端访问监听地址</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2379&quot;</span><br><span class="line"></span><br><span class="line">#[Clustering]</span><br><span class="line"># 集群通告地址</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2380&quot;</span><br><span class="line"># 客户端通告地址</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2379&quot;</span><br><span class="line"># 集群节点地址</span><br><span class="line">ETCD_INITIAL_CLUSTER&#x3D;&quot;etcd-1&#x3D;https:&#x2F;&#x2F;192.168.1.120:2380,etcd-2&#x3D;https:&#x2F;&#x2F;192.168.1.121:2380,etcd-3&#x3D;https:&#x2F;&#x2F;192.168.1.122:2380&quot;</span><br><span class="line"># 集群token</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN&#x3D;&quot;etcd-cluster&quot;</span><br><span class="line"># 加入集群的当前状态，new表示新集群，existing表示加入已有集群</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE&#x3D;&quot;new&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="systemd管理etcd"><a href="#systemd管理etcd" class="headerlink" title="systemd管理etcd"></a>systemd管理etcd</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;etcd.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Etcd Server</span><br><span class="line">After&#x3D;network.target</span><br><span class="line">After&#x3D;network-online.target</span><br><span class="line">Wants&#x3D;network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;cfg&#x2F;etcd.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcd \</span><br><span class="line">--cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \</span><br><span class="line">--key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--peer-cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \</span><br><span class="line">--peer-key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--peer-trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--logger&#x3D;zap</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">LimitNOFILE&#x3D;65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="拷贝证书到相应目录"><a href="#拷贝证书到相应目录" class="headerlink" title="拷贝证书到相应目录"></a>拷贝证书到相应目录</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp ~&#x2F;TLS&#x2F;etcd&#x2F;ca*pem ~&#x2F;TLS&#x2F;etcd&#x2F;server*pem &#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;</span><br></pre></td></tr></table></figure><h4 id="将master1所有文件拷贝到node1、node2"><a href="#将master1所有文件拷贝到node1、node2" class="headerlink" title="将master1所有文件拷贝到node1、node2"></a>将master1所有文件拷贝到node1、node2</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;opt&#x2F;etcd&#x2F; root@node1:&#x2F;opt</span><br><span class="line">scp &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;etcd.service root@node1:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;</span><br><span class="line">scp -r &#x2F;opt&#x2F;etcd&#x2F; root@node2:&#x2F;opt</span><br><span class="line">scp &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;etcd.service root@node2:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;</span><br></pre></td></tr></table></figure><h4 id="修改node1、node2上的etcd-conf配置文件中的相关配置"><a href="#修改node1、node2上的etcd-conf配置文件中的相关配置" class="headerlink" title="修改node1、node2上的etcd.conf配置文件中的相关配置"></a>修改node1、node2上的etcd.conf配置文件中的相关配置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#[Member]</span><br><span class="line"># 节点名称</span><br><span class="line">ETCD_NAME&#x3D;&quot;etcd-1&quot; #修改此处节点名称 node1改为etcd-2 node2改为etcd-3</span><br><span class="line"># 数据目录</span><br><span class="line">ETCD_DATA_DIR&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;default.etcd&quot;</span><br><span class="line"># 集群通信监听地址</span><br><span class="line">ETCD_LISTEN_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2380&quot; #修改此处为当前服务器地址</span><br><span class="line"># 客户端访问监听地址</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2379&quot; #修改此处为当前服务器地址</span><br><span class="line"></span><br><span class="line">#[Clustering]</span><br><span class="line"># 集群通告地址</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2380&quot; #修改此处为当前服务器地址</span><br><span class="line"># 客户端通告地址</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2379&quot; #修改此处为当前服务器地址</span><br><span class="line"># 集群节点地址</span><br><span class="line">ETCD_INITIAL_CLUSTER&#x3D;&quot;etcd-1&#x3D;https:&#x2F;&#x2F;192.168.1.120:2380,etcd-2&#x3D;https:&#x2F;&#x2F;192.168.1.121:2380,etcd-3&#x3D;https:&#x2F;&#x2F;192.168.1.122:2380&quot;</span><br><span class="line"># 集群token</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN&#x3D;&quot;etcd-cluster&quot;</span><br><span class="line"># 加入集群的当前状态，new表示新集群，existing表示加入已有集群</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE&#x3D;&quot;new&quot;</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机自启"><a href="#启动并设置开机自启" class="headerlink" title="启动并设置开机自启"></a>启动并设置开机自启</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start etcd</span><br><span class="line">systemctl enable etcd</span><br></pre></td></tr></table></figure><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ETCDCTL_API&#x3D;3 &#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcdctl --cacert&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem --cert&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem --key&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem --endpoints&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:2379,https:&#x2F;&#x2F;192.168.1.121:2379,https:&#x2F;&#x2F;192.168.1.122:2379&quot; endpoint health --write-out&#x3D;table</span><br></pre></td></tr></table></figure><h2 id="安装docker（master1、master2、node1、node2）"><a href="#安装docker（master1、master2、node1、node2）" class="headerlink" title="安装docker（master1、master2、node1、node2）"></a>安装docker（master1、master2、node1、node2）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">yum install docker-ce -y</span><br><span class="line">curl -sSL https:&#x2F;&#x2F;get.daocloud.io&#x2F;daotools&#x2F;set_mirror.sh | sh -s http:&#x2F;&#x2F;bc437cce.m.daocloud.io</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure><h2 id="部署master1（master1）"><a href="#部署master1（master1）" class="headerlink" title="部署master1（master1）"></a>部署master1（master1）</h2><h3 id="生成kube-apiserver证书"><a href="#生成kube-apiserver证书" class="headerlink" title="生成kube-apiserver证书"></a>生成kube-apiserver证书</h3><h4 id="自签CA证书-1"><a href="#自签CA证书-1" class="headerlink" title="自签CA证书"></a>自签CA证书</h4><p>进入工作目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;TLS&#x2F;k8s</span><br></pre></td></tr></table></figure><p>创建申请文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">         &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">         &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure><h4 id="使用CA签发kube-apiserver-HTTPS证书"><a href="#使用CA签发kube-apiserver-HTTPS证书" class="headerlink" title="使用CA签发kube-apiserver HTTPS证书"></a>使用CA签发kube-apiserver HTTPS证书</h4><p>创建证书申请文件：</p><blockquote><p>hosts字段配置所有机器IP，包括虚拟vip，可以再预留多个IP，方便后期扩容</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; server-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;10.0.0.1&quot;,</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.1.120&quot;,</span><br><span class="line">      &quot;192.168.1.121&quot;,</span><br><span class="line">      &quot;192.168.1.122&quot;,</span><br><span class="line">      &quot;192.168.1.123&quot;,</span><br><span class="line">      &quot;192.168.1.124&quot;,</span><br><span class="line">      &quot;192.168.1.100&quot;,</span><br><span class="line">      &quot;kubernetes&quot;,</span><br><span class="line">      &quot;kubernetes.default&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster.local&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure><h3 id="解压二进制包"><a href="#解压二进制包" class="headerlink" title="解压二进制包"></a>解压二进制包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl,logs&#125;</span><br><span class="line">tar zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">cd kubernetes&#x2F;server&#x2F;bin</span><br><span class="line">cp kube-apiserver kube-scheduler kube-controller-manager &#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br><span class="line">cp kubectl &#x2F;usr&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><h3 id="部署kube-apiserver"><a href="#部署kube-apiserver" class="headerlink" title="部署kube-apiserver"></a>部署kube-apiserver</h3><h4 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-apiserver.conf &lt;&lt; EOF</span><br><span class="line">KUBE_APISERVER_OPTS&#x3D;&quot;--logtostderr&#x3D;false \\</span><br><span class="line">--v&#x3D;2 \\</span><br><span class="line">--log-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs \\</span><br><span class="line">--etcd-servers&#x3D;https:&#x2F;&#x2F;192.168.1.120:2379,https:&#x2F;&#x2F;192.168.1.121:2379,https:&#x2F;&#x2F;192.168.1.122:2379 \\</span><br><span class="line">--bind-address&#x3D;192.168.1.120 \\</span><br><span class="line">--secure-port&#x3D;6443 \\</span><br><span class="line">--advertise-address&#x3D;192.168.1.120 \\</span><br><span class="line">--allow-privileged&#x3D;true \\</span><br><span class="line">--service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \\</span><br><span class="line">--enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\</span><br><span class="line">--authorization-mode&#x3D;RBAC,Node \\</span><br><span class="line">--enable-bootstrap-token-auth&#x3D;true \\</span><br><span class="line">--token-auth-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv \\</span><br><span class="line">--service-node-port-range&#x3D;30000-32767 \\</span><br><span class="line">--kubelet-client-certificate&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server.pem \\</span><br><span class="line">--kubelet-client-key&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server-key.pem \\</span><br><span class="line">--tls-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server.pem  \\</span><br><span class="line">--tls-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server-key.pem \\</span><br><span class="line">--client-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\</span><br><span class="line">--service-account-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem \\</span><br><span class="line">--service-account-issuer&#x3D;api \\</span><br><span class="line">--service-account-signing-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server-key.pem \\</span><br><span class="line">--etcd-cafile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \\</span><br><span class="line">--etcd-certfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \\</span><br><span class="line">--etcd-keyfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \\</span><br><span class="line">--requestheader-client-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\</span><br><span class="line">--proxy-client-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server.pem \\</span><br><span class="line">--proxy-client-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server-key.pem \\</span><br><span class="line">--requestheader-allowed-names&#x3D;kubernetes \\</span><br><span class="line">--requestheader-extra-headers-prefix&#x3D;X-Remote-Extra- \\</span><br><span class="line">--requestheader-group-headers&#x3D;X-Remote-Group \\</span><br><span class="line">--requestheader-username-headers&#x3D;X-Remote-User \\</span><br><span class="line">--enable-aggregator-routing&#x3D;true \\</span><br><span class="line">--audit-log-maxage&#x3D;30 \\</span><br><span class="line">--audit-log-maxbackup&#x3D;3 \\</span><br><span class="line">--audit-log-maxsize&#x3D;100 \\</span><br><span class="line">--audit-log-path&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs&#x2F;k8s-audit.log&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>•   –logtostderr：启用日志</p><p>•   —v：日志等级</p><p>•   –log-dir：日志目录</p><p>•   –etcd-servers：etcd集群地址</p><p>•   –bind-address：监听地址</p><p>•   –secure-port：https安全端口</p><p>•   –advertise-address：集群通告地址</p><p>•   –allow-privileged：启用授权</p><p>•   –service-cluster-ip-range：Service虚拟IP地址段</p><p>•   –enable-admission-plugins：准入控制模块</p><p>•   –authorization-mode：认证授权，启用RBAC授权和节点自管理</p><p>•   –enable-bootstrap-token-auth：启用TLS bootstrap机制</p><p>•   –token-auth-file：bootstrap token文件</p><p>•   –service-node-port-range：Service nodeport类型默认分配端口范围</p><p>•   –kubelet-client-xxx：apiserver访问kubelet客户端证书</p><p>•   –tls-xxx-file：apiserver https证书</p><p>•   1.20版本必须加的参数：–service-account-issuer，–service-account-signing-key-file</p><p>•   –etcd-xxxfile：连接Etcd集群证书</p><p>•   –audit-log-xxx：审计日志</p><p>•   启动聚合层相关配置：–requestheader-client-ca-file，–proxy-client-cert-file，–proxy-client-key-file，–requestheader-allowed-names，–requestheader-extra-headers-prefix，–requestheader-group-headers，–requestheader-username-headers，–enable-aggregator-routing</p><h4 id="拷贝刚刚生成的证书到指定目录"><a href="#拷贝刚刚生成的证书到指定目录" class="headerlink" title="拷贝刚刚生成的证书到指定目录"></a>拷贝刚刚生成的证书到指定目录</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp ~&#x2F;TLS&#x2F;k8s&#x2F;ca*pem ~&#x2F;TLS&#x2F;k8s&#x2F;server*pem &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;</span><br></pre></td></tr></table></figure><h4 id="启动TLS-Bootstrapping机制"><a href="#启动TLS-Bootstrapping机制" class="headerlink" title="启动TLS Bootstrapping机制"></a>启动TLS Bootstrapping机制</h4><p>生成token：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">head -c 16 &#x2F;dev&#x2F;urandom | od -An -t x | tr -d &#39; &#39;</span><br></pre></td></tr></table></figure><p>写入文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv &lt;&lt; EOF</span><br><span class="line">16e183444ad387caf9ad5f0fe6b83ea5,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="systemd管理apiserver"><a href="#systemd管理apiserver" class="headerlink" title="systemd管理apiserver"></a>systemd管理apiserver</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes API Server</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-apiserver.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-apiserver \$KUBE_APISERVER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机自启-1"><a href="#启动并设置开机自启-1" class="headerlink" title="启动并设置开机自启"></a>启动并设置开机自启</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver </span><br><span class="line">systemctl enable kube-apiserver</span><br></pre></td></tr></table></figure><h3 id="部署kube-controller-manager"><a href="#部署kube-controller-manager" class="headerlink" title="部署kube-controller-manager"></a>部署kube-controller-manager</h3><h4 id="创建配置文件-1"><a href="#创建配置文件-1" class="headerlink" title="创建配置文件"></a>创建配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager.conf &lt;&lt; EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS&#x3D;&quot;--logtostderr&#x3D;false \\</span><br><span class="line">--v&#x3D;2 \\</span><br><span class="line">--log-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs \\</span><br><span class="line">--leader-elect&#x3D;true \\</span><br><span class="line">--kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager.kubeconfig \\</span><br><span class="line">--bind-address&#x3D;127.0.0.1 \\</span><br><span class="line">--allocate-node-cidrs&#x3D;true \\</span><br><span class="line">--cluster-cidr&#x3D;10.244.0.0&#x2F;16 \\</span><br><span class="line">--service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \\</span><br><span class="line">--cluster-signing-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\</span><br><span class="line">--cluster-signing-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem  \\</span><br><span class="line">--root-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\</span><br><span class="line">--service-account-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem \\</span><br><span class="line">--cluster-signing-duration&#x3D;87600h0m0s&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>•   –kubeconfig：连接apiserver配置文件</p><p>•   –leader-elect：当该组件启动多个时，自动选举（HA）</p><p>•   –cluster-signing-cert-file/–cluster-signing-key-file：自动为kubelet颁发证书的CA，与apiserver保持一致</p><h4 id="生成kubeconfig文件"><a href="#生成kubeconfig文件" class="headerlink" title="生成kubeconfig文件"></a>生成kubeconfig文件</h4><p>切换工作目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;TLS&#x2F;k8s</span><br></pre></td></tr></table></figure><p>创建证书请求文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; kube-controller-manager-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;, </span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure><p>生成kubeconfig文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG&#x3D;&quot;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager.kubeconfig&quot;</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:6443&quot;</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-credentials kube-controller-manager \</span><br><span class="line">  --client-certificate&#x3D;.&#x2F;kube-controller-manager.pem \</span><br><span class="line">  --client-key&#x3D;.&#x2F;kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;kube-controller-manager \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config use-context default --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure><h4 id="systemd管理controller-manager"><a href="#systemd管理controller-manager" class="headerlink" title="systemd管理controller-manager"></a>systemd管理controller-manager</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Controller Manager</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机自启-2"><a href="#启动并设置开机自启-2" class="headerlink" title="启动并设置开机自启"></a>启动并设置开机自启</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-controller-manager</span><br><span class="line">systemctl enable kube-controller-manager</span><br></pre></td></tr></table></figure><h3 id="部署kube-scheduler"><a href="#部署kube-scheduler" class="headerlink" title="部署kube-scheduler"></a>部署kube-scheduler</h3><h4 id="创建配置文件-2"><a href="#创建配置文件-2" class="headerlink" title="创建配置文件"></a>创建配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler.conf &lt;&lt; EOF</span><br><span class="line">KUBE_SCHEDULER_OPTS&#x3D;&quot;--logtostderr&#x3D;false \\</span><br><span class="line">--v&#x3D;2 \\</span><br><span class="line">--log-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs \\</span><br><span class="line">--leader-elect \\</span><br><span class="line">--kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler.kubeconfig \\</span><br><span class="line">--bind-address&#x3D;127.0.0.1&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>•   –kubeconfig：连接apiserver配置文件</p><p>•   –leader-elect：当该组件启动多个时，自动选举（HA）</p><h4 id="生成kubeconfig文件-1"><a href="#生成kubeconfig文件-1" class="headerlink" title="生成kubeconfig文件"></a>生成kubeconfig文件</h4><p>切换工作目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;TLS&#x2F;k8s</span><br></pre></td></tr></table></figure><p>创建证书请求文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br></pre></td></tr></table></figure><p>生成kubeconfig文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG&#x3D;&quot;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler.kubeconfig&quot;</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:6443&quot;</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-credentials kube-scheduler \</span><br><span class="line">  --client-certificate&#x3D;.&#x2F;kube-scheduler.pem \</span><br><span class="line">  --client-key&#x3D;.&#x2F;kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;kube-scheduler \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config use-context default --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure><h4 id="systemd管理scheduler"><a href="#systemd管理scheduler" class="headerlink" title="systemd管理scheduler"></a>systemd管理scheduler</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-scheduler.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Scheduler</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-scheduler \$KUBE_SCHEDULER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机启动"><a href="#启动并设置开机启动" class="headerlink" title="启动并设置开机启动"></a>启动并设置开机启动</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-scheduler</span><br><span class="line">systemctl enable kube-scheduler</span><br></pre></td></tr></table></figure><h4 id="查看集群状态-1"><a href="#查看集群状态-1" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><p>生成kubectl连接集群的证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes admin-csr.json | cfssljson -bare admin</span><br></pre></td></tr></table></figure><p>生成kubeconfig文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;root&#x2F;.kube</span><br><span class="line">KUBE_CONFIG&#x3D;&quot;&#x2F;root&#x2F;.kube&#x2F;config&quot;</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:6443&quot;</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-credentials cluster-admin \</span><br><span class="line">  --client-certificate&#x3D;.&#x2F;admin.pem \</span><br><span class="line">  --client-key&#x3D;.&#x2F;admin-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;cluster-admin \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config use-context default --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure><p>通过kubectl查看集群状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br></pre></td></tr></table></figure><h4 id="授权kubelet-bootstrap用户允许请求证书"><a href="#授权kubelet-bootstrap用户允许请求证书" class="headerlink" title="授权kubelet-bootstrap用户允许请求证书"></a>授权kubelet-bootstrap用户允许请求证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubelet-bootstrap \</span><br><span class="line">--clusterrole&#x3D;system:node-bootstrapper \</span><br><span class="line">--user&#x3D;kubelet-bootstrap</span><br></pre></td></tr></table></figure><h2 id="部署node（master1、node1、node2）"><a href="#部署node（master1、node1、node2）" class="headerlink" title="部署node（master1、node1、node2）"></a>部署node（master1、node1、node2）</h2><blockquote><p>这里master1也作为worker节点，我们先只对master1操作，后面拷贝到node1和node2</p></blockquote><h3 id="创建工作目录和准备二进制文件"><a href="#创建工作目录和准备二进制文件" class="headerlink" title="创建工作目录和准备二进制文件"></a>创建工作目录和准备二进制文件</h3><p>创建工作目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl,logs&#125;</span><br></pre></td></tr></table></figure><p>给master1、node1、node2准备二进制文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp kubelet kube-proxy &#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br><span class="line">scp kubelet kube-proxy root@node1:&#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br><span class="line">scp kubelet kube-proxy root@node2:&#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br></pre></td></tr></table></figure><h3 id="部署kubelet"><a href="#部署kubelet" class="headerlink" title="部署kubelet"></a>部署kubelet</h3><h4 id="创建配置文件-3"><a href="#创建配置文件-3" class="headerlink" title="创建配置文件"></a>创建配置文件</h4><blockquote><p>注意修改主机名</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.conf &lt;&lt; EOF</span><br><span class="line">KUBELET_OPTS&#x3D;&quot;--logtostderr&#x3D;false \\</span><br><span class="line">--v&#x3D;2 \\</span><br><span class="line">--log-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs \\</span><br><span class="line">--hostname-override&#x3D;master1 \\</span><br><span class="line">--network-plugin&#x3D;cni \\</span><br><span class="line">--kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.kubeconfig \\</span><br><span class="line">--bootstrap-kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;bootstrap.kubeconfig \\</span><br><span class="line">--config&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet-config.yml \\</span><br><span class="line">--cert-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl \\</span><br><span class="line">--pod-infra-container-image&#x3D;lizhenliang&#x2F;pause-amd64:3.0&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>•   –hostname-override：显示名称，集群中唯一</p><p>•   –network-plugin：启用CNI</p><p>•   –kubeconfig：空路径，会自动生成，后面用于连接apiserver</p><p>•   –bootstrap-kubeconfig：首次启动向apiserver申请证书</p><p>•   –config：配置参数文件</p><p>•   –cert-dir：kubelet证书生成目录</p><p>•   –pod-infra-container-image：管理Pod网络容器的镜像</p><h4 id="配置参数文件"><a href="#配置参数文件" class="headerlink" title="配置参数文件"></a>配置参数文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet-config.yml &lt;&lt; EOF</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io&#x2F;v1beta1</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.0.0.2</span><br><span class="line">clusterDomain: cluster.local </span><br><span class="line">failSwapOn: false</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem </span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="生成kubelet初次加入集群引导kubeconfig文件"><a href="#生成kubelet初次加入集群引导kubeconfig文件" class="headerlink" title="生成kubelet初次加入集群引导kubeconfig文件"></a>生成kubelet初次加入集群引导kubeconfig文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG&#x3D;&quot;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;bootstrap.kubeconfig&quot;</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:6443&quot; # apiserver IP:PORT</span><br><span class="line">TOKEN&#x3D;&quot;16e183444ad387caf9ad5f0fe6b83ea5&quot; # 与token.csv里保持一致</span><br><span class="line"></span><br><span class="line"># 生成 kubelet bootstrap kubeconfig 配置文件</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-credentials &quot;kubelet-bootstrap&quot; \</span><br><span class="line">  --token&#x3D;$&#123;TOKEN&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;&quot;kubelet-bootstrap&quot; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config use-context default --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure><h4 id="systemd管理kubelet"><a href="#systemd管理kubelet" class="headerlink" title="systemd管理kubelet"></a>systemd管理kubelet</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kubelet.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Kubelet</span><br><span class="line">After&#x3D;docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubelet \$KUBELET_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">LimitNOFILE&#x3D;65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>启动并设置开机启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure><p>批准kubelet证书申请并加入集群</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get csr</span><br><span class="line">kubectl certificate approve node-csr-cpZHvIc7wzZb_6Vln-ab9WF2rovEBJRiUlIiARWTJ_g</span><br></pre></td></tr></table></figure><h3 id="部署kube-proxy"><a href="#部署kube-proxy" class="headerlink" title="部署kube-proxy"></a>部署kube-proxy</h3><h4 id="创建配置文件-4"><a href="#创建配置文件-4" class="headerlink" title="创建配置文件"></a>创建配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.conf &lt;&lt; EOF</span><br><span class="line">KUBE_PROXY_OPTS&#x3D;&quot;--logtostderr&#x3D;false \\</span><br><span class="line">--v&#x3D;2 \\</span><br><span class="line">--log-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;logs \\</span><br><span class="line">--config&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy-config.yml&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="配置参数文件-1"><a href="#配置参数文件-1" class="headerlink" title="配置参数文件"></a>配置参数文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy-config.yml &lt;&lt; EOF</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io&#x2F;v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">metricsBindAddress: 0.0.0.0:10249</span><br><span class="line">clientConnection:</span><br><span class="line">  kubeconfig: &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.kubeconfig</span><br><span class="line">hostnameOverride: master1</span><br><span class="line">clusterCIDR: 10.0.0.0&#x2F;24</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="生成kube-proxy-kubeconfig文件"><a href="#生成kube-proxy-kubeconfig文件" class="headerlink" title="生成kube-proxy.kubeconfig文件"></a>生成kube-proxy.kubeconfig文件</h4><p>切换工作目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;TLS&#x2F;k8s</span><br></pre></td></tr></table></figure><p>创建证书请求文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br></pre></td></tr></table></figure><p>生成kubeconfig文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG&#x3D;&quot;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.kubeconfig&quot;</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.1.120:6443&quot;</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate&#x3D;.&#x2F;kube-proxy.pem \</span><br><span class="line">  --client-key&#x3D;.&#x2F;kube-proxy-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;kube-proxy \</span><br><span class="line">  --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br><span class="line">kubectl config use-context default --kubeconfig&#x3D;$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure><h4 id="systemd管理kube-proxy"><a href="#systemd管理kube-proxy" class="headerlink" title="systemd管理kube-proxy"></a>systemd管理kube-proxy</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Proxy</span><br><span class="line">After&#x3D;network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.conf</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-proxy \$KUBE_PROXY_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">LimitNOFILE&#x3D;65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机启动-1"><a href="#启动并设置开机启动-1" class="headerlink" title="启动并设置开机启动"></a>启动并设置开机启动</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-proxy</span><br><span class="line">systemctl enable kube-proxy</span><br></pre></td></tr></table></figure><h4 id="部署网络组件"><a href="#部署网络组件" class="headerlink" title="部署网络组件"></a>部署网络组件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply calico.yaml</span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><h4 id="授权apiserver访问kubelet"><a href="#授权apiserver访问kubelet" class="headerlink" title="授权apiserver访问kubelet"></a>授权apiserver访问kubelet</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; apiserver-to-kubelet-rbac.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io&#x2F;autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes&#x2F;proxy</span><br><span class="line">      - nodes&#x2F;stats</span><br><span class="line">      - nodes&#x2F;log</span><br><span class="line">      - nodes&#x2F;spec</span><br><span class="line">      - nodes&#x2F;metrics</span><br><span class="line">      - pods&#x2F;log</span><br><span class="line">    verbs:</span><br><span class="line">      - &quot;*&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kubernetes</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></table></figure><h3 id="新增node1和node2节点"><a href="#新增node1和node2节点" class="headerlink" title="新增node1和node2节点"></a>新增node1和node2节点</h3><h4 id="拷贝master1上的文件到node1和node2节点："><a href="#拷贝master1上的文件到node1和node2节点：" class="headerlink" title="拷贝master1上的文件到node1和node2节点："></a>拷贝master1上的文件到node1和node2节点：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;opt&#x2F;kubernetes root@node1:&#x2F;opt&#x2F;</span><br><span class="line">scp -r &#x2F;opt&#x2F;kubernetes root@node2:&#x2F;opt&#x2F;</span><br><span class="line">scp -r &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;&#123;kubelet,kube-proxy&#125;.service root@node1:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system</span><br><span class="line">scp -r &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;&#123;kubelet,kube-proxy&#125;.service root@node2:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system</span><br><span class="line">scp &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem root@node1:&#x2F;opt&#x2F;kubernetes&#x2F;ssl</span><br><span class="line">scp &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem root@node2:&#x2F;opt&#x2F;kubernetes&#x2F;ssl</span><br></pre></td></tr></table></figure><h4 id="删除node1和node2的kubelet证书和kubeconfig文件："><a href="#删除node1和node2的kubelet证书和kubeconfig文件：" class="headerlink" title="删除node1和node2的kubelet证书和kubeconfig文件："></a>删除node1和node2的kubelet证书和kubeconfig文件：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -f &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.kubeconfig </span><br><span class="line">rm -f &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kubelet*</span><br></pre></td></tr></table></figure><h4 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h4><blockquote><p>vim /opt/kubernetes/cfg/kubelet.conf</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--hostname-override&#x3D;node1</span><br></pre></td></tr></table></figure><blockquote><p>vim /opt/kubernetes/cfg/kube-proxy-config.yml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hostnameOverride: node1</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机自启-3"><a href="#启动并设置开机自启-3" class="headerlink" title="启动并设置开机自启"></a>启动并设置开机自启</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet kube-proxy</span><br><span class="line">systemctl enable kubelet kube-proxy</span><br></pre></td></tr></table></figure><h4 id="在Master上批准新Node-kubelet证书申请"><a href="#在Master上批准新Node-kubelet证书申请" class="headerlink" title="在Master上批准新Node kubelet证书申请"></a>在Master上批准新Node kubelet证书申请</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get csr</span><br><span class="line">kubectl certificate approve node-csr-17xyMtSOCXukCJKwTxgf22j4UBbNB5Q6WtCBAV_BWbs</span><br><span class="line">kubectl certificate approve node-csr-fxT7uV4zvIh1RJVQ7K6E-hLSS47GmBW5VBFBOrKzVRI</span><br></pre></td></tr></table></figure><h2 id="部署CoreDNS"><a href="#部署CoreDNS" class="headerlink" title="部署CoreDNS"></a>部署CoreDNS</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f coredns.yaml</span><br></pre></td></tr></table></figure><h2 id="新增master2（master2）"><a href="#新增master2（master2）" class="headerlink" title="新增master2（master2）"></a>新增master2（master2）</h2><h3 id="创建Etcd证书目录"><a href="#创建Etcd证书目录" class="headerlink" title="创建Etcd证书目录"></a>创建Etcd证书目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;etcd&#x2F;ssl</span><br></pre></td></tr></table></figure><h3 id="拷贝文件（master1操作）"><a href="#拷贝文件（master1操作）" class="headerlink" title="拷贝文件（master1操作）"></a>拷贝文件（master1操作）</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;opt&#x2F;kubernetes root@master2:&#x2F;opt</span><br><span class="line">scp -r &#x2F;opt&#x2F;etcd&#x2F;ssl root@master2:&#x2F;opt&#x2F;etcd</span><br><span class="line">scp &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube* root@master2:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system</span><br><span class="line">scp &#x2F;usr&#x2F;bin&#x2F;kubectl  root@master2:&#x2F;usr&#x2F;bin</span><br><span class="line">scp -r ~&#x2F;.kube root@master2:~</span><br></pre></td></tr></table></figure><h3 id="删除证书文件"><a href="#删除证书文件" class="headerlink" title="删除证书文件"></a>删除证书文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -f &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.kubeconfig </span><br><span class="line">rm -f &#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kubelet*</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><blockquote><p>vim /opt/kubernetes/cfg/kube-apiserver.conf</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">--bind-address&#x3D;192.168.1.123 \</span><br><span class="line">--advertise-address&#x3D;192.168.1.123 \</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>vim /opt/kubernetes/cfg/kube-controller-manager.kubeconfig</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">server: https:&#x2F;&#x2F;192.168.1.123:6443</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>vim /opt/kubernetes/cfg/kube-scheduler.kubeconfig</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">server: https:&#x2F;&#x2F;192.168.1.123:6443</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>vim /opt/kubernetes/cfg/kubelet.conf</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">--hostname-override&#x3D;master2</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>vim /opt/kubernetes/cfg/kube-proxy-config.yml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">hostnameOverride: master2</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>vim ~/.kube/config</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">server: https:&#x2F;&#x2F;192.168.1.123:6443</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="启动设置开机启动"><a href="#启动设置开机启动" class="headerlink" title="启动设置开机启动"></a>启动设置开机启动</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class="line">systemctl enable kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br></pre></td></tr></table></figure><h3 id="查看集群组件状态"><a href="#查看集群组件状态" class="headerlink" title="查看集群组件状态"></a>查看集群组件状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br></pre></td></tr></table></figure><h3 id="批准kubelet证书申请"><a href="#批准kubelet证书申请" class="headerlink" title="批准kubelet证书申请"></a>批准kubelet证书申请</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get csr</span><br><span class="line">kubectl certificate approve node-csr-h5nTCqbICGiH_YYIsbuemNpA6PNyGy19hKdilgjkWkM</span><br><span class="line"># 查看node</span><br><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><h3 id="部署Nginx-Keepalived高可用"><a href="#部署Nginx-Keepalived高可用" class="headerlink" title="部署Nginx+Keepalived高可用"></a>部署Nginx+Keepalived高可用</h3><h4 id="安装nginx和keepalived"><a href="#安装nginx和keepalived" class="headerlink" title="安装nginx和keepalived"></a>安装nginx和keepalived</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br><span class="line">yum install nginx keepalived -y</span><br></pre></td></tr></table></figure><h4 id="Nginx配置文件（主备一样）"><a href="#Nginx配置文件（主备一样）" class="headerlink" title="Nginx配置文件（主备一样）"></a>Nginx配置文件（主备一样）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user nginx;</span><br><span class="line">worker_processes auto;</span><br><span class="line">error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log;</span><br><span class="line">pid &#x2F;run&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line">include &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;modules&#x2F;*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 四层负载均衡，为两台Master apiserver组件提供负载均衡</span><br><span class="line">stream &#123;</span><br><span class="line"></span><br><span class="line">    log_format  main  &#39;$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent&#39;;</span><br><span class="line"></span><br><span class="line">    access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;k8s-access.log  main;</span><br><span class="line"></span><br><span class="line">    upstream k8s-apiserver &#123;</span><br><span class="line">       server 192.168.1.120:6443;   # Master1 APISERVER IP:PORT</span><br><span class="line">       server 192.168.1.123:6443;   # Master2 APISERVER IP:PORT</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">       listen 6443;</span><br><span class="line">       proxy_pass k8s-apiserver;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">    access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line"></span><br><span class="line">    include             &#x2F;etc&#x2F;nginx&#x2F;mime.types;</span><br><span class="line">    default_type        application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        server_name  _;</span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Keepalived配置（Master）"><a href="#Keepalived配置（Master）" class="headerlink" title="Keepalived配置（Master）"></a>Keepalived配置（Master）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">     failover@firewall.loc</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id NGINX_MASTER</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">    script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth1</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.100&#x2F;24</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_nginx</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Keepalived配置（Backup）"><a href="#Keepalived配置（Backup）" class="headerlink" title="Keepalived配置（Backup）"></a>Keepalived配置（Backup）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">     failover@firewall.loc</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id NGINX_BACKUP</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">    script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface eth1</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 90</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    # 虚拟IP</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.100&#x2F;24</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_nginx</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="心跳检测脚本（主备都准备）"><a href="#心跳检测脚本（主备都准备）" class="headerlink" title="心跳检测脚本（主备都准备）"></a>心跳检测脚本（主备都准备）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh  &lt;&lt; &quot;EOF&quot;</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">count&#x3D;$(ss -antp |grep 6443 |egrep -cv &quot;grep|$$&quot;)</span><br><span class="line"></span><br><span class="line">if [ &quot;$count&quot; -eq 0 ];then</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line">chmod +x &#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh</span><br></pre></td></tr></table></figure><h4 id="启动并设置开机启动-2"><a href="#启动并设置开机启动-2" class="headerlink" title="启动并设置开机启动"></a>启动并设置开机启动</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start nginx keepalived</span><br><span class="line">systemctl enable nginx keepalived</span><br></pre></td></tr></table></figure><h4 id="查看虚拟VIP是否生成"><a href="#查看虚拟VIP是否生成" class="headerlink" title="查看虚拟VIP是否生成"></a>查看虚拟VIP是否生成</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@nginx1 ~]# ip address</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.2.15&#x2F;24 brd 10.0.2.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 84121sec preferred_lft 84121sec</span><br><span class="line">    inet6 fe80::5054:ff:fe4d:77d3&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 08:00:27:7e:84:7a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.1.124&#x2F;24 brd 192.168.1.255 scope global noprefixroute eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.1.100&#x2F;24 scope global secondary eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a00:27ff:fe7e:847a&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h4 id="测试虚拟VIP是否可以漂移"><a href="#测试虚拟VIP是否可以漂移" class="headerlink" title="测试虚拟VIP是否可以漂移"></a>测试虚拟VIP是否可以漂移</h4><p>关闭Nginx Master，在Nginx Backup查看虚拟vip</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@nginx2 ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.2.15&#x2F;24 brd 10.0.2.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 83903sec preferred_lft 83903sec</span><br><span class="line">    inet6 fe80::5054:ff:fe4d:77d3&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 08:00:27:a7:3b:77 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.1.125&#x2F;24 brd 192.168.1.255 scope global noprefixroute eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.1.100&#x2F;24 scope global secondary eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a00:27ff:fea7:3b77&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h4 id="通过虚拟vip访问"><a href="#通过虚拟vip访问" class="headerlink" title="通过虚拟vip访问"></a>通过虚拟vip访问</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k https:&#x2F;&#x2F;192.168.1.100:6443&#x2F;version</span><br></pre></td></tr></table></figure><h4 id="修改所有k8s-node节点连接LoadBalance的VIP"><a href="#修改所有k8s-node节点连接LoadBalance的VIP" class="headerlink" title="修改所有k8s node节点连接LoadBalance的VIP"></a>修改所有k8s node节点连接LoadBalance的VIP</h4><p>之前我们所有node节点连接的apiserver都是单点的，现在需要改成通过连接VIP走nginx来访问apiserver</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i &#39;s#192.168.1.120:6443#192.168.1.100:6443#&#39; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;*</span><br><span class="line">systemctl restart kubelet kube-proxy</span><br></pre></td></tr></table></figure><p>最后检查节点状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决Kubernetes的Pod与宿主机时区不同步问题</title>
      <link href="2021/04/13/%E8%A7%A3%E5%86%B3Kubernetes%E7%9A%84Pod%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E6%97%B6%E5%8C%BA%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/"/>
      <url>2021/04/13/%E8%A7%A3%E5%86%B3Kubernetes%E7%9A%84Pod%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E6%97%B6%E5%8C%BA%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Kubernetes集群运行的容器默认会使用UTC时间，即与北京时间会有8小时的时差，下面将给出几种方案解决容器与宿主机时区不一致问题。</p><h2 id="通过volumes将时区文件挂到Pod中"><a href="#通过volumes将时区文件挂到Pod中" class="headerlink" title="通过volumes将时区文件挂到Pod中"></a>通过volumes将时区文件挂到Pod中</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: busybox</span><br><span class="line">      image: busybox</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      command:</span><br><span class="line">        - sleep</span><br><span class="line">        - &quot;3600&quot;</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - name: timezone</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;localtime</span><br><span class="line">  volumes:</span><br><span class="line">    - name: timezone</span><br><span class="line">      hostPath:</span><br><span class="line">        path: &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai</span><br></pre></td></tr></table></figure><p>查看容器的时区</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master k8s-list]# kubectl exec -it busybox -- date</span><br><span class="line">Tue Apr 13 10:59:40 CST 2021</span><br></pre></td></tr></table></figure><h2 id="通过定制Dockfile修改时区"><a href="#通过定制Dockfile修改时区" class="headerlink" title="通过定制Dockfile修改时区"></a>通过定制Dockfile修改时区</h2><blockquote><p>vim Dockerfile</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">RUN rm -rf &#x2F;etc&#x2F;localtime</span><br><span class="line">COPY localtime &#x2F;etc&#x2F;localtime</span><br></pre></td></tr></table></figure><p>查看容器的时区</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master k8s-list]# docker exec -it busybox sh</span><br><span class="line">&#x2F; # date</span><br><span class="line">Tue Apr 13 11:18:06 CST 2021</span><br></pre></td></tr></table></figure><h2 id="通过环境变量修改时区"><a href="#通过环境变量修改时区" class="headerlink" title="通过环境变量修改时区"></a>通过环境变量修改时区</h2><blockquote><p>并不是适用所有容器</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: nginx</span><br><span class="line">      image: nginx</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">      env:</span><br><span class="line">        - name: TZ</span><br><span class="line">          value: Asia&#x2F;Shanghai</span><br></pre></td></tr></table></figure><p>查看容器的时区</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master k8s-list]# kubectl exec -it nginx -- date</span><br><span class="line">Tue Apr 13 11:28:50 CST 2021</span><br></pre></td></tr></table></figure><h2 id="通过拷贝时区文件到容器"><a href="#通过拷贝时区文件到容器" class="headerlink" title="通过拷贝时区文件到容器"></a>通过拷贝时区文件到容器</h2><p>还可以通过拷贝时区文件到容器中来修改时区，但是这种方式有个不好的地方，就是删除容器重新创建，还需要我们再次进入容器内修改</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 拷贝宿主机时区文件到容器</span><br><span class="line">kubectl cp  &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai busybox:&#x2F;etc&#x2F;localtime</span><br><span class="line">[root@master k8s-list]# kubectl exec -it busybox -- date</span><br><span class="line">Tue Apr 13 15:06:03 CST 2021</span><br></pre></td></tr></table></figure><p>还可以实现批量修改</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量修改命名空间下的所有pod的时区</span><br><span class="line">for i in $(kubectl get pods |grep -v &#39;NAME&#39; |awk &#39;&#123;print $1&#125;&#39;);do kubectl cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai $i:&#x2F;etc&#x2F;localtime;done</span><br><span class="line">[root@master k8s-list]# kubectl exec -it nfs-client-provisioner-5f4d4ddf87-9b69q -- date</span><br><span class="line">Tue Apr 13 15:10:39 CST 2021</span><br><span class="line">[root@master k8s-list]# kubectl exec -it nginx -- date</span><br><span class="line">Tue Apr 13 15:10:42 CST 2021</span><br><span class="line">[root@master k8s-list]# kubectl exec -it busybox -- date</span><br><span class="line">Tue Apr 13 15:10:47 CST 2021</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logstash收集java日志</title>
      <link href="2021/04/13/logstash%E6%94%B6%E9%9B%86java%E6%97%A5%E5%BF%97/"/>
      <url>2021/04/13/logstash%E6%94%B6%E9%9B%86java%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>与典型的单行日志不同，java异常日志有多行，而且他们并不总是完全统一的，因此，大多数grok规则都无法开箱即用，在大多数情况下，需要特殊的配置才能正确搜集异常日志。</p><h2 id="匹配多行日志"><a href="#匹配多行日志" class="headerlink" title="匹配多行日志"></a>匹配多行日志</h2><p>我们根据日期来匹配多行日期，也就是如果匹配到当前行不是以日期开头的，就将改行归类到前一个日期行</p><p>之前看到其他文章都是根据匹配空格来匹配多行，但是有的java日常日志会输出Cause by，Cause by那行并不是以空格开始的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2021-03-25 05:10:48,019 [http-nio-8080-exec-12] ERROR &#x2F;api&#x2F;getIndex.jsp - 系统出现异常</span><br><span class="line">sun.reflect.GeneratedMethodAccessor1281: 异常</span><br><span class="line">        at sun.reflect.GeneratedMethodAccessor1281.invoke(Unknown Source)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189)</span><br><span class="line">        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)</span><br><span class="line">2021-03-25 05:10:58,523 [http-nio-8080-exec-35] INFO  com.up.cs.util.filterutil.UrlFilter - 拦截请求</span><br></pre></td></tr></table></figure><p>logstash匹配多行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  file &#123;</span><br><span class="line">    path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;test.log&quot;</span><br><span class="line">    start_position &#x3D;&gt; &quot;beginning&quot;</span><br><span class="line">    stat_interval &#x3D;&gt; &quot;2&quot;</span><br><span class="line">    codec &#x3D;&gt; multiline &#123;</span><br><span class="line">      pattern &#x3D;&gt; &quot;^%&#123;TIMESTAMP_ISO8601&#125;&quot;</span><br><span class="line">      negate &#x3D;&gt; true</span><br><span class="line">      what &#x3D;&gt; &quot;previous&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="grok解析日志"><a href="#grok解析日志" class="headerlink" title="grok解析日志"></a>grok解析日志</h2><p>%{TIMESTAMP_ISO8601:timestamp} 匹配日期时间</p><p>%{SYSLOG5424SD:thread} 匹配线程</p><p>%{LOGLEVEL:severity} 匹配日志级别</p><p>(?m) %{GREEDYDATA:message} 匹配后面所有内容（包含异常的多行日志）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(?m)%&#123;TIMESTAMP_ISO8601:timestamp&#125; %&#123;SYSLOG5424SD:thread&#125; %&#123;LOGLEVEL:severity&#125; %&#123;GREEDYDATA:message&#125;</span><br></pre></td></tr></table></figure><h2 id="日期处理"><a href="#日期处理" class="headerlink" title="日期处理"></a>日期处理</h2><p>我们需要将日志输出中日志作为我们后面显示在kibana中的指标，并不能以logstash采集的时间作为日志时间指标</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">date &#123;</span><br><span class="line">  match &#x3D;&gt; [&quot;timestamp&quot; , &quot;yyyy-MM-dd HH:mm:ss&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控ElasticSearch</title>
      <link href="2021/04/13/Prometheus%E7%9B%91%E6%8E%A7ElasticSearch/"/>
      <url>2021/04/13/Prometheus%E7%9B%91%E6%8E%A7ElasticSearch/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="下载exporter"><a href="#下载exporter" class="headerlink" title="下载exporter"></a>下载exporter</h2><p>下载地址：<a href="https://github.com/justwatchcom/elasticsearch_exporter/releases">https://github.com/justwatchcom/elasticsearch_exporter/releases</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf elasticsearch_exporter-1.1.0.linux-amd64.tar.gz</span><br><span class="line">cd elasticsearch_exporter-1.1.0.linux-amd64</span><br><span class="line">cp elasticsearch_exporter &#x2F;usr&#x2F;local&#x2F;bin</span><br><span class="line"># 启动</span><br><span class="line">nohup elasticsearch_exporter --es.uri&#x3D;http:&#x2F;&#x2F;localhost:9200 --es.all --es.cluster_settings --es.indices --es.indices_settings --es.shards --es.snapshots &gt;&gt; logs&#x2F;elasticsearch_exporter.log &amp;</span><br></pre></td></tr></table></figure><p>查看监控的指标</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -s http:&#x2F;&#x2F;localhost:9114&#x2F;metrics |grep elasticsearch_cluster_health_status</span><br></pre></td></tr></table></figure><h2 id="配置prometheus"><a href="#配置prometheus" class="headerlink" title="配置prometheus"></a>配置prometheus</h2><p>增加es指标搜集配置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: elasticsearch</span><br><span class="line">  static_configs:</span><br><span class="line">    - targets: [&#39;192.168.1.112:9114&#39;]</span><br></pre></td></tr></table></figure><h2 id="配置grafana监控模板"><a href="#配置grafana监控模板" class="headerlink" title="配置grafana监控模板"></a>配置grafana监控模板</h2><p>导入grafana模板id：6483</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/04/13/Prometheus%E7%9B%91%E6%8E%A7ElasticSearch/a1.png"></p><h2 id="配置rules"><a href="#配置rules" class="headerlink" title="配置rules"></a>配置rules</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: mysqld_rules</span><br><span class="line">  rules:</span><br><span class="line">  - alert: ElasticsearchHeapUsageTooHigh</span><br><span class="line">    expr: 100 * elasticsearch_jvm_memory_used_bytes&#123;area&#x3D;&quot;heap&quot;&#125; &#x2F; elasticsearch_jvm_memory_max_bytes&#123;area&#x3D;&quot;heap&quot;&#125; &gt; 90</span><br><span class="line">    for: 2m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Heap Usage Too High (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: The heap usage is over 90%\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchHeapUsageWarning</span><br><span class="line">    expr: 100 * elasticsearch_jvm_memory_used_bytes&#123;area&#x3D;&quot;heap&quot;&#125; &#x2F; elasticsearch_jvm_memory_max_bytes&#123;area&#x3D;&quot;heap&quot;&#125; &gt; 80</span><br><span class="line">    for: 2m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Heap Usage warning (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: The heap usage is over 80%\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchDiskOutOfSpace</span><br><span class="line">    expr: 100 * elasticsearch_filesystem_data_available_bytes &#x2F; elasticsearch_filesystem_data_size_bytes  &lt; 10</span><br><span class="line">    for: 2m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch disk out of space (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: The disk usage is over 90%\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchDiskSpaceLow</span><br><span class="line">    expr: 100 * elasticsearch_filesystem_data_available_bytes &#x2F; elasticsearch_filesystem_data_size_bytes  &lt; 20</span><br><span class="line">    for: 2m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch disk space low (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: The disk usage is over 80%\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchClusterRed</span><br><span class="line">    expr: elasticsearch_cluster_health_status&#123;color&#x3D;&quot;red&quot;&#125; &#x3D;&#x3D; 1</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Cluster Red (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elastic Cluster Red status\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchClusterYellow</span><br><span class="line">    expr: elasticsearch_cluster_health_status&#123;color&#x3D;&quot;yellow&quot;&#125; &#x3D;&#x3D; 1</span><br><span class="line">    for: 3m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Cluster Yellow (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elastic Cluster Yellow status\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchHealthyNodes</span><br><span class="line">    expr: elasticsearch_cluster_health_number_of_nodes &lt; 3</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Healthy Nodes (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Missing node in Elasticsearch cluster\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchHealthyDataNodes</span><br><span class="line">    expr: elasticsearch_cluster_health_number_of_data_nodes &lt; 3</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch Healthy Data Nodes (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Missing data node in Elasticsearch cluster\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchRelocatingShards</span><br><span class="line">    expr: elasticsearch_cluster_health_relocating_shards &gt; 0</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: info</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch relocating shards (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch is relocating shards\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchRelocatingShardsTooLong</span><br><span class="line">    expr: elasticsearch_cluster_health_relocating_shards &gt; 0</span><br><span class="line">    for: 15m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch relocating shards too long (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch has been relocating shards for 15min\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchInitializingShards</span><br><span class="line">    expr: elasticsearch_cluster_health_initializing_shards &gt; 0</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: info</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch initializing shards (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch is initializing shards\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchInitializingShardsTooLong</span><br><span class="line">    expr: elasticsearch_cluster_health_initializing_shards &gt; 0</span><br><span class="line">    for: 15m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch initializing shards too long (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch has been initializing shards for 15 min\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchUnassignedShards</span><br><span class="line">    expr: elasticsearch_cluster_health_unassigned_shards &gt; 0</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch unassigned shards (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch has unassigned shards\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchPendingTasks</span><br><span class="line">    expr: elasticsearch_cluster_health_number_of_pending_tasks &gt; 0</span><br><span class="line">    for: 15m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch pending tasks (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Elasticsearch has pending tasks. Cluster works slowly.\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: ElasticsearchNoNewDocuments</span><br><span class="line">    expr: increase(elasticsearch_indices_docs&#123;es_data_node&#x3D;&quot;true&quot;&#125;[10m]) &lt; 1</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Elasticsearch no new documents (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: No new documents for 10 min!\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控MySQL</title>
      <link href="2021/03/21/Prometheus%E7%9B%91%E6%8E%A7MySQL/"/>
      <url>2021/03/21/Prometheus%E7%9B%91%E6%8E%A7MySQL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装mysqld-exporter"><a href="#安装mysqld-exporter" class="headerlink" title="安装mysqld_exporter"></a>安装mysqld_exporter</h2><p>下载地址：<a href="https://github.com/prometheus/mysqld_exporter/">https://github.com/prometheus/mysqld_exporter/</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压</span><br><span class="line">tar zxvf mysqld_exporter-0.12.1.linux-amd64.tar.gz</span><br><span class="line">cd mysqld_exporter-0.12.1.linux-amd64</span><br><span class="line">cp mysqld_exporter &#x2F;usr&#x2F;local&#x2F;bin</span><br></pre></td></tr></table></figure><h2 id="为exporter创建MySQL账号并授权"><a href="#为exporter创建MySQL账号并授权" class="headerlink" title="为exporter创建MySQL账号并授权"></a>为exporter创建MySQL账号并授权</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 登录</span><br><span class="line">mysql -uroot -p</span><br><span class="line"># 创建账号</span><br><span class="line">mysql&gt; CREATE USER &#39;exporter&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123321&#39;;</span><br><span class="line"># 授权</span><br><span class="line">mysql&gt; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO &#39;exporter&#39;@&#39;localhost&#39;;</span><br></pre></td></tr></table></figure><p>为exporter账号配置免密连接</p><blockquote><p>vim /usr/local/mysqld_exporter-0.12.1.linux-amd64/.my.cnf</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[client]</span><br><span class="line">user&#x3D;exporter</span><br><span class="line">password&#x3D;123321</span><br></pre></td></tr></table></figure><h2 id="启动mysqld-exporter"><a href="#启动mysqld-exporter" class="headerlink" title="启动mysqld_exporter"></a>启动mysqld_exporter</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup mysqld_exporter --config.my-cnf&#x3D;.my.cnf &gt;&gt; logs&#x2F;mysqld_exporter.log &amp;</span><br></pre></td></tr></table></figure><h2 id="配置Prometheus"><a href="#配置Prometheus" class="headerlink" title="配置Prometheus"></a>配置Prometheus</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: mysql</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#39;192.168.1.113:9104&#39;]</span><br></pre></td></tr></table></figure><h2 id="配置grafana模板"><a href="#配置grafana模板" class="headerlink" title="配置grafana模板"></a>配置grafana模板</h2><p>引入grafana模板7362：<a href="https://grafana.com/dashboards/7362">https://grafana.com/dashboards/7362</a></p><h2 id="配置Rules规则"><a href="#配置Rules规则" class="headerlink" title="配置Rules规则"></a>配置Rules规则</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: mysqld_rules</span><br><span class="line">  rules:</span><br><span class="line">  - alert: MysqlDown</span><br><span class="line">    expr: mysql_up &#x3D;&#x3D; 0</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL down (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: MySQL instance is down on &#123;&#123; $labels.instance &#125;&#125;\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: MysqlTooManyConnections(&gt;80%)</span><br><span class="line">    expr: 100*avg(rate(mysql_global_status_threads_connected[1m]))by(instance) &#x2F; avg(mysql_global_variables_max_connections)by(instance)</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL too many connections (&gt; 80%) (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: More than 80% of MySQL connections are in use on &#123;&#123; $labels.instance &#125;&#125;\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: MysqlHighThreadsRunning</span><br><span class="line">    expr: 100*avg(rate(mysql_global_status_threads_running[1m]))by(instance) &#x2F; avg(mysql_global_variables_max_connections)by(instance)</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL high threads running (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: More than 60% of MySQL connections are in running state on &#123;&#123; $labels.instance &#125;&#125;\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: MysqlSlowQueries</span><br><span class="line">    expr: increase(mysql_global_status_slow_queries[1m]) &gt; 0</span><br><span class="line">    for: 2m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL slow queries (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: MySQL server mysql has some new slow query.\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: MysqlInnodbLogWaits</span><br><span class="line">    expr: rate(mysql_global_status_innodb_log_waits[15m]) &gt; 10</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL InnoDB log waits (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: MySQL innodb log writes stalling\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br><span class="line">  - alert: MysqlRestarted</span><br><span class="line">    expr: mysql_global_status_uptime &lt; 60</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: info</span><br><span class="line">    annotations:</span><br><span class="line">      summary: MySQL restarted (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: MySQL has just been restarted, less than one minute ago on &#123;&#123; $labels.instance &#125;&#125;.\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;\n  LABELS: &#123;&#123; $labels &#125;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus使用BlackBox_exporter黑盒探测</title>
      <link href="2021/03/21/Prometheus%E4%BD%BF%E7%94%A8BlackBox-exporter%E9%BB%91%E7%9B%92%E6%8E%A2%E6%B5%8B/"/>
      <url>2021/03/21/Prometheus%E4%BD%BF%E7%94%A8BlackBox-exporter%E9%BB%91%E7%9B%92%E6%8E%A2%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在生产环境，我们肯定需要对我们的服务、端口等进行探测、监控和告警，以便第一时间获取服务的状态。blackbox_exporter提供icmp、tcp、udp、http等多种探针。</p><h2 id="安装BlackBox-exporter"><a href="#安装BlackBox-exporter" class="headerlink" title="安装BlackBox_exporter"></a>安装BlackBox_exporter</h2><p>下载地址：<a href="https://github.com/prometheus/blackbox_exporter">https://github.com/prometheus/blackbox_exporter</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf blackbox_exporter-0.18.0.linux-amd64.tar.gz</span><br><span class="line"># 启动</span><br><span class="line">cd blackbox_exporter-0.18.0.linux-amd64</span><br><span class="line">cp blackbox_exporter &#x2F;usr&#x2F;local&#x2F;bin</span><br><span class="line">nohup blackbox_exporter &gt;&gt; logs&#x2F;blackbox_exporter.log &amp;</span><br></pre></td></tr></table></figure><h2 id="配置Prometheus"><a href="#配置Prometheus" class="headerlink" title="配置Prometheus"></a>配置Prometheus</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: icmp_probe</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  params:</span><br><span class="line">    module: [icmp]</span><br><span class="line">  static_configs:</span><br><span class="line">    - targets: [&#39;180.101.49.11&#39;]</span><br><span class="line">  relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      target_label: __param_target</span><br><span class="line">    - source_labels: [__param_target]</span><br><span class="line">      target_label: instance</span><br><span class="line">    - target_label: __address__</span><br><span class="line">      replacement: 127.0.0.1:9115</span><br><span class="line">- job_name: tcp_probe</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  params:</span><br><span class="line">    module: [tcp_connect]</span><br><span class="line">  static_configs:</span><br><span class="line">    - targets: [&#39;172.19.205.2:8080&#39;]</span><br><span class="line">  relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      target_label: __param_target</span><br><span class="line">    - source_labels: [__param_target]</span><br><span class="line">      target_label: instance</span><br><span class="line">    - target_label: __address__</span><br><span class="line">      replacement: 127.0.0.1:9115</span><br><span class="line">- job_name: http_probe</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  params:</span><br><span class="line">    module: [http_2xx]</span><br><span class="line">  static_configs:</span><br><span class="line">    - targets: [&#39;http:www.baidu.com&#39;]</span><br><span class="line">  relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      target_label: __param_target</span><br><span class="line">    - source_labels: [__param_target]</span><br><span class="line">      target_label: instance</span><br><span class="line">    - target_label: __address__</span><br><span class="line">      replacement: 127.0.0.1:9115</span><br></pre></td></tr></table></figure><h2 id="配置Grafana模板"><a href="#配置Grafana模板" class="headerlink" title="配置Grafana模板"></a>配置Grafana模板</h2><p>引入 13659 模板id</p><h2 id="配置Rules规则"><a href="#配置Rules规则" class="headerlink" title="配置Rules规则"></a>配置Rules规则</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: blackbox_rules</span><br><span class="line">  rules:</span><br><span class="line">  - alert: BlackboxProbeFailed</span><br><span class="line">    expr: probe_success &#x3D;&#x3D; 0</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox probe failed (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Probe failed\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxSlowProbe</span><br><span class="line">    expr: probe_duration_seconds &gt; 1</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox slow probe (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Blackbox probe took more than 1s to complete\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxProbeHttpFailure</span><br><span class="line">    expr: probe_http_status_code &lt;&#x3D; 199 OR probe_http_status_code &gt;&#x3D; 400</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox probe HTTP failure (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: HTTP status code is not 200-399\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxSslCertificateWillExpireSoon</span><br><span class="line">    expr: (probe_ssl_earliest_cert_expiry - time()) &#x2F; 3600 &#x2F; 24 &lt; 7</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox SSL certificate will expire soon (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: SSL certificate expires in 7 days\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxSslCertificateWillExpireSoon</span><br><span class="line">    expr: (probe_ssl_earliest_cert_expiry - time()) &#x2F; 3600 &#x2F; 24 &lt; 3</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox SSL certificate will expire soon (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: SSL certificate expires in 3 days\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxSslCertificateWillExpireSoon</span><br><span class="line">    expr: (probe_ssl_earliest_cert_expiry - time())  &lt;&#x3D; 0</span><br><span class="line">    for: 0m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox SSL certificate expired (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: SSL certificate has expired already\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxProbeSlowHttp</span><br><span class="line">    expr: probe_http_duration_seconds &gt; 1</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox probe slow HTTP (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: HTTP request took more than 1s\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxProbeSlowPing</span><br><span class="line">    expr: probe_icmp_duration_seconds &gt; 1</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox probe slow ping (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Blackbox ping took more than 1s\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br><span class="line">  - alert: BlackboxProbeSlowDNS</span><br><span class="line">    expr: probe_dns_lookup_time_seconds &gt; 1</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Blackbox probe slow dns (instance &#123;&#123; $labels.instance &#125;&#125;)</span><br><span class="line">      description: Blackbox dns took more than 1s\n  VALUE &#x3D; &#123;&#123; $value &#125;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为Prometheus配置安全认证</title>
      <link href="2021/03/21/%E4%B8%BAPrometheus%E9%85%8D%E7%BD%AE%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/"/>
      <url>2021/03/21/%E4%B8%BAPrometheus%E9%85%8D%E7%BD%AE%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Prometheus的UI界面登录是没有认证，我们通过nginx basic添加认证机制</p><h2 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h2><p>下载地址：<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 编译</span><br><span class="line">tar zxvf nginx-1.16.0.tar.gz</span><br><span class="line">cd nginx-1.16.0</span><br><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_stub_status_module --with-http_ssl_module</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"># 验证是否安装成功</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;nginx</span><br><span class="line">.&#x2F;sbin&#x2F;nginx -t</span><br></pre></td></tr></table></figure><h2 id="安装apache-htpasswd工具"><a href="#安装apache-htpasswd工具" class="headerlink" title="安装apache-htpasswd工具"></a>安装apache-htpasswd工具</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install httpd-tools</span><br></pre></td></tr></table></figure><h2 id="配置认证账号"><a href="#配置认证账号" class="headerlink" title="配置认证账号"></a>配置认证账号</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf</span><br><span class="line"># 账号admin ，然后设置密码</span><br><span class="line">htpasswd -c ht.passwd admin</span><br></pre></td></tr></table></figure><p>在nginx.conf配置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        client_body_buffer_size 20m;</span><br><span class="line">        server_name  ~^(.+)?.twf.cn$;</span><br><span class="line">        if ($host &#x3D; prometheus.twf.cn)&#123;</span><br><span class="line">                rewrite ^(.*)$ https:&#x2F;&#x2F;$host$1 permanent;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen  443 ssl;</span><br><span class="line">        server_name  ~^(.+)?.twf.cn$;</span><br><span class="line">        client_body_buffer_size 20m;</span><br><span class="line"></span><br><span class="line">        ssl_certificate     &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;cert&#x2F;ca.pem;</span><br><span class="line">        ssl_certificate_key  &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;cert&#x2F;ca.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">                if ($host &#x3D; prometheus.twf.cn)&#123;</span><br><span class="line">                        proxy_pass http:&#x2F;&#x2F;127.0.0.1:9090;</span><br><span class="line">                &#125;</span><br><span class="line">                auth_basic &quot;Basic Authentication&quot;;</span><br><span class="line">                auth_basic_user_file &quot;ht.passwd&quot;;</span><br><span class="line">                client_max_body_size    100m;</span><br><span class="line">                proxy_set_header Host $http_host;</span><br><span class="line">                proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="配置Prometheus"><a href="#配置Prometheus" class="headerlink" title="配置Prometheus"></a>配置Prometheus</h2><p>主要重新配置Prometheus启动参数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup prometheus --config.file prometheus.yml --storage.tsdb.path&#x3D;&#x2F;data&#x2F;prometheus --web.external-url&#x3D;http:&#x2F;&#x2F;localhost:19090   --web.route-prefix&#x3D;&quot;&#x2F;&quot;  --web.enable-lifecycle  --web.listen-address&#x3D;&quot;localhost:9090&quot;  &gt;&gt; logs&#x2F;prometheus.log &amp;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes初始化容器</title>
      <link href="2021/03/21/Kubernetes%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%B9%E5%99%A8/"/>
      <url>2021/03/21/Kubernetes%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%B9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>初始化容器（Init Container）是用来做初始化工作的，可以是一个或者多个，如果存在多个InitC，这些InitC会按照定义的顺序依次执行，只有所有InitC执行完毕后，主容器才会被启动。在一个Pod中，所有的容器都是共享数据卷和网络命名空间的，因此我们可以把一些初始化的操作交给InitC来完成。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>创建一个busybox的Pod</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">spec:</span><br><span class="line">  initContainers:</span><br><span class="line">    - name: init-demo</span><br><span class="line">      image: busybox</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      command:</span><br><span class="line">        - sh</span><br><span class="line">        - -c</span><br><span class="line">        - wget -O &#x2F;workdir&#x2F;index.html http:&#x2F;&#x2F;www.baidu.com</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;workdir</span><br><span class="line">          name: workdir</span><br><span class="line">  containers:</span><br><span class="line">    - name: busybox</span><br><span class="line">      image: busybox</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      command:</span><br><span class="line">        - sleep</span><br><span class="line">        - &quot;3600&quot;</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;workdir</span><br><span class="line">          name: workdir</span><br><span class="line">  volumes:</span><br><span class="line">    - name: workdir</span><br><span class="line">      emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure><p>查看 Events</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl describe pod busybox</span><br></pre></td></tr></table></figure><p>查看初始化操作的结果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it busybox -- cat &#x2F;workdir&#x2F;index.html</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes之Pod生命周期</title>
      <link href="2021/02/03/Kubernetes%E4%B9%8BPod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>2021/02/03/Kubernetes%E4%B9%8BPod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本篇文章我们主要介绍Pod的生命周期。Pod遵循所定义的生命周期，在起始Pending阶段，如果Pod中primary容器中至少有一个开始运行，则其状态变为Running，然后再经过成功或失败阶段，主要取决于Pod中的任何容器是否因失败而终止。</p><p>Pod在其生命周期内仅仅只能被scheduled调度一次，一旦Pod被scheduled调度分配到某个Node节点后，该Pod将在Node上运行直到其停止或终止。在Pod运行的同时，kubelet能够重新启动容器以处理一些错误，在Pod中，Kubernetes会跟踪不同容器的状态，并且确定采取任何措施使Pod健康运行。</p><h2 id="Pod寿命"><a href="#Pod寿命" class="headerlink" title="Pod寿命"></a>Pod寿命</h2><p>像各个应用程序容器一样，Pod的寿命也是相对短暂的，当创建一个Pod时，会为其分配一个唯一的ID（UID），并将其调度到最合适的Node，直到其终止或删除为止。如果此Node死掉，Kubernetes会在超时后删除该Node节点上的Pod。</p><p>Pod本身并不能自我修复，如果Pod被安排到节点然后失败，又或者缺少资源，都会导致Pod被删除。Kubernetes使用更高级的抽象，也就是控制器，使用Pod控制器管理一次性的Pod实例工作。</p><h2 id="Pod-phase"><a href="#Pod-phase" class="headerlink" title="Pod phase"></a>Pod phase</h2><p>Pod的status字段是PodStatus对象，其中包含一个phase字段，可以通过以下命令查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pod &lt;pod name&gt; -o yaml</span><br></pre></td></tr></table></figure><p>Pod phase字段简要的对Pod处于生命周期位置进行概括，以下是Pod phase可能的值：</p><table><thead><tr><th>值</th><th>描述</th></tr></thead><tbody><tr><td>Pending</td><td>挂起。Pod已经被Kubernetes集群所接受，但是尚未有一个或多个容器可以运行，该状态包括Pod等待所花费的时间，以及容器镜像下载所需的时间</td></tr><tr><td>Running</td><td>正在运行。Pod已经被绑定在Node上，并且Pod内所有容器被创建，至少有一个容器已经运行，或者正在启动或重新启动</td></tr><tr><td>Succeeded</td><td>成功。Pod中所有容器都已经成功终止，并且不会再重启</td></tr><tr><td>Failed</td><td>失败。Pod中所有容器都已终止，并且至少有一个容器是因为失败终止，也就是说至少一个容器以非0状态退出或者被系统终止</td></tr><tr><td>Unknown</td><td>因为某些原因无法获取Pod状态，通常是因为与Pod所在的节点通信时发生错误</td></tr></tbody></table><blockquote><p>删除Pod时Terminating并不是Pod生命周期之一，Kubernetes授予Pod适当终止的期限，默认为30秒，可以使用 – force 来强制删除Pod</p></blockquote><p>如果某个Node节点死亡或与集群断开连接，Kubernetes会应用一个策略，将该节点上的所有Pod的phase设置为Failed</p><h2 id="容器状态"><a href="#容器状态" class="headerlink" title="容器状态"></a>容器状态</h2><p>除了Pod总体状态，Kubernetes还会跟踪Pod内每个容器状态，你可以通过使用容器生命周期钩子来触发事件，来使容器在某些时间点运行。</p><p>一旦Scheduler将Pod分配给Node节点上，kubelet会为该Pod创建容器，容器有三种状态：Waiting、Running和Terminated。</p><p>可以通过以下命令查看Pod内容器的状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl describe pod &lt;pod name&gt;</span><br></pre></td></tr></table></figure><h3 id="Waiting"><a href="#Waiting" class="headerlink" title="Waiting"></a>Waiting</h3><p>处于Waiting状态的容器仍在运行以完成启动所需的操作，例如，从容器镜像注册表中提取容器镜像，或应用secret数据。当使用kubectl查询Pod容器状态是Waiting时，还会看到一个reason字段，reason字段简述了容器处于该状态的原因。</p><h3 id="Running"><a href="#Running" class="headerlink" title="Running"></a>Running</h3><p>该Running状态表示容器正在执行且没有任何问题，如果postStart配置了一个挂钩，则它已经执行完成。当使用kubectl查询Pod容器状态是Running时，还会看到有关容器何时进入Running状态的信息。</p><h3 id="Terminated"><a href="#Terminated" class="headerlink" title="Terminated"></a>Terminated</h3><p>处于Terminated状态表示容器开始执行，然后运行完成或者由于某种原因失败。如果preStop配置了挂钩，则挂钩在容器进入Terminated状态之前运行。当使用kubectl查询Pod容器状态是Terminated时，还会看到一个原因，一个退出代码以及容器执行开始和结束时间。</p><h2 id="容器重启策略"><a href="#容器重启策略" class="headerlink" title="容器重启策略"></a>容器重启策略</h2><p>容器的重启策略由spec.restartPolicy字段指定，有以下三种：</p><ul><li>Always：容器失效时，kubelet自动重启该容器</li><li>OnFailure：容器终止运行且以非0退出时重启</li><li>Never：不论状态如何，kubelet都不重启该容器</li></ul><p>restartPolicy策略应用于Pod中所有的容器，在Pod中容器退出后，kubelet会以指数级退避延迟（10s、20s、40s等）重启容器，上限为5分钟，一旦容器执行了10分钟而没有任何问题，kubelet将重置该容器退避计时器。</p><h2 id="Pod-conditions"><a href="#Pod-conditions" class="headerlink" title="Pod conditions"></a>Pod conditions</h2><p>Pod status字段下有一个数组类型的conditions字段，记录了通过该condition条件的情况，可以通过以下命令查看status.conditions字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pod &lt;pod name&gt; -o yaml</span><br></pre></td></tr></table></figure><table><thead><tr><th>字段</th><th>描述</th></tr></thead><tbody><tr><td>type</td><td>Pod condition名称</td></tr><tr><td>status</td><td>指该条件是否适用，可能的指”True”、”False”、”Unknown”</td></tr><tr><td>lastProbeTime</td><td>上一次探测Pod条件的时间戳</td></tr><tr><td>lastTransitionTime</td><td>Pod上一次从一种状态转换为另一种状态的时间戳。</td></tr><tr><td>reason</td><td>机器可读的文本，表示最后一次状态变更的原因标识</td></tr><tr><td>message</td><td>人可读，表示最后一次状态变更的原因</td></tr></tbody></table><p>该type字段可能的值：</p><p>PodScheduled：Pod已经被Scheduler调度到某个Node</p><p>Initialized：所有init containers都已成功启动</p><p>Ready：Pod已经能够处理请求，可以被添加到后端的service负载</p><p>ContainersReady：所有容器都处于”Ready”状态</p><h2 id="容器探针"><a href="#容器探针" class="headerlink" title="容器探针"></a>容器探针</h2><p>探针是通过周期性的执行来诊断kubelet上的容器，kubelet调用探针执行诊断由容器实现的Handler，主要有三种类型的处理程序：</p><ul><li>ExecAction：在容器内部执行命令，如果命令以状态0退出，则认为诊断成功。</li><li>TCPSocketAction：对指定端口上Pod的IP地址执行TCP检查，如果端口打开，则认为诊断成功。</li><li>HTTPSocketAction：对指定端口和Pod IP地址执行HTTP的GET请求，如果响应的状态码大于或等于200且小于400，则认为诊断成功。</li></ul><p>探针具体有以下三个结果：</p><ul><li>Success：诊断成功</li><li>Failure：诊断失败</li><li>Unknown：诊断失败，不采取任何措施</li></ul><p>kubelet可以对容器诊断有三种探针方式：</p><ul><li>livenessProbe：指示容器是否正在运行。如果存活性探针失败，则kubelet将杀死该容器，并且按照重启策略执行相应的操作。如果容器未提供存活性探针，则默认状态为Success。</li><li>readinessProbe：指示容器是否准备好响应请求。如果就绪性探针失败，则端点控制器将从与Pod匹配的Service的端点中删除该Pod的IP地址，初始延迟之前的就绪状态默认为Failure。如果容器未提供就绪性探针，则默认状态为Success。</li><li>startupProbe：指示容器中的应用是否已启动。如果提供了启动探针，则将禁用所有其他探针，知道启动成功成功。如果启动探针失败，则kubelet将杀死容器，并且该容器将受到重启策略的约束。如果容器未提供启动探针，则默认状态为Success。</li></ul><blockquote><p>这里很多人将readinessProbe和startupProbe搞混，其实还是有区别的。举个例子，当一个应用程序Pod启动需要60s的时间，readinessProbe探针我们设定每10s探针一次（失败3次认为探针失败），那么在容器还没有启动完成，kubelet就会杀死Pod，按照重启策略一直重启Pod，其实我们修改readinessProbe将失败次数改为6次，也可以解决这个问题，但是问题来了，要是下一个应用程序启动需要70秒，那就还需要修改。但是使用startupProbe探针，我们可以设定每10s探针一次（失败10次认为探针失败），也就是在100s内应用程序启动成功就没有问题，而且startupProbe也不受重启策略的约束，但是这种方式还是不能确定具体时间，只能给一个大概的范围。</p></blockquote><h2 id="Pod终止"><a href="#Pod终止" class="headerlink" title="Pod终止"></a>Pod终止</h2><p>Pod是集群节点上运行的进程，当我们不再需要时，允许这些进程正常终止。</p><p>一个Pod正常终止的流程如下：</p><ol><li><p>用户使用kubectl工具手动删除特定的Pod</p></li><li><p>API Server更新宽限期（默认30s），超过宽限期Pod被视为”dead”状态</p></li><li><p>将Pod标记为”Terminating”状态，kubelet看到Pod状态标记为”Terminating”，便开始关闭该Pod相关进程</p><p>（1）如果Pod容器中定义了preStop钩子，则kubelet会在容器内部运行该钩子。如果preStop在宽限期到期后仍在运行，则kubelet要求将宽限期再延迟2秒</p><p>（2）kubelet向容器内进程发送TERM信号</p></li><li><p>在kubelet正常关闭的同时，endpoints控制器监控到Pod对象关闭，将Pod与Service匹配的endpoints列表中删除</p></li><li><p>当宽限期到期时，kubelet会触发强制关闭，若存在任何一个运行的进程，Pod将收到SIGKILL信号</p></li><li><p>通过将宽限期设置为0（立即删除），kubelet请求API Server强制删除Pod对象</p></li><li><p>API Server删除Pod对象，然后该Pod不再从客户端可见</p></li></ol><h2 id="强制Pod终止"><a href="#强制Pod终止" class="headerlink" title="强制Pod终止"></a>强制Pod终止</h2><p>默认情况下，所有删除均在30秒内完成，也可以通过kubectl delete命令支持 –grace-period=<seconds>允许覆盖默认的宽限期</seconds></p><p>将宽限期设置为0，表示强行并立即从API Server中删除Pod</p><blockquote><p>必须指定额外标志 –force 一起与 –grace-period=0 使用</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署Consul集群</title>
      <link href="2021/02/01/Kubernetes%E9%83%A8%E7%BD%B2Consul%E9%9B%86%E7%BE%A4/"/>
      <url>2021/02/01/Kubernetes%E9%83%A8%E7%BD%B2Consul%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kubernetes以Statefulset方式部署Consul集群</p><h2 id="应用namespace"><a href="#应用namespace" class="headerlink" title="应用namespace"></a>应用namespace</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: public-service</span><br><span class="line">  labels:</span><br><span class="line">    name: public-service</span><br></pre></td></tr></table></figure><h2 id="应用statefulset"><a href="#应用statefulset" class="headerlink" title="应用statefulset"></a>应用statefulset</h2><blockquote><p>需要先部署nfs storage class</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: consul</span><br><span class="line">  namespace: public-service</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  serviceName: consul</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: consul</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: consul</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 10</span><br><span class="line">      securityContext:</span><br><span class="line">        fsGroup: 1000</span><br><span class="line">      # affinity:</span><br><span class="line">      #   podAntiAffinity:</span><br><span class="line">      #     requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      #       - labelSelector:</span><br><span class="line">      #           matchExpressions:</span><br><span class="line">      #             - key: app</span><br><span class="line">      #               operator: In</span><br><span class="line">      #               values:</span><br><span class="line">      #                 - consul</span><br><span class="line">      #         topologyKey: kubernetes.io&#x2F;hostname</span><br><span class="line">      containers:</span><br><span class="line">        - name: consul</span><br><span class="line">          image: consul:1.8</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8500</span><br><span class="line">              name: ui-port</span><br><span class="line">            - containerPort: 8400</span><br><span class="line">              name: alt-port</span><br><span class="line">            - containerPort: 53</span><br><span class="line">              name: udp-port</span><br><span class="line">            - containerPort: 8443</span><br><span class="line">              name: https-port</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">              name: http-port</span><br><span class="line">            - containerPort: 8301</span><br><span class="line">              name: serflan</span><br><span class="line">            - containerPort: 8302</span><br><span class="line">              name: serfwan</span><br><span class="line">            - containerPort: 8600</span><br><span class="line">              name: consuldns</span><br><span class="line">            - containerPort: 8300</span><br><span class="line">              name: server</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_IP</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: status.podIP</span><br><span class="line">            - name: NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          args:</span><br><span class="line">            - &quot;agent&quot;</span><br><span class="line">            - &quot;-server&quot;</span><br><span class="line">            - &quot;-advertise&#x3D;$(POD_IP)&quot;</span><br><span class="line">            - &quot;-bind&#x3D;0.0.0.0&quot;</span><br><span class="line">            - &quot;-bootstrap-expect&#x3D;3&quot;</span><br><span class="line">            - &quot;-data-dir&#x3D;&#x2F;consul&#x2F;data&quot;</span><br><span class="line">            - &quot;-disable-host-node-id&quot;</span><br><span class="line">            - &quot;-domain&#x3D;cluster.local&quot;</span><br><span class="line">            - &quot;-retry-join&#x3D;consul-0.consul.$(NAMESPACE).svc.cluster.local&quot;</span><br><span class="line">            - &quot;-retry-join&#x3D;consul-1.consul.$(NAMESPACE).svc.cluster.local&quot;</span><br><span class="line">            - &quot;-retry-join&#x3D;consul-2.consul.$(NAMESPACE).svc.cluster.local&quot;</span><br><span class="line">            - &quot;-client&#x3D;0.0.0.0&quot;</span><br><span class="line">            - &quot;-ui&quot;</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: &quot;200m&quot;</span><br><span class="line">              memory: &quot;512Mi&quot;</span><br><span class="line">            requests:</span><br><span class="line">              cpu: &quot;100m&quot;</span><br><span class="line">              memory: &quot;128Mi&quot;</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - &#x2F;bin&#x2F;sh</span><br><span class="line">                  - -c</span><br><span class="line">                  - consul leave</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: consul-data</span><br><span class="line">              mountPath: &#x2F;consul&#x2F;data</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: consul-data</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io&#x2F;storage-class: &quot;managed-nfs-storage&quot;</span><br><span class="line">      spec:</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 5Gi</span><br></pre></td></tr></table></figure><h2 id="应用service"><a href="#应用service" class="headerlink" title="应用service"></a>应用service</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: consul</span><br><span class="line">  namespace: public-service</span><br><span class="line">  labels:</span><br><span class="line">    name: consul</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">    - name: defult</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 8500</span><br><span class="line">    - name: http</span><br><span class="line">      port: 8500</span><br><span class="line">      targetPort: 8500</span><br><span class="line">    - name: https</span><br><span class="line">      port: 8443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">    - name: rpc</span><br><span class="line">      port: 8400</span><br><span class="line">      targetPort: 8400</span><br><span class="line">    - name: serflan-tcp</span><br><span class="line">      protocol: &quot;TCP&quot;</span><br><span class="line">      port: 8301</span><br><span class="line">      targetPort: 8301</span><br><span class="line">    - name: serflan-udp</span><br><span class="line">      protocol: &quot;UDP&quot;</span><br><span class="line">      port: 8301</span><br><span class="line">      targetPort: 8301</span><br><span class="line">    - name: serfwan-tcp</span><br><span class="line">      protocol: &quot;TCP&quot;</span><br><span class="line">      port: 8302</span><br><span class="line">      targetPort: 8302</span><br><span class="line">    - name: serfwan-udp</span><br><span class="line">      protocol: &quot;UDP&quot;</span><br><span class="line">      port: 8302</span><br><span class="line">      targetPort: 8302</span><br><span class="line">    - name: server</span><br><span class="line">      port: 8300</span><br><span class="line">      targetPort: 8300</span><br><span class="line">    - name: consuldns</span><br><span class="line">      port: 8600</span><br><span class="line">      targetPort: 8600</span><br><span class="line">  selector:</span><br><span class="line">    app: consul</span><br></pre></td></tr></table></figure><h2 id="应用ingress"><a href="#应用ingress" class="headerlink" title="应用ingress"></a>应用ingress</h2><blockquote><p>需要先部署ingress-nginx</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: consul</span><br><span class="line">  namespace: public-service</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: consul.example.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: consul</span><br><span class="line">              servicePort: 80</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分布式特性</title>
      <link href="2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/"/>
      <url>2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="分布式特性"><a href="#分布式特性" class="headerlink" title="分布式特性"></a>分布式特性</h2><p>es支持集群模式，是一个分布式系统，主要有以下好处：</p><ul><li>增大系统容量，如内存、磁盘，使得es集群可以支持PB级的数据</li><li>提高系统可用性，即使部分节点停止服务，整个集群依然可以提供正常服务</li></ul><p>es集群由多个es实例组成：</p><ul><li>不同集群通过集群名称来区分，可通过cluster.name进行配置</li><li>每个es实例本质上是一个JVM进程，通过node.name配置实例名称</li></ul><h2 id="Cluster-State"><a href="#Cluster-State" class="headerlink" title="Cluster State"></a>Cluster State</h2><p>es集群相关的数据称为cluster state，主要记录如下信息：</p><ul><li>节点信息，比如索引名称、连接地址等</li><li>索引信息：比如索引名称、配置等</li><li>……</li></ul><h2 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h2><p>一个集群只能有一个Master，只有master可以修改cluster state</p><p>cluster state存储在每个节点上，master维护最新版本并同步给其他节点</p><p>master节点是通过集群中所有节点选举产生的，可以被选举的节点称为master-eligible，可以通过node.master配置哪些节点可以被选举</p><h2 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node"></a>Coordinating Node</h2><p>处理请求的节点称为coordinating节点，该节点为所有节点的默认角色，不能取消</p><ul><li>路由请求到正确的节点处理，比如创建索引的请求到master节点</li></ul><h2 id="Data-Node"><a href="#Data-Node" class="headerlink" title="Data Node"></a>Data Node</h2><p>存储数据的节点称为data节点，默认所有节点都是data节点，可以通过配置node.data配置哪些节点可以存储数据</p><h2 id="系统可用性"><a href="#系统可用性" class="headerlink" title="系统可用性"></a>系统可用性</h2><p>服务可用性：2个节点的情况下，允许其中1个节点停止服务</p><p>数据可用性：（1）引入副本（Replication）解决（2）每个节点上都有完备的数据</p><p>es提供集群使得服务实现可用性，引入副本，例如test_index在es-01实例的节点上，那么test_index有一个数据副本存储在另一台节点之上</p><h2 id="增大系统容量"><a href="#增大系统容量" class="headerlink" title="增大系统容量"></a>增大系统容量</h2><p>es引入分片（Shard）的概念来使数据分布在所有节点上，分片使得es能够支持PB级数据</p><ul><li>分片存储了部分数据，可以分布在任意节点</li><li>分片数在索引创建时指定，并且后续不允许在修改</li><li>分片有主分片和副本分片之分，副本分片也就是上面提到的副本（Replication），实现数据可用性</li></ul><h2 id="Cluster-Health"><a href="#Cluster-Health" class="headerlink" title="Cluster Health"></a>Cluster Health</h2><p>可以通过下面API查看集群健康状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XGET http:&#x2F;&#x2F;localhost:9200&#x2F;_cluster&#x2F;health?pretty</span><br></pre></td></tr></table></figure><p>集群的健康状态有3种：</p><ul><li>green：健康状态，所有主副分片都正常分配</li><li>yellow：所有主分片都正常分配，但是有副本分片未正常分配</li><li>red：有主分片未分配</li></ul><h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><p>集群中的各个节点都会互相的做心跳检测，当es-02和es-03发现es-01无法响应后，会发起master选举</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/a1.png"></p><p>假如es-02被选举成为新的master后，由于主分片P0下线，集群状态变为Red</p><p>master（es-02）认为P0未被分配，就将其副本R0提升为P0，此时，所有主分片都被分配，但仍有副本分片未分配，集群状态变为Yello</p><p>master（es-02）会为P0和P2生成新的副本，集群状态变为绿色</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/a2.png"></p><h2 id="文档分布式存储"><a href="#文档分布式存储" class="headerlink" title="文档分布式存储"></a>文档分布式存储</h2><h3 id="文档存储"><a href="#文档存储" class="headerlink" title="文档存储"></a>文档存储</h3><p>es通过下面算法计算文档存储在哪个分片上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shard &#x3D; hash(routing) % numbers_of_primary_shards</span><br></pre></td></tr></table></figure><ul><li>hash算法可以保证文档均匀的分散在所有分片上</li><li>routing是一个关键参数，默认是文档id，也可以自行指定</li><li>numbers_of_primary_shards为主分片数</li></ul><h3 id="文档创建与读取流程"><a href="#文档创建与读取流程" class="headerlink" title="文档创建与读取流程"></a>文档创建与读取流程</h3><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/a3.png"></p><h4 id="文档创建流程"><a href="#文档创建流程" class="headerlink" title="文档创建流程"></a>文档创建流程</h4><ul><li>client发送创建文档的请求到es-03</li><li>es-03通过routing算法计算该文档应该存储在P2分片，查询cluster state后得知P2分片在es-02上，然后将创建文档的请求发给es-02</li><li>P2接收到请求并且执行创建文档的请求，然后将同样的请求发送给副本R2</li><li>R2接收并执行创建文档请求后，通知P2成功的结果</li><li>P2接收副本分片R2结果后，返回成功给es-02</li><li>es-02返回结果给client</li></ul><h4 id="文档读取流程"><a href="#文档读取流程" class="headerlink" title="文档读取流程"></a>文档读取流程</h4><ul><li>client向es-03发送获取文档的请求</li><li>es-03通过routing算法计算该文档存储在P2，查询cluster state得知主分片P2、副本分片R2列表，然后以轮询的机制获取一个分片，比如这里是R2，就将请求转发到es-01</li><li>R2接收并执行读取文档请求，将结果返回给es-03</li><li>es-03返回结果给client</li></ul><h4 id="文档批量创建流程"><a href="#文档批量创建流程" class="headerlink" title="文档批量创建流程"></a>文档批量创建流程</h4><ul><li>client向es-03发送批量创建文档的请求（bulk）</li><li>es-03通过routing计算所有文档的分片，然后按照主分片分配对应的执行操作，同时发送请求到涉及的主分片</li><li>主分片接收请求并执行，将同样的请求同步到副本分片</li><li>副本分片执行后将结果返回给主分片</li><li>主分片获得副本分片执行结果，返回给es-03</li><li>es-03将结果返回给client</li></ul><h4 id="文档批量读取流程"><a href="#文档批量读取流程" class="headerlink" title="文档批量读取流程"></a>文档批量读取流程</h4><ul><li>client向es-03发送批量读取文档的请求（mget）</li><li>es-03通过routing计算所有文档对应的分片，然后以轮询的机制获取参与的分片，按照分片构建mget请求，同时发送请求到涉及的分片</li><li>涉及处理请求的分片将结果返回给es-03</li><li>es-03返回结果给client</li></ul><h3 id="文档搜索实时性"><a href="#文档搜索实时性" class="headerlink" title="文档搜索实时性"></a>文档搜索实时性</h3><p>es会将文档写入倒排索引，倒排索引一旦生成，不能修改，其好处有：</p><ul><li>不用考虑并发写文件问题，杜绝锁机制带来的性能问题</li><li>由于文件不在更改，可充分利用文件系统缓存</li><li>利于对文件进行压缩存储</li></ul><p>其坏处为需要写入新文档时，必须重新构建倒排索引文件，然后代替老文件，新文件才能被索引，导致文档实时性差。解决方案就是写入的新文档直接生成新的倒排索引文件，查询时同时将请求引导到所有的索引文件，然后做结果汇总计算。</p><p>Lucene采用这种方案，它构建的单个倒排索引称为segment，合在一起称为Index，ES中的一个shard对应Lucene Index，Lucene 会有一个专门的文件来记录所有的 segment 信息，称为 commit point。</p><h4 id="refresh"><a href="#refresh" class="headerlink" title="refresh"></a>refresh</h4><p>segment写入磁盘的过程依然很耗时，可以借助文件系统缓存的特性，将segment在缓存中创建并开放查询来进一步提高文档实时性，该过程在ES里面称为refresh。</p><p>在refresh之前，文档会先存储在一个buffer中，refresh时将buffer中的所有文档清空并生成segment</p><p>es默认每1秒执行一次refresh，refresh发生时机主要有以下几种情况：</p><ul><li>间隔时间到达，通过index.setting.refresh.interval来设定</li><li>index buffer占满时，其大小通过indices.memory.index_buffer.size设置，默认为JVM heap的10%，所有分片共享</li><li>flush发生时也会触发refresh</li></ul><h4 id="translog"><a href="#translog" class="headerlink" title="translog"></a>translog</h4><p>如果在内存中的segment还没有写入磁盘前宕机，那么其中的文档也就无法恢复，es为了解决这个问题，引入translog机制</p><ul><li>写入文档到buffer，同时将该操作写入translog</li><li>translog会及时写入到磁盘（fsync），相关配置 index.translog.*</li><li>es启动时检查translog文件，从中恢复数据</li></ul><h4 id="flush"><a href="#flush" class="headerlink" title="flush"></a>flush</h4><p>flush负责的主要工作如下：</p><ul><li>将translog写入磁盘</li><li>将index buffer清空，其中的文档生成一个新的segment，相当于refresh操作</li><li>更新commit point并写入磁盘</li><li>执行fsync操作，将内存中的segment写入磁盘</li><li>删除旧的translog文件</li></ul><p>flush发生的时机主要如下几种情况：</p><ul><li>间隔时间到达，通过index.translog.flush_threshold_period参数</li><li>translog占满时，其大小可以通过index.translog.flush_threshold_size控制，默认512MB，每个index都有自己的translog</li></ul><h4 id="删除与更新文档"><a href="#删除与更新文档" class="headerlink" title="删除与更新文档"></a>删除与更新文档</h4><p>segment一旦生成就不能修改，Lucene专门维护一个.del文件，记录所有已经删除的文档，.del 文档上记录的是文档在 Lucene 内部记录的 ID；在查询结果返回前会过滤掉 .del 中的所有文档</p><h4 id="Segment-merge"><a href="#Segment-merge" class="headerlink" title="Segment merge"></a>Segment merge</h4><p>随着segment的增多，一次查询segment数量增多，查询变慢，es会定时的进行segment merge操作，减少segment的数量，也可以通过 force_merge API 可以手动强制做 segment merge 的操作。</p><h2 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h2><p>脑裂问题是分布式系统的经典问题，例如下图：</p><ul><li>集群的各个es实例都会互相做心跳检测，当es-01的心跳线出现问题时，无法与es-02和es-03进行通信</li><li>es-02和es-03会进行选举master，比如es-02称为新的master，此时会更新cluster state</li><li>es-01也会检测到无法与es-02和es-03通信，然后自己会组件集群，也会更新cluster state</li></ul><p>这样子就会同时存在2个master和数据存在2个差异的cluster state，当心跳线恢复之后，无法正确选出master</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/26/ElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/a1.png"></p><p>解决方法：</p><p>在可选举的master-eligible节点大于等于quorum时才可以进行选举</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">quorum &#x3D; master-eligible 节点数 &#x2F; 2 + 1</span><br></pre></td></tr></table></figure><p>就如上面所说，心跳线出现问题时，整个集群被一分为二</p><ul><li>左侧是1个节点数，master-eligible=1，quorum=1/2+1，即不满足master-eligible节点大于等于quorum条件，无法进行选举</li><li>右侧2个节点，master-eligible=2，quorum=2/2+1，即满足master-eligible节点大于等于quorum条件，可以进行选举</li></ul><p>es提供 discover.zen.minimum_master.nodes参数，设定其值为quorum即可避免脑裂问题</p>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch集群org.elasticsearch.discovery.MasterNotDiscoveredException问题</title>
      <link href="2021/01/26/ElasticSearch%E9%9B%86%E7%BE%A4org-elasticsearch-discovery-MasterNotDiscoveredException%E9%97%AE%E9%A2%98/"/>
      <url>2021/01/26/ElasticSearch%E9%9B%86%E7%BE%A4org-elasticsearch-discovery-MasterNotDiscoveredException%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>三台es实例的集群日志出现org.elasticsearch.discovery.MasterNotDiscoveredException问题</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[WARN ][r.suppressed] [elasticsearch-01] path: &#x2F;_cat&#x2F;health, params: &#123;pretty&#x3D;, v&#x3D;&#125;</span><br><span class="line">org.elasticsearch.discovery.MasterNotDiscoveredException: null </span><br><span class="line">at org.elasticsearch.action.support.master.TransportMasterNodeAction$AsyncSingleAction$4.onTimeout(TransportMasterNodeAction.java:259) [elasticsearch-7.1.0.jar:7.1.0]</span><br><span class="line">    at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onTimeout(ClusterStateObserver.java:322) [elasticsearch-7.1.0.jar:7.1.0]</span><br><span class="line">    at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onTimeout(ClusterStateObserver.java:249) [elasticsearch-7.1.0.jar:7.1.0]</span><br><span class="line">    at org.elasticsearch.cluster.service.ClusterApplierService$NotifyTimeout.run(ClusterApplierService.java:555) [elasticsearch-7.1.0.jar:7.1.0]</span><br><span class="line">    at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.1.0.jar:7.1.0]</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_11]</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_11]</span><br><span class="line">    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_11]</span><br></pre></td></tr></table></figure><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>（1）确认hostname配置正确</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $&#123;HOSTNAME&#125;</span><br></pre></td></tr></table></figure><p>（2）确认elasticsearch.yml文件下面配置项正确</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 三台实例保证相同</span><br><span class="line">cluster.name: my-cluster</span><br><span class="line"># 设置成对应的 $&#123;HOSTNAME&#125;</span><br><span class="line">node.name: es-01</span><br><span class="line"># 设置成三台实例的 $&#123;HOSTNAME&#125;</span><br><span class="line">discovery.seed_hosts: [&quot;es-01&quot;, &quot;es-02&quot;, &quot;es-03&quot;]</span><br><span class="line">cluster.initial_master_nodes: [&quot;es-01&quot;, &quot;es-02&quot;, &quot;es-03&quot;]</span><br></pre></td></tr></table></figure><p>（3）如果上面都确认过了，还是出现该错误，那么再调整日志级别，打印更详细的日志</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">logger.org.elasticsearch.cluster.coordination.ClusterBootstrapService: TRACE</span><br><span class="line">logger.org.elasticsearch.discovery: TRACE</span><br></pre></td></tr></table></figure><p>我的机器由2网卡enp0s3、enp0s8，我通过调整日志级别后，在日志中发现es自动发现集群node从各个机器的enp0s3上10.0.2.15的IP上发现，应该是network.host绑定0.0.0.0导致的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 增加 network.publish_host 配置</span><br><span class="line">network.publish_host: 192.168.1.100</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch之Search</title>
      <link href="2021/01/23/ElasticSearch%E4%B9%8BSearch/"/>
      <url>2021/01/23/ElasticSearch%E4%B9%8BSearch/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>es提供Search API使我们能够对es中存储的数据进行查询分析，endpoint为_search，有以下查询形式：</p><ul><li>GET /_search</li><li>GET /my_index/_search</li><li>GET /my_index1,my_index2/_search</li><li>GET /my_*/_search</li></ul><h2 id="URI-Search"><a href="#URI-Search" class="headerlink" title="URI Search"></a>URI Search</h2><p>通过url query参数来实现查询，常用参数如下：</p><p>q 指定查询的语句，默认语法 Query String Syntax</p><p>df q中不指定字段时默认查询的字段，如果不指定，es会查询所有字段</p><p>sort 排序，asc升序 desc降序</p><p>timeout 指定超时时间，默认不超时</p><p>from,size 用于分页</p><h3 id="范查询"><a href="#范查询" class="headerlink" title="范查询"></a>范查询</h3><p>在所有字段中匹配 alfred 的值,返回相关匹配的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 开启profile参数可以对查询效率优化</span><br><span class="line">GET test_search&#x2F;_search?q&#x3D;alfred</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="指定字段查询"><a href="#指定字段查询" class="headerlink" title="指定字段查询"></a>指定字段查询</h3><p>查找username含有alfred的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alfred</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred或 所有字段中匹配way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># alfred和way之间的空格会被当做“或” 即查找username:alfred 或者 查找所有含有way的文档，way查询会被当成范查询，在所有字段中查找</span><br><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alfred way</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:&quot;alfred way&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred或者username含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:(alfred way)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="布尔操作符"><a href="#布尔操作符" class="headerlink" title="布尔操作符"></a>布尔操作符</h3><ul><li>AND（&amp;&amp;）、OR（||）、NOT（!）</li><li>+-分别对应must和must not</li></ul><blockquote><p>+在url中会被解析成空格，要使用%2B代替</p></blockquote><p>查找username含有alfred 且 所有字段中匹配way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># alfred只会在username中查找，way的查询会使用范查询</span><br><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alfred AND way</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred且username含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:(alfred AND way)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred且username不含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:(alfred NOT way)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred且username含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:(alfred %2Bway)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h3><p>支持数字和日期</p><p>（1）区间写法</p><ul><li>age:[1 TO 10] 意为 1&lt;=age&lt;=10</li><li>age:[1 TO 10} 意为 1&lt;=age&lt;10</li><li>age:[1 TO ] 意为 age&gt;=1</li><li>age:[* TO 10] 意为 age&lt;=10</li></ul><p>（2）算数符号写法</p><ul><li>age:&gt;=1</li><li>age:(&gt;=1 &amp;&amp; &lt;=10) 或者 age:(+&gt;1 +&lt;10)</li></ul><p>查找username含有alfred或者age大于20的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alfred age:&gt;20</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找birth在1980到1990之间的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;birth:(&gt;1980 AND &lt;1990)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通配符查询"><a href="#通配符查询" class="headerlink" title="通配符查询"></a>通配符查询</h3><p>通配符匹配执行效率低，且占用较多内存，不建议使用</p><blockquote><p>如无特殊需求，不要将 ?/* 放在最前面</p></blockquote><p>?代表1个字符， *代表0或多个字符</p><ul><li>name:t?m</li><li>name:torn*</li><li>name:t*m</li></ul><p>查找username含有alf开头的所有文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alf*</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>与通配符类似，正则表达式也比较持内存</p><h3 id="模糊匹配"><a href="#模糊匹配" class="headerlink" title="模糊匹配"></a>模糊匹配</h3><ul><li>name:roam~1</li><li>匹配与roam差一个词，比如 foam roams等</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:alfed~1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="近似度查询"><a href="#近似度查询" class="headerlink" title="近似度查询"></a>近似度查询</h3><ul><li>“fox quick”~5</li><li>以term为单位进行差异比较，比如”quick fox” “quick brown fox” 都会被匹配，允许有5个单位的差异</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?q&#x3D;username:&quot;alfred&quot;~1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;profile&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Query-DSL"><a href="#Query-DSL" class="headerlink" title="Query DSL"></a>Query DSL</h2><p>基于JSON定义的查询语言，主要分为字段类查询和复合查询</p><h3 id="字段类查询"><a href="#字段类查询" class="headerlink" title="字段类查询"></a>字段类查询</h3><p>主要分为以下2类</p><p>（1）全文匹配</p><p>针对text类型的字段进行全文检索，会对查询语句先进行分词处理，如match、match_path、等query类型</p><p>（2）单词匹配</p><p>不会对查询语句做分词处理，会直接匹配字段的倒排索引，如term、terms、range等query类型</p><h4 id="match"><a href="#match" class="headerlink" title="match"></a>match</h4><p>查找username含有alfred或者username含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 会将 alfred way 先进行分词</span><br><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &quot;alfred way&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找username含有alfred且username含有way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 提供 operator 参数控制查询语法且或关系，operator默认为or</span><br><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &quot;alfred way&quot;,</span><br><span class="line">        &quot;operator&quot;: &quot;and&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找 username含有alfred、username含有way、username含有room 至少满足2个条件的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># username中含有alfred、way、room三个单词，只要满足含有其他任意2个，就匹配</span><br><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &quot;alfred way room&quot;,</span><br><span class="line">        &quot;minimum_should_match&quot;: &quot;2&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="match-phrase"><a href="#match-phrase" class="headerlink" title="match_phrase"></a>match_phrase</h4><p>以字段作检索，词语查询，顺序检索</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &quot;alfred way&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用slop参数可以控制查询词语的差异，这里就是最多允许有一个单词的差异</span><br><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &quot;alfred way&quot;,</span><br><span class="line">        &quot;slop&quot;: &quot;1&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="query-string"><a href="#query-string" class="headerlink" title="query_string"></a>query_string</h4><p>完全类似于上面url方式的查询</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;default_field&quot;: &quot;username&quot;,</span><br><span class="line">      &quot;query&quot;: &quot;alfred AND way&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;fields&quot;: [</span><br><span class="line">          &quot;username&quot;,</span><br><span class="line">          &quot;job&quot;</span><br><span class="line">      ]</span><br><span class="line">      &quot;query&quot;: &quot;alfred OR (way AND room)&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="simple-query-string"><a href="#simple-query-string" class="headerlink" title="simple_query_string"></a>simple_query_string</h4><p>类似query_string,但是会忽略错误的查询语法，并且仅支持部分查询语法</p><p>不能使用AND、OR、NOT等关键词</p><ul><li>+代指AND</li><li>|代指OR</li><li>-代指NOT</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;fields&quot;: [</span><br><span class="line">          &quot;username&quot;</span><br><span class="line">      ]</span><br><span class="line">      &quot;query&quot;: &quot;alfred | way&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="term"><a href="#term" class="headerlink" title="term"></a>term</h4><p>将查询语句作为整个单词进行查询，即不对查询的语句进行分词</p><p>查询username含有alfred的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &quot;alfred&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询username含有alfred way的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># alfred way会被作为一整块在倒排索引中查找</span><br><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: &quot;alfred way&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="terms"><a href="#terms" class="headerlink" title="terms"></a>terms</h4><p>查询某个字段里含有多个关键词的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;username&quot;: [</span><br><span class="line">        &quot;alfred&quot;,</span><br><span class="line">        &quot;way&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="range"><a href="#range" class="headerlink" title="range"></a>range</h4><p>范围查询主要针对数值和日期类型</p><p>查询age大于等于10，小于等于20的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;range&quot;: &#123;</span><br><span class="line">      &quot;age&quot;: &#123;</span><br><span class="line">        &quot;gte&quot;: 10,</span><br><span class="line">        &quot;lte&quot;: 20</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询birth大于等于1990-01-01的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;range&quot;: &#123;</span><br><span class="line">      &quot;birth&quot;: &#123;</span><br><span class="line">        &quot;gte&quot;: &quot;1990-01-01&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询 birth大于等于当前时间-30年的文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;range&quot;: &#123;</span><br><span class="line">      &quot;birth&quot;: &#123;</span><br><span class="line">        &quot;gte&quot;: &quot;now-30y&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="复合查询"><a href="#复合查询" class="headerlink" title="复合查询"></a>复合查询</h3><p>指包含字段类查询或复合查询类型，主要包含：</p><ul><li>constant_soure query</li><li>bool query</li><li>dis_max query</li><li>function_score query</li><li>boosting query</li></ul><h4 id="bool-query"><a href="#bool-query" class="headerlink" title="bool query"></a>bool query</h4><p>它由一个或多个子句组成，每个子句都有特定的类型：</p><p>must：返回的文档必须满足must子句的条件，并且计算相关性得分</p><p>filter：返回的文档必须满足filter子句条件，但是不计算相关性得分</p><p>must_not：返回的文档必须不满足must_not条件</p><p>should：如果查询中指包含should（不包含must），文档至少满足一个条件（但是可以通过minimum_should_match控制满足条件的个数或者百分比）；如果同时存在should和must，文档不必满足should条件，如果满足should条件，可以增加相关性得分</p><h2 id="Count-API"><a href="#Count-API" class="headerlink" title="Count API"></a>Count API</h2><p>获取符合条件的文档数，endpoint为_count</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_count</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;range&quot;: &#123;</span><br><span class="line">      &quot;birth&quot;: &#123;</span><br><span class="line">        &quot;gte&quot;: &quot;now-30y&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Source-Filtering"><a href="#Source-Filtering" class="headerlink" title="Source Filtering"></a>Source Filtering</h2><p>过滤返回结果中_source中的字段，主要有以下几种方式：</p><p>（1）url参数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search?_source&#x3D;username</span><br></pre></td></tr></table></figure><p>（2）不返回_source</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_source&quot;: false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）返回部分字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_source&quot;: [&quot;username&quot;,&quot;age&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test_search&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;includes&quot;: &quot;*i*&quot;,</span><br><span class="line">    &quot;excludes&quot;: &quot;birth&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch之mapping</title>
      <link href="2021/01/23/ElasticSearch%E4%B9%8Bmapping/"/>
      <url>2021/01/23/ElasticSearch%E4%B9%8Bmapping/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Mapping类似于数据库中的表结构定义，主要作用如下：</p><ul><li>定义 Index 下的字段名（Field Name）</li><li>定义字段的类型，比如数值型、字符型、布尔型等</li><li>定义倒排索引相关的配置，比如是否索引、记录position等</li></ul><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>核心数据类型：</p><ul><li><p>字符串型 text、keyword</p></li><li><p>数值型：log、integer、short、byte、double、float、half_float、scaled_float</p></li><li><p>布尔：boolean</p></li><li><p>日期：date</p></li><li><p>二进制：binary</p></li><li><p>范围类型：integer_range、float_range、long_range、double_range、date_range</p></li></ul><p>复杂数据类型：</p><ul><li>数组类型 array</li><li>对象类型 object</li><li>嵌套类型 nested object</li></ul><p>地理位置数据类型：</p><ul><li>geo_point</li><li>geo_shape</li></ul><p>专用类型：</p><ul><li>记录ip地址 ip</li><li>实现自动补全 completion</li><li>记录分词数 token_count</li><li>记录字符串hash值 murmur3</li><li>percolator</li><li>join</li></ul><p>多字段特征 multi-fields：</p><ul><li>允许对同一个字段采用不同的配置，比如对人名可以进行拼音搜索</li></ul><h2 id="自定义Mapping"><a href="#自定义Mapping" class="headerlink" title="自定义Mapping"></a>自定义Mapping</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;title&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;age&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E4%B9%8Bmapping/a1.png"></p><h2 id="dynamic参数"><a href="#dynamic参数" class="headerlink" title="dynamic参数"></a>dynamic参数</h2><p>Mapping中的字段类型一旦设定后，就禁止直接修改，主要原因是Lucene为了提高效率，不允许直接修改mapping，一旦修改，会影响倒排索引的方式。但是允许我们新增字段，通过dynamic参数来控制字段的新增：</p><ul><li>true：默认，允许自动新增字段</li><li>false：不允许自动新增字段，但是文档可以正常写入，但无法对该字段进行查询等操作</li><li>strict：文档不能写入，报错</li></ul><p>新增otherField字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;otherField&quot;:&quot;someValue&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以查询到otherField字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST put_mapping&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;otherField&quot;: &quot;someValue&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改dynamic为false</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E4%B9%8Bmapping/a2.png"></p><p>新增anotherField字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;anotherField&quot;:&quot;someValue&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询，anotherField没有被查到</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST put_mapping&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;anotherField&quot;: &quot;someValue&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改dynamic为strict</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping&#x2F;_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;dynamic&quot;: &quot;strict&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>新增字段会直接报错</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping&#x2F;_doc&#x2F;2</span><br><span class="line">&#123;</span><br><span class="line">  &quot;anotherField1&quot;:&quot;someValue&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="copy-to参数"><a href="#copy-to参数" class="headerlink" title="copy_to参数"></a>copy_to参数</h2><p>将该字段的值复制到目标字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;first_name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;copy_to&quot;: &quot;full_name&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;last_name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;copy_to&quot;: &quot;full_name&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;full_name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping1&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;first_name&quot;: &quot;John&quot;,</span><br><span class="line">  &quot;last_name&quot;: &quot;Smith&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>根据full_name查询文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET put_mapping1&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;full_name&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &quot;John Smith&quot;</span><br><span class="line">        , &quot;operator&quot;: &quot;and&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="index参数"><a href="#index参数" class="headerlink" title="index参数"></a>index参数</h2><p>控制当前字段是否索引，默认为true，即记录索引，false不记录索引，即不可搜索</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping2</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        </span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;age&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;long&quot;,</span><br><span class="line">        &quot;index&quot;: false</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping2&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John&quot;,</span><br><span class="line">  &quot;age&quot;: 20</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>根据age字段搜索</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET put_mapping2&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;age&quot;: 20</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="index-options参数"><a href="#index-options参数" class="headerlink" title="index_options参数"></a>index_options参数</h2><p>用于控制倒排索引记录的内容，有如下4种配置</p><ul><li>docs 只记录doc id</li><li>freqs 记录doc id 和 term frequencies</li><li>positions 记录 doc id、term frequencies、term position</li><li>offsets 记录 doc id、term frequencies、term position、character offsets</li></ul><blockquote><p>text类型默认配置为positions，其他默认为docs，记录越多，占用空间越大</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping3</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        , &quot;index_options&quot;: &quot;positions&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;age&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;long&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="null-value"><a href="#null-value" class="headerlink" title="null_value"></a>null_value</h2><p>当字段遇到null值时处理的策略，默认为null，此时es会忽略，可以设置该值，来设定字段的默认值</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping4</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;age&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;long&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;sex&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">        &quot;null_value&quot;: &quot;男&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="dynamic-mapping"><a href="#dynamic-mapping" class="headerlink" title="dynamic mapping"></a>dynamic mapping</h2><p>es会根据json数据类型自动识别文档的字段类型，从而降低用户使用的成本</p><table><thead><tr><th>JSON类型</th><th>ElasticSearch类型</th></tr></thead><tbody><tr><td>null</td><td>忽略</td></tr><tr><td>boolean</td><td>boolean</td></tr><tr><td>浮点数</td><td>float</td></tr><tr><td>整数</td><td>long</td></tr><tr><td>object</td><td>object</td></tr><tr><td>array</td><td>由第一个非null类型决定</td></tr><tr><td>string</td><td>匹配为日期设为date（默认开启）；匹配数字的话设为float或long（默认关闭）；设为text类型，附带keyword子字段</td></tr></tbody></table><p>创建一个文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping4&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John&quot;,</span><br><span class="line">  &quot;age&quot;: 20,</span><br><span class="line">  &quot;birth&quot;: &quot;1996-10-01&quot;,</span><br><span class="line">  &quot;married&quot;: false,</span><br><span class="line">  &quot;year&quot;: &quot;2021&quot;,</span><br><span class="line">  &quot;tags&quot;: [&quot;boy&quot;,&quot;fashion&quot;],</span><br><span class="line">  &quot;money&quot;: 100.01</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看数据类型</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET put_mapping4&#x2F;_mapping</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E4%B9%8Bmapping/a3.png"></p><h2 id="日期识别"><a href="#日期识别" class="headerlink" title="日期识别"></a>日期识别</h2><p>es默认的日志识别格式是：</p><ul><li>strict_date_optional_time ISO datetime格式</li><li>yyyy/MM/dd HH:mm:ss Z</li><li>yyyy/MM/dd Z</li></ul><p>日期的自动识别可以自行配置日期格式，以满足自己特定的需求：</p><ul><li>dynamic_date_formats 可以自定义日期格式</li><li>date_detection 可以关闭日期自动识别机制</li></ul><p>创建一个 MM/dd/yyyy 日期识别机制</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;dynamic_date_formats&quot;: [&quot;MM&#x2F;dd&#x2F;yyyy&quot;], </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT put_mapping&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John&quot;,</span><br><span class="line">  &quot;age&quot;: 20,</span><br><span class="line">  &quot;birth&quot;: &quot;10&#x2F;01&#x2F;1996&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E4%B9%8Bmapping/a4.png"></p><p>设置date_detection为false，关闭日期自动识别</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E4%B9%8Bmapping/a5.png"></p><h2 id="数字识别"><a href="#数字识别" class="headerlink" title="数字识别"></a>数字识别</h2><p>es默认不会在字符串中自动识别数字，可以通过 numeric_detection 开启字符串中数字的自动识别</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;numeric_detection&quot;: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="dynamic-templates"><a href="#dynamic-templates" class="headerlink" title="dynamic templates"></a>dynamic templates</h2><p>允许es自动识别数据类型、字段名来动态设定字段类型，可实现如下效果：</p><ul><li>所有字符串都设定为keyword类型</li><li>所有以message开头的字段都设定为text类型</li><li>所有以log_开头的字段都设定为long类型</li><li>所有自动匹配为double类型的都设为float类型，以节省空间</li></ul><p>匹配规则一般有如下几个参数：</p><ul><li>match_mapping_type 匹配es自动识别的字段类型</li><li>match,unmatch 匹配字段名</li><li>path_match,path_unmatch 匹配路径</li></ul><p>将所有自动匹配string类型的都设定为keyword类型</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;strings_as_keywords&quot;: &#123;</span><br><span class="line">          &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">          &quot;mapping&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keywaord&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;  </span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将所有以message开头的都设定为text类型</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;put_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;message_as_text&quot;: &#123;</span><br><span class="line">          &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">          &quot;match&quot;: &quot;message&quot;,</span><br><span class="line">          &quot;mapping&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;  </span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分词</title>
      <link href="2021/01/23/ElasticSearch%E5%88%86%E8%AF%8D/"/>
      <url>2021/01/23/ElasticSearch%E5%88%86%E8%AF%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>分词器是es中专门处理分词的组件，就是按照一定的逻辑，将一段文本分析成多个词语的工具</p><p>分词器组成如下：</p><ul><li>character filters：针对原始文本进行处理，比如去除html特殊标记符</li><li>tokenizer：将原始文本按照一定规则切分为单词</li><li>token filters：针对tokenizer处理的单词进行再加工，比如转小写、删除或新增等处理</li></ul><h2 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h2><p>es自带了以下的分词器：</p><ul><li>standard（默认）</li><li>simple</li><li>whitespace</li><li>stop</li><li>keyword</li><li>pattern</li><li>language</li></ul><h2 id="Standard-Analyzer"><a href="#Standard-Analyzer" class="headerlink" title="Standard Analyzer"></a>Standard Analyzer</h2><p>标准分词器是默认分词器，如未指定，则使用该分词器</p><p>描述&amp;特征：</p><ul><li>默认分词器，如果未指定，则使用该分词器</li><li>按词切分，支持多语言</li><li>小写处理，它删除大多数标点符号、小写术语，并支持删除停止词</li></ul><p>standard由以下组成：</p><ul><li>tokenizer：standard tokenizer</li><li>token filter：standard token filter 、lower case token filter、stop token filter</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;standard&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生以下结果</p><p>[2, running, quick, brown, foxes, leap, over, lazy, dogs, in, the, summer, evening]</p><h2 id="Simple-Analyzer"><a href="#Simple-Analyzer" class="headerlink" title="Simple Analyzer"></a>Simple Analyzer</h2><p>描述&amp;特征：</p><ul><li>按照非字母切分</li><li>小写处理</li></ul><p>standard由以下组成：</p><ul><li>tokenizer：Lower Case Tokenizer</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;simple&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生以下结果</p><p>[running, quick, brown, foxes, leap, over, lazy, dogs, in, the, summer, evening]</p><h2 id="Whitespace-Analyzer"><a href="#Whitespace-Analyzer" class="headerlink" title="Whitespace Analyzer"></a>Whitespace Analyzer</h2><p>描述&amp;特征：</p><ul><li>空白字符作为分隔符，当遇到任何空白字符，空白分词器将文本分成术语</li></ul><p>whitespace由以下组成：</p><ul><li>Tokenizer：Whitespace Tokenizer</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;whitespace&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生以下结果</p><p>[2, running, Quick, brown, foxes, leap, over, lazy, dogs, in, the, summer, evening.]</p><h2 id="Stop-Analyzer"><a href="#Stop-Analyzer" class="headerlink" title="Stop Analyzer"></a>Stop Analyzer</h2><p>描述&amp;特征：</p><ul><li>删除停止词，停止词指 the、an、的、这等等</li></ul><p>stop由以下组成：</p><ul><li>Tokenizer：Lower Case Tokenizer</li><li>Token Filters：Stop Token Filter</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;stop&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生以下结果</p><p>[running, quick, brown, foxes, leap, over, lazy, dogs, summer, evening]</p><h2 id="Keyword-Analyze"><a href="#Keyword-Analyze" class="headerlink" title="Keyword Analyze"></a>Keyword Analyze</h2><p>描述&amp;特征：</p><ul><li>不分词，直接将输入作为一个单词输出</li></ul><p>keyword由以下组成：</p><ul><li>Tokenizer：Keyword Tokenizer</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;keyword&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生以下结果</p><p>[2 running Quick brown-foxes leap over lazy dogs in the summer evening.]</p><h2 id="Pattern-Analyzer"><a href="#Pattern-Analyzer" class="headerlink" title="Pattern Analyzer"></a>Pattern Analyzer</h2><p>描述&amp;特征：</p><ul><li>通过正则表达式自定义分隔符，默认是\W+，即非字词的符号作为分隔符</li></ul><p>pattern由以下组成：</p><ul><li>Tokenizer：Pattern Tokenizer</li><li>Token Filters：Lower case Token Filter、Stop Token Filter</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;analyzer&quot;: &quot;pattern&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>[2, running, quick, brown, foxes, leap, over, lazy, dogs, in, the, summer, evening]</p><h2 id="Language-Analyzers"><a href="#Language-Analyzers" class="headerlink" title="Language Analyzers"></a>Language Analyzers</h2><p>es提供多语言特定的分析工具</p><h2 id="自定义分词"><a href="#自定义分词" class="headerlink" title="自定义分词"></a>自定义分词</h2><p>当自带的分词无法满足需求时，可以自定义分词，自定义分词主要通过自定义Character Filters、Tokenizer和Token Filter实现</p><h3 id="Character-Filters"><a href="#Character-Filters" class="headerlink" title="Character Filters"></a>Character Filters</h3><p>在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符串等，会影响后续tokenizer解析的position和offest信息</p><p>自带的如下：</p><ul><li>HTML Strip去除html标签和转换html实体</li><li>Mapping进行字符替换操作</li><li>Pattern Replace进行正则匹配替换</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;tokenizer&quot;: &quot;keyword&quot;,</span><br><span class="line">  &quot;char_filter&quot;: [&quot;html_strip&quot;],</span><br><span class="line">  &quot;text&quot;: &quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;&#x2F;b&gt;!&lt;&#x2F;p&gt;&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生下面输出</p><p>[I’m so happy!]</p><h3 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h3><p>将原始文本按照一定规则切分为单词</p><p>自带的如下：</p><ul><li>standard 按照单词进行分割</li><li>letter 按照非字符类进行分割</li><li>whitespace 按照空格进行分割</li><li>UAX URL Email 按照standard分割，但不会分割邮箱和url</li><li>NGram和Edge NGram连词分割</li><li>Path Hierarchy 按照文件路径进行切割</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;tokenizer&quot;: &quot;path_hierarchy&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;&#x2F;es&#x2F;data&#x2F;log&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生下面输出</p><p>[/es, /es/data, /es/data/log]</p><h3 id="Token-Filters"><a href="#Token-Filters" class="headerlink" title="Token Filters"></a>Token Filters</h3><p>对tokenizer输出的单词进行增加、删除、修改等操作</p><p>自带的如下：</p><ul><li>lowercase将所有单词转换为小写</li><li>stop删除stop words</li><li>NGram和Edge NGram连词分割</li><li>Synonym添加近义词</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;text&quot;: &quot;a Hello,world!&quot;,</span><br><span class="line">  &quot;tokenizer&quot;: &quot;standard&quot;,</span><br><span class="line">  &quot;filter&quot;: [</span><br><span class="line">    &quot;stop&quot;,</span><br><span class="line">    &quot;lowercase&quot;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;ngram&quot;,</span><br><span class="line">      &quot;min_gram&quot;: 4,</span><br><span class="line">      &quot;max_gram&quot;: 4</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生下面输出</p><p>[hell, ello, worl, orld]</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_analyze?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;text&quot;: &quot;a Hello,world!&quot;,</span><br><span class="line">  &quot;tokenizer&quot;: &quot;standard&quot;,</span><br><span class="line">  &quot;filter&quot;: [</span><br><span class="line">    &quot;stop&quot;,</span><br><span class="line">    &quot;lowercase&quot;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;type&quot;: &quot;ngram&quot;,</span><br><span class="line">      &quot;min_gram&quot;: 2,</span><br><span class="line">      &quot;max_gram&quot;: 3</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>会产生下面输出</p><p>[he, hel, el, ell, ll, llo, lo, wo, wor, or, orl, rl, rld, ld]</p><h2 id="自定义分词器"><a href="#自定义分词器" class="headerlink" title="自定义分词器"></a>自定义分词器</h2><p>创建一个 my_custom_analyzer 名称的分词器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPUT http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index_1?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_custom_analyzer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;custom&quot;,</span><br><span class="line">          &quot;tokenizer&quot;: &quot;standard&quot;,</span><br><span class="line">          &quot;char_filter&quot;: [</span><br><span class="line">            &quot;html_strip&quot;</span><br><span class="line">          ],</span><br><span class="line">          &quot;filter&quot;: [</span><br><span class="line">            &quot;lowercase&quot;,</span><br><span class="line">            &quot;asciifolding&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>来个有难度的分词器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPUT http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index_2?pretty -d &#39;</span><br><span class="line">&#123; </span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_custom_analyzer2&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;custom&quot;,</span><br><span class="line">          &quot;tokenizer&quot;: &quot;punctuation&quot;,</span><br><span class="line">          &quot;char_filter&quot;: [</span><br><span class="line">            &quot;emoticons&quot;</span><br><span class="line">          ],</span><br><span class="line">          &quot;filter&quot;: [</span><br><span class="line">            &quot;lowercase&quot;,</span><br><span class="line">            &quot;english_stop&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;punctuation&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;pattern&quot;,</span><br><span class="line">          &quot;pattern&quot;: &quot;[ .,!?]&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;char_filter&quot;: &#123;</span><br><span class="line">        &quot;emoticons&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;mapping&quot;,</span><br><span class="line">          &quot;mappings&quot;: [</span><br><span class="line">            &quot;:) &#x3D;&gt; _happy_&quot;,</span><br><span class="line">            &quot;:( &#x3D;&gt; _sad_&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;english_stop&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;stop&quot;,</span><br><span class="line">          &quot;stopwords&quot;: &quot;_english_&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><p>查看效果</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/ElasticSearch%E5%88%86%E8%AF%8D/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch基本知识</title>
      <link href="2021/01/23/ElasticSearch%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"/>
      <url>2021/01/23/ElasticSearch%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>ElasticSearch是一个基于Lucene的搜索服务器，它提供一个分布式多用户的全文搜索引擎，基于REST风格的web接口</p><h2 id="常用术语"><a href="#常用术语" class="headerlink" title="常用术语"></a>常用术语</h2><ul><li>文档Document：es存储的数据是文档型的，一条数据对应一篇文档，即可以理解为mysql中的一行数据，一个文档可以有多个字段，即mysql数据库一行可以有多个列</li><li>索引Index：有具有相同字段的文档列表组成，一个文档的集合，对应mysql中的table。在es6.0之前一个index下可以创建多种type，有人将index比作database，type比作table，es6.0之后，index下只能创建一种类型的type，所以将index比作table会更好理解一点</li><li>节点Node：一个es的运行实例，是集群的构成单元</li><li>集群Cluster：由一个或多个节点组成</li></ul><h2 id="Document"><a href="#Document" class="headerlink" title="Document"></a>Document</h2><p>Document其实就是一个Json Object，由字段（Field）组成，常见的数据类型如下：</p><ul><li>字符串：text、keyword</li><li>数值型：log、integer、short、byte、double、float、half_float、scaled_float</li><li>布尔：boolean</li><li>日期：date</li><li>二进制：binary</li><li>范围类型：integer_range、float_range、long_range、double_range、date_range</li></ul><p>每一个document都有一个唯一的id标识，即对应mysql中的主键，目前可以自行指定，如未指定es将自动生成</p><p>在每一个document中都有一些元数据（document metadata），主要用来标注文档的相关信息：</p><ul><li>_index：文档所在的索引名</li><li>_type：文档所在的类型名</li><li>_id：文档唯一id</li><li>_uid：组合id，由 _type 和 _id组成 （6.x _type不再起作用，同 _id 一样）</li><li>_source：文档的原始Json数据</li><li>_all：整合所有字段内容到该字段，默认禁用</li></ul><h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h2><p>Index在数据库类似Table，Index中存储的是具有相同结构的Document，每个Index都有自己的mapping定义，用于定义字段名和类型</p><p>一个集群中可以有多个Index，比如：nginx的access.log可以按照日期每天生成一个Index来存储</p><h2 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h2><p>ElasticSearch对外提供REST API：</p><ul><li>URI指定资源，如Index、Document等</li><li>HTTP Method指明资源操作类型，如GET、POST、PUT、DELETE等</li></ul><p>常用交互方式：</p><ul><li>Curl命令行</li><li>Kibana DevTools</li></ul><h3 id="Index-API"><a href="#Index-API" class="headerlink" title="Index API"></a>Index API</h3><p>创建索引</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master ~]# curl -X PUT &#39;http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true,</span><br><span class="line">  &quot;shards_acknowledged&quot; : true,</span><br><span class="line">  &quot;index&quot; : &quot;test_index&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看索引</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master ~]# curl -X GET &#39;http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_cat&#x2F;indices?pretty&#39;</span><br><span class="line">green open filebeat-7.2.0-2021.01.20-000001 zjUeoHT4TVSSuKaLwE71Gg 1 1 4037 0   5.2mb  2.5mb</span><br><span class="line">green open .kibana_1                        9ndxc6KESMW2OAzwMSwcIw 1 1    5 0   147kb 70.6kb</span><br><span class="line">green open .kibana_task_manager             P_NssAqSSwGdUUXgVH5x7A 1 1    2 0 108.3kb 53.7kb</span><br><span class="line">green open test_index                       7lPjFgWqRWOtZX3YMZ58ew 1 1    0 0    460b   230b</span><br></pre></td></tr></table></figure><p>删除索引</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@master ~]# curl -X DELETE &#39;http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Document-API"><a href="#Document-API" class="headerlink" title="Document API"></a>Document API</h3><p>创建文档</p><blockquote><p>如果索引不存在，es会自动创建对应的index和type</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># test_index&#x2F;doc&#x2F;1 表示 索引名称&#x2F;type&#x2F;id</span><br><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPUT http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;1 -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;:&quot;zhangsan&quot;,</span><br><span class="line">  &quot;age&quot;:20</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><p>不指明id创建document</p><blockquote><p>若不指明id，es会自动创建id</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;:&quot;lisi&quot;,</span><br><span class="line">  &quot;age&quot;:21</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><p>查询文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XGET http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;1?pretty</span><br></pre></td></tr></table></figure><p>查询所有文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XGET http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;_search?pretty</span><br></pre></td></tr></table></figure><p>根据条件查询文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XGET http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;_search?pretty -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">      &quot;term&quot;:&#123;</span><br><span class="line">        &quot;_id&quot;:1</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><p>修改文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 将test_index（index）下doc（type）的id为1的数据 name字段的值 修改为 xiaohong</span><br><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;1&#x2F;_update?pretty -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;:&#123;</span><br><span class="line">      &quot;name&quot;:&quot;xiaohong&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><p>在文档中添加新的字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;1&#x2F;_update?pretty -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;:&#123;</span><br><span class="line">      &quot;sex&quot;:&quot;girl&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><p>删除文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XDELETE http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;1?pretty</span><br></pre></td></tr></table></figure><p>根据条件删除对应文档</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 删除满足age:20的所有文档数据</span><br><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;test_index&#x2F;doc&#x2F;_delete_by_query?pretty -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">      &quot;match&quot;:&#123;</span><br><span class="line">        &quot;age&quot;:20</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><h3 id="批量写入API"><a href="#批量写入API" class="headerlink" title="批量写入API"></a>批量写入API</h3><p>es允许批量对文档数据进行操作，使用 _bulk 完成下面操作</p><p>action_type有4种index（创建文档）、update（更新文档）、create（创建文档）、delete（删除文档）</p><p>index和create区别在于，当文档已经存在时，index操作会覆盖文档，create则报错（create只负责创建文档）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_bulk?pretty -d &#39;</span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;name&quot; : &quot;mayun&quot; , &quot;age&quot; : 51 &#125;</span><br><span class="line">&#123; &quot;update&quot; : &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;doc&quot; : &#123; &quot;age&quot; : 52 &#125;&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XPOST http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_bulk?pretty -d &#39;</span><br><span class="line">&#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;name&quot; : &quot;mahuateng&quot; , &quot;age&quot; : 50 &#125;</span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;name&quot; : &quot;leijun&quot; , &quot;age&quot; : 55 &#125;</span><br><span class="line">&#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><h3 id="批量查询API"><a href="#批量查询API" class="headerlink" title="批量查询API"></a>批量查询API</h3><p>es允许一次查询多个文档，使用 _mget 完成下面操作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &#39;Content-Type: application&#x2F;json&#39; -XGET http:&#x2F;&#x2F;10.244.2.18:9200&#x2F;_mget?pretty -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;docs&quot;: [</span><br><span class="line">    &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125;,</span><br><span class="line">    &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK Stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署filebeat</title>
      <link href="2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2filebeat/"/>
      <url>2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2filebeat/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>kubernetes部署filebeat搜集日志的方案大致分为两种：</p><ul><li>daemonset模式：在每个节点跑一个filebeat用来采集标准输出和标准错误输出的日志，然后发送出去，也就是通过kubectl logs 能看到的日志，默认会存储在/var/log/containers/目录下</li><li>sidecar模式：就是在pod中再额外增加一个filebeat容器，通过emptdir共享目录使得filebeat能够采集到日志</li></ul><p>我们使用第一种方式部署filebeat</p><blockquote><p>应用 filebeat-kubernetes.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改下面内容 es地址，因为都在 log-system 名称空间下，es使用stafulset+headless部署    </span><br><span class="line"># - name: ELASTICSEARCH_HOST</span><br><span class="line">#   value: es-out  </span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: filebeat-config</span><br><span class="line">  namespace: log-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: filebeat</span><br><span class="line">data:</span><br><span class="line">  filebeat.yml: |-</span><br><span class="line">    filebeat.inputs:</span><br><span class="line">    - type: container</span><br><span class="line">      paths:</span><br><span class="line">        - &#x2F;var&#x2F;log&#x2F;containers&#x2F;*.log</span><br><span class="line">      processors:</span><br><span class="line">        - add_kubernetes_metadata:</span><br><span class="line">            host: $&#123;NODE_NAME&#125;</span><br><span class="line">            matchers:</span><br><span class="line">            - logs_path:</span><br><span class="line">                logs_path: &quot;&#x2F;var&#x2F;log&#x2F;containers&#x2F;&quot;</span><br><span class="line">    # To enable hints based autodiscover, remove &#96;filebeat.inputs&#96; configuration and uncomment this:</span><br><span class="line">    #filebeat.autodiscover:</span><br><span class="line">    #  providers:</span><br><span class="line">    #    - type: kubernetes</span><br><span class="line">    #      node: $&#123;NODE_NAME&#125;</span><br><span class="line">    #      hints.enabled: true</span><br><span class="line">    #      hints.default_config:</span><br><span class="line">    #        type: container</span><br><span class="line">    #        paths:</span><br><span class="line">    #          - &#x2F;var&#x2F;log&#x2F;containers&#x2F;*$&#123;data.kubernetes.container.id&#125;.log</span><br><span class="line">    processors:</span><br><span class="line">      - add_cloud_metadata:</span><br><span class="line">      - add_host_metadata:</span><br><span class="line">    cloud.id: $&#123;ELASTIC_CLOUD_ID&#125;</span><br><span class="line">    cloud.auth: $&#123;ELASTIC_CLOUD_AUTH&#125;</span><br><span class="line">    output.elasticsearch:</span><br><span class="line">      hosts: [&#39;$&#123;ELASTICSEARCH_HOST:elasticsearch&#125;:$&#123;ELASTICSEARCH_PORT:9200&#125;&#39;]</span><br><span class="line">      username: $&#123;ELASTICSEARCH_USERNAME&#125;</span><br><span class="line">      password: $&#123;ELASTICSEARCH_PASSWORD&#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: filebeat</span><br><span class="line">  namespace: log-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: filebeat</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: filebeat</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: filebeat</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: filebeat</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">      containers:</span><br><span class="line">      - name: filebeat</span><br><span class="line">        image: elastic&#x2F;filebeat:7.2.0</span><br><span class="line">        args: [</span><br><span class="line">          &quot;-c&quot;, &quot;&#x2F;etc&#x2F;filebeat.yml&quot;,</span><br><span class="line">          &quot;-e&quot;,</span><br><span class="line">        ]</span><br><span class="line">        env:</span><br><span class="line">        - name: ELASTICSEARCH_HOST</span><br><span class="line">          value: es-out  </span><br><span class="line">        - name: ELASTICSEARCH_PORT</span><br><span class="line">          value: &quot;9200&quot;</span><br><span class="line">        - name: ELASTICSEARCH_USERNAME</span><br><span class="line">          value: elastic</span><br><span class="line">        - name: ELASTICSEARCH_PASSWORD</span><br><span class="line">          value: changeme</span><br><span class="line">        - name: ELASTIC_CLOUD_ID</span><br><span class="line">          value:</span><br><span class="line">        - name: ELASTIC_CLOUD_AUTH</span><br><span class="line">          value:</span><br><span class="line">        - name: NODE_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: spec.nodeName</span><br><span class="line">        securityContext:</span><br><span class="line">          runAsUser: 0</span><br><span class="line">          # If using Red Hat OpenShift uncomment this:</span><br><span class="line">          #privileged: true</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 200Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;filebeat.yml</span><br><span class="line">          readOnly: true</span><br><span class="line">          subPath: filebeat.yml</span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: &#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;data</span><br><span class="line">        - name: varlibdockercontainers</span><br><span class="line">          mountPath: &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: varlog</span><br><span class="line">          mountPath: &#x2F;var&#x2F;log</span><br><span class="line">          readOnly: true</span><br><span class="line">      volumes:</span><br><span class="line">      - name: config</span><br><span class="line">        configMap:</span><br><span class="line">          defaultMode: 0640</span><br><span class="line">          name: filebeat-config</span><br><span class="line">      - name: varlibdockercontainers</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers</span><br><span class="line">      - name: varlog</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;log</span><br><span class="line">      # data folder stores a registry of read status for all files, so we don&#39;t send everything again on a Filebeat pod restart</span><br><span class="line">      - name: data</span><br><span class="line">        hostPath:</span><br><span class="line">          # When filebeat runs as non-root user, this directory needs to be writable by group (g+w).</span><br><span class="line">          path: &#x2F;var&#x2F;lib&#x2F;filebeat-data</span><br><span class="line">          type: DirectoryOrCreate</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: filebeat</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: filebeat</span><br><span class="line">  namespace: log-system</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: filebeat</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: filebeat</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: filebeat</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group</span><br><span class="line">  resources:</span><br><span class="line">  - namespaces</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - watch</span><br><span class="line">  - list</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: filebeat</span><br><span class="line">  namespace: log-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: filebeat</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>可以看到filebeat开始搜集日志了，在elasticsearch-head查看索引</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2filebeat/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ingress-nginx配置basic认证</title>
      <link href="2021/01/23/Ingress-nginx%E9%85%8D%E7%BD%AEbasic%E8%AE%A4%E8%AF%81/"/>
      <url>2021/01/23/Ingress-nginx%E9%85%8D%E7%BD%AEbasic%E8%AE%A4%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="创建用户密码文件"><a href="#创建用户密码文件" class="headerlink" title="创建用户密码文件"></a>创建用户密码文件</h2><p>安装htpasswd工具</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y httpd-tools</span><br></pre></td></tr></table></figure><p>创建认证文件,输入密码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 名称一定要是 auth</span><br><span class="line"># -c表示创建文件</span><br><span class="line">htpasswd -c auth admin</span><br><span class="line"># 在增加一个用户</span><br><span class="line">htpasswd auth tangweifeng</span><br><span class="line"># 删除用户</span><br><span class="line">htpasswd -D auth admin</span><br></pre></td></tr></table></figure><p>查看文件内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat auth</span><br><span class="line">tangweifeng:$apr1$u8Oa4OvD$Is5bWmcOveLex.TFgHB9c1</span><br><span class="line">admin:$apr1$ESHmtuXv$hVSij4XjWTAnhzFmNxjkg1</span><br></pre></td></tr></table></figure><h2 id="创建secret"><a href="#创建secret" class="headerlink" title="创建secret"></a>创建secret</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret generic basic-auth --from-file&#x3D;authfile</span><br></pre></td></tr></table></figure><h2 id="在Ingress中使用"><a href="#在Ingress中使用" class="headerlink" title="在Ingress中使用"></a>在Ingress中使用</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: web</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io&#x2F;auth-type: basic</span><br><span class="line">    nginx.ingress.kubernetes.io&#x2F;auth-secret: basic-auth</span><br><span class="line">    nginx.ingress.kubernetes.io&#x2F;auth-realm: &#39;提示信息&#39;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: web.ocp.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: web</span><br><span class="line">          servicePort: 80</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署kafka集群</title>
      <link href="2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4/"/>
      <url>2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>kafka需要依赖zookeeper，所以需要先部署zk</p><h2 id="准备存储"><a href="#准备存储" class="headerlink" title="准备存储"></a>准备存储</h2><p>参考文章：<a href="https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/">https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</a></p><h2 id="名称空间"><a href="#名称空间" class="headerlink" title="名称空间"></a>名称空间</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create ns log-system</span><br></pre></td></tr></table></figure><h2 id="部署zookeeper集群"><a href="#部署zookeeper集群" class="headerlink" title="部署zookeeper集群"></a>部署zookeeper集群</h2><blockquote><p>应用 service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: zk-hs</span><br><span class="line">  namespace: log-system</span><br><span class="line">  labels:</span><br><span class="line">    app: zk</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 2888</span><br><span class="line">    name: server</span><br><span class="line">  - port: 3888</span><br><span class="line">    name: leader-election</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: zk</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: zk-cs</span><br><span class="line">  namespace: kafka</span><br><span class="line">  labels:</span><br><span class="line">    app: zk</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 2181</span><br><span class="line">    name: client</span><br><span class="line">  selector:</span><br><span class="line">    app: zk</span><br></pre></td></tr></table></figure><blockquote><p>应用 statefulset</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: zk</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: zk</span><br><span class="line">  serviceName: zk-hs</span><br><span class="line">  replicas: 3</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  podManagementPolicy: Parallel</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: zk</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        travis.io&#x2F;schedule-only: &quot;kafka&quot;</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;travis.io&#x2F;schedule-only&quot;</span><br><span class="line">          operator: &quot;Equal&quot;</span><br><span class="line">          value: &quot;kafka&quot;</span><br><span class="line">          effect: &quot;NoSchedule&quot;</span><br><span class="line">        - key: &quot;travis.io&#x2F;schedule-only&quot;</span><br><span class="line">          operator: &quot;Equal&quot;</span><br><span class="line">          value: &quot;kafka&quot;</span><br><span class="line">          effect: &quot;NoExecute&quot;</span><br><span class="line">          tolerationSeconds: 3600</span><br><span class="line">        - key: &quot;travis.io&#x2F;schedule-only&quot;</span><br><span class="line">          operator: &quot;Equal&quot;</span><br><span class="line">          value: &quot;kafka&quot;</span><br><span class="line">          effect: &quot;PreferNoSchedule&quot;</span><br><span class="line">      affinity:</span><br><span class="line">        podAntiAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            - labelSelector:</span><br><span class="line">                matchExpressions:</span><br><span class="line">                  - key: &quot;app&quot;</span><br><span class="line">                    operator: In</span><br><span class="line">                    values:</span><br><span class="line">                      - zk</span><br><span class="line">              topologyKey: &quot;kubernetes.io&#x2F;hostname&quot;</span><br><span class="line">      containers:</span><br><span class="line">        - name: kubernetes-zookeeper</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          image: tangweifeng&#x2F;zookeeper:3.4.10</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              memory: &quot;200Mi&quot;</span><br><span class="line">              cpu: &quot;0.1&quot;</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 2181</span><br><span class="line">              name: client</span><br><span class="line">            - containerPort: 2888</span><br><span class="line">              name: server</span><br><span class="line">            - containerPort: 3888</span><br><span class="line">              name: leader-election</span><br><span class="line">          command:</span><br><span class="line">            - sh</span><br><span class="line">            - -c</span><br><span class="line">            - &quot;start-zookeeper \</span><br><span class="line">          --servers&#x3D;3 \</span><br><span class="line">          --data_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;zookeeper&#x2F;data \</span><br><span class="line">          --data_log_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;zookeeper&#x2F;data&#x2F;log \</span><br><span class="line">          --conf_dir&#x3D;&#x2F;opt&#x2F;zookeeper&#x2F;conf \</span><br><span class="line">          --client_port&#x3D;2181 \</span><br><span class="line">          --election_port&#x3D;3888 \</span><br><span class="line">          --server_port&#x3D;2888 \</span><br><span class="line">          --tick_time&#x3D;2000 \</span><br><span class="line">          --init_limit&#x3D;10 \</span><br><span class="line">          --sync_limit&#x3D;5 \</span><br><span class="line">          --heap&#x3D;512M \</span><br><span class="line">          --max_client_cnxns&#x3D;60 \</span><br><span class="line">          --snap_retain_count&#x3D;3 \</span><br><span class="line">          --purge_interval&#x3D;12 \</span><br><span class="line">          --max_session_timeout&#x3D;40000 \</span><br><span class="line">          --min_session_timeout&#x3D;4000 \</span><br><span class="line">          --log_level&#x3D;INFO&quot;</span><br><span class="line">          readinessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">                - sh</span><br><span class="line">                - -c</span><br><span class="line">                - &quot;zookeeper-ready 2181&quot;</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">          livenessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">                - sh</span><br><span class="line">                - -c</span><br><span class="line">                - &quot;zookeeper-ready 2181&quot;</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: datadir</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;zookeeper</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsUser: 1000</span><br><span class="line">        fsGroup: 1000</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: datadir</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io&#x2F;storage-class: &quot;managed-nfs-storage&quot;</span><br><span class="line">      spec:</span><br><span class="line">        accessModes: [ &quot;ReadWriteMany&quot; ]</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 200Mi</span><br></pre></td></tr></table></figure><p>验证集群</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># for i in 0 1 2; do kubectl exec zk-$i -n log-system zkServer.sh status; done</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;usr&#x2F;bin&#x2F;..&#x2F;etc&#x2F;zookeeper&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;usr&#x2F;bin&#x2F;..&#x2F;etc&#x2F;zookeeper&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;usr&#x2F;bin&#x2F;..&#x2F;etc&#x2F;zookeeper&#x2F;zoo.cfg</span><br><span class="line">Mode: leader</span><br></pre></td></tr></table></figure><h2 id="部署kafka集群"><a href="#部署kafka集群" class="headerlink" title="部署kafka集群"></a>部署kafka集群</h2><blockquote><p>应用 service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kafka-svc</span><br><span class="line">  namespace: log-system</span><br><span class="line">  labels:</span><br><span class="line">    app: kafka</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 9092</span><br><span class="line">    name: server</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: kafka</span><br></pre></td></tr></table></figure><blockquote><p>应用 statefulset</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kafka</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kafka</span><br><span class="line">  serviceName: kafka-svc</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kafka</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      containers:</span><br><span class="line">        - name: k8s-kafka</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          image: tangweifeng&#x2F;kafka:2.2.0</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              memory: &quot;600Mi&quot;</span><br><span class="line">              cpu: 500m</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9092</span><br><span class="line">              name: server</span><br><span class="line">          command:</span><br><span class="line">            - sh</span><br><span class="line">            - -c</span><br><span class="line">            - &quot;exec kafka-server-start.sh &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties --override broker.id&#x3D;$&#123;HOSTNAME##*-&#125; \</span><br><span class="line">          --override listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9092 \</span><br><span class="line">          --override zookeeper.connect&#x3D;zk-0.zk-hs.log-system.svc.cluster.local:2181,zk-1.zk-hs.log-system.svc.cluster.local:2181,zk-2.zk-hs.log-system.svc.cluster.local:2181 \</span><br><span class="line">          --override log.dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kafka \</span><br><span class="line">          --override auto.create.topics.enable&#x3D;true \</span><br><span class="line">          --override auto.leader.rebalance.enable&#x3D;true \</span><br><span class="line">          --override background.threads&#x3D;10 \</span><br><span class="line">          --override compression.type&#x3D;producer \</span><br><span class="line">          --override delete.topic.enable&#x3D;false \</span><br><span class="line">          --override leader.imbalance.check.interval.seconds&#x3D;300 \</span><br><span class="line">          --override leader.imbalance.per.broker.percentage&#x3D;10 \</span><br><span class="line">          --override log.flush.interval.messages&#x3D;9223372036854775807 \</span><br><span class="line">          --override log.flush.offset.checkpoint.interval.ms&#x3D;60000 \</span><br><span class="line">          --override log.flush.scheduler.interval.ms&#x3D;9223372036854775807 \</span><br><span class="line">          --override log.retention.bytes&#x3D;-1 \</span><br><span class="line">          --override log.retention.hours&#x3D;168 \</span><br><span class="line">          --override log.roll.hours&#x3D;168 \</span><br><span class="line">          --override log.roll.jitter.hours&#x3D;0 \</span><br><span class="line">          --override log.segment.bytes&#x3D;1073741824 \</span><br><span class="line">          --override log.segment.delete.delay.ms&#x3D;60000 \</span><br><span class="line">          --override message.max.bytes&#x3D;1000012 \</span><br><span class="line">          --override min.insync.replicas&#x3D;1 \</span><br><span class="line">          --override num.io.threads&#x3D;8 \</span><br><span class="line">          --override num.network.threads&#x3D;3 \</span><br><span class="line">          --override num.recovery.threads.per.data.dir&#x3D;1 \</span><br><span class="line">          --override num.replica.fetchers&#x3D;1 \</span><br><span class="line">          --override offset.metadata.max.bytes&#x3D;4096 \</span><br><span class="line">          --override offsets.commit.required.acks&#x3D;-1 \</span><br><span class="line">          --override offsets.commit.timeout.ms&#x3D;5000 \</span><br><span class="line">          --override offsets.load.buffer.size&#x3D;5242880 \</span><br><span class="line">          --override offsets.retention.check.interval.ms&#x3D;600000 \</span><br><span class="line">          --override offsets.retention.minutes&#x3D;1440 \</span><br><span class="line">          --override offsets.topic.compression.codec&#x3D;0 \</span><br><span class="line">          --override offsets.topic.num.partitions&#x3D;50 \</span><br><span class="line">          --override offsets.topic.replication.factor&#x3D;3 \</span><br><span class="line">          --override offsets.topic.segment.bytes&#x3D;104857600 \</span><br><span class="line">          --override queued.max.requests&#x3D;500 \</span><br><span class="line">          --override quota.consumer.default&#x3D;9223372036854775807 \</span><br><span class="line">          --override quota.producer.default&#x3D;9223372036854775807 \</span><br><span class="line">          --override replica.fetch.min.bytes&#x3D;1 \</span><br><span class="line">          --override replica.fetch.wait.max.ms&#x3D;500 \</span><br><span class="line">          --override replica.high.watermark.checkpoint.interval.ms&#x3D;5000 \</span><br><span class="line">          --override replica.lag.time.max.ms&#x3D;10000 \</span><br><span class="line">          --override replica.socket.receive.buffer.bytes&#x3D;65536 \</span><br><span class="line">          --override replica.socket.timeout.ms&#x3D;30000 \</span><br><span class="line">          --override request.timeout.ms&#x3D;30000 \</span><br><span class="line">          --override socket.receive.buffer.bytes&#x3D;102400 \</span><br><span class="line">          --override socket.request.max.bytes&#x3D;104857600 \</span><br><span class="line">          --override socket.send.buffer.bytes&#x3D;102400 \</span><br><span class="line">          --override unclean.leader.election.enable&#x3D;true \</span><br><span class="line">          --override zookeeper.session.timeout.ms&#x3D;6000 \</span><br><span class="line">          --override zookeeper.set.acl&#x3D;false \</span><br><span class="line">          --override broker.id.generation.enable&#x3D;true \</span><br><span class="line">          --override connections.max.idle.ms&#x3D;600000 \</span><br><span class="line">          --override controlled.shutdown.enable&#x3D;true \</span><br><span class="line">          --override controlled.shutdown.max.retries&#x3D;3 \</span><br><span class="line">          --override controlled.shutdown.retry.backoff.ms&#x3D;5000 \</span><br><span class="line">          --override controller.socket.timeout.ms&#x3D;30000 \</span><br><span class="line">          --override default.replication.factor&#x3D;1 \</span><br><span class="line">          --override fetch.purgatory.purge.interval.requests&#x3D;1000 \</span><br><span class="line">          --override group.max.session.timeout.ms&#x3D;300000 \</span><br><span class="line">          --override group.min.session.timeout.ms&#x3D;6000 \</span><br><span class="line">          --override inter.broker.protocol.version&#x3D;2.2.0 \</span><br><span class="line">          --override log.cleaner.backoff.ms&#x3D;15000 \</span><br><span class="line">          --override log.cleaner.dedupe.buffer.size&#x3D;134217728 \</span><br><span class="line">          --override log.cleaner.delete.retention.ms&#x3D;86400000 \</span><br><span class="line">          --override log.cleaner.enable&#x3D;true \</span><br><span class="line">          --override log.cleaner.io.buffer.load.factor&#x3D;0.9 \</span><br><span class="line">          --override log.cleaner.io.buffer.size&#x3D;524288 \</span><br><span class="line">          --override log.cleaner.io.max.bytes.per.second&#x3D;1.7976931348623157E308 \</span><br><span class="line">          --override log.cleaner.min.cleanable.ratio&#x3D;0.5 \</span><br><span class="line">          --override log.cleaner.min.compaction.lag.ms&#x3D;0 \</span><br><span class="line">          --override log.cleaner.threads&#x3D;1 \</span><br><span class="line">          --override log.cleanup.policy&#x3D;delete \</span><br><span class="line">          --override log.index.interval.bytes&#x3D;4096 \</span><br><span class="line">          --override log.index.size.max.bytes&#x3D;10485760 \</span><br><span class="line">          --override log.message.timestamp.difference.max.ms&#x3D;9223372036854775807 \</span><br><span class="line">          --override log.message.timestamp.type&#x3D;CreateTime \</span><br><span class="line">          --override log.preallocate&#x3D;false \</span><br><span class="line">          --override log.retention.check.interval.ms&#x3D;300000 \</span><br><span class="line">          --override max.connections.per.ip&#x3D;2147483647 \</span><br><span class="line">          --override num.partitions&#x3D;4 \</span><br><span class="line">          --override producer.purgatory.purge.interval.requests&#x3D;1000 \</span><br><span class="line">          --override replica.fetch.backoff.ms&#x3D;1000 \</span><br><span class="line">          --override replica.fetch.max.bytes&#x3D;1048576 \</span><br><span class="line">          --override replica.fetch.response.max.bytes&#x3D;10485760 \</span><br><span class="line">          --override reserved.broker.max.id&#x3D;1000 &quot;</span><br><span class="line">          env:</span><br><span class="line">            - name: KAFKA_HEAP_OPTS</span><br><span class="line">              value : &quot;-Xmx512M -Xms512M&quot;</span><br><span class="line">            - name: KAFKA_OPTS</span><br><span class="line">              value: &quot;-Dlogging.level&#x3D;INFO&quot;</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: datadir</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;kafka</span><br><span class="line">          readinessProbe:</span><br><span class="line">            tcpSocket:</span><br><span class="line">              port: 9092</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">            initialDelaySeconds: 5</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsUser: 1000</span><br><span class="line">        fsGroup: 1000</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: datadir</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io&#x2F;storage-class: &quot;managed-nfs-storage&quot;</span><br><span class="line">      spec:</span><br><span class="line">        accessModes: [ &quot;ReadWriteMany&quot; ]</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage:  300Mi</span><br></pre></td></tr></table></figure><p>验证kafka集群</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建一个topic</span><br><span class="line">&#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --create --zookeeper zk-0.zk-hs.log-system.svc.cluster.local:2181,zk-1.zk-hs.log-system.svc.cluster.local:2181,zk-2.zk-hs.log-system.svc.cluster.local:2181 --replication-factor 2 --partitions 3 --topic demo_topics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4/a1.png"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 列出所有topic</span><br><span class="line">&#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --list --zookeeper zk-0.zk-hs.log-system.svc.cluster.local:2181,zk-1.zk-hs.log-system.svc.cluster.local:2181,zk-2.zk-hs.log-system.svc.cluster.local:2181</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4/a2.png"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看demo_topics详细情况</span><br><span class="line">&#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --describe --zookeeper zk-0.zk-hs.log-system.svc.cluster.local:2181,zk-1.zk-hs.log-system.svc.cluster.local:2181,zk-2.zk-hs.log-system.svc.cluster.local:2181 --topic demo_topics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4/a3.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署kibana</title>
      <link href="2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kibana/"/>
      <url>2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kibana/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文介绍在Kubernetes集群上的名称空间设置Kibana的过程</p><h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create ns log-system</span><br></pre></td></tr></table></figure><h2 id="Configmap"><a href="#Configmap" class="headerlink" title="Configmap"></a>Configmap</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># es-out 是es集群的headless svc</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: log-system</span><br><span class="line">data:</span><br><span class="line">  kibana.yml: |</span><br><span class="line">    server.name: kibana.twf.com</span><br><span class="line">    server.host: &quot;0.0.0.0&quot;</span><br><span class="line">    elasticsearch.hosts: [&quot;http:&#x2F;&#x2F;es-out:9200&#x2F;&quot;]</span><br></pre></td></tr></table></figure><h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kibana</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kibana</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: kibana-config</span><br><span class="line">          configMap:</span><br><span class="line">            name: kibana</span><br><span class="line">      containers:</span><br><span class="line">        - name: kibana</span><br><span class="line">          image: kibana:7.2.0</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 5601</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: &#x2F;usr&#x2F;share&#x2F;kibana&#x2F;config</span><br><span class="line">              name: kibana-config</span><br><span class="line">          env:</span><br><span class="line">            - name: CLUSTER_NAME</span><br><span class="line">              value: es-cluster</span><br></pre></td></tr></table></figure><h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: kibana</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 5601</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过node ip:nodeport 方式访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/23/Kubernetes%E9%83%A8%E7%BD%B2kibana/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署elasticsearch-head</title>
      <link href="2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2elasticsearch-head/"/>
      <url>2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2elasticsearch-head/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在之前已经部署好了elasticsearch集群了，下面开始部署es-head。es-head是一个nodejs项目，所以我们使用deployment部署就可以了。</p><blockquote><p>在之前的configmap中我们已经加入了 http.cors.enabled: true 和 http.cors.allow-origin: “*”，处理跨域拒绝访问问题</p></blockquote><h2 id="创建deployment"><a href="#创建deployment" class="headerlink" title="创建deployment"></a>创建deployment</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: es-head</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: es-head</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: es-head</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: es-head</span><br><span class="line">          image: mobz&#x2F;elasticsearch-head:5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9100</span><br></pre></td></tr></table></figure><h2 id="创建service"><a href="#创建service" class="headerlink" title="创建service"></a>创建service</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: es-head</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: es-head</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9100</span><br><span class="line">      targetPort: 9100</span><br></pre></td></tr></table></figure><h2 id="测试es连接"><a href="#测试es连接" class="headerlink" title="测试es连接"></a>测试es连接</h2><p>通过node ip:nodepod访问es-head页面,然后输入node ip + es-out的svc nodeport 连接即可</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2elasticsearch-head/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署ElasticSearch集群</title>
      <link href="2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2ElasticSearch%E9%9B%86%E7%BE%A4/"/>
      <url>2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2ElasticSearch%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>ElasticSearch跟MySQL类似，都需要使用StatefulSet去部署这类有状态服务</p><p>es配置中常见的参数：</p><ul><li>cluster.name：集群名称，确保同一集群中的节点此配置名称相同</li><li>node.name：节点名称，表示集群中节点名称</li><li>network.host：es监听的IP地址</li><li>discovery.seed_hosts：节点发现地址，配置成域名（域名下解析到多个IP地址），那么es将处理所有发现的IP地址</li><li>cluster.initial_master_nodes：集群内所有的node.name</li></ul><h2 id="部署NFS-storageclass"><a href="#部署NFS-storageclass" class="headerlink" title="部署NFS storageclass"></a>部署NFS storageclass</h2><p>参考文章：<a href="https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/">https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</a></p><h2 id="创建namespace"><a href="#创建namespace" class="headerlink" title="创建namespace"></a>创建namespace</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: log-system</span><br><span class="line">  labels:</span><br><span class="line">    name: log-system</span><br></pre></td></tr></table></figure><h2 id="创建configmap"><a href="#创建configmap" class="headerlink" title="创建configmap"></a>创建configmap</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: es</span><br><span class="line">  namespace: log-system</span><br><span class="line">data:</span><br><span class="line">  elasticsearch.yml: |</span><br><span class="line">    cluster.name: &quot;es-cluster&quot;</span><br><span class="line">    node.name: &quot;$&#123;POD_NAME&#125;&quot;</span><br><span class="line">    network.host: 0.0.0.0</span><br><span class="line">    discovery.seed_hosts: &quot;elasticsearch-discovery&quot;</span><br><span class="line">    cluster.initial_master_nodes: &quot;es-0,es-1,es-2&quot;</span><br><span class="line">    http.cors.enabled: &quot;true&quot;</span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure><h2 id="创建statefulset"><a href="#创建statefulset" class="headerlink" title="创建statefulset"></a>创建statefulset</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: es</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: es</span><br><span class="line">  serviceName: es</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: es-data</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io&#x2F;storage-class: &quot;managed-nfs-storage&quot;</span><br><span class="line">      spec:</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 5Gi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: es</span><br><span class="line">    spec:</span><br><span class="line">      initContainers:</span><br><span class="line">        - name: increase-vm-max-map</span><br><span class="line">          image: busybox</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          command:</span><br><span class="line">            - sysctl</span><br><span class="line">            - -w</span><br><span class="line">            - vm.max_map_count&#x3D;262144</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">        - name: increase-fd-ulimit</span><br><span class="line">          image: busybox</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          command:</span><br><span class="line">            - sh</span><br><span class="line">            - -c</span><br><span class="line">            - ulimit -n 65536</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">      containers:</span><br><span class="line">        - name: elasticsearch</span><br><span class="line">          image: elasticsearch:7.2.0</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9200</span><br><span class="line">              name: es-cli</span><br><span class="line">            - containerPort: 9300</span><br><span class="line">              name: es-iner</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: &#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data</span><br><span class="line">              name: es-data</span><br><span class="line">            - mountPath: &#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.yml</span><br><span class="line">              name: es-config</span><br><span class="line">              subPath: elasticsearch.yml</span><br><span class="line">      volumes:</span><br><span class="line">        - name: es-config</span><br><span class="line">          configMap:</span><br><span class="line">            name: es</span><br></pre></td></tr></table></figure><h2 id="创建service"><a href="#创建service" class="headerlink" title="创建service"></a>创建service</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: es-out</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: es</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9200</span><br><span class="line">      targetPort: 9200</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: elasticsearch-discovery</span><br><span class="line">  namespace: log-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9300</span><br><span class="line">      targetPort: 9300</span><br><span class="line">  selector:</span><br><span class="line">    app: es</span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><p>查看pod,svc情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods,svc -n log-system</span><br></pre></td></tr></table></figure><p>使用curl访问es-out svc的9200端口，查看集群健康状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;10.1.213.20:9200&#x2F;_cat&#x2F;health?v</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/19/Kubernetes%E9%83%A8%E7%BD%B2ElasticSearch%E9%9B%86%E7%BE%A4/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant环境下部署Kubernetes集群</title>
      <link href="2021/01/19/Vagrant%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2021/01/19/Vagrant%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>安装VirtualBox</li><li>安装Vagrant</li><li>准备CentOS7的vagrant box</li></ul><h2 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h2><blockquote><p>打开cmd窗口，在一个新建的目录下执行下面操作</p></blockquote><p>添加box</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant box add centos7 D:\vagrantbox\CentOS-7.box</span><br></pre></td></tr></table></figure><p>初始化box，生成Vagrantfile</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant init</span><br></pre></td></tr></table></figure><p>将生成的Vagrantfile清空，复制下面内容进去</p><blockquote><p>需要注意下面三个ip，需要根据自己内网ip决定，通过ipconfig查看自己的内网ip网段</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-01&quot; do |master|</span><br><span class="line">    master.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    master.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    master.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.110&quot;</span><br><span class="line">    master.ssh.insert_key &#x3D; false</span><br><span class="line">    master.vm.hostname &#x3D; &quot;master&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-02&quot; do |node1|</span><br><span class="line">    node1.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node1.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node1.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.111&quot;</span><br><span class="line">    node1.ssh.insert_key &#x3D; false</span><br><span class="line">    node1.vm.hostname &#x3D; &quot;node1&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-03&quot; do |node2|</span><br><span class="line">    node2.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node2.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node2.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.112&quot;</span><br><span class="line">    node2.ssh.insert_key &#x3D; false</span><br><span class="line">    node2.vm.hostname &#x3D; &quot;node2&quot;</span><br><span class="line">  end</span><br><span class="line">  </span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>启动虚拟机</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><h2 id="部署Kubernetes"><a href="#部署Kubernetes" class="headerlink" title="部署Kubernetes"></a>部署Kubernetes</h2><p>使用SSH工具连接，用户名：root  密码：vagrant</p><h3 id="关闭防火墙、selinux和swap"><a href="#关闭防火墙、selinux和swap" class="headerlink" title="关闭防火墙、selinux和swap"></a>关闭防火墙、selinux和swap</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">setenforce 0</span><br><span class="line">swapoff -a</span><br></pre></td></tr></table></figure><h3 id="更换阿里云yum源"><a href="#更换阿里云yum源" class="headerlink" title="更换阿里云yum源"></a>更换阿里云yum源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y wget</span><br><span class="line">cd &#x2F;etc&#x2F;yum.repos.d</span><br><span class="line">mv CentOS-Base.repo CentOS-Base.repo.bak</span><br><span class="line">wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line">yum update -y</span><br></pre></td></tr></table></figure><h3 id="同步时间"><a href="#同步时间" class="headerlink" title="同步时间"></a>同步时间</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用亚洲上海时间</span><br><span class="line">cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime</span><br><span class="line"># 使用ntpdate同步时间</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure><h3 id="添加主机名与IP对应关系"><a href="#添加主机名与IP对应关系" class="headerlink" title="添加主机名与IP对应关系"></a>添加主机名与IP对应关系</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;hosts</span><br><span class="line">192.168.0.110 master</span><br><span class="line">192.168.0.111 node1</span><br><span class="line">192.168.0.112 node2</span><br></pre></td></tr></table></figure><h3 id="将桥接的IPv4流量传递到iptables的链"><a href="#将桥接的IPv4流量传递到iptables的链" class="headerlink" title="将桥接的IPv4流量传递到iptables的链"></a>将桥接的IPv4流量传递到iptables的链</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOF</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">EOF</span><br><span class="line"># 是配置生效</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#安装需要的软件包</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">#设置yum源</span><br><span class="line">yum-config-manager --add-repo https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">#安装docker</span><br><span class="line">yum install docker-ce-17.12.1.ce -y</span><br><span class="line">#设置开机自启，启动docker</span><br><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><h3 id="添加Kubernetes阿里云yum软件源"><a href="#添加Kubernetes阿里云yum软件源" class="headerlink" title="添加Kubernetes阿里云yum软件源"></a>添加Kubernetes阿里云yum软件源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name&#x3D;Kubernetes</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line">repo_gpgcheck&#x3D;0</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="安装kubeadm、kubelet和kebectl"><a href="#安装kubeadm、kubelet和kebectl" class="headerlink" title="安装kubeadm、kubelet和kebectl"></a>安装kubeadm、kubelet和kebectl</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y kubelet-1.15.0 kubeadm-1.15.0 kubectl-1.15.0</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure><h3 id="部署kubernetes-master"><a href="#部署kubernetes-master" class="headerlink" title="部署kubernetes master"></a>部署kubernetes master</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#在master执行初始化</span><br><span class="line">kubeadm init \</span><br><span class="line">--apiserver-advertise-address&#x3D;192.168.0.110 \</span><br><span class="line">--image-repository registry.aliyuncs.com&#x2F;google_containers \</span><br><span class="line">--kubernetes-version v1.15.0 \</span><br><span class="line">--service-cidr&#x3D;10.1.0.0&#x2F;16 \</span><br><span class="line">--pod-network-cidr&#x3D;10.244.0.0&#x2F;16</span><br><span class="line"></span><br><span class="line"># 配置kubeconfig</span><br><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure><h3 id="安装pod网络插件CNI"><a href="#安装pod网络插件CNI" class="headerlink" title="安装pod网络插件CNI"></a>安装pod网络插件CNI</h3><h4 id="使用flannel"><a href="#使用flannel" class="headerlink" title="使用flannel"></a>使用flannel</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;a70459be0084506e4ec919aa1c114638878db11b&#x2F;Documentation&#x2F;kube-flannel.yml</span><br></pre></td></tr></table></figure><p>或者使用这个（镜像已经更改）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 需要通过 --iface 指定网卡</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - pods</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes&#x2F;status</span><br><span class="line">    verbs:</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: flannel</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">          &quot;delegate&quot;: &#123;</span><br><span class="line">            &quot;hairpinMode&quot;: true,</span><br><span class="line">            &quot;isDefaultGateway&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;portmap&quot;,</span><br><span class="line">          &quot;capabilities&quot;: &#123;</span><br><span class="line">            &quot;portMappings&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.244.0.0&#x2F;16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;vxlan&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds-amd64</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io&#x2F;arch: amd64</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: tangweifeng&#x2F;flannel:v0.11.0-amd64</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: tangweifeng&#x2F;flannel:v0.11.0-amd64</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --iface&#x3D;eth0</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">        - name: run</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;run</span><br><span class="line">        - name: cni</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-flannel-cfg</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds-arm64</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io&#x2F;arch: arm64</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-arm64</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-arm64</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">        - name: run</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;run</span><br><span class="line">        - name: cni</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-flannel-cfg</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds-arm</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io&#x2F;arch: arm</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-arm</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-arm</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">        - name: run</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;run</span><br><span class="line">        - name: cni</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-flannel-cfg</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds-ppc64le</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io&#x2F;arch: ppc64le</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-ppc64le</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-ppc64le</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">        - name: run</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;run</span><br><span class="line">        - name: cni</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-flannel-cfg</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds-s390x</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io&#x2F;arch: s390x</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-s390x</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io&#x2F;coreos&#x2F;flannel:v0.11.0-s390x</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">        - name: run</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;run</span><br><span class="line">        - name: cni</span><br><span class="line">          hostPath:</span><br><span class="line">            path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-flannel-cfg</span><br></pre></td></tr></table></figure><h4 id="使用calico"><a href="#使用calico" class="headerlink" title="使用calico"></a>使用calico</h4><blockquote><p>应用 rbac-kdd.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;docs.projectcalico.org&#x2F;v3.3&#x2F;getting-started&#x2F;kubernetes&#x2F;installation&#x2F;hosted&#x2F;rbac-kdd.yaml</span><br></pre></td></tr></table></figure><blockquote><p>修改 calico.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先使用wget下载</span><br><span class="line">wget </span><br><span class="line">https:&#x2F;&#x2F;docs.projectcalico.org&#x2F;v3.3&#x2F;getting-started&#x2F;kubernetes&#x2F;installation&#x2F;hosted&#x2F;kubernetes-datastore&#x2F;calico-networking&#x2F;1.7&#x2F;calico.yaml</span><br><span class="line"></span><br><span class="line"># 修改ipip模式关闭</span><br><span class="line">- name: CALICO_IPV4POOL_IPIP</span><br><span class="line">  value: &quot;off&quot;</span><br><span class="line">  </span><br><span class="line"># 修改 typha_service_name</span><br><span class="line">typha_service_name: &quot;calico-typha&quot;</span><br><span class="line"></span><br><span class="line"># 修改replicas</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 2</span><br><span class="line">  </span><br><span class="line"># 修改pod的网段CALICO_IPV4POOL_CIDR</span><br><span class="line">- name: CALICO_IPV4POOL_CIDR</span><br><span class="line">  value: &quot;10.244.0.0&#x2F;16&quot;</span><br></pre></td></tr></table></figure><h3 id="将Node加入集群"><a href="#将Node加入集群" class="headerlink" title="将Node加入集群"></a>将Node加入集群</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.0.110:6443 --token gp9xxu.02wjmglj28pd15dh \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:13cb5de08479e721b1c3a7796089871bb84c826c06dc09c51c87cc73c9c82cc0 </span><br></pre></td></tr></table></figure><h3 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#当节点都是Ready状态，表示集群初始化成功</span><br><span class="line">kubectl get nodes</span><br><span class="line">#查看kube-system名称空间pod状态,全部运行为成功</span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Vagrant </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vagrant </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant快照备份与恢复</title>
      <link href="2021/01/18/Vagrant%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"/>
      <url>2021/01/18/Vagrant%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Vagrant快照插件安装"><a href="#Vagrant快照插件安装" class="headerlink" title="Vagrant快照插件安装"></a>Vagrant快照插件安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant plugin install vagrant-vbox-snapshot</span><br></pre></td></tr></table></figure><h2 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h2><blockquote><p>下文中 k8s-01 指的是vagrant创建的虚拟机，也就是vagrantfile中config.vm.define定义的</p></blockquote><h3 id="创建快照"><a href="#创建快照" class="headerlink" title="创建快照"></a>创建快照</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant snapshot take k8s-01 &quot;centos-init&quot;</span><br></pre></td></tr></table></figure><h3 id="查看快照"><a href="#查看快照" class="headerlink" title="查看快照"></a>查看快照</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant snapshot list k8s-01</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/Vagrant%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/a1.png"></p><h3 id="恢复指定节点的快照"><a href="#恢复指定节点的快照" class="headerlink" title="恢复指定节点的快照"></a>恢复指定节点的快照</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant snapshot go k8s-01 &quot;centos-init&quot;</span><br></pre></td></tr></table></figure><h3 id="删除一个快照"><a href="#删除一个快照" class="headerlink" title="删除一个快照"></a>删除一个快照</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant snapshot delete k8s-01 &quot;centos-init&quot;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Vagrant </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vagrant </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant调整磁盘大小</title>
      <link href="2021/01/18/Vagrant%E8%B0%83%E6%95%B4%E7%A3%81%E7%9B%98%E5%A4%A7%E5%B0%8F/"/>
      <url>2021/01/18/Vagrant%E8%B0%83%E6%95%B4%E7%A3%81%E7%9B%98%E5%A4%A7%E5%B0%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant plugin install vagrant-disksize</span><br></pre></td></tr></table></figure><h2 id="修改vagrantfile"><a href="#修改vagrantfile" class="headerlink" title="修改vagrantfile"></a>修改vagrantfile</h2><p>通过 master.disksize.size node1.disksize.size node2.disksize.size 调整三台虚拟机磁盘大小</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-01&quot; do |master|</span><br><span class="line">    master.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    master.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    master.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.110&quot;</span><br><span class="line">    master.ssh.insert_key &#x3D; false</span><br><span class="line">    master.vm.hostname &#x3D; &quot;master&quot;</span><br><span class="line">    master.disksize.size &#x3D; &quot;40GB&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-02&quot; do |node1|</span><br><span class="line">    node1.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node1.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node1.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.111&quot;</span><br><span class="line">    node1.ssh.insert_key &#x3D; false</span><br><span class="line">    node1.vm.hostname &#x3D; &quot;node1&quot;</span><br><span class="line">    node1.disksize.size &#x3D; &quot;40GB&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-03&quot; do |node2|</span><br><span class="line">    node2.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node2.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node2.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.112&quot;</span><br><span class="line">    node2.ssh.insert_key &#x3D; false</span><br><span class="line">    node2.vm.hostname &#x3D; &quot;node2&quot;</span><br><span class="line">    node2.disksize.size &#x3D; &quot;40GB&quot;</span><br><span class="line">  end</span><br><span class="line">  </span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>重新启动即可</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant halt</span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Vagrant </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vagrant </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant调整CPU和内存</title>
      <link href="2021/01/18/Vagrant%E8%B0%83%E6%95%B4CPU%E5%92%8C%E5%86%85%E5%AD%98/"/>
      <url>2021/01/18/Vagrant%E8%B0%83%E6%95%B4CPU%E5%92%8C%E5%86%85%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="修改vagrantfile"><a href="#修改vagrantfile" class="headerlink" title="修改vagrantfile"></a>修改vagrantfile</h2><p>通过 vb.memory vb.cpus 调整三台虚拟机cpu和内存</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-01&quot; do |master|</span><br><span class="line">    master.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    master.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    master.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.110&quot;</span><br><span class="line">    master.ssh.insert_key &#x3D; false</span><br><span class="line">    master.vm.hostname &#x3D; &quot;master&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-02&quot; do |node1|</span><br><span class="line">    node1.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node1.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node1.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.111&quot;</span><br><span class="line">    node1.ssh.insert_key &#x3D; false</span><br><span class="line">    node1.vm.hostname &#x3D; &quot;node1&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;k8s-03&quot; do |node2|</span><br><span class="line">    node2.vm.box &#x3D;  &quot;centos7&quot;</span><br><span class="line">    node2.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">      vb.memory &#x3D; &quot;4096&quot;</span><br><span class="line">      vb.cpus &#x3D; 2</span><br><span class="line">    end</span><br><span class="line">    node2.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.112&quot;</span><br><span class="line">    node2.ssh.insert_key &#x3D; false</span><br><span class="line">    node2.vm.hostname &#x3D; &quot;node2&quot;</span><br><span class="line">  end</span><br><span class="line">  </span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>重新启动即可</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant halt</span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Vagrant </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vagrant </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ReplicationController、ReplicaSet和Deployment关联</title>
      <link href="2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/"/>
      <url>2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>ReplicationController、ReplicaSet和Deployment都是Kubernetes中Pod的控制器</p><h2 id="ReplicationController和ReplicaSet"><a href="#ReplicationController和ReplicaSet" class="headerlink" title="ReplicationController和ReplicaSet"></a>ReplicationController和ReplicaSet</h2><p>RC（ReplicationController）主要是用来确保容器应用的副本数始终保持在用户定义的副本数，也就是说容器异常退出，RC会自动创建新的Pod来替代。官方建议使用RS（ReplicaSet）来取代RC</p><p>RS（ReplicaSet）跟RC没有本质的区别，只是RS支持集合式的selector</p><blockquote><p>应用 nginx.yaml</p></blockquote><p>我们定义了3个副本的RS控制器的nginx Pod，具有app=nginx的标签</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: ReplicaSet</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br></pre></td></tr></table></figure><p>删除Pod，RS会自动创建新的Pod代替他们</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a1.png"></p><p>查看Pod标签</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a2.png"></p><p>我们给nginx-6462b修改标签，RS通过matchLabel匹配app=nginx标签关联的Pod副本数变成2个了，又会重新创建一个新的Pod</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a3.png"></p><p>当我们删除RS时，可以看到，标签app=test-nginx的Pod没有被删除</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a4.png"></p><h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p>虽然RS可以独立使用，但是一般还是建议使用Deployment来管理RS，主要是Deployment还支持滚动更新、回滚等操作</p><p>当我们创建一组deployment控制器类型的Pod时，deployment并不是直接管理Pod的，而是通过replicaset管理这组Pod，当使用deployment滚动更新时，deployment会创建一个新的replicaset:v2，然后replicaset:v2创建第一个pod:v2,当第一个pod:v2成功running后，replicaset:v1会销毁一个pod:v1；接着replicaset:v2会创建第二个pod:v2，待第二个pod:v2成功running后，replicaset:v1会销毁第二个pod:v1，依次按照这样子更新，直到replicaset:v2维持期望的副本数，这时，replicaset:v1维护的Pod副本数已经全部销毁，但是replicaset:v1控制器并不会销毁，而是处于一种停止状态，这是为了后续的回滚操作。</p><p>回滚和滚动更新类似，replicaset从v2版本回滚到v1版本，首先会创建第一个pod:v1，成功运行后，销毁一个pod:v2，然后创建第二个pod:v1，成功运行后，销毁另一个pod:v2。</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a5.png"></p><p>创建一组deployment控制器类型的nginx Pod</p><blockquote><p>应用 nginx.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br></pre></td></tr></table></figure><p>可以看到deployment关联着RS控制器管理Pod</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a6.png"></p><p>将nginx镜像更新为nginx:1.7.9</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># deployment指deployment控制器 nginx指deployment的名称 nginx&#x3D;nginx:1.7.9指将原来nginx name名称的容器更新为nginx:1.7.9 --record参数可以记录当前版本的Deployment都执行哪些命令</span><br><span class="line">kubectl set image deployment nginx nginx&#x3D;nginx:1.7.9 --record</span><br></pre></td></tr></table></figure><p>可以看到有个新的RS生成了</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a7.png"></p><p>你也可以通过下面命令暂停和开始更新</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#暂停更新</span><br><span class="line">kubectl rollout pause deployments nginx</span><br><span class="line">#查看更新过程中的状态信息</span><br><span class="line">kubectl rollout status deployments nginx</span><br><span class="line">#继续之前的更新</span><br><span class="line">kubectl rollout resume deployments nginx</span><br></pre></td></tr></table></figure><p>待更新完成，查看Pod和RS，之前的RS并不会被销毁</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a8.png"></p><p>查看更新后的镜像</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a9.png"></p><p>查看滚动更新历史</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/18/ReplicationController%E3%80%81ReplicaSet%E5%92%8CDeployment%E5%85%B3%E8%81%94/a10.png"></p><p>回滚上个版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx</span><br></pre></td></tr></table></figure><p>回滚到指定版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl rollout undo deployment nginx --to-revision&#x3D;1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes使用ipvs代替iptables</title>
      <link href="2021/01/16/Kubernetes%E4%BD%BF%E7%94%A8ipvs%E4%BB%A3%E6%9B%BFiptables/"/>
      <url>2021/01/16/Kubernetes%E4%BD%BF%E7%94%A8ipvs%E4%BB%A3%E6%9B%BFiptables/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>kubernetes1.8版本开始，kube-proxy引入了ipvs模式，kube-proxy监控pod的变化并创建ipvs rules，ipvs与iptables类似，也是在kernel下通过netfilter实现的，但是采用hash表存储规则，在规则多的情况下，hash表查询速率的优势就会显现出来。</p><h2 id="开启内核参数"><a href="#开启内核参数" class="headerlink" title="开启内核参数"></a>开启内核参数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOF</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">EOF</span><br><span class="line"># 是配置生效</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h2 id="安装ipvs"><a href="#安装ipvs" class="headerlink" title="安装ipvs"></a>安装ipvs</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y ipvsadm ipset</span><br><span class="line"></span><br><span class="line"># 临时生效</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line"></span><br><span class="line"># 永久生效</span><br><span class="line">cat &gt; &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules &lt;&lt;EOF</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="配置kube-proxy"><a href="#配置kube-proxy" class="headerlink" title="配置kube-proxy"></a>配置kube-proxy</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改 mode 字段，修改成 mode: &quot;ipvs&quot;</span><br><span class="line">kubectl edit cm kube-proxy -n kube-system</span><br><span class="line"># 重新生成kube-proxy</span><br><span class="line">kubectl get pod -n kube-system | grep kube-proxy | awk &#39;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&#39;</span><br></pre></td></tr></table></figure><h2 id="测试是否生效"><a href="#测试是否生效" class="headerlink" title="测试是否生效"></a>测试是否生效</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipvsadm -L -n</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/16/Kubernetes%E4%BD%BF%E7%94%A8ipvs%E4%BB%A3%E6%9B%BFiptables/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubeadm join流程</title>
      <link href="2021/01/14/Kubeadm-join%E6%B5%81%E7%A8%8B/"/>
      <url>2021/01/14/Kubeadm-join%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在kubeadm init过程中，会生成bootstrap token，node节点可以安装kubelet和kubeadm，执行kubeadm join加入到这个集群。</p><p>首先一开始，node上的kubeadm会发起一次“不安全模式”访问kube-apiserver，从而拿到保存在etcd中的cluster-info，也就是我们在kubeadm中最后说到的configmap，cluster-info保存着ca.crt等master的重要数据，而bootstrap token则扮演这个过程中的安全验证角色。node上的kubelet只要拿到cluster-info数据，那么之后就可以以“安全模式”连接到apiserver上去，这样一个新的节点就加入到了集群。</p><p>那么我们上面谈到node通过kubeadm join加入集群，在执行join命令时，首先会对当前node环境进行检查，然后会携带2个重要的参数discover-token-ca-cert-hash和token，进行身份验证</p><h2 id="discover-token-ca-cert-hash"><a href="#discover-token-ca-cert-hash" class="headerlink" title="discover-token-ca-cert-hash"></a>discover-token-ca-cert-hash</h2><p>用于node验证master身份，保证当前node join到正确的master中，执行join时，apiserver会下发下发ca.crt公钥证书，这个证书数据会被node存放在/etc/kubernetes/pki目录下面，然后kubeadm会用公钥证书的哈希值与–discover-token-ca-cert-hash的值进行比对，确定是否为正确的master</p><p>通过openssl计算公钥哈希值</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl x509 -in ca.crt -noout -pubkey | openssl rsa -pubin -outform DER 2&gt;&#x2F;dev&#x2F;null | sha256sum | cut -d&#39; &#39; -f1</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-join%E6%B5%81%E7%A8%8B/a1.png"></p><p>可以看到，在join的时候，master将ca.crt下发到node的/etc/kubernetes/pki目录下，然后通过openssl计算ca.crt的哈希值，跟我们join的–discover-token-ca-cert-hash是完全相同的</p><h2 id="token"><a href="#token" class="headerlink" title="token"></a>token</h2><p>用于master验证node身份，要想在集群首次引导启动时进行token验证，必须在kube-apiserver.yaml中开启enable-bootstrap-token-auth，一旦将此选项设置为true，那么就允许apiserver在集群init的时候，开启token验证。</p><p>token分为2段，例如我们这个 “oddhj0.q6ee7d16phc6bth2”，以 “.” 分割，前面一段是token id，后面一段是secret，当kubeadm join访问apiserver的时候，会在请求的header中携带这一个token，apiserver会根据这个token进行身份验证。</p><p>apiserver会查询kube-system名称空间下是否存在bootstrap-token前缀的secret</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get secret -n kube-system | grep bootstrap-token</span><br><span class="line">bootstrap-token-oddhj0                           bootstrap.kubernetes.io&#x2F;token         7      6h36m</span><br></pre></td></tr></table></figure><p>apiserver会用这个查询到的secret和header中的token进行验证</p><p>通过 kubectl get secret bootstrap-token-oddhj0 -o yaml -n kube-system 查看 token-id 和 token-secret 字段的值</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-join%E6%B5%81%E7%A8%8B/a2.png"></p><p>进行base64解码</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-join%E6%B5%81%E7%A8%8B/a3.png"></p><p>将这2个解码后的数据进行组合，就是 “oddhj0.q6ee7d16phc6bth2”，与header中的token完全一致</p><p>最后整个验证过程就完成，node就会成功加入到集群中</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubeadm init流程</title>
      <link href="2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/"/>
      <url>2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="1-引导前检查（pre-flight-checks）"><a href="#1-引导前检查（pre-flight-checks）" class="headerlink" title="1.引导前检查（pre-flight checks）"></a>1.引导前检查（pre-flight checks）</h2><p>kubeadm init执行之后，首先会进行pre-flight checks检查，确保master节点可以满足master组件可以安装的所有条件</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a1.png"></p><p>error级别的检查：</p><ul><li>kubeadm版本要与kubernetes版本的对比检查，kubeadm版本不小于kubernetes版本</li><li>kubernetes安装的系统需求检查，内核版本需大于3.10以上，4.x以上，是否设置了cgroups子系统，后端服务是否正常工作</li><li>其他检查：用户、主机、端口、swap、工具等</li></ul><h2 id="2-生成私钥和数字证书"><a href="#2-生成私钥和数字证书" class="headerlink" title="2.生成私钥和数字证书"></a>2.生成私钥和数字证书</h2><p>kubeadm会为整个集群生成多组私钥和数字证书，如果不指定外部的证书授权机构，kubeadm init会自建证书授权机构，并生成ca的私钥（ca.key）、自签署的公钥数字证书（ca.crt），用于签发后续kubernetes需要的其他公钥证书</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a2.png"></p><blockquote><p>kubeadm init生成的证书都在/etc/kubernetes/pki目录下</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a3.png"></p><h3 id="自建CA"><a href="#自建CA" class="headerlink" title="自建CA"></a>自建CA</h3><p>如果不指定外部的证书授权机构，kubeadm init会自建证书授权机构，并生成ca的私钥（ca.key）、自签署的公钥数字证书（ca.crt），用于签发后续kubernetes需要的其他公钥证书</p><p>查看ca.crt证书内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pki]# openssl x509 -in ca.crt -noout -text</span><br><span class="line">Certificate:</span><br><span class="line">    Data:</span><br><span class="line">        Version: 3 (0x2)</span><br><span class="line">        Serial Number: 0 (0x0)</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">        Issuer: CN&#x3D;kubernetes</span><br><span class="line">        Validity</span><br><span class="line">            Not Before: Jan 14 02:37:42 2021 GMT</span><br><span class="line">            Not After : Jan 12 02:37:42 2031 GMT</span><br><span class="line">        Subject: CN&#x3D;kubernetes</span><br><span class="line">        Subject Public Key Info:</span><br><span class="line">            Public Key Algorithm: rsaEncryption</span><br><span class="line">                Public-Key: (2048 bit)</span><br><span class="line">                Modulus:</span><br><span class="line">                    00:e1:9d:a8:43:d5:8f:74:99:40:21:df:88:a9:7b:</span><br><span class="line">                    cf:37:24:00:fc:87:73:3d:29:0c:5c:f1:53:46:40:</span><br><span class="line">                    56:16:97:fb:a4:c8:fb:2e:23:74:bc:18:e0:c6:c8:</span><br><span class="line">                    7e:d5:35:49:c6:23:5b:1a:82:80:ed:90:be:c2:2b:</span><br><span class="line">                    0f:94:fc:27:d3:7f:f7:3f:80:be:f9:e4:6e:64:d4:</span><br><span class="line">                    dc:1a:49:d0:f2:64:4b:45:6f:a3:9e:e3:c1:c9:a5:</span><br><span class="line">                    a0:20:51:65:b2:78:85:09:00:49:f6:ae:07:3a:e0:</span><br><span class="line">                    e1:c4:b5:10:fd:7b:fc:e3:c5:83:86:77:22:f8:34:</span><br><span class="line">                    26:df:c6:8d:7e:51:b4:cf:24:3e:08:9f:1e:6d:dd:</span><br><span class="line">                    85:99:16:6f:3f:f0:ea:78:6c:4f:15:e7:4a:40:03:</span><br><span class="line">                    0b:ab:a0:6f:c5:e1:b9:3b:43:69:94:44:09:88:fe:</span><br><span class="line">                    7d:48:6e:6c:ec:8e:7b:31:4a:e3:dd:c0:1d:48:33:</span><br><span class="line">                    05:93:5b:ec:9b:18:e9:a0:d1:bd:31:7b:60:0b:4e:</span><br><span class="line">                    6f:74:d6:5d:5c:7b:70:ce:43:ba:cd:7c:4c:93:32:</span><br><span class="line">                    db:e4:58:3d:73:11:bc:66:53:6c:a7:57:17:66:95:</span><br><span class="line">                    6e:12:90:5e:5f:5b:f6:a6:9e:9c:bc:45:40:e6:50:</span><br><span class="line">                    5c:b4:56:6b:a1:e8:55:e7:2f:29:20:fe:37:74:d0:</span><br><span class="line">                    fa:b7</span><br><span class="line">                Exponent: 65537 (0x10001)</span><br><span class="line">        X509v3 extensions:</span><br><span class="line">            X509v3 Key Usage: critical</span><br><span class="line">                Digital Signature, Key Encipherment, Certificate Sign</span><br><span class="line">            X509v3 Basic Constraints: critical</span><br><span class="line">                CA:TRUE</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">         88:d5:b9:ed:94:25:bd:57:a8:f0:da:eb:ec:98:6b:c0:f0:ee:</span><br><span class="line">         0b:27:a9:bd:52:3a:2e:35:78:ee:35:a1:a0:a3:a7:52:8a:f6:</span><br><span class="line">         52:bd:a2:b4:f7:bc:2b:39:2c:a3:a8:9d:be:02:3a:fd:79:cc:</span><br><span class="line">         32:aa:a4:44:fc:85:91:d2:89:88:20:fd:8f:e0:de:19:23:78:</span><br><span class="line">         cd:f5:7c:ae:fd:41:c6:bd:e3:e1:27:43:b5:74:00:f7:ae:c6:</span><br><span class="line">         a5:25:7d:f9:d6:e4:4e:c6:7c:94:9b:f0:38:f3:53:be:8b:35:</span><br><span class="line">         68:20:7e:0e:b7:ad:96:47:3b:6b:e3:4b:10:47:df:b3:c3:44:</span><br><span class="line">         4e:58:91:82:e0:4d:b3:b2:6d:49:44:d0:cc:2d:8b:66:63:dc:</span><br><span class="line">         37:67:44:0c:ca:51:ea:ca:ac:bf:8b:60:dc:b3:d8:fd:7b:4f:</span><br><span class="line">         8a:c9:9f:4b:32:37:bb:83:5c:af:8b:59:f5:32:35:b0:3d:82:</span><br><span class="line">         c3:50:af:5f:6c:9b:79:98:7c:1d:07:21:57:dc:fb:92:6a:54:</span><br><span class="line">         47:24:e6:2c:24:c4:80:17:21:a5:ac:90:e3:f4:54:ea:d0:2f:</span><br><span class="line">         6c:44:84:9e:51:62:66:76:e9:91:32:c4:a8:cc:12:ff:43:43:</span><br><span class="line">         4e:16:71:22:d6:c2:5d:7d:bb:f1:ff:3c:a7:ce:cc:38:29:ca:</span><br><span class="line">         fb:ca:44:98</span><br></pre></td></tr></table></figure><h3 id="apiserver私钥和公钥证书"><a href="#apiserver私钥和公钥证书" class="headerlink" title="apiserver私钥和公钥证书"></a>apiserver私钥和公钥证书</h3><p>kubeadm会生成apiserver的私钥文件（apiserver.key），用ca来签发apiserver的公钥数字证书（apiserver.crt）</p><p>查看apiserver.crt证书内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pki]# openssl x509 -in apiserver.crt -noout -text</span><br><span class="line">Certificate:</span><br><span class="line">    Data:</span><br><span class="line">        Version: 3 (0x2)</span><br><span class="line">        Serial Number: 6548373687643854637 (0x5ae07f2c9486d72d)</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">        Issuer: CN&#x3D;kubernetes</span><br><span class="line">        Validity</span><br><span class="line">            Not Before: Jan 14 02:37:42 2021 GMT</span><br><span class="line">            Not After : Jan 14 02:37:43 2022 GMT</span><br><span class="line">        Subject: CN&#x3D;kube-apiserver</span><br><span class="line">        Subject Public Key Info:</span><br><span class="line">            Public Key Algorithm: rsaEncryption</span><br><span class="line">                Public-Key: (2048 bit)</span><br><span class="line">                Modulus:</span><br><span class="line">                    00:cd:8c:87:bf:18:0a:61:b4:51:d3:22:20:e3:72:</span><br><span class="line">                    42:4e:ac:32:cc:d2:0a:41:3c:f0:70:eb:34:3c:09:</span><br><span class="line">                    0a:68:a4:f5:6d:c6:0a:8d:5f:93:dc:dd:9c:9f:68:</span><br><span class="line">                    21:97:f9:3d:95:da:4a:2f:69:82:ae:35:f1:e2:c4:</span><br><span class="line">                    cd:78:3a:98:55:9a:0f:24:d5:ae:19:92:c6:d7:8b:</span><br><span class="line">                    ff:5f:81:99:a6:52:0c:c3:9c:eb:d3:e9:91:47:f9:</span><br><span class="line">                    cf:51:1e:6b:a5:83:0d:c0:37:e0:61:3d:b7:ee:09:</span><br><span class="line">                    02:e9:25:b4:ef:2d:58:9b:e7:2a:b5:74:bf:e8:a1:</span><br><span class="line">                    62:f4:8c:ae:58:25:b3:bc:a8:c3:af:58:db:25:e6:</span><br><span class="line">                    85:14:2e:39:70:86:1f:c4:27:70:50:6c:05:85:aa:</span><br><span class="line">                    e5:8e:9b:1c:55:b0:95:96:25:e7:df:f2:f6:42:be:</span><br><span class="line">                    6e:ed:85:46:72:c7:db:64:e2:23:d7:ca:38:e9:9a:</span><br><span class="line">                    24:7b:de:1b:ca:e3:b4:ac:c2:41:fa:bc:af:88:7e:</span><br><span class="line">                    0c:15:72:f7:f7:2b:3a:a9:fd:7a:57:1d:95:2c:c9:</span><br><span class="line">                    61:c6:48:ac:cf:2d:db:62:4d:41:be:e6:69:01:a0:</span><br><span class="line">                    97:5f:0f:66:b7:c3:3d:2f:12:84:3f:78:fc:87:40:</span><br><span class="line">                    8c:74:7e:23:4c:c0:f0:c8:f0:9e:1a:4f:1b:7e:a5:</span><br><span class="line">                    db:3f</span><br><span class="line">                Exponent: 65537 (0x10001)</span><br><span class="line">        X509v3 extensions:</span><br><span class="line">            X509v3 Key Usage: critical</span><br><span class="line">                Digital Signature, Key Encipherment</span><br><span class="line">            X509v3 Extended Key Usage: </span><br><span class="line">                TLS Web Server Authentication</span><br><span class="line">            X509v3 Subject Alternative Name: </span><br><span class="line">                DNS:k8s-master, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP Address:10.1.0.1, IP Address:192.168.83.128</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">         41:04:f1:f1:ec:03:61:30:1e:57:4e:bf:d5:f1:29:0e:ab:99:</span><br><span class="line">         68:3d:51:0e:d4:e4:98:d3:87:4f:9d:4c:d5:3a:50:73:0a:87:</span><br><span class="line">         49:a6:fe:a6:99:34:4f:24:40:ca:ee:a8:37:bf:09:3c:c3:d8:</span><br><span class="line">         36:f4:f6:9f:29:ad:e8:71:90:aa:1d:cf:fc:db:4a:50:9b:3d:</span><br><span class="line">         c4:3f:e5:f8:07:4f:d3:9a:c4:7f:50:ca:2f:92:65:42:e5:b4:</span><br><span class="line">         27:7e:41:bb:87:17:5a:1c:01:e0:f7:70:38:59:a6:f3:e5:03:</span><br><span class="line">         07:a6:c7:de:03:b9:32:e7:f7:79:8d:ed:d6:3d:0f:6e:e2:79:</span><br><span class="line">         a4:22:a7:50:95:d4:83:8e:42:fa:59:10:02:cd:82:80:27:16:</span><br><span class="line">         80:e0:45:99:b0:85:60:76:d7:e9:07:ed:cc:68:c5:80:b0:82:</span><br><span class="line">         6a:b9:24:b9:3c:b9:4d:5e:88:a6:54:7a:45:79:35:46:5e:68:</span><br><span class="line">         7b:77:f2:78:5c:3c:60:79:63:de:96:79:c3:c6:85:3b:ef:d2:</span><br><span class="line">         3f:02:de:70:d7:f6:5c:4d:64:fb:ad:f9:31:62:ae:1b:ae:8c:</span><br><span class="line">         b6:b6:cf:9e:cc:ac:a9:3a:b5:f4:63:6d:80:95:c8:79:e8:d9:</span><br><span class="line">         8f:88:1d:80:15:97:58:c6:65:ce:98:4b:b1:6c:1b:29:ec:60:</span><br><span class="line">         8c:39:65:b5</span><br></pre></td></tr></table></figure><h3 id="apiserver访问kubelet使用的客户端私钥与证书"><a href="#apiserver访问kubelet使用的客户端私钥与证书" class="headerlink" title="apiserver访问kubelet使用的客户端私钥与证书"></a>apiserver访问kubelet使用的客户端私钥与证书</h3><p>apiserver需要向各个node的kubelet主动发起连接，kubelet会通过client端的ssl证书，校验apiserver建立的连接</p><p>apiserver-kubelet-client.crt和apiserver-kubelet-client.key用来校验apiserver身份的数字证书</p><h3 id="serviceaccount私钥和公钥"><a href="#serviceaccount私钥和公钥" class="headerlink" title="serviceaccount私钥和公钥"></a>serviceaccount私钥和公钥</h3><p>sa.key和sa.pub是一对数字证书</p><h3 id="Etcd相关私钥和数字证书"><a href="#Etcd相关私钥和数字证书" class="headerlink" title="Etcd相关私钥和数字证书"></a>Etcd相关私钥和数字证书</h3><p>首先etcd是整个k8s集群的数据中心，只有apiserver才可以访问，所有组件都是通过apiserver存储数据的，为了建立apiserver和etcd的安全通信，kubeadm init会生成apiserver访问etcd的安全证书，即apiserver-etcd-client.crt和apiserver-etcd-client.key，其中apiserver-etcd-client.crt并不是由ca.crt签发的，而是有pki/etcd/ca.crt签发</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 并不是由&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt签发</span><br><span class="line">[root@k8s-master pki]# openssl verify -CAfile ca.crt apiserver-etcd-client.crt </span><br><span class="line">apiserver-etcd-client.crt: O &#x3D; system:masters, CN &#x3D; kube-apiserver-etcd-client</span><br><span class="line">error 20 at 0 depth lookup:unable to get local issuer certificate</span><br><span class="line"># 是由&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt签发</span><br><span class="line">[root@k8s-master pki]# openssl verify -CAfile etcd&#x2F;ca.crt apiserver-etcd-client.crt </span><br><span class="line">apiserver-etcd-client.crt: OK</span><br></pre></td></tr></table></figure><h2 id="3-生成控制平面组件kubeconfig文件，这些配置用于组件间的通信鉴权"><a href="#3-生成控制平面组件kubeconfig文件，这些配置用于组件间的通信鉴权" class="headerlink" title="3.生成控制平面组件kubeconfig文件，这些配置用于组件间的通信鉴权"></a>3.生成控制平面组件kubeconfig文件，这些配置用于组件间的通信鉴权</h2><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a4.png"></p><p>这些文件生成在/etc/kubernetes目录下</p><ul><li>kubelet.conf：被kubelet组件使用，用于访问apiserver</li><li>scheduler.conf：被scheduler组件使用，用于访问apiserver</li><li>controller-manager.conf：被controller-manager组件使用，用于访问apiserver</li><li>admin.conf：包含整个集群的最高权限配置数据</li></ul><p>admin.conf中包含cluster、user和context信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# cat admin.conf </span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: </span><br><span class="line">    server: https:&#x2F;&#x2F;192.168.83.128:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kubernetes-admin</span><br><span class="line">  name: kubernetes-admin@kubernetes</span><br><span class="line">current-context: kubernetes-admin@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: kubernetes-admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: </span><br><span class="line">    client-key-data: </span><br></pre></td></tr></table></figure><p>一旦配置 $KUBECONFIG 变量，指向/etc/kubernetes/admin.conf，则kubectl就会使用KUBECONFIG变量所配置的信息。contexts用来将users和clusters绑定，从而通过切换context来变换不通身份管理不同集群</p><h2 id="4-生成控制平面组件manifest文件"><a href="#4-生成控制平面组件manifest文件" class="headerlink" title="4.生成控制平面组件manifest文件"></a>4.生成控制平面组件manifest文件</h2><p>这些文件会被master节点的kubelet读取，并且启动控制平面组件，并维护控制平面组件状态</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a5.png"></p><p>这些文件存在/etc/kubernetes/manifests目录下</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a6.png"></p><h2 id="5-下载镜像，等待控制平面组件启动"><a href="#5-下载镜像，等待控制平面组件启动" class="headerlink" title="5.下载镜像，等待控制平面组件启动"></a>5.下载镜像，等待控制平面组件启动</h2><p>kubeadm会依赖kubelet下载镜像并且启动static pod，kubelet会一直探测 localhost:6443/healthz（apiserver存活性探针）</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a7.png"></p><p>查看 kube-apiserver.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 192.168.83.128</span><br><span class="line">        path: &#x2F;healthz</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="6-用kubeadm-config保存Configuration"><a href="#6-用kubeadm-config保存Configuration" class="headerlink" title="6.用kubeadm-config保存Configuration"></a>6.用kubeadm-config保存Configuration</h2><p>kubeadm-config是ConfigMap</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a8.png"></p><h2 id="7-设定Master标志"><a href="#7-设定Master标志" class="headerlink" title="7.设定Master标志"></a>7.设定Master标志</h2><p>将当前节点设置为master，即打上相关的labels和taints</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a9.png"></p><h2 id="8-生成bootstrap-token"><a href="#8-生成bootstrap-token" class="headerlink" title="8.生成bootstrap token"></a>8.生成bootstrap token</h2><p>node节点可以使用这个token加入kubernetes集群，在生成token之后，kubeadm会将ca.crt等master重要信息通过configmap保存在etcd，这个configmap名字是cluster-info</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a10.png"></p><h2 id="9-安装DNS和kube-proxy组件"><a href="#9-安装DNS和kube-proxy组件" class="headerlink" title="9.安装DNS和kube-proxy组件"></a>9.安装DNS和kube-proxy组件</h2><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubeadm-init%E6%B5%81%E7%A8%8B/a11.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二进制搭建Kubernetes集群</title>
      <link href="2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><table><thead><tr><th>IP</th><th>配置</th><th>主机名</th><th>组件</th></tr></thead><tbody><tr><td>192.168.83.128</td><td>2c4g</td><td>k8s-master</td><td>apiserver、controller-manager、scheduler、etcd</td></tr><tr><td>192.168.83.129</td><td>2c4g</td><td>k8s-node1</td><td>kubelet、kube-proxy、docker、flannel、etcd</td></tr><tr><td>192.168.83.130</td><td>2c4g</td><td>k8s-node2</td><td>kubelet、kube-proxy、docker、flannel、etcd</td></tr></tbody></table><blockquote><p>关闭防火墙</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><blockquote><p>关闭selinux</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><blockquote><p>关闭swap</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure><blockquote><p>添加主机名与IP对应关系（记得设置主机名）</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;hosts</span><br><span class="line">192.168.83.128 k8s-master</span><br><span class="line">192.168.83.129 k8s-node1</span><br><span class="line">192.168.83.130 k8s-node2</span><br></pre></td></tr></table></figure><blockquote><p>将桥接的IPv4流量传递到iptables的链</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>使配置生效</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><blockquote><p>同步时间</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure><h2 id="部署Etcd集群"><a href="#部署Etcd集群" class="headerlink" title="部署Etcd集群"></a>部署Etcd集群</h2><p>需要使用cfssl来签发证书，下载cfssl工具</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl_linux-amd64</span><br><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssljson_linux-amd64</span><br><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl-certinfo_linux-amd64</span><br><span class="line">chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;cfssl</span><br><span class="line">mv cfssljson_linux-amd64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;cfssljson</span><br><span class="line">mv cfssl-certinfo_linux-amd64 &#x2F;usr&#x2F;bin&#x2F;cfssl-certinfo</span><br></pre></td></tr></table></figure><h3 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h3><blockquote><p>vim ca-config.json</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;www&quot;: &#123;</span><br><span class="line">         &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">         &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>vim ca-csr.json</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;etcd CA&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;Beijing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>vim server-csr.json</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改下面三个ip</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    &quot;192.168.83.128&quot;,</span><br><span class="line">    &quot;192.168.83.129&quot;,</span><br><span class="line">    &quot;192.168.83.130&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成证书</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;www server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure><h3 id="部署Etcd"><a href="#部署Etcd" class="headerlink" title="部署Etcd"></a>部署Etcd</h3><p>下载二进制包：<a href="https://github.com/coreos/etcd/releases/tag/v3.2.12">https://github.com/coreos/etcd/releases/tag/v3.2.12</a></p><blockquote><p>以下步骤三台机器相同，只需要将etcd配置中的ip修改成对应的机器ip即可</p></blockquote><p>创建etcd目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压二进制包</span><br><span class="line">tar zxvf etcd-v3.2.12-linux-amd64.tar.gz</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;etcd&#x2F;&#123;bin,cfg,ssl&#125;</span><br><span class="line">cp etcd-v3.2.12-linux-amd64&#x2F;etcd &#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;</span><br><span class="line">cp etcd-v3.2.12-linux-amd64&#x2F;etcdctl &#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;</span><br><span class="line"># 将刚刚生成的证书拷贝到三台机器的&#x2F;opt&#x2F;etcd&#x2F;ssl目录下</span><br><span class="line">cp ca*pem server*pem &#x2F;opt&#x2F;etcd&#x2F;ssl</span><br></pre></td></tr></table></figure><p>创建etcd配置文件，需要将ip修改成对应node机器的ip</p><blockquote><p>vim /opt/etcd/cfg/etcd</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#[Member]</span><br><span class="line"># 节点名称</span><br><span class="line">ETCD_NAME&#x3D;&quot;etcd01&quot;</span><br><span class="line"># 数据目录</span><br><span class="line">ETCD_DATA_DIR&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;default.etcd&quot;</span><br><span class="line"># 集群通信监听地址</span><br><span class="line">ETCD_LISTEN_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2380&quot;</span><br><span class="line"># 客户端访问监听地址</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2379&quot;</span><br><span class="line"></span><br><span class="line">#[Clustering]</span><br><span class="line"># 集群通告地址</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2380&quot;</span><br><span class="line"># 客户端通告地址</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2379&quot;</span><br><span class="line"># 集群节点地址</span><br><span class="line">ETCD_INITIAL_CLUSTER&#x3D;&quot;etcd01&#x3D;https:&#x2F;&#x2F;192.168.83.128:2380,etcd02&#x3D;https:&#x2F;&#x2F;192.168.83.129:2380,etcd03&#x3D;https:&#x2F;&#x2F;192.168.83.130:2380&quot;</span><br><span class="line"># 集群token</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN&#x3D;&quot;etcd-cluster&quot;</span><br><span class="line"># 加入集群的当前状态，new表示新集群，existing表示加入已有集群</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE&#x3D;&quot;new&quot;</span><br></pre></td></tr></table></figure><p>systemd管理etcd</p><blockquote><p>vim /usr/lib/systemd/system/etcd.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Etcd Server</span><br><span class="line">After&#x3D;network.target</span><br><span class="line">After&#x3D;network-online.target</span><br><span class="line">Wants&#x3D;network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;cfg&#x2F;etcd</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcd \</span><br><span class="line">--name&#x3D;$&#123;ETCD_NAME&#125; \</span><br><span class="line">--data-dir&#x3D;$&#123;ETCD_DATA_DIR&#125; \</span><br><span class="line">--listen-peer-urls&#x3D;$&#123;ETCD_LISTEN_PEER_URLS&#125; \</span><br><span class="line">--listen-client-urls&#x3D;$&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http:&#x2F;&#x2F;127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls&#x3D;$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \</span><br><span class="line">--initial-advertise-peer-urls&#x3D;$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \</span><br><span class="line">--initial-cluster&#x3D;$&#123;ETCD_INITIAL_CLUSTER&#125; \</span><br><span class="line">--initial-cluster-token&#x3D;$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \</span><br><span class="line">--initial-cluster-state&#x3D;new \</span><br><span class="line">--cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \</span><br><span class="line">--key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--peer-cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \</span><br><span class="line">--peer-key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--peer-trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">LimitNOFILE&#x3D;65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动etcd并设置开机自启</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start etcd</span><br><span class="line">systemctl enable etcd</span><br></pre></td></tr></table></figure><p>检查集群状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcdctl \</span><br><span class="line">--ca-file&#x3D;ca.pem --cert-file&#x3D;server.pem --key-file&#x3D;server-key.pem \</span><br><span class="line">--endpoints&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2379,https:&#x2F;&#x2F;192.168.83.129:2379,https:&#x2F;&#x2F;192.168.83.130:2379&quot; \</span><br><span class="line">cluster-health</span><br></pre></td></tr></table></figure><h2 id="部署Docker"><a href="#部署Docker" class="headerlink" title="部署Docker"></a>部署Docker</h2><p>在Node上执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">yum install docker-ce -y</span><br><span class="line">curl -sSL https:&#x2F;&#x2F;get.daocloud.io&#x2F;daotools&#x2F;set_mirror.sh | sh -s http:&#x2F;&#x2F;bc437cce.m.daocloud.io</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure><h2 id="部署Flannel"><a href="#部署Flannel" class="headerlink" title="部署Flannel"></a>部署Flannel</h2><p>向etcd中写入预定义子网段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcdctl \</span><br><span class="line">--ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem --cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem --key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--endpoints&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:2379,https:&#x2F;&#x2F;192.168.83.129:2379,https:&#x2F;&#x2F;192.168.83.130:2379&quot; \</span><br><span class="line">set &#x2F;coreos.com&#x2F;network&#x2F;config  &#39;&#123; &quot;Network&quot;: &quot;172.17.0.0&#x2F;16&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><p>以下操作都在每个Node中执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;flannel&#x2F;releases&#x2F;download&#x2F;v0.10.0&#x2F;flannel-v0.10.0-linux-amd64.tar.gz</span><br><span class="line">tar zxvf flannel-v0.10.0-linux-amd64.tar.gz</span><br><span class="line">mkdir &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl&#125; -p</span><br><span class="line">mv flanneld mk-docker-opts.sh &#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br></pre></td></tr></table></figure><p>配置flannel</p><blockquote><p>vim  /opt/kubernetes/cfg/flanneld</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FLANNEL_OPTIONS&#x3D;&quot;--etcd-endpoints&#x3D;https:&#x2F;&#x2F;192.168.83.128:2379,https:&#x2F;&#x2F;192.168.83.129:2379,https:&#x2F;&#x2F;192.168.83.130:2379 -etcd-cafile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem -etcd-certfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem -etcd-keyfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem&quot;</span><br></pre></td></tr></table></figure><p>systemd管理flannel</p><blockquote><p>vim  /usr/lib/systemd/system/flanneld.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Flanneld overlay address etcd agent</span><br><span class="line">After&#x3D;network-online.target network.target</span><br><span class="line">Before&#x3D;docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;flanneld</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;flanneld --ip-masq $FLANNEL_OPTIONS</span><br><span class="line">ExecStartPost&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d &#x2F;run&#x2F;flannel&#x2F;subnet.env</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>在docker启动项中指定子网段</p><blockquote><p>vim /usr/lib/systemd/system/docker.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Docker Application Container Engine</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;docs.docker.com</span><br><span class="line">After&#x3D;network-online.target firewalld.service</span><br><span class="line">Wants&#x3D;network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;run&#x2F;flannel&#x2F;subnet.env</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd $DOCKER_NETWORK_OPTIONS</span><br><span class="line">ExecReload&#x3D;&#x2F;bin&#x2F;kill -s HUP $MAINPID</span><br><span class="line">LimitNOFILE&#x3D;infinity</span><br><span class="line">LimitNPROC&#x3D;infinity</span><br><span class="line">LimitCORE&#x3D;infinity</span><br><span class="line">TimeoutStartSec&#x3D;0</span><br><span class="line">Delegate&#x3D;yes</span><br><span class="line">KillMode&#x3D;process</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">StartLimitBurst&#x3D;3</span><br><span class="line">StartLimitInterval&#x3D;60s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>重启flannel和docker</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart flanneld</span><br><span class="line">systemctl enable flanneld</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><p>通过 ip a 命令查看并确保docker0和flannel1在一个网段</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a1.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a2.png"></p><p>在当前节点访问另一个Node节点docker0 IP，确保能够通信</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a3.png"></p><h2 id="在Master上部署组件"><a href="#在Master上部署组件" class="headerlink" title="在Master上部署组件"></a>在Master上部署组件</h2><h3 id="生成证书-1"><a href="#生成证书-1" class="headerlink" title="生成证书"></a>生成证书</h3><h4 id="生成CA证书"><a href="#生成CA证书" class="headerlink" title="生成CA证书"></a>生成CA证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">         &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">         &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure><h4 id="生成apiserver证书"><a href="#生成apiserver证书" class="headerlink" title="生成apiserver证书"></a>生成apiserver证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 将192.168.83.128修改成master节点ip</span><br><span class="line">cat &gt; server-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;10.0.0.1&quot;,</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.83.128&quot;,</span><br><span class="line">      &quot;kubernetes&quot;,</span><br><span class="line">      &quot;kubernetes.default&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster.local&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure><h4 id="生成kube-proxy证书"><a href="#生成kube-proxy证书" class="headerlink" title="生成kube-proxy证书"></a>生成kube-proxy证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br></pre></td></tr></table></figure><p>最后所有的证书</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls *pem</span><br><span class="line">ca-key.pem  ca.pem  kube-proxy-key.pem  kube-proxy.pem  server-key.pem  server.pem</span><br></pre></td></tr></table></figure><h3 id="部署apiserver"><a href="#部署apiserver" class="headerlink" title="部署apiserver"></a>部署apiserver</h3><p>下载二进制包：<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md</a></p><p>下载 kubernetes-server-linux-amd64.tar.gz 即可</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">mkdir &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl&#125; -p</span><br><span class="line">cd kubernetes&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp kube-apiserver kube-scheduler kube-controller-manager kubectl &#x2F;opt&#x2F;kubernetes&#x2F;bin</span><br></pre></td></tr></table></figure><p>将刚刚生成的证书拷贝过来</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp *pem &#x2F;opt&#x2F;kubernetes&#x2F;ssl</span><br></pre></td></tr></table></figure><p>创建token文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 文件内容依次是 随机字符串，用户名，UID，用户组</span><br><span class="line">cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv &lt;&lt; EOF</span><br><span class="line">674c457d4dcf2eefe4920d7dbb6b0ddc,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建apiserver配置文件</p><blockquote><p>vim /opt/kubernetes/cfg/kube-apiserver</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_APISERVER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \</span><br><span class="line">--v&#x3D;4 \</span><br><span class="line">--etcd-servers&#x3D;https:&#x2F;&#x2F;192.168.83.128:2379,https:&#x2F;&#x2F;192.168.83.129:2379,https:&#x2F;&#x2F;192.168.83.130:2379 \</span><br><span class="line">--bind-address&#x3D;192.168.83.128 \</span><br><span class="line">--secure-port&#x3D;6443 \</span><br><span class="line">--advertise-address&#x3D;192.168.83.128 \</span><br><span class="line">--allow-privileged&#x3D;true \</span><br><span class="line">--service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \</span><br><span class="line">--enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota,NodeRestriction \</span><br><span class="line">--authorization-mode&#x3D;RBAC,Node \</span><br><span class="line">--enable-bootstrap-token-auth \</span><br><span class="line">--token-auth-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv \</span><br><span class="line">--service-node-port-range&#x3D;30000-50000 \</span><br><span class="line">--tls-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server.pem  \</span><br><span class="line">--tls-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;server-key.pem \</span><br><span class="line">--client-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--service-account-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem \</span><br><span class="line">--etcd-cafile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--etcd-certfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server.pem \</span><br><span class="line">--etcd-keyfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;server-key.pem&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li>–logtostderr   启用日志</li><li>–v   日志等级</li><li>–etcd-servers   etcd集群地址</li><li>–bind-address   监听地址</li><li>–secure-port   https安全端口</li><li>–advertise-address   集群通告地址</li><li>–allow-privileged   启用授权</li><li>–service-cluster-ip-range   service虚拟ip地址段</li><li>–authorization-mode   认证授权，启用RBAC授权和节点自管理</li><li>–enable-bootstrap-token-auth   启用TLS bootstrap功能</li><li>–token-auth-file   token文件</li><li>–service-node-port-range   service node类型默认分配的端口范围</li></ul><p>systemd管理apiserver</p><blockquote><p>vim  /usr/lib/systemd/system/kube-apiserver.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes API Server</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-apiserver</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-apiserver $KUBE_APISERVER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver</span><br><span class="line">systemctl start kube-apiserver</span><br></pre></td></tr></table></figure><h3 id="部署scheduler"><a href="#部署scheduler" class="headerlink" title="部署scheduler"></a>部署scheduler</h3><blockquote><p>vim  /opt/kubernetes/cfg/kube-scheduler</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_SCHEDULER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \</span><br><span class="line">--v&#x3D;4 \</span><br><span class="line">--master&#x3D;127.0.0.1:8080 \</span><br><span class="line">--leader-elect&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li>–master   连接本地的apiserver</li><li>–leader-elect   当前组件启动多个时，自动选举</li></ul><p>systemd管理schduler</p><blockquote><p>vim /usr/lib/systemd/system/kube-scheduler.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Scheduler</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-scheduler $KUBE_SCHEDULER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-scheduler</span><br><span class="line">systemctl start kube-scheduler</span><br></pre></td></tr></table></figure><h3 id="部署controller-manager"><a href="#部署controller-manager" class="headerlink" title="部署controller-manager"></a>部署controller-manager</h3><blockquote><p>vim /opt/kubernetes/cfg/kube-controller-manager</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_CONTROLLER_MANAGER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \</span><br><span class="line">--v&#x3D;4 \</span><br><span class="line">--master&#x3D;127.0.0.1:8080 \</span><br><span class="line">--leader-elect&#x3D;true \</span><br><span class="line">--address&#x3D;127.0.0.1 \</span><br><span class="line">--service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \</span><br><span class="line">--cluster-name&#x3D;kubernetes \</span><br><span class="line">--cluster-signing-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--cluster-signing-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem  \</span><br><span class="line">--root-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \</span><br><span class="line">--service-account-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem&quot;</span><br></pre></td></tr></table></figure><p>systemd管理controller-manager</p><blockquote><p>vim /usr/lib/systemd/system/kube-controller-manager.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Controller Manager</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-controller-manager</span><br><span class="line">systemctl start kube-controller-manager</span><br></pre></td></tr></table></figure><p>所有组件都启动成功后，查看集群组件状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl get cs</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a4.png"></p><h2 id="在Node上部署组件"><a href="#在Node上部署组件" class="headerlink" title="在Node上部署组件"></a>在Node上部署组件</h2><h3 id="将-kubelet-bootstrap-用户绑定到系统集群角色"><a href="#将-kubelet-bootstrap-用户绑定到系统集群角色" class="headerlink" title="将 kubelet-bootstrap 用户绑定到系统集群角色"></a>将 kubelet-bootstrap 用户绑定到系统集群角色</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl create clusterrolebinding kubelet-bootstrap \</span><br><span class="line">  --clusterrole&#x3D;system:node-bootstrapper \</span><br><span class="line">  --user&#x3D;kubelet-bootstrap</span><br></pre></td></tr></table></figure><h3 id="创建-kubeconfig-文件"><a href="#创建-kubeconfig-文件" class="headerlink" title="创建 kubeconfig 文件"></a>创建 kubeconfig 文件</h3><p>在Master上的生成证书的目录下执行下面命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建 kubelet bootstrapping kubeconfig 变量</span><br><span class="line">BOOTSTRAP_TOKEN&#x3D;674c457d4dcf2eefe4920d7dbb6b0ddc</span><br><span class="line">KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;192.168.83.128:6443&quot;</span><br><span class="line"># 设置集群参数</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;.&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;bootstrap.kubeconfig</span><br><span class="line"># 设置客户端认证参数</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token&#x3D;$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig&#x3D;bootstrap.kubeconfig</span><br><span class="line"># 设置上下文参数</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;kubelet-bootstrap \</span><br><span class="line">  --kubeconfig&#x3D;bootstrap.kubeconfig</span><br><span class="line"># 设置默认上下文</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config use-context default --kubeconfig&#x3D;bootstrap.kubeconfig</span><br><span class="line"># 创建kube-proxy kubeconfig文件</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;.&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate&#x3D;.&#x2F;kube-proxy.pem \</span><br><span class="line">  --client-key&#x3D;.&#x2F;kube-proxy-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config set-context default \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;kube-proxy \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl config use-context default --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><p>执行完成后当前证书目录下会生成 bootstrap.kubeconfig  kube-proxy.kubeconfig这2个文件，将他们拷贝到Node节点的 /opt/kubernetes/cfg 目录下</p><h3 id="部署kubelet"><a href="#部署kubelet" class="headerlink" title="部署kubelet"></a>部署kubelet</h3><p>将之前二进制包里面的kubelet和kube-proxy拷贝到Node上的/opt/kubernetes/bin目录下</p><p>下面在所有Node节点上执行，注意需要修改对应的ip：</p><p>创建kubelet配置文件</p><blockquote><p>vim /opt/kubernetes/cfg/kubelet</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBELET_OPTS&#x3D;&quot;--logtostderr&#x3D;true \</span><br><span class="line">--v&#x3D;4 \</span><br><span class="line">--hostname-override&#x3D;192.168.83.129 \</span><br><span class="line">--kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.kubeconfig \</span><br><span class="line">--bootstrap-kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;bootstrap.kubeconfig \</span><br><span class="line">--config&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.config \</span><br><span class="line">--cert-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl \</span><br><span class="line">--pod-infra-container-image&#x3D;registry.cn-hangzhou.aliyuncs.com&#x2F;google-containers&#x2F;pause-amd64:3.0&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li>–hostname-override   在集群中显示的主机名</li><li>–kubeconfig   指定 kubeconfig 文件位置，会自动生成</li><li>–bootstrap-kubeconfig   指定刚才生成的 bootstrap.kubeconfig 文件</li><li>–cert-dir   颁发证书存放位置</li><li>–pod-infra-container-image   管理Pod网络的镜像</li></ul><p>创建kubelet.config配置文件</p><blockquote><p>vim /opt/kubernetes/cfg/kubelet.config</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io&#x2F;v1beta1</span><br><span class="line">address: 192.168.83.129</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">clusterDNS: [&quot;10.0.0.2&quot;]</span><br><span class="line">clusterDomain: cluster.local.</span><br><span class="line">failSwapOn: false</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: true</span><br></pre></td></tr></table></figure><p>systemd管理kubelet</p><blockquote><p>vim /usr/lib/systemd/system/kubelet.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Kubelet</span><br><span class="line">After&#x3D;docker.service</span><br><span class="line">Requires&#x3D;docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubelet $KUBELET_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">KillMode&#x3D;process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet</span><br><span class="line">systemctl start kubelet</span><br></pre></td></tr></table></figure><p>在Master节点审批Node加入集群</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl get csr</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl certificate approve &lt;CONDITION&gt;</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl get node</span><br></pre></td></tr></table></figure><h3 id="部署kube-proxy"><a href="#部署kube-proxy" class="headerlink" title="部署kube-proxy"></a>部署kube-proxy</h3><blockquote><p>vim /opt/kubernetes/cfg/kube-proxy</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBE_PROXY_OPTS&#x3D;&quot;--logtostderr&#x3D;true \</span><br><span class="line">--v&#x3D;4 \</span><br><span class="line">--hostname-override&#x3D;192.168.83.129 \</span><br><span class="line">--cluster-cidr&#x3D;10.0.0.0&#x2F;24 \</span><br><span class="line">--kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.kubeconfig&quot;</span><br></pre></td></tr></table></figure><p>systemd管理kube-proxy</p><blockquote><p>vim /usr/lib/systemd/system/kube-proxy.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Proxy</span><br><span class="line">After&#x3D;network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-proxy $KUBE_PROXY_OPTS</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-proxy</span><br><span class="line">systemctl start kube-proxy</span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl get cs</span><br><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl get node</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a5.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><blockquote><p>vim nginx.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br></pre></td></tr></table></figure><p>应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a6.png"></p><p>通过node ip+nodeport访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a7.png"></p><blockquote><p>注意：</p><p>如果你的Master不想承担工作负载，那么无需在master部署docker、flannel、kubelet和kube-proxy；反之，则在master上执行上面docker部署和flannel部署的操作</p></blockquote><p>最后同意master的自签证请求，将master加入集群</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%90%AD%E5%BB%BAKubernetes%E9%9B%86%E7%BE%A4/a8.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes组件及介绍</title>
      <link href="2021/01/14/Kubernetes%E7%BB%84%E4%BB%B6%E5%8F%8A%E4%BB%8B%E7%BB%8D/"/>
      <url>2021/01/14/Kubernetes%E7%BB%84%E4%BB%B6%E5%8F%8A%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kubernetes节点包含Master（主控节点）和Node（工作节点）</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/14/Kubernetes%E7%BB%84%E4%BB%B6%E5%8F%8A%E4%BB%8B%E7%BB%8D/a1.png"></p><h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><p>K8S中的Master是集群的控制节点，负责整个集群的管理和控制</p><p>在Master节点上运行着这些Kubernetes组件：</p><ul><li>apiserver：它是集群的统一入口，提供集群管理的REST API接口，只有apiserver可以操作etcd</li><li>scheduler：负责资源的调度，通过apiserver的watch接口监听新建Pod副本信息，并通过调度算法为该新建的Pod选择最合适的node</li><li>controller-manager：K8S集群所有资源对象的自动化控制中心，集群内所有controller的核心管理者，针对每一种资源都有相应的controller，保证其下管理的controller所对应的资源都处于期望的状态</li><li>etcd：用于保存集群资源对象以及状态数据</li><li>docker：负责容器的创建和管理</li></ul><h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2><p>Node是K8S集群的工作节点，Master会把任务分配给Node，当Node发生宕机时，Master会把此Node上的工作负载转移到其他Node</p><p>每个Node节点上运行着这些组件：</p><ul><li>Kubelet：Master分配到Node节点上的管家，负责管理该Node上容器的生命周期，并定期的向Master上报节点资源、pod状态等</li><li>kube-proxy：实现Service的通信和负载均衡功能</li><li>docker：负责容器的创建和管理</li></ul>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins持续发布OCP微服务到Kubernetes</title>
      <link href="2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/"/>
      <url>2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>Kubernetes集群：<a href="https://1335402049.github.io/2019/10/26/Kubeadm%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/">https://1335402049.github.io/2019/10/26/Kubeadm%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/</a></li><li>GitLab(独立部署)：<a href="https://1335402049.github.io/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/">https://1335402049.github.io/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</a></li><li>Jenkins：<a href="https://1335402049.github.io/2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/">https://1335402049.github.io/2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/</a></li><li>Harbor：<a href="https://1335402049.github.io/2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/">https://1335402049.github.io/2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/</a></li></ul><h2 id="OCP项目准备与配置"><a href="#OCP项目准备与配置" class="headerlink" title="OCP项目准备与配置"></a>OCP项目准备与配置</h2><blockquote><p>ocp项目作者Gitee地址：<a href="https://gitee.com/owenwangwen/open-capacity-platform">https://gitee.com/owenwangwen/open-capacity-platform</a></p></blockquote><h3 id="修改docker仓库配置"><a href="#修改docker仓库配置" class="headerlink" title="修改docker仓库配置"></a>修改docker仓库配置</h3><p>修改 open-capacity-platform/pom.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 大概55、56行 将 docker.host 改成 docker.repostory 增加 docker.registry.name 标签</span><br><span class="line">&lt;!-- harbor地址，默认80端口 --&gt;</span><br><span class="line">&lt;docker.repostory&gt;192.168.1.112&lt;&#x2F;docker.repostory&gt;</span><br><span class="line">&lt;!-- harbor项目地址 --&gt;</span><br><span class="line">&lt;docker.registry.name&gt;ocp&lt;&#x2F;docker.registry.name&gt;</span><br><span class="line">&lt;!-- 制作镜像的前缀 --&gt;</span><br><span class="line">&lt;docker.image.prefix&gt;ocp&lt;&#x2F;docker.image.prefix&gt;</span><br></pre></td></tr></table></figure><h3 id="修改eureka配置"><a href="#修改eureka配置" class="headerlink" title="修改eureka配置"></a>修改eureka配置</h3><p>修改 open-capacity-platform/register-center/eureka-server/src/main/resources/application-slave0.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># service名称为cloud-eureka</span><br><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br><span class="line">prefer-ip-address: false</span><br><span class="line"># instance字段下增加 hostname appname</span><br><span class="line">hostname: cloud-eureka</span><br><span class="line">appname: eureka-server</span><br></pre></td></tr></table></figure><h3 id="修改auth-server配置"><a href="#修改auth-server配置" class="headerlink" title="修改auth-server配置"></a>修改auth-server配置</h3><p>修改 open-capacity-platform/oauth-center/auth-server/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改 open-capacity-platform/oauth-center/auth-server/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># auth-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;auth-center-mysql:3306&#x2F;oauth-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h3 id="修改user-center配置"><a href="#修改user-center配置" class="headerlink" title="修改user-center配置"></a>修改user-center配置</h3><p>修改 open-capacity-platform/business-center/user-center/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改 open-capacity-platform/business-center/user-center/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># user-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;user-center-mysql:3306&#x2F;user-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h3 id="修改log-center配置"><a href="#修改log-center配置" class="headerlink" title="修改log-center配置"></a>修改log-center配置</h3><p>修改 open-capacity-platform/monitor-center/log-center/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改 open-capacity-platform/monitor-center/log-center/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># log-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;log-center-mysql:3306&#x2F;log-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h3 id="修改api-gateway配置"><a href="#修改api-gateway配置" class="headerlink" title="修改api-gateway配置"></a>修改api-gateway配置</h3><p>修改 open-capacity-platform/api-gateway/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改 open-capacity-platform/api-gateway/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url: jdbc:mysql:&#x2F;&#x2F;auth-center-mysql:3306&#x2F;oauth-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false</span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h3 id="修改back-center配置"><a href="#修改back-center配置" class="headerlink" title="修改back-center配置"></a>修改back-center配置</h3><p>修改 open-capacity-platform/web-portal/back-center/src/main/view/static/module/config.js</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># api-gateway的url,端口通过 kubectl get svc -n ingress-nginx 查看</span><br><span class="line">base_server: &#39;http:&#x2F;&#x2F;api-gateway.ocp.com:32080&#x2F;&#39;</span><br><span class="line"># eureka_server的url</span><br><span class="line">eureka_server: &#39;http:&#x2F;&#x2F;eureka.ocp.com:32080&#x2F;&#39;</span><br></pre></td></tr></table></figure><p>在 open-capacity-platform/web-portal/back-center/dockerfile 里编写Dockerfile制作nginx镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM tangweifeng&#x2F;nginx</span><br><span class="line">RUN rm -rf &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">ADD .&#x2F;src&#x2F;main&#x2F;view&#x2F;static &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">EXPOSE 80</span><br><span class="line">CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure><h3 id="编写-dockerfile-auth-center"><a href="#编写-dockerfile-auth-center" class="headerlink" title="编写 dockerfile_auth-center"></a>编写 dockerfile_auth-center</h3><blockquote><p>vim open-capacity-platform/sql/dockerfile_auth-center </p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM mysql:5.7.26</span><br><span class="line">ADD 02.oauth-center.sql &#x2F;docker-entrypoint-initdb.d&#x2F;02.oauth-center.sql</span><br><span class="line">EXPOSE 3306</span><br></pre></td></tr></table></figure><h3 id="编写-dockerfile-log-center"><a href="#编写-dockerfile-log-center" class="headerlink" title="编写 dockerfile_log-center"></a>编写 dockerfile_log-center</h3><blockquote><p>vim open-capacity-platform/sql/dockerfile_log-center</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM mysql:5.7.26 </span><br><span class="line">ADD 05.log-center.sql &#x2F;docker-entrypoint-initdb.d&#x2F;05.log-center.sql </span><br><span class="line">EXPOSE 3306</span><br></pre></td></tr></table></figure><h3 id="编写-dockerfile-user-center"><a href="#编写-dockerfile-user-center" class="headerlink" title="编写 dockerfile_user-center"></a>编写 dockerfile_user-center</h3><blockquote><p>vim open-capacity-platform/sql/dockerfile_user-center</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM mysql:5.7.26</span><br><span class="line">ADD 01.user-center.sql &#x2F;docker-entrypoint-initdb.d&#x2F;01.user-center.sql</span><br><span class="line">EXPOSE 3306</span><br></pre></td></tr></table></figure><h2 id="部署ingress-nginx"><a href="#部署ingress-nginx" class="headerlink" title="部署ingress-nginx"></a>部署ingress-nginx</h2><p>参考这篇文章：<a href="https://1335402049.github.io/2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/">https://1335402049.github.io/2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/</a></p><h2 id="部署nfs-storageclass"><a href="#部署nfs-storageclass" class="headerlink" title="部署nfs storageclass"></a>部署nfs storageclass</h2><p>在部署微服务之前，考虑mysql、redis等服务数据的存储，我们准备使用nfs storageclass进行动态pv的创建，可以参考这篇文章：<a href="https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/">https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</a></p><h2 id="Kubernetes资源清单"><a href="#Kubernetes资源清单" class="headerlink" title="Kubernetes资源清单"></a>Kubernetes资源清单</h2><h3 id="eureka"><a href="#eureka" class="headerlink" title="eureka"></a>eureka</h3><blockquote><p>eureka-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: eureka</span><br><span class="line">  serviceName: cloud-eureka</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: eureka</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: eureka-server</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;eureka-server</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 1111</span><br></pre></td></tr></table></figure><blockquote><p>eureka-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - port: 1111</span><br><span class="line">      targetPort: 1111</span><br><span class="line">  selector:</span><br><span class="line">    app: eureka</span><br></pre></td></tr></table></figure><blockquote><p>eureka-ingress.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: eureka</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: eureka.ocp.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: cloud-eureka</span><br><span class="line">              servicePort: 1111</span><br></pre></td></tr></table></figure><h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><h4 id="auth-center-mysql"><a href="#auth-center-mysql" class="headerlink" title="auth-center-mysql"></a>auth-center-mysql</h4><blockquote><p>auth-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p> auth-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>auth-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: auth-center-mysql</span><br><span class="line">  serviceName: auth-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: auth-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: auth-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      volumes:</span><br><span class="line">        - name: auth-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: auth-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: auth-center-mysql</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;auth-center-mysql</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: auth-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: auth-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: auth-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>auth-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: auth-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h4 id="log-center-mysql"><a href="#log-center-mysql" class="headerlink" title="log-center-mysql"></a>log-center-mysql</h4><blockquote><p>log-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p>log-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>log-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: log-center-mysql</span><br><span class="line">  serviceName: log-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: log-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: log-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      volumes:</span><br><span class="line">        - name: log-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: log-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: log-center-mysql</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;log-center-mysql</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: log-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: log-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: log-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>log-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: log-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h4 id="user-center-mysql"><a href="#user-center-mysql" class="headerlink" title="user-center-mysql"></a>user-center-mysql</h4><blockquote><p>user-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p>user-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>user-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: user-center-mysql</span><br><span class="line">  serviceName: user-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: user-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: user-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      volumes:</span><br><span class="line">        - name: user-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: user-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: user-center-mysql</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;user-center-mysql</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: user-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: user-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: user-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>user-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: user-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h3 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h3><blockquote><p>redis-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">data:</span><br><span class="line">  redis.conf: |-</span><br><span class="line">    ################################## INCLUDES ###################################</span><br><span class="line">    # include &#x2F;path&#x2F;to&#x2F;local.conf</span><br><span class="line">    # include &#x2F;path&#x2F;to&#x2F;other.conf</span><br><span class="line"></span><br><span class="line">    ################################## MODULES #####################################</span><br><span class="line">    # loadmodule &#x2F;path&#x2F;to&#x2F;my_module.so</span><br><span class="line">    # loadmodule &#x2F;path&#x2F;to&#x2F;other_module.so</span><br><span class="line"></span><br><span class="line">    bind 0.0.0.0</span><br><span class="line"></span><br><span class="line">    protected-mode no</span><br><span class="line"></span><br><span class="line">    port 6379</span><br><span class="line"></span><br><span class="line">    tcp-backlog 511</span><br><span class="line"></span><br><span class="line">    # unixsocket &#x2F;tmp&#x2F;redis.sock</span><br><span class="line">    # unixsocketperm 700</span><br><span class="line"></span><br><span class="line">    timeout 0</span><br><span class="line"></span><br><span class="line">    tcp-keepalive 300</span><br><span class="line"></span><br><span class="line">    ################################# GENERAL #####################################</span><br><span class="line"></span><br><span class="line">    daemonize no</span><br><span class="line"></span><br><span class="line">    supervised no</span><br><span class="line"></span><br><span class="line">    pidfile &#x2F;data&#x2F;pid&#x2F;redis_6379.pid</span><br><span class="line"></span><br><span class="line">    loglevel notice</span><br><span class="line"></span><br><span class="line">    logfile &quot;&#x2F;data&#x2F;logs&#x2F;redis.log&quot;</span><br><span class="line"></span><br><span class="line">    # syslog-enabled no</span><br><span class="line"></span><br><span class="line">    # syslog-ident redis</span><br><span class="line"></span><br><span class="line">    # syslog-facility local0</span><br><span class="line"></span><br><span class="line">    databases 16</span><br><span class="line"></span><br><span class="line">    always-show-logo yes</span><br><span class="line"></span><br><span class="line">    save 900 1</span><br><span class="line">    save 300 10</span><br><span class="line">    save 60 10000</span><br><span class="line"></span><br><span class="line">    stop-writes-on-bgsave-error yes</span><br><span class="line"></span><br><span class="line">    rdbcompression yes</span><br><span class="line"></span><br><span class="line">    rdbchecksum yes</span><br><span class="line"></span><br><span class="line">    dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line">    dir &#x2F;data</span><br><span class="line"></span><br><span class="line">    # replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"></span><br><span class="line">    # masterauth &lt;master-password&gt;</span><br><span class="line"></span><br><span class="line">    replica-serve-stale-data yes</span><br><span class="line"></span><br><span class="line">    replica-read-only yes</span><br><span class="line"></span><br><span class="line">    repl-diskless-sync no</span><br><span class="line"></span><br><span class="line">    repl-diskless-sync-delay 5</span><br><span class="line"></span><br><span class="line">    # repl-ping-replica-period 10</span><br><span class="line"></span><br><span class="line">    # repl-timeout 60</span><br><span class="line"></span><br><span class="line">    repl-disable-tcp-nodelay no</span><br><span class="line"></span><br><span class="line">    # repl-backlog-size 1mb</span><br><span class="line"></span><br><span class="line">    # repl-backlog-ttl 3600</span><br><span class="line"></span><br><span class="line">    replica-priority 100</span><br><span class="line"></span><br><span class="line">    # min-replicas-to-write 3</span><br><span class="line">    # min-replicas-max-lag 10</span><br><span class="line"></span><br><span class="line">    # replica-announce-ip 5.5.5.5</span><br><span class="line">    # replica-announce-port 1234</span><br><span class="line"></span><br><span class="line">    # requirepass xxxx</span><br><span class="line"></span><br><span class="line">    # rename-command CONFIG &quot;&quot;</span><br><span class="line"></span><br><span class="line">    maxclients 2000</span><br><span class="line"></span><br><span class="line">    # maxmemory &lt;bytes&gt;</span><br><span class="line"></span><br><span class="line">    # maxmemory-policy noeviction</span><br><span class="line"></span><br><span class="line">    # maxmemory-samples 5</span><br><span class="line"></span><br><span class="line">    # replica-ignore-maxmemory yes</span><br><span class="line"></span><br><span class="line">    lazyfree-lazy-eviction no</span><br><span class="line">    lazyfree-lazy-expire no</span><br><span class="line">    lazyfree-lazy-server-del no</span><br><span class="line">    replica-lazy-flush no</span><br><span class="line"></span><br><span class="line">    appendonly yes</span><br><span class="line"></span><br><span class="line">    appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line">    # appendfsync always</span><br><span class="line">    appendfsync everysec</span><br><span class="line">    # appendfsync no</span><br><span class="line"></span><br><span class="line">    no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line">    auto-aof-rewrite-percentage 100</span><br><span class="line">    auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line">    aof-load-truncated yes</span><br><span class="line"></span><br><span class="line">    aof-use-rdb-preamble yes</span><br><span class="line"></span><br><span class="line">    lua-time-limit 5000</span><br><span class="line"></span><br><span class="line">    # cluster-enabled yes</span><br><span class="line"></span><br><span class="line">    # cluster-config-file nodes-6379.conf</span><br><span class="line"></span><br><span class="line">    # cluster-node-timeout 15000</span><br><span class="line"></span><br><span class="line">    # cluster-replica-validity-factor 10</span><br><span class="line"></span><br><span class="line">    # cluster-migration-barrier 1</span><br><span class="line"></span><br><span class="line">    # cluster-require-full-coverage yes</span><br><span class="line"></span><br><span class="line">    # cluster-replica-no-failover no</span><br><span class="line"></span><br><span class="line">    # cluster-announce-ip 10.1.1.5</span><br><span class="line">    # cluster-announce-port 6379</span><br><span class="line">    # cluster-announce-bus-port 6380</span><br><span class="line"></span><br><span class="line">    slowlog-log-slower-than 10000</span><br><span class="line"></span><br><span class="line">    slowlog-max-len 128</span><br><span class="line"></span><br><span class="line">    latency-monitor-threshold 0</span><br><span class="line"></span><br><span class="line">    #  notify-keyspace-events Elg</span><br><span class="line"></span><br><span class="line">    #  notify-keyspace-events Ex</span><br><span class="line"></span><br><span class="line">    notify-keyspace-events &quot;&quot;</span><br><span class="line"></span><br><span class="line">    hash-max-ziplist-entries 512</span><br><span class="line">    hash-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line">    list-max-ziplist-size -2</span><br><span class="line"></span><br><span class="line">    list-compress-depth 0</span><br><span class="line"></span><br><span class="line">    set-max-intset-entries 512</span><br><span class="line"></span><br><span class="line">    zset-max-ziplist-entries 128</span><br><span class="line">    zset-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line">    hll-sparse-max-bytes 3000</span><br><span class="line"></span><br><span class="line">    stream-node-max-bytes 4096</span><br><span class="line">    stream-node-max-entries 100</span><br><span class="line"></span><br><span class="line">    activerehashing yes</span><br><span class="line"></span><br><span class="line">    client-output-buffer-limit normal 0 0 0</span><br><span class="line">    client-output-buffer-limit replica 256mb 64mb 60</span><br><span class="line">    client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line"></span><br><span class="line">    # client-query-buffer-limit 1gb</span><br><span class="line"></span><br><span class="line">    # proto-max-bulk-len 512mb</span><br><span class="line"></span><br><span class="line">    hz 10</span><br><span class="line"></span><br><span class="line">    dynamic-hz yes</span><br><span class="line"></span><br><span class="line">    aof-rewrite-incremental-fsync yes</span><br><span class="line"></span><br><span class="line">    rdb-save-incremental-fsync yes</span><br><span class="line"></span><br><span class="line">    # lfu-log-factor 10</span><br><span class="line">    # lfu-decay-time 1</span><br><span class="line"></span><br><span class="line">    ########################### ACTIVE DEFRAGMENTATION #######################</span><br><span class="line">    # activedefrag yes</span><br><span class="line">    # active-defrag-ignore-bytes 100mb</span><br><span class="line">    # active-defrag-threshold-lower 10</span><br><span class="line">    # active-defrag-threshold-upper 100</span><br><span class="line">    # active-defrag-cycle-min 5</span><br><span class="line">    # active-defrag-cycle-max 75</span><br><span class="line">    # active-defrag-max-scan-fields 1000</span><br></pre></td></tr></table></figure><blockquote><p>redis-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: ocp-redis</span><br><span class="line">  serviceName: ocp-redis</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: ocp-redis-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: ocp-redis</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: ocp-redis-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: ocp-redis</span><br><span class="line">      containers:</span><br><span class="line">        - name: ocp-redis</span><br><span class="line">          image: redis:5.0.5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 6379</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: ocp-redis-data</span><br><span class="line">              mountPath: &#x2F;data</span><br><span class="line">            - name: ocp-redis-conf</span><br><span class="line">              mountPath: &#x2F;data&#x2F;redis.conf</span><br><span class="line">          command:</span><br><span class="line">            - redis-server</span><br><span class="line">            - &#x2F;data&#x2F;redis.conf</span><br></pre></td></tr></table></figure><blockquote><p>redis-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: ocp-redis</span><br><span class="line">  ports:</span><br><span class="line">    - port: 6379</span><br><span class="line">      targetPort: 6379</span><br></pre></td></tr></table></figure><h3 id="auth-server"><a href="#auth-server" class="headerlink" title="auth-server"></a>auth-server</h3><blockquote><p>auth-server-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: auth-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: auth-server</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: auth-server</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;auth-server</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8000</span><br></pre></td></tr></table></figure><blockquote><p>auth-server-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-server</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: auth-server</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8000</span><br><span class="line">      targetPort: 8000</span><br></pre></td></tr></table></figure><h3 id="user-center"><a href="#user-center" class="headerlink" title="user-center"></a>user-center</h3><blockquote><p>user-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: user-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: user-center</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: user-center</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;user-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 7000</span><br></pre></td></tr></table></figure><blockquote><p>user-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: user-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 7000</span><br><span class="line">      targetPort: 7000</span><br></pre></td></tr></table></figure><h3 id="log-center"><a href="#log-center" class="headerlink" title="log-center"></a>log-center</h3><blockquote><p>log-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: log-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: log-center</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: log-center</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;log-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 5006</span><br></pre></td></tr></table></figure><blockquote><p>log-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: log-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 5006</span><br><span class="line">      targetPort: 5006</span><br></pre></td></tr></table></figure><h3 id="api-gateway"><a href="#api-gateway" class="headerlink" title="api-gateway"></a>api-gateway</h3><blockquote><p>api-gateway-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: api-gateway</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: api-gateway</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: api-gateway</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;api-gateway</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9200</span><br></pre></td></tr></table></figure><blockquote><p>api-gateway-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: api-gateway</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9200</span><br><span class="line">      targetPort: 9200</span><br></pre></td></tr></table></figure><blockquote><p>api-gateway-ingress.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: api-gateway.ocp.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: api-gateway</span><br><span class="line">              servicePort: 9200</span><br></pre></td></tr></table></figure><h3 id="back-center"><a href="#back-center" class="headerlink" title="back-center"></a>back-center</h3><blockquote><p>back-center-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">data:</span><br><span class="line">  nginx.conf: |-</span><br><span class="line">    user  nginx;</span><br><span class="line">    worker_processes  1;</span><br><span class="line"></span><br><span class="line">    error_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn;</span><br><span class="line">    pid        &#x2F;var&#x2F;run&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line">    events &#123;</span><br><span class="line">        worker_connections  1024;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    http &#123;</span><br><span class="line">        include       &#x2F;etc&#x2F;nginx&#x2F;mime.types;</span><br><span class="line">        default_type  application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">        log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">                          &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">                          &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">        access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">        sendfile        on;</span><br><span class="line">        #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">        keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">        #gzip  on;</span><br><span class="line"></span><br><span class="line">        server &#123;</span><br><span class="line">            listen       80;</span><br><span class="line">            listen  [::]:80;</span><br><span class="line">            server_name  localhost;</span><br><span class="line"></span><br><span class="line">            location &#x2F; &#123;</span><br><span class="line">                root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">                index  index.html index.htm;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line"></span><br><span class="line">            location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line">                root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>back-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: back-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: back-center</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nginx-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: back-center</span><br><span class="line">      containers:</span><br><span class="line">        - name: back-center</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;back-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nginx-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line">              subPath: nginx.conf</span><br></pre></td></tr></table></figure><blockquote><p>back-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: back-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br></pre></td></tr></table></figure><h2 id="推送项目到GitLab"><a href="#推送项目到GitLab" class="headerlink" title="推送项目到GitLab"></a>推送项目到GitLab</h2><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/a1.png"></p><h2 id="Jenkins持续发布"><a href="#Jenkins持续发布" class="headerlink" title="Jenkins持续发布"></a>Jenkins持续发布</h2><ul><li>在jenkins配置kubernetes，参考文章：<a href="https://1335402049.github.io/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/">https://1335402049.github.io/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/</a></li><li>在jenkins配置GitLab凭据（凭据选择用户名密码类型，填写gitlab登录的用户名密码），以及如何远程执行GitLab上的jenkinsfile，参考文章：<a href="https://1335402049.github.io/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/">https://1335402049.github.io/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/</a></li></ul><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/a2.png"></p><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>目前整个ocp微服务持续集成/持续交付分为7个流水线任务</p><h4 id="mysql-redis"><a href="#mysql-redis" class="headerlink" title="mysql_redis"></a>mysql_redis</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;make mysql image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd sql</span><br><span class="line">                    docker build -f dockerfile_auth-center -t 120.78.187.149&#x2F;ocp&#x2F;auth-center-mysql .</span><br><span class="line">                    docker build -f dockerfile_user-center -t 120.78.187.149&#x2F;ocp&#x2F;user-center-mysql .</span><br><span class="line">                    docker build -f dockerfile_log-center -t 120.78.187.149&#x2F;ocp&#x2F;log-center-mysql .</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;log-center-mysql</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;auth-center-mysql</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;user-center-mysql</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply mysql resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    kubectl create secret docker-registry harbor-registry  --docker-server&#x3D;192.168.1.112 --docker-username&#x3D;admin --docker-password&#x3D;harbor123 --docker-email&#x3D;admin@qq.com -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;auth-center-mysql&#x2F;auth-center-mysql-secret.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;auth-center-mysql&#x2F;auth-center-mysql-configmap.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;auth-center-mysql&#x2F;auth-center-mysql-statefulset.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;auth-center-mysql&#x2F;auth-center-mysql-service.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;user-center-mysql&#x2F;user-center-mysql-secret.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;user-center-mysql&#x2F;user-center-mysql-configmap.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;user-center-mysql&#x2F;user-center-mysql-statefulset.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;user-center-mysql&#x2F;user-center-mysql-service.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;log-center-mysql&#x2F;log-center-mysql-secret.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;log-center-mysql&#x2F;log-center-mysql-configmap.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;log-center-mysql&#x2F;log-center-mysql-statefulset.yaml -n default</span><br><span class="line">                    kubectl apply -f k8s&#x2F;log-center-mysql&#x2F;log-center-mysql-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">       stage(&#39;apply redis resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;redis</span><br><span class="line">                    kubectl apply -f redis-configmap.yaml -n default</span><br><span class="line">                    kubectl apply -f redis-statefulset.yaml -n default</span><br><span class="line">                    kubectl apply -f redis-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="eureka-1"><a href="#eureka-1" class="headerlink" title="eureka"></a>eureka</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;unpack code&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh &quot;mvn -U -pl register-center&#x2F;eureka-server&#x2F; -am clean package -DskipTests&quot;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make eureka image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                          cd register-center&#x2F;eureka-server &amp;&amp; mvn docker:build</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker tag ocp&#x2F;eureka-server 120.78.187.149&#x2F;ocp&#x2F;eureka-server</span><br><span class="line">                           docker rmi ocp&#x2F;eureka-server</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;eureka-server</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply eureka resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;eureka</span><br><span class="line">                    kubectl apply -f eureka-statefulset.yaml -n default</span><br><span class="line">                    kubectl apply -f eureka-service.yaml -n default</span><br><span class="line">                    kubectl apply -f eureka-ingress.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="auth-server-1"><a href="#auth-server-1" class="headerlink" title="auth-server"></a>auth-server</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;unpack code&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh &quot;mvn -U -pl oauth-center&#x2F;auth-server -am clean package -DskipTests&quot;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make auth-server image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                   cd oauth-center&#x2F;auth-server &amp;&amp; mvn docker:build</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker tag ocp&#x2F;auth-server 120.78.187.149&#x2F;ocp&#x2F;auth-server</span><br><span class="line">                           docker rmi ocp&#x2F;auth-server</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;auth-server</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply auth-server resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;auth-server</span><br><span class="line">                    kubectl apply -f auth-server-deployment.yaml -n default</span><br><span class="line">                    kubectl apply -f auth-server-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="user-center-1"><a href="#user-center-1" class="headerlink" title="user-center"></a>user-center</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;unpack code&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh &quot;mvn -U -pl business-center&#x2F;user-center -am clean package -DskipTests&quot;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make user-center image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                   cd business-center&#x2F;user-center &amp;&amp; mvn docker:build</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker tag ocp&#x2F;user-center 120.78.187.149&#x2F;ocp&#x2F;user-center</span><br><span class="line">                           docker rmi ocp&#x2F;user-center</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;user-center</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply user-center resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;user-center</span><br><span class="line">                    kubectl apply -f user-center-deployment.yaml -n default</span><br><span class="line">                    kubectl apply -f user-center-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="log-center-1"><a href="#log-center-1" class="headerlink" title="log-center"></a>log-center</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;unpack code&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh &quot;mvn -U -pl monitor-center&#x2F;log-center -am clean package -DskipTests&quot;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make log-center image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                   cd monitor-center&#x2F;log-center &amp;&amp; mvn docker:build</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker tag ocp&#x2F;log-center 120.78.187.149&#x2F;ocp&#x2F;log-center</span><br><span class="line">                           docker rmi ocp&#x2F;log-center</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;log-center</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply log-center resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;log-center</span><br><span class="line">                    kubectl apply -f log-center-deployment.yaml -n default</span><br><span class="line">                    kubectl apply -f log-center-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="api-gateway-1"><a href="#api-gateway-1" class="headerlink" title="api-gateway"></a>api-gateway</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;unpack code&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh &quot;mvn -U -pl api-gateway -am clean package -DskipTests&quot;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make api-gateway image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                   cd api-gateway &amp;&amp; mvn docker:build</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker tag ocp&#x2F;api-gateway 120.78.187.149&#x2F;ocp&#x2F;api-gateway</span><br><span class="line">                           docker rmi ocp&#x2F;api-gateway</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;api-gateway</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;apply api-gateway resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;api-gateway</span><br><span class="line">                    kubectl apply -f api-gateway-deployment.yaml -n default</span><br><span class="line">                    kubectl apply -f api-gateway-service.yaml -n default</span><br><span class="line">                    kubectl apply -f api-gateway-ingress.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="back-center-1"><a href="#back-center-1" class="headerlink" title="back-center"></a>back-center</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;make back-center image&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                   cd web-portal&#x2F;back-center&#x2F;</span><br><span class="line">                   docker build -t 120.78.187.149&#x2F;ocp&#x2F;back-center .</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;upload image&#39;) &#123;</span><br><span class="line">                   steps &#123;</span><br><span class="line">                       sh&#39;&#39;&#39;</span><br><span class="line">                           docker login 120.78.187.149 -u admin -p tang1611</span><br><span class="line">                           docker push 120.78.187.149&#x2F;ocp&#x2F;back-center</span><br><span class="line">                       &#39;&#39;&#39;</span><br><span class="line">                   &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;apply back-center resource list&#39;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh&#39;&#39;&#39;</span><br><span class="line">                    cd k8s&#x2F;back-center</span><br><span class="line">                    kubectl apply -f back-center-configmap.yaml -n default</span><br><span class="line">                    kubectl apply -f back-center-deployment.yaml -n default</span><br><span class="line">                    kubectl apply -f back-center-service.yaml -n default</span><br><span class="line">                &#39;&#39;&#39;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 windows的hosts文件里面添加记录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.1.110 eureka.ocp.com</span><br><span class="line">192.168.1.110 api-gateway.ocp.com</span><br></pre></td></tr></table></figure><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><blockquote><p>在构建之前，由于cnych/jenkins:jnlp6镜像没有maven环境，我们在这个镜像基础上重新制作镜像，增加maven环境</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 直接拉取即可,修改jenkins slave的pod模板，填写这个镜像</span><br><span class="line">docker pull tangweifeng&#x2F;jenkins-slave:latest</span><br></pre></td></tr></table></figure><blockquote><p>还需要再本地宿主机上安装maven，提前准备下载好本地需要的依赖jar</p></blockquote><p>修改本地maven的settings.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在setting标签下添加localRepository</span><br><span class="line">&lt;localRepository&gt;&#x2F;nfs&#x2F;jarHome&lt;&#x2F;localRepository&gt;</span><br></pre></td></tr></table></figure><p>执行，依赖会被下载到/nfs/jarHome路径下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean package -DskipTests</span><br></pre></td></tr></table></figure><p>修改jenkins slave 的Pod模板，增加一个volume</p><blockquote><p>如果不这样挂载依赖到容器里面，每次构建都会耗费大量时间在maven打包上</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/a3.png"></p><p>按照顺序依次执行pipeline，mysql_redis - eureka - auth-server - user-center - log-center - api-gateway - back-center</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/a4.png"></p><blockquote><p>上面的各个pipeline脚本还有很多需要完善的地方，需要根据自己的实际情况进行完善，比如：job的触发器、sonarqube代码质量检查、邮件通知、自动化测试、shell脚本进行一些特定需求的开发、在制作镜像的时候先判断docker上是否存在此镜像（是否需要先进行删除）等等其他需求</p></blockquote><p>最后在pipeline执行完成之，pod等资源被成功创建运行后，在浏览器通过任意node的ip:NodePort（back-center的nodeport）访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2021/01/05/Jenkins%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B8%83OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0Kubernetes/a5.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubeadm重新获取token</title>
      <link href="2021/01/02/Kubeadm%E9%87%8D%E6%96%B0%E8%8E%B7%E5%8F%96token/"/>
      <url>2021/01/02/Kubeadm%E9%87%8D%E6%96%B0%E8%8E%B7%E5%8F%96token/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>当你的token忘记或者过期了，可以重新获取token，让新机器加入集群中</p><h2 id="获取token"><a href="#获取token" class="headerlink" title="获取token"></a>获取token</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm token create</span><br><span class="line">kubeadm token list</span><br></pre></td></tr></table></figure><h2 id="获取CA公钥的哈希值"><a href="#获取CA公钥的哈希值" class="headerlink" title="获取CA公钥的哈希值"></a>获取CA公钥的哈希值</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl x509 -pubkey -in &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt | openssl rsa -pubin -outform der 2&gt;&#x2F;dev&#x2F;null | openssl dgst -sha256 -hex | sed  &#39;s&#x2F;^ .* &#x2F;&#x2F;&#39;</span><br></pre></td></tr></table></figure><h2 id="节点加入集群"><a href="#节点加入集群" class="headerlink" title="节点加入集群"></a>节点加入集群</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.1.110:6443 --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;CA公钥哈希值&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins配置Kubernetes集群</title>
      <link href="2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>安装 Kubernetes 插件</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a1.png"></p><h2 id="配置集群信息"><a href="#配置集群信息" class="headerlink" title="配置集群信息"></a>配置集群信息</h2><p>Manage Jenkins -&gt; Configure System -&gt; Cloud</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a2.png"></p><h2 id="配置Pod模板"><a href="#配置Pod模板" class="headerlink" title="配置Pod模板"></a>配置Pod模板</h2><p>配置 jenkins slave 容器</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a3.png"></p><p>配置volume，让pod中容器共享宿主机docker以及可以使用kebuctl命令访问k8s集群</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a4.png"></p><p>避免权限问题，配置serviceaccount</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a5.png"></p><h2 id="测试Freestyle-project"><a href="#测试Freestyle-project" class="headerlink" title="测试Freestyle project"></a>测试Freestyle project</h2><p>创建任务</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a6.png"></p><p>输入刚刚在pod模板填写的标签</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a7.png"></p><p>构建里面编写shell脚本</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a8.png"></p><p>保存后 Build Now，查看pod的整个过程</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a9.png"></p><p>在jenkins控制台查看构建结果</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a10.png"></p><h2 id="测试Pipeline"><a href="#测试Pipeline" class="headerlink" title="测试Pipeline"></a>测试Pipeline</h2><p>下载 Pipeline 插件</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a11.png"></p><p>创建流水线</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a12.png"></p><p>编写pipeline</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label &#39;node1&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;hello world&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;echo &#39;hello world&#39;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;docker&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;docker info&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;kubectl&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;kubectl get pods&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>保存后 Build Now，查看结果</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E9%85%8D%E7%BD%AEKubernetes%E9%9B%86%E7%BE%A4/a13.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署jenkins</title>
      <link href="2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/"/>
      <url>2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Jenkins Master运行在Kubernetes集群的一个node上，并且数据存储到volume上去，Jenkins Slave会按照需求动态的创建并且自动删除。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/a1.png"></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>首先需要nfs storageclass动态创建pv，参考这篇文章：<a href="https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/">https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</a></p><blockquote><p>应用 namespace</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create ns devops</span><br></pre></td></tr></table></figure><blockquote><p>应用 rbac</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-sa</span><br><span class="line">  namespace: devops</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-crd</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: jenkins-sa</span><br><span class="line">  namespace: devops</span><br></pre></td></tr></table></figure><blockquote><p>应用 pvc</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-pvc</span><br><span class="line">  namespace: devops</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io&#x2F;storage-class: &quot;managed-nfs-storage&quot;</span><br><span class="line">spec:</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 3Gi</span><br></pre></td></tr></table></figure><blockquote><p>应用 deployment</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: devops</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: jenkins</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: jenkins</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 10</span><br><span class="line">      serviceAccountName: jenkins-sa</span><br><span class="line">      containers:</span><br><span class="line">        - name: jenkins</span><br><span class="line">          image: jenkins&#x2F;jenkins:lts</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          env:</span><br><span class="line">            - name: JAVA_OPTS</span><br><span class="line">              value: -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay&#x3D;0 -Dhudson.slaves.NodeProvisioner.MARGIN&#x3D;50 -Dhudson.slaves.NodeProvisioner.MARGIN0&#x3D;0.85 -Duser.timezone&#x3D;Asia&#x2F;Shanghai</span><br><span class="line">          ports:</span><br><span class="line">            - name: web</span><br><span class="line">              containerPort: 8080</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: agent</span><br><span class="line">              containerPort: 50000</span><br><span class="line">              protocol: TCP</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 1000m</span><br><span class="line">              memory: 1Gi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 500m</span><br><span class="line">              memory: 512Mi</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;login</span><br><span class="line">              port: 8080</span><br><span class="line">            initialDelaySeconds: 60</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">            failureThreshold: 12</span><br><span class="line">          readinessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;login</span><br><span class="line">              port: 8080</span><br><span class="line">            initialDelaySeconds: 60</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">            failureThreshold: 12</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: jenkinshome</span><br><span class="line">              mountPath: &#x2F;var&#x2F;jenkins_home</span><br><span class="line">      volumes:</span><br><span class="line">        - name: jenkinshome</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: jenkins-pvc</span><br></pre></td></tr></table></figure><blockquote><p>应用 svc</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: devops </span><br><span class="line">  labels:</span><br><span class="line">    app: jenkins</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: jenkins</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: web</span><br><span class="line">    nodePort: 30002</span><br><span class="line">  - name: agent</span><br><span class="line">    port: 50000</span><br><span class="line">    targetPort: agent</span><br></pre></td></tr></table></figure><h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><p>通过node:NodePort登录jenkins</p><p>密码可以通过 cat /nfs/devops-jenkins-pvc-pvc-14c9df34-833b-47ce-b423-45b16a66b9b6/secrets/initialAdminPassword 查看</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Kubernetes%E9%83%A8%E7%BD%B2jenkins/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins发布pod到Kubernetes</title>
      <link href="2020/12/30/Jenkins%E5%8F%91%E5%B8%83pod%E5%88%B0Kubernetes/"/>
      <url>2020/12/30/Jenkins%E5%8F%91%E5%B8%83pod%E5%88%B0Kubernetes/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>因为jenkins是独立部署的，所以这种方式发布pod到k8s上，我想到的是提高jenkins用户权限（以root用户启动jenkins）来使用kubectl命令</p><h2 id="编写资源清单"><a href="#编写资源清单" class="headerlink" title="编写资源清单"></a>编写资源清单</h2><blockquote><p>应用 secret</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret docker-registry harbor-registry  --docker-server&#x3D;192.168.1.112 --docker-username&#x3D;admin --docker-password&#x3D;harbor123 --docker-email&#x3D;admin@qq.com</span><br></pre></td></tr></table></figure><blockquote><p>statefulset</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: eureka</span><br><span class="line">  serviceName: cloud-eureka</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: eureka</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: harbor-registry</span><br><span class="line">      containers:</span><br><span class="line">        - name: eureka-server</span><br><span class="line">          image: 192.168.1.112&#x2F;ocp&#x2F;eureka-server</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 1111</span><br></pre></td></tr></table></figure><blockquote><p>svc</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 1111</span><br><span class="line">      targetPort: 1111</span><br><span class="line">  selector:</span><br><span class="line">    app: eureka</span><br></pre></td></tr></table></figure><h2 id="编写pipeline"><a href="#编写pipeline" class="headerlink" title="编写pipeline"></a>编写pipeline</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;apply statefulset&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;kubectl apply -f &#x2F;vagrant&#x2F;ocp&#x2F;eureka&#x2F;test.yaml&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;apply svc&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;kubectl apply -f &#x2F;vagrant&#x2F;ocp&#x2F;eureka&#x2F;test1.yaml&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E5%8F%91%E5%B8%83pod%E5%88%B0Kubernetes/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins打包制作镜像并上传harbor</title>
      <link href="2020/12/30/Jenkins%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%8A%E4%BC%A0harbor/"/>
      <url>2020/12/30/Jenkins%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%8A%E4%BC%A0harbor/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前面文章已经将代码从git拉取到本地了，现在需要将本地代码打包制作成镜像，然后上传到harbor仓库</p><h2 id="配置maven"><a href="#配置maven" class="headerlink" title="配置maven"></a>配置maven</h2><p>在全局工具设置里面配置maven地址</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%8A%E4%BC%A0harbor/a1.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%8A%E4%BC%A0harbor/a2.png"></p><p>在pipeline使用tools使用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tools &#123;</span><br><span class="line">    # 这里的maven名称也就是全局工具配置的名称</span><br><span class="line">    maven &#39;maven&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="拉取git上代码"><a href="#拉取git上代码" class="headerlink" title="拉取git上代码"></a>拉取git上代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stage(&#39;mvn clean package&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;mvn clean package -DskipTests&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h2><p>因为使用了 docker 的 maven 插件 com.spotify.docker-maven-plugin 进行 docker 镜像的构建，dockerfile都是提前编写好的，然后使用 mvn docker:build 进行制作镜像</p><p>Dockerfile文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM openjdk:8-jdk-alpine</span><br><span class="line">VOLUME &#x2F;tmp</span><br><span class="line">ADD eureka-server.jar app.jar</span><br><span class="line">RUN sh -c &#39;touch &#x2F;app.jar&#39;</span><br><span class="line">ENV JAVA_OPTS&#x3D;&quot;&quot;</span><br><span class="line">ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd&#x3D;file:&#x2F;dev&#x2F;.&#x2F;urandom -jar &#x2F;app.jar&quot; ]</span><br></pre></td></tr></table></figure><p>使用 com.spotify.docker-maven-plugin 插件后，在pom.xml配置docker仓库地址</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">     &lt;!-- harbor地址，默认80端口 --&gt;</span><br><span class="line">    &lt;docker.repostory&gt;192.168.1.112&lt;&#x2F;docker.repostory&gt;</span><br><span class="line">    &lt;!-- harbor项目地址 --&gt;</span><br><span class="line">    &lt;docker.registry.name&gt;ocp&lt;&#x2F;docker.registry.name&gt;</span><br><span class="line">    &lt;!-- 制作镜像的前缀 --&gt;</span><br><span class="line">    &lt;docker.image.prefix&gt;ocp&lt;&#x2F;docker.image.prefix&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stage(&#39;mvn docker build&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;cd register-center&#x2F;eureka-server &amp;&amp; mvn docker:build&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="上传镜像到harbor"><a href="#上传镜像到harbor" class="headerlink" title="上传镜像到harbor"></a>上传镜像到harbor</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stage(&#39;docker login&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;docker login 192.168.1.112 -u admin -p harbor123&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">stage(&#39;docker tag&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;docker tag ocp&#x2F;eureka-server 192.168.1.112&#x2F;ocp&#x2F;eureka-server&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">stage(&#39;docker rmi&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;docker rmi ocp&#x2F;eureka-server&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">stage(&#39;docker push harbor&#39;) &#123;</span><br><span class="line">    steps &#123;</span><br><span class="line">        sh &quot;docker push 192.168.1.112&#x2F;ocp&#x2F;eureka-server&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%8A%E4%BC%A0harbor/a3.png"></p><h2 id="pipeline脚本"><a href="#pipeline脚本" class="headerlink" title="pipeline脚本"></a>pipeline脚本</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    tools &#123;</span><br><span class="line">        maven &#39;maven&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">       git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">       credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">       git_branch &#x3D; &#39;master&#39;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;mvn clean package&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;mvn clean package -DskipTests&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;mvn docker build&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;cd register-center&#x2F;eureka-server &amp;&amp; mvn docker:build&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">        stage(&#39;docker login&#39;) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh &quot;docker login 192.168.1.112 -u admin -p harbor123&quot;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#39;docker tag&#39;) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh &quot;docker tag ocp&#x2F;eureka-server 192.168.1.112&#x2F;ocp&#x2F;eureka-server&quot;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#39;docker rmi&#39;) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh &quot;docker rmi ocp&#x2F;eureka-server&quot;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#39;docker push harbor&#39;) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh &quot;docker push 192.168.1.112&#x2F;ocp&#x2F;eureka-server&quot;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins拉取GitLab上的代码</title>
      <link href="2020/12/30/Jenkins%E6%8B%89%E5%8F%96GitLab%E4%B8%8A%E7%9A%84%E4%BB%A3%E7%A0%81/"/>
      <url>2020/12/30/Jenkins%E6%8B%89%E5%8F%96GitLab%E4%B8%8A%E7%9A%84%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="jenkinsfile"><a href="#jenkinsfile" class="headerlink" title="jenkinsfile"></a>jenkinsfile</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">     environment &#123;</span><br><span class="line">        git_url &#x3D; &#39;http:&#x2F;&#x2F;192.168.1.112&#x2F;root&#x2F;open-capacity-platform.git&#39;</span><br><span class="line">        credentialsId &#x3D; &#39;gitlab&#39;</span><br><span class="line">        git_branch &#x3D; &#39;master&#39;</span><br><span class="line">     &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#39;clean workspace&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                cleanWs()</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage(&#39;pull git code&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:&quot;$&#123;credentialsId&#125;&quot;,url:&quot;$&#123;git_url&#125;&quot;,branch: &quot;$&#123;git_branch&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>credentialsId在凭据里面查看</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E6%8B%89%E5%8F%96GitLab%E4%B8%8A%E7%9A%84%E4%BB%A3%E7%A0%81/a1.png"></p><h2 id="查看执行结果"><a href="#查看执行结果" class="headerlink" title="查看执行结果"></a>查看执行结果</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E6%8B%89%E5%8F%96GitLab%E4%B8%8A%E7%9A%84%E4%BB%A3%E7%A0%81/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins从远程git仓库执行jenkinsfile</title>
      <link href="2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/"/>
      <url>2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="编写脚本并上传git仓库"><a href="#编写脚本并上传git仓库" class="headerlink" title="编写脚本并上传git仓库"></a>编写脚本并上传git仓库</h2><p>首先将pipeline脚本写好上传至git仓库</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/a1.png"></p><p>test-demo1.File 文本简单输出 helloworld</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&#39;print helloworld&#39;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                echo &quot;helloworld&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="jenkins执行远程git仓库jenkinsfile"><a href="#jenkins执行远程git仓库jenkinsfile" class="headerlink" title="jenkins执行远程git仓库jenkinsfile"></a>jenkins执行远程git仓库jenkinsfile</h2><p>在jenkins机器上生成ssh key</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;root@example.com&quot;</span><br></pre></td></tr></table></figure><p>将公钥id_rsa.pub内容复制到gitlab上，图片中key位置中</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/a2.png"></p><p>在jenkins上添加凭据，将私钥id_rsa内容复制进图片中key位置</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/a3.png"></p><p>在jenkins中创建流水线，并配置</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/a4.png"></p><p>执行流水线任务</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/30/Jenkins%E4%BB%8E%E8%BF%9C%E7%A8%8Bgit%E4%BB%93%E5%BA%93%E6%89%A7%E8%A1%8Cjenkinsfile/a5.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决jenkins无权限执行docker指令问题</title>
      <link href="2020/12/30/%E8%A7%A3%E5%86%B3jenkins%E6%97%A0%E6%9D%83%E9%99%90%E6%89%A7%E8%A1%8Cdocker%E6%8C%87%E4%BB%A4%E9%97%AE%E9%A2%98/"/>
      <url>2020/12/30/%E8%A7%A3%E5%86%B3jenkins%E6%97%A0%E6%9D%83%E9%99%90%E6%89%A7%E8%A1%8Cdocker%E6%8C%87%E4%BB%A4%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>jenkins pipeline执行docker指令出现 Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.35/images/json: dial unix /var/run/docker.sock: connect: permission denied 问题</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>(1)修改用户组</p><p>将jenkins用户加入docker用户组</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usermod -a -G docker jenkins</span><br></pre></td></tr></table></figure><p>重启jenkins</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart jenkins</span><br></pre></td></tr></table></figure><p>（2）修改jenkins启动用户</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vim &#x2F;etc&#x2F;sysconfig&#x2F;jenkins</span><br><span class="line">JENKINS_USER&#x3D;&quot;root&quot;</span><br></pre></td></tr></table></figure><p>重启jenkins</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart jenkins</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker登录harbor出现getsockopt connection refused</title>
      <link href="2020/12/30/Docker%E7%99%BB%E5%BD%95harbor%E5%87%BA%E7%8E%B0getsockopt-connection-refused/"/>
      <url>2020/12/30/Docker%E7%99%BB%E5%BD%95harbor%E5%87%BA%E7%8E%B0getsockopt-connection-refused/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>docker登录harbor出现 Error response from daemon: Get <a href="https://192.168.1.112/v2/">https://192.168.1.112/v2/</a>: dial tcp 192.168.1.112:443: getsockopt: connection refused</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>可以看到docker是使用https登录的，但是harbor没有配置https，所以出现这个问题。</p><blockquote><p>修改 /usr/lib/systemd/system/docker.service</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在 ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd 后面加上 --insecure-registry</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd  --insecure-registry&#x3D;192.168.1.112</span><br></pre></td></tr></table></figure><p>重新启动docker</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修改Docker默认存储位置</title>
      <link href="2020/12/30/%E4%BF%AE%E6%94%B9Docker%E9%BB%98%E8%AE%A4%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"/>
      <url>2020/12/30/%E4%BF%AE%E6%94%B9Docker%E9%BB%98%E8%AE%A4%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>docker默认的数据目录是/var/lib/docker</p><blockquote><p>修改 /usr/lib/systemd/system/docker.service </p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 通过 --graph 参数指定数据存储的目录</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd --graph &#x2F;data&#x2F;docker</span><br></pre></td></tr></table></figure><p>重启</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><blockquote><p>注：或者修改/etc/docker/daemon.json文件实现   v17.05.0 之后使用 data-root，旧版本请使用 graph</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123; </span><br><span class="line">  &quot;data-root&quot;: &quot;&#x2F;data&#x2F;docker&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署OCP微服务项目</title>
      <link href="2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/"/>
      <url>2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>首先感谢大佬提供的 open-capacity-platform 开源项目，希望通过这次部署，加深对Kubernetes的应用。下面放上 ocp 作者的gitee地址：<a href="https://gitee.com/owenwangwen/open-capacity-platform">https://gitee.com/owenwangwen/open-capacity-platform</a></p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>Kubernetes集群</li><li>安装JDK1.8</li><li>安装Maven</li><li>安装Git</li><li>安装Harbor或者使用Docker hub</li></ul><h2 id="在master节点上安装JDK1-8"><a href="#在master节点上安装JDK1-8" class="headerlink" title="在master节点上安装JDK1.8"></a>在master节点上安装JDK1.8</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk-*</span><br></pre></td></tr></table></figure><h2 id="在master节点上安装Maven"><a href="#在master节点上安装Maven" class="headerlink" title="在master节点上安装Maven"></a>在master节点上安装Maven</h2><p>参考文章：<a href="https://1335402049.github.io/2020/04/19/Linux%E4%B8%8BMaven%E5%AE%89%E8%A3%85/">https://1335402049.github.io/2020/04/19/Linux%E4%B8%8BMaven%E5%AE%89%E8%A3%85/</a></p><h2 id="在master节点上安装Git"><a href="#在master节点上安装Git" class="headerlink" title="在master节点上安装Git"></a>在master节点上安装Git</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y git</span><br></pre></td></tr></table></figure><h2 id="在-master-节点上克隆ocp代码仓库"><a href="#在-master-节点上克隆ocp代码仓库" class="headerlink" title="在 master 节点上克隆ocp代码仓库"></a>在 master 节点上克隆ocp代码仓库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;gitee.com&#x2F;owenwangwen&#x2F;open-capacity-platform.git</span><br></pre></td></tr></table></figure><h2 id="构建docker镜像并推送到仓库"><a href="#构建docker镜像并推送到仓库" class="headerlink" title="构建docker镜像并推送到仓库"></a>构建docker镜像并推送到仓库</h2><p>修改 open-capacity-platform/pom.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 大概在55 56行</span><br><span class="line"># 指定仓库地址，如果是docker hub 修改为 unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock</span><br><span class="line">&lt;docker.host&gt;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock&lt;&#x2F;docker.host&gt;</span><br><span class="line"># 指定镜像前缀，修改成你自己docker hub上的账号</span><br><span class="line">&lt;docker.image.prefix&gt;tangweifeng&lt;&#x2F;docker.image.prefix&gt;</span><br></pre></td></tr></table></figure><h2 id="构建jar包"><a href="#构建jar包" class="headerlink" title="构建jar包"></a>构建jar包</h2><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><h4 id="修改eureka配置"><a href="#修改eureka配置" class="headerlink" title="修改eureka配置"></a>修改eureka配置</h4><p>修改 open-capacity-platform/register-center/eureka-server/src/main/resources/application-slave0.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># service名称为eureka</span><br><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br><span class="line">prefer-ip-address: false</span><br><span class="line"># instance字段下增加 hostname appname</span><br><span class="line">hostname: cloud-eureka</span><br><span class="line">appname: eureka-server</span><br></pre></td></tr></table></figure><h4 id="修改auth-server配置"><a href="#修改auth-server配置" class="headerlink" title="修改auth-server配置"></a>修改auth-server配置</h4><p>修改open-capacity-platform/oauth-center/auth-server/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改open-capacity-platform/oauth-center/auth-server/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># auth-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;auth-center-mysql:3306&#x2F;oauth-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h4 id="修改user-center配置"><a href="#修改user-center配置" class="headerlink" title="修改user-center配置"></a>修改user-center配置</h4><p>修改open-capacity-platform/business-center/user-center/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改open-capacity-platform/business-center/user-center/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># user-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;user-center-mysql:3306&#x2F;user-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h4 id="修改log-center配置"><a href="#修改log-center配置" class="headerlink" title="修改log-center配置"></a>修改log-center配置</h4><p>修改open-capacity-platform/monitor-center/log-center/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改open-capacity-platform/monitor-center/log-center/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># log-center-mysql 是后面部署的 headless 名称</span><br><span class="line">url: jdbc:mysql:&#x2F;&#x2F;log-center-mysql:3306&#x2F;log-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false </span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h4 id="修改api-gateway配置"><a href="#修改api-gateway配置" class="headerlink" title="修改api-gateway配置"></a>修改api-gateway配置</h4><p>修改open-capacity-platform/api-gateway/src/main/resources/bootstrap.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">defaultZone: http:&#x2F;&#x2F;cloud-eureka-0.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-1.cloud-eureka:1111&#x2F;eureka,http:&#x2F;&#x2F;cloud-eureka-2.cloud-eureka:1111&#x2F;eureka</span><br></pre></td></tr></table></figure><p>修改open-capacity-platform/api-gateway/src/main/resources/application.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url: jdbc:mysql:&#x2F;&#x2F;auth-center-mysql:3306&#x2F;oauth-center?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;allowMultiQueries&#x3D;true&amp;useSSL&#x3D;false</span><br><span class="line"># mysql用户名和密码</span><br><span class="line">username: root</span><br><span class="line">password: xxxx</span><br><span class="line"></span><br><span class="line"># redis配置</span><br><span class="line"># ocp-redis 是后面部署的 headless 名称</span><br><span class="line">host: ocp-redis</span><br></pre></td></tr></table></figure><h3 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform</span><br><span class="line">mvn clean package -DskipTests</span><br></pre></td></tr></table></figure><h3 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h3><h4 id="制作eureka镜像"><a href="#制作eureka镜像" class="headerlink" title="制作eureka镜像"></a>制作eureka镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform&#x2F;register-center&#x2F;eureka-server</span><br><span class="line">mvn docker:build</span><br></pre></td></tr></table></figure><h4 id="制作auth-server镜像"><a href="#制作auth-server镜像" class="headerlink" title="制作auth-server镜像"></a>制作auth-server镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform&#x2F;oauth-center&#x2F;auth-server</span><br><span class="line">mvn docker:build</span><br></pre></td></tr></table></figure><h4 id="制作user-center镜像"><a href="#制作user-center镜像" class="headerlink" title="制作user-center镜像"></a>制作user-center镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform&#x2F;business-center&#x2F;user-center</span><br><span class="line">mvn docker:build</span><br></pre></td></tr></table></figure><h4 id="制作log-center镜像"><a href="#制作log-center镜像" class="headerlink" title="制作log-center镜像"></a>制作log-center镜像</h4><p>制作镜像的时候会出现 pull access denied for frolvlad/alpine-oraclejdk8, repository does not exist or may require ‘docker login’ 错误</p><p>是因为dockerfile里面的 frolvlad/alpine-oraclejdk8 已经找不到了，可以将 open-capacity-platform/monitor-center/log-center/src/main/docker中的第一行 frolvlad/alpine-oraclejdk8替换成openjdk:8-jdk-alpine</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform&#x2F;monitor-center&#x2F;log-center</span><br><span class="line">mvn docker:build</span><br></pre></td></tr></table></figure><h4 id="制作api-gateway镜像"><a href="#制作api-gateway镜像" class="headerlink" title="制作api-gateway镜像"></a>制作api-gateway镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd open-capacity-platform&#x2F;api-gateway</span><br><span class="line">mvn docker:build</span><br></pre></td></tr></table></figure><h3 id="上传镜像至docker-hub"><a href="#上传镜像至docker-hub" class="headerlink" title="上传镜像至docker hub"></a>上传镜像至docker hub</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 登录</span><br><span class="line">docker login</span><br><span class="line"># 这边的 需要指定前缀 ，镜像使用 docker images 查看，前缀就是在一开始的pom.xml中定义的&lt;docker.image.prefix&gt;</span><br><span class="line">docker push tangweifeng&#x2F;eureka-server</span><br><span class="line">docker push tangweifeng&#x2F;auth-server</span><br><span class="line">docker push tangweifeng&#x2F;user-center</span><br><span class="line">docker push tangweifeng&#x2F;log-center</span><br><span class="line">docker push tangweifeng&#x2F;api-gateway</span><br></pre></td></tr></table></figure><h2 id="存储准备"><a href="#存储准备" class="headerlink" title="存储准备"></a>存储准备</h2><p>在部署微服务之前，考虑mysql、redis等服务数据的存储，我们准备使用nfs storageclass进行动态pv的创建，可以参考这篇文章<a href="https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/">https://1335402049.github.io/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</a></p><p>确认相关资源起来</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a1.png"></p><h2 id="部署ingress-nginx"><a href="#部署ingress-nginx" class="headerlink" title="部署ingress-nginx"></a>部署ingress-nginx</h2><p>参考这篇文章：<a href="https://1335402049.github.io/2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/">https://1335402049.github.io/2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/</a></p><h2 id="部署eureka"><a href="#部署eureka" class="headerlink" title="部署eureka"></a>部署eureka</h2><blockquote><p>应用 eureka-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: eureka</span><br><span class="line">  serviceName: cloud-eureka</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: eureka</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: eureka-server</span><br><span class="line">          image: tangweifeng&#x2F;eureka-server</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 1111</span><br></pre></td></tr></table></figure><blockquote><p>应用 eureka-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: cloud-eureka</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - port: 1111</span><br><span class="line">      targetPort: 1111</span><br><span class="line">  selector:</span><br><span class="line">    app: eureka</span><br></pre></td></tr></table></figure><blockquote><p>应用 eureka-ingress.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: eureka</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: eureka.twf.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: cloud-eureka</span><br><span class="line">              servicePort: 1111</span><br></pre></td></tr></table></figure><p>配置修改windows hosts文件，然后访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a2.png"></p><h2 id="部署MySQL"><a href="#部署MySQL" class="headerlink" title="部署MySQL"></a>部署MySQL</h2><h3 id="部署auth-center-mysql"><a href="#部署auth-center-mysql" class="headerlink" title="部署auth-center-mysql"></a>部署auth-center-mysql</h3><blockquote><p>应用 auth-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p>应用 auth-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>应用 auth-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: auth-center-mysql</span><br><span class="line">  serviceName: auth-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: auth-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: auth-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: auth-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: auth-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: auth-center-mysql</span><br><span class="line">          image: mysql:5.7.26</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: auth-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: auth-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: auth-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>应用 auth-center-mysql-service.yaml</p></blockquote><p>我们先使用NodePort方式暴露，然后导入数据后，之后你也可以修改为headless</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: auth-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><p>在 auth-center-mysql 起来后，使用navicat或者其他工具连接mysql，将 open-capacity-platform/sql/02.oauth-center.sql导入数据库</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a3.png"></p><blockquote><p>修改并应用 auth-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: auth-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h3 id="部署log-center-mysql"><a href="#部署log-center-mysql" class="headerlink" title="部署log-center-mysql"></a>部署log-center-mysql</h3><blockquote><p>应用 log-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p>应用 log-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>应用 log-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: log-center-mysql</span><br><span class="line">  serviceName: log-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: log-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: log-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: log-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: log-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: log-center-mysql</span><br><span class="line">          image: mysql:5.7.26</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: log-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: log-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: log-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>应用 log-center-mysql-service.yaml</p></blockquote><p>我们先使用NodePort方式暴露，然后导入数据后，之后你也可以修改为headless</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: log-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><p>在 log-center-mysql 起来后，使用navicat或者其他工具连接mysql，将 open-capacity-platform/sql/05.log-center.sql导入数据库</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a4.png"></p><blockquote><p>修改并应用 log-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: log-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h3 id="部署user-center-mysql"><a href="#部署user-center-mysql" class="headerlink" title="部署user-center-mysql"></a>部署user-center-mysql</h3><blockquote><p>应用 user-center-mysql-secret.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">data:</span><br><span class="line">  # 使用 echo -n &#39;&lt;密码&gt;&#39; |base64 获取加密后的密码</span><br><span class="line">  password: dGFuZzE2MTE&#x3D;</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br></pre></td></tr></table></figure><blockquote><p>应用 user-center-mysql-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">data:</span><br><span class="line">  mysqld.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    pid-file    &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid</span><br><span class="line">    socket        &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock</span><br><span class="line">    datadir        &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">    #log-error    &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;error.log</span><br><span class="line">    # By default we only accept connections from localhost</span><br><span class="line">    #bind-address    &#x3D; 127.0.0.1</span><br><span class="line">    # Disabling symbolic-links is recommended to prevent assorted security risks</span><br></pre></td></tr></table></figure><blockquote><p>应用 user-center-mysql-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: user-center-mysql</span><br><span class="line">  serviceName: user-center-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: user-center-mysql-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: user-center-mysql</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: user-center-mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: user-center-mysql</span><br><span class="line">      containers:</span><br><span class="line">        - name: user-center-mysql</span><br><span class="line">          image: mysql:5.7.26</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: user-center-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: user-center-mysql-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">            - name: user-center-mysql-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</span><br></pre></td></tr></table></figure><blockquote><p>应用 user-center-mysql-service.yaml</p></blockquote><p>我们先使用NodePort方式暴露，然后导入数据后，之后你也可以修改为headless</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: user-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><p>在 user-center-mysql 起来后，使用navicat或者其他工具连接mysql，将 open-capacity-platform/sql/01.user-center.sql导入数据库</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a5.png"></p><blockquote><p>修改并应用 user-center-mysql-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center-mysql</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: user-center-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      targetPort: 3306</span><br></pre></td></tr></table></figure><h2 id="部署Redis"><a href="#部署Redis" class="headerlink" title="部署Redis"></a>部署Redis</h2><blockquote><p>应用 redis-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">data:</span><br><span class="line">  redis.conf: |-</span><br><span class="line">    ################################## INCLUDES ###################################</span><br><span class="line">    # include &#x2F;path&#x2F;to&#x2F;local.conf</span><br><span class="line">    # include &#x2F;path&#x2F;to&#x2F;other.conf</span><br><span class="line"></span><br><span class="line">    ################################## MODULES #####################################</span><br><span class="line">    # loadmodule &#x2F;path&#x2F;to&#x2F;my_module.so</span><br><span class="line">    # loadmodule &#x2F;path&#x2F;to&#x2F;other_module.so</span><br><span class="line"></span><br><span class="line">    bind 0.0.0.0</span><br><span class="line"></span><br><span class="line">    protected-mode no</span><br><span class="line"></span><br><span class="line">    port 6379</span><br><span class="line"></span><br><span class="line">    tcp-backlog 511</span><br><span class="line"></span><br><span class="line">    # unixsocket &#x2F;tmp&#x2F;redis.sock</span><br><span class="line">    # unixsocketperm 700</span><br><span class="line"></span><br><span class="line">    timeout 0</span><br><span class="line"></span><br><span class="line">    tcp-keepalive 300</span><br><span class="line"></span><br><span class="line">    ################################# GENERAL #####################################</span><br><span class="line"></span><br><span class="line">    daemonize no</span><br><span class="line"></span><br><span class="line">    supervised no</span><br><span class="line"></span><br><span class="line">    pidfile &#x2F;data&#x2F;pid&#x2F;redis_6379.pid</span><br><span class="line"></span><br><span class="line">    loglevel notice</span><br><span class="line"></span><br><span class="line">    logfile &quot;&#x2F;data&#x2F;logs&#x2F;redis.log&quot;</span><br><span class="line"></span><br><span class="line">    # syslog-enabled no</span><br><span class="line"></span><br><span class="line">    # syslog-ident redis</span><br><span class="line"></span><br><span class="line">    # syslog-facility local0</span><br><span class="line"></span><br><span class="line">    databases 16</span><br><span class="line"></span><br><span class="line">    always-show-logo yes</span><br><span class="line"></span><br><span class="line">    save 900 1</span><br><span class="line">    save 300 10</span><br><span class="line">    save 60 10000</span><br><span class="line"></span><br><span class="line">    stop-writes-on-bgsave-error yes</span><br><span class="line"></span><br><span class="line">    rdbcompression yes</span><br><span class="line"></span><br><span class="line">    rdbchecksum yes</span><br><span class="line"></span><br><span class="line">    dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line">    dir &#x2F;data</span><br><span class="line"></span><br><span class="line">    # replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"></span><br><span class="line">    # masterauth &lt;master-password&gt;</span><br><span class="line"></span><br><span class="line">    replica-serve-stale-data yes</span><br><span class="line"></span><br><span class="line">    replica-read-only yes</span><br><span class="line"></span><br><span class="line">    repl-diskless-sync no</span><br><span class="line"></span><br><span class="line">    repl-diskless-sync-delay 5</span><br><span class="line"></span><br><span class="line">    # repl-ping-replica-period 10</span><br><span class="line"></span><br><span class="line">    # repl-timeout 60</span><br><span class="line"></span><br><span class="line">    repl-disable-tcp-nodelay no</span><br><span class="line"></span><br><span class="line">    # repl-backlog-size 1mb</span><br><span class="line"></span><br><span class="line">    # repl-backlog-ttl 3600</span><br><span class="line"></span><br><span class="line">    replica-priority 100</span><br><span class="line"></span><br><span class="line">    # min-replicas-to-write 3</span><br><span class="line">    # min-replicas-max-lag 10</span><br><span class="line"></span><br><span class="line">    # replica-announce-ip 5.5.5.5</span><br><span class="line">    # replica-announce-port 1234</span><br><span class="line"></span><br><span class="line">    # requirepass xxxx</span><br><span class="line"></span><br><span class="line">    # rename-command CONFIG &quot;&quot;</span><br><span class="line"></span><br><span class="line">    maxclients 2000</span><br><span class="line"></span><br><span class="line">    # maxmemory &lt;bytes&gt;</span><br><span class="line"></span><br><span class="line">    # maxmemory-policy noeviction</span><br><span class="line"></span><br><span class="line">    # maxmemory-samples 5</span><br><span class="line"></span><br><span class="line">    # replica-ignore-maxmemory yes</span><br><span class="line"></span><br><span class="line">    lazyfree-lazy-eviction no</span><br><span class="line">    lazyfree-lazy-expire no</span><br><span class="line">    lazyfree-lazy-server-del no</span><br><span class="line">    replica-lazy-flush no</span><br><span class="line"></span><br><span class="line">    appendonly yes</span><br><span class="line"></span><br><span class="line">    appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line">    # appendfsync always</span><br><span class="line">    appendfsync everysec</span><br><span class="line">    # appendfsync no</span><br><span class="line"></span><br><span class="line">    no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line">    auto-aof-rewrite-percentage 100</span><br><span class="line">    auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line">    aof-load-truncated yes</span><br><span class="line"></span><br><span class="line">    aof-use-rdb-preamble yes</span><br><span class="line"></span><br><span class="line">    lua-time-limit 5000</span><br><span class="line"></span><br><span class="line">    # cluster-enabled yes</span><br><span class="line"></span><br><span class="line">    # cluster-config-file nodes-6379.conf</span><br><span class="line"></span><br><span class="line">    # cluster-node-timeout 15000</span><br><span class="line"></span><br><span class="line">    # cluster-replica-validity-factor 10</span><br><span class="line"></span><br><span class="line">    # cluster-migration-barrier 1</span><br><span class="line"></span><br><span class="line">    # cluster-require-full-coverage yes</span><br><span class="line"></span><br><span class="line">    # cluster-replica-no-failover no</span><br><span class="line"></span><br><span class="line">    # cluster-announce-ip 10.1.1.5</span><br><span class="line">    # cluster-announce-port 6379</span><br><span class="line">    # cluster-announce-bus-port 6380</span><br><span class="line"></span><br><span class="line">    slowlog-log-slower-than 10000</span><br><span class="line"></span><br><span class="line">    slowlog-max-len 128</span><br><span class="line"></span><br><span class="line">    latency-monitor-threshold 0</span><br><span class="line"></span><br><span class="line">    #  notify-keyspace-events Elg</span><br><span class="line"></span><br><span class="line">    #  notify-keyspace-events Ex</span><br><span class="line"></span><br><span class="line">    notify-keyspace-events &quot;&quot;</span><br><span class="line"></span><br><span class="line">    hash-max-ziplist-entries 512</span><br><span class="line">    hash-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line">    list-max-ziplist-size -2</span><br><span class="line"></span><br><span class="line">    list-compress-depth 0</span><br><span class="line"></span><br><span class="line">    set-max-intset-entries 512</span><br><span class="line"></span><br><span class="line">    zset-max-ziplist-entries 128</span><br><span class="line">    zset-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line">    hll-sparse-max-bytes 3000</span><br><span class="line"></span><br><span class="line">    stream-node-max-bytes 4096</span><br><span class="line">    stream-node-max-entries 100</span><br><span class="line"></span><br><span class="line">    activerehashing yes</span><br><span class="line"></span><br><span class="line">    client-output-buffer-limit normal 0 0 0</span><br><span class="line">    client-output-buffer-limit replica 256mb 64mb 60</span><br><span class="line">    client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line"></span><br><span class="line">    # client-query-buffer-limit 1gb</span><br><span class="line"></span><br><span class="line">    # proto-max-bulk-len 512mb</span><br><span class="line"></span><br><span class="line">    hz 10</span><br><span class="line"></span><br><span class="line">    dynamic-hz yes</span><br><span class="line"></span><br><span class="line">    aof-rewrite-incremental-fsync yes</span><br><span class="line"></span><br><span class="line">    rdb-save-incremental-fsync yes</span><br><span class="line"></span><br><span class="line">    # lfu-log-factor 10</span><br><span class="line">    # lfu-decay-time 1</span><br><span class="line"></span><br><span class="line">    ########################### ACTIVE DEFRAGMENTATION #######################</span><br><span class="line">    # activedefrag yes</span><br><span class="line">    # active-defrag-ignore-bytes 100mb</span><br><span class="line">    # active-defrag-threshold-lower 10</span><br><span class="line">    # active-defrag-threshold-upper 100</span><br><span class="line">    # active-defrag-cycle-min 5</span><br><span class="line">    # active-defrag-cycle-max 75</span><br><span class="line">    # active-defrag-max-scan-fields 1000</span><br></pre></td></tr></table></figure><blockquote><p>应用 redis-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: ocp-redis</span><br><span class="line">  serviceName: ocp-redis</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: ocp-redis-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteMany</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 500Mi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: ocp-redis</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: ocp-redis-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: ocp-redis</span><br><span class="line">      containers:</span><br><span class="line">        - name: ocp-redis</span><br><span class="line">          image: redis:5.0.5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 6379</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: ocp-redis-data</span><br><span class="line">              mountPath: &#x2F;data</span><br><span class="line">            - name: ocp-redis-conf</span><br><span class="line">              mountPath: &#x2F;data&#x2F;redis.conf</span><br><span class="line">          command:</span><br><span class="line">            - redis-server</span><br><span class="line">            - &#x2F;data&#x2F;redis.conf</span><br></pre></td></tr></table></figure><blockquote><p>应用 redis-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: ocp-redis</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: ocp-redis</span><br><span class="line">  ports:</span><br><span class="line">    - port: 6379</span><br><span class="line">      targetPort: 6379</span><br></pre></td></tr></table></figure><h2 id="部署auth-server"><a href="#部署auth-server" class="headerlink" title="部署auth-server"></a>部署auth-server</h2><blockquote><p>应用 auth-server-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: auth-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: auth-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: auth-server</span><br><span class="line">          image: tangweifeng&#x2F;auth-server</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8000</span><br></pre></td></tr></table></figure><blockquote><p>应用 auth-server-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: auth-server</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: auth-server</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8000</span><br><span class="line">      targetPort: 8000</span><br></pre></td></tr></table></figure><h2 id="部署user-center"><a href="#部署user-center" class="headerlink" title="部署user-center"></a>部署user-center</h2><blockquote><p>应用 user-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: user-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: user-center</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: user-center</span><br><span class="line">          image: tangweifeng&#x2F;user-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 7000</span><br></pre></td></tr></table></figure><blockquote><p>应用 user-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: user-center</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: user-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 7000</span><br><span class="line">      targetPort: 7000</span><br></pre></td></tr></table></figure><h2 id="部署log-center"><a href="#部署log-center" class="headerlink" title="部署log-center"></a>部署log-center</h2><blockquote><p>应用 log-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: log-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: log-center</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: log-center</span><br><span class="line">          image: tangweifeng&#x2F;log-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 5006</span><br></pre></td></tr></table></figure><blockquote><p>应用 log-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: log-center</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: log-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 5006</span><br><span class="line">      targetPort: 5006</span><br></pre></td></tr></table></figure><h2 id="部署api-gateway"><a href="#部署api-gateway" class="headerlink" title="部署api-gateway"></a>部署api-gateway</h2><blockquote><p>应用 api-gateway-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: api-gateway</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: api-gateway</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: api-gateway</span><br><span class="line">          image: tangweifeng&#x2F;api-gateway</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9200</span><br></pre></td></tr></table></figure><blockquote><p>应用 api-gateway-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: api-gateway</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9200</span><br><span class="line">      targetPort: 9200</span><br></pre></td></tr></table></figure><blockquote><p>应用 api-gateway-ingress.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: api-gateway</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: api-gateway.ocp.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: api-gateway</span><br><span class="line">              servicePort: 9200</span><br></pre></td></tr></table></figure><p>在windows hosts文件里面添加映射规则</p><h2 id="部署back-center"><a href="#部署back-center" class="headerlink" title="部署back-center"></a>部署back-center</h2><p>在完成上面所有的部署后，我们再来部署一个前端的项目back-center。</p><p>修改open-capacity-platform/web-portal/back-center/src/main/view/static/module/config.js</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># api-gateway的url,端口通过 kubectl get svc -n ingress-nginx 查看</span><br><span class="line">base_server: &#39;http:&#x2F;&#x2F;api-gateway.ocp.com:32080&#x2F;&#39;</span><br><span class="line"># eureka_server的url</span><br><span class="line">eureka_server: &#39;http:&#x2F;&#x2F;eureka.twf.com:32080&#x2F;&#39;</span><br></pre></td></tr></table></figure><p>在 open-capacity-platform/web-portal/back-center/dockerfile 里编写Dockerfile制作nginx镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM tangweifeng&#x2F;nginx</span><br><span class="line">RUN rm -rf &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">ADD .&#x2F;src&#x2F;main&#x2F;view&#x2F;static &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">EXPOSE 80</span><br><span class="line">CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure><p>制作镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build -t tangweifeng&#x2F;back-center .</span><br></pre></td></tr></table></figure><p>上传到远程仓库</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker push tangweifeng&#x2F;back-center</span><br></pre></td></tr></table></figure><blockquote><p>应用 back-center-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">data:</span><br><span class="line">  nginx.conf: |-</span><br><span class="line">    user  nginx;</span><br><span class="line">    worker_processes  1;</span><br><span class="line"></span><br><span class="line">    error_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn;</span><br><span class="line">    pid        &#x2F;var&#x2F;run&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line">    events &#123;</span><br><span class="line">        worker_connections  1024;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    http &#123;</span><br><span class="line">        include       &#x2F;etc&#x2F;nginx&#x2F;mime.types;</span><br><span class="line">        default_type  application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">        log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">                          &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">                          &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">        access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">        sendfile        on;</span><br><span class="line">        #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">        keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">        #gzip  on;</span><br><span class="line"></span><br><span class="line">        server &#123;</span><br><span class="line">            listen       80;</span><br><span class="line">            listen  [::]:80;</span><br><span class="line">            server_name  localhost;</span><br><span class="line"></span><br><span class="line">            location &#x2F; &#123;</span><br><span class="line">                root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">                index  index.html index.htm;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line"></span><br><span class="line">            location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line">                root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>应用 back-center-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: back-center</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: back-center</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nginx-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: back-center</span><br><span class="line">      containers:</span><br><span class="line">        - name: back-center</span><br><span class="line">          image: tangweifeng&#x2F;back-center</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nginx-conf</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line">              subPath: nginx.conf</span><br></pre></td></tr></table></figure><blockquote><p>应用 back-center-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: back-center</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br></pre></td></tr></table></figure><blockquote><p>应用 back-center-ingress.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: back-center</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: &quot;nginx&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: ocp.twf.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - path: &#x2F;</span><br><span class="line">            backend:</span><br><span class="line">              serviceName: back-center</span><br><span class="line">              servicePort: 80</span><br></pre></td></tr></table></figure><p>在windows hosts增加一条主机映射规则</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过 ocp.twf.com:32080 访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a6.png"></p><p>默认用户名和密码都是admin</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2OCP%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE/a7.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署alertmanager</title>
      <link href="2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2alertmanager/"/>
      <url>2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2alertmanager/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>应用 alertmanager-configmap.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-config</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">data:</span><br><span class="line">  alertmanager.yml: |</span><br><span class="line">    global:</span><br><span class="line">      resolve_timeout: 5m</span><br><span class="line">      smtp_smarthost: &#39;smtp.qq.com:463&#39;</span><br><span class="line">      smtp_from: &#39;1335402049@qq.com&#39;</span><br><span class="line">      smtp_auth_username: &#39;1335402049@qq.com&#39;</span><br><span class="line">      smtp_auth_password: &#39;xxxxxxxxx&#39;</span><br><span class="line"></span><br><span class="line">    receivers:</span><br><span class="line">    - name: default-receiver</span><br><span class="line">      email_configs:</span><br><span class="line">      - to: &quot;1335402049@qq.com&quot;</span><br><span class="line"></span><br><span class="line">    route:</span><br><span class="line">      group_interval: 1m</span><br><span class="line">      group_wait: 10s</span><br><span class="line">      receiver: default-receiver</span><br><span class="line">      repeat_interval: 1m</span><br></pre></td></tr></table></figure><p>应用 alertmanager-pvc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: managed-nfs-storage</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: &quot;1Gi&quot;</span><br></pre></td></tr></table></figure><p>应用 alertmanager-deployment.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: alertmanager</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    version: v0.14.0</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: alertmanager</span><br><span class="line">      version: v0.14.0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: alertmanager</span><br><span class="line">        version: v0.14.0</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">        - name: prometheus-alertmanager</span><br><span class="line">          image: &quot;prom&#x2F;alertmanager:v0.14.0&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --config.file&#x3D;&#x2F;etc&#x2F;config&#x2F;alertmanager.yml</span><br><span class="line">            - --storage.path&#x3D;&#x2F;data</span><br><span class="line">            - --web.external-url&#x3D;&#x2F;</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9093</span><br><span class="line">          readinessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;#&#x2F;status</span><br><span class="line">              port: 9093</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">            - name: storage-volume</span><br><span class="line">              mountPath: &quot;&#x2F;data&quot;</span><br><span class="line">              subPath: &quot;&quot;</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 50Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 50Mi</span><br><span class="line">        - name: prometheus-alertmanager-configmap-reload</span><br><span class="line">          image: &quot;jimmidyson&#x2F;configmap-reload:v0.1&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --volume-dir&#x3D;&#x2F;etc&#x2F;config</span><br><span class="line">            - --webhook-url&#x3D;http:&#x2F;&#x2F;localhost:9093&#x2F;-&#x2F;reload</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 10Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 10m</span><br><span class="line">               memory: 10Mi</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: alertmanager-config</span><br><span class="line">        - name: storage-volume</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: alertmanager</span><br></pre></td></tr></table></figure><p>应用 alertmanager-service.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;name: &quot;Alertmanager&quot;</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 9093</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: alertmanager</span><br><span class="line">  type: &quot;ClusterIP&quot;</span><br></pre></td></tr></table></figure><p>修改prometheus-configmap.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改alert相关配置</span><br><span class="line">alerting:</span><br><span class="line">      # 告警配置文件</span><br><span class="line">      alertmanagers:</span><br><span class="line">      - static_configs:</span><br><span class="line">          - targets: [&quot;alertmanager:80&quot;]</span><br></pre></td></tr></table></figure><p>修改prometheus-configmap.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 增加rule_files配置</span><br><span class="line">data:</span><br><span class="line">  prometheus.yml: |</span><br><span class="line">    # 添加：指定读取rules配置</span><br><span class="line">    rule_files:</span><br><span class="line">    - &#x2F;etc&#x2F;config&#x2F;rules&#x2F;*.rules</span><br></pre></td></tr></table></figure><p>重新应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prometheus-configmap.yaml</span><br></pre></td></tr></table></figure><p>编写prometheus-rules.yaml并应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-rules</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  # 通用角色</span><br><span class="line">  general.rules: |</span><br><span class="line">    groups:</span><br><span class="line">    - name: general.rules</span><br><span class="line">      rules:</span><br><span class="line">      - alert: InstanceDown</span><br><span class="line">        expr: up &#x3D;&#x3D; 0</span><br><span class="line">        for: 1m</span><br><span class="line">        labels:</span><br><span class="line">          severity: error </span><br><span class="line">        annotations:</span><br><span class="line">          summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; 停止工作&quot;</span><br><span class="line">          description: &quot;&#123;&#123; $labels.instance &#125;&#125; job &#123;&#123; $labels.job &#125;&#125; 已经停止5分钟以上.&quot;</span><br><span class="line">  # Node对所有资源的监控</span><br><span class="line">  node.rules: |</span><br><span class="line">    groups:</span><br><span class="line">    - name: node.rules</span><br><span class="line">      rules:</span><br><span class="line">      - alert: NodeFilesystemUsage</span><br><span class="line">        expr: 100 - (node_filesystem_free_bytes&#123;fstype&#x3D;~&quot;ext4|xfs&quot;&#125; &#x2F; node_filesystem_size_bytes&#123;fstype&#x3D;~&quot;ext4|xfs&quot;&#125; * 100) &gt; 80 </span><br><span class="line">        for: 1m</span><br><span class="line">        labels:</span><br><span class="line">          severity: warning </span><br><span class="line">        annotations:</span><br><span class="line">          summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; : &#123;&#123; $labels.mountpoint &#125;&#125; 分区使用率过高&quot;</span><br><span class="line">          description: &quot;&#123;&#123; $labels.instance &#125;&#125;: &#123;&#123; $labels.mountpoint &#125;&#125; 分区使用大于80% (当前值: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line"></span><br><span class="line">      - alert: NodeMemoryUsage</span><br><span class="line">        expr: 100 - (node_memory_MemFree_bytes+node_memory_Cached_bytes+node_memory_Buffers_bytes) &#x2F; node_memory_MemTotal_bytes * 100 &gt; 80</span><br><span class="line">        for: 1m</span><br><span class="line">        labels:</span><br><span class="line">          severity: warning</span><br><span class="line">        annotations:</span><br><span class="line">          summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; 内存使用率过高&quot;</span><br><span class="line">          description: &quot;&#123;&#123; $labels.instance &#125;&#125;内存使用大于80% (当前值: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line"></span><br><span class="line">      - alert: NodeCPUUsage    </span><br><span class="line">        expr: 100 - (avg(irate(node_cpu_seconds_total&#123;mode&#x3D;&quot;idle&quot;&#125;[5m])) by (instance) * 100) &gt; 60 </span><br><span class="line">        for: 1m</span><br><span class="line">        labels:</span><br><span class="line">          severity: warning</span><br><span class="line">        annotations:</span><br><span class="line">          summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; CPU使用率过高&quot;       </span><br><span class="line">          description: &quot;&#123;&#123; $labels.instance &#125;&#125;CPU使用大于60% (当前值: &#123;&#123; $value &#125;&#125;)&quot;</span><br></pre></td></tr></table></figure><p>挂载rules到prometheus-statefulset</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  # 部署命名空间 </span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: prometheus</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    version: v2.2.1</span><br><span class="line">spec:</span><br><span class="line">  serviceName: &quot;prometheus&quot;</span><br><span class="line">  replicas: 1</span><br><span class="line">  podManagementPolicy: &quot;Parallel&quot;</span><br><span class="line">  updateStrategy:</span><br><span class="line">   type: &quot;RollingUpdate&quot;</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: prometheus</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: prometheus</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: prometheus</span><br><span class="line">      # 初始化容器</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: &quot;init-chown-data&quot;</span><br><span class="line">        image: &quot;busybox:latest&quot;</span><br><span class="line">        imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">        command: [&quot;chown&quot;, &quot;-R&quot;, &quot;65534:65534&quot;, &quot;&#x2F;data&quot;]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: prometheus-data</span><br><span class="line">          mountPath: &#x2F;data</span><br><span class="line">          subPath: &quot;&quot;</span><br><span class="line">      containers:</span><br><span class="line">        - name: prometheus-server-configmap-reload</span><br><span class="line">          image: &quot;jimmidyson&#x2F;configmap-reload:v0.1&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --volume-dir&#x3D;&#x2F;etc&#x2F;config</span><br><span class="line">            - --webhook-url&#x3D;http:&#x2F;&#x2F;localhost:9090&#x2F;-&#x2F;reload</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 10Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 10Mi</span><br><span class="line"></span><br><span class="line">        - name: prometheus-server</span><br><span class="line">          # 主要使用镜像</span><br><span class="line">          image: &quot;prom&#x2F;prometheus:v2.2.1&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --config.file&#x3D;&#x2F;etc&#x2F;config&#x2F;prometheus.yml</span><br><span class="line">            - --storage.tsdb.path&#x3D;&#x2F;data</span><br><span class="line">            - --web.console.libraries&#x3D;&#x2F;etc&#x2F;prometheus&#x2F;console_libraries</span><br><span class="line">            - --web.console.templates&#x3D;&#x2F;etc&#x2F;prometheus&#x2F;consoles</span><br><span class="line">            - --web.enable-lifecycle</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9090</span><br><span class="line">          readinessProbe:</span><br><span class="line">            # 健康检查</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;-&#x2F;ready</span><br><span class="line">              port: 9090</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;-&#x2F;healthy</span><br><span class="line">              port: 9090</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          # based on 10 running nodes with 30 pods each</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 200m</span><br><span class="line">              memory: 1000Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 200m</span><br><span class="line">              memory: 1000Mi</span><br><span class="line">          # 数据卷</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">            - name: prometheus-data</span><br><span class="line">              mountPath: &#x2F;data</span><br><span class="line">              subPath: &quot;&quot;</span><br><span class="line">            - name: prometheus-rules</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config&#x2F;rules</span><br><span class="line">              subPath: &quot;&quot;</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: prometheus-config</span><br><span class="line">        - name: prometheus-rules</span><br><span class="line">          configMap:</span><br><span class="line">            name: prometheus-rules</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: prometheus-data</span><br><span class="line">    spec:</span><br><span class="line">      # 使用动态PV、修改为已创建的PV动态存储</span><br><span class="line">      storageClassName: managed-nfs-storage</span><br><span class="line">      accessModes:</span><br><span class="line">        - ReadWriteOnce</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: &quot;5Gi&quot;</span><br></pre></td></tr></table></figure><p>重新应用prometheus-statefulset.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prometheus-statefulset.yaml</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/23/Kubernetes%E9%83%A8%E7%BD%B2alertmanager/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控Kubernetes集群</title>
      <link href="2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>目前prometheus对于Kubernetes集群的监控主要是包括这几方面：</p><table><thead><tr><th>监控指标</th><th>具体实现</th><th>描述</th></tr></thead><tbody><tr><td>pod、container性能</td><td>cadvisor</td><td>容器cpu、内存、网络等</td></tr><tr><td>node性能</td><td>node_exporter</td><td>各节点cpu、内存、磁盘、网络等</td></tr><tr><td>K8S资源对象</td><td>kube-state-metrics</td><td>pod、deployment、service等资源</td></tr></tbody></table><h2 id="部署prometheus"><a href="#部署prometheus" class="headerlink" title="部署prometheus"></a>部署prometheus</h2><blockquote><p>应用 prometheus-rbac.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line"># 创建 ServiceAccount 授予权限</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile </span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    # 授予的权限</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">      - nodes&#x2F;metrics</span><br><span class="line">      - services</span><br><span class="line">      - endpoints</span><br><span class="line">      - pods</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - nonResourceURLs:</span><br><span class="line">      - &quot;&#x2F;metrics&quot;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">---</span><br><span class="line"># 角色绑定</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: prometheus</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><blockquote><p>应用 prometheus-configmap.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># configuration format https:&#x2F;&#x2F;prometheus.io&#x2F;docs&#x2F;prometheus&#x2F;latest&#x2F;configuration&#x2F;configuration&#x2F;</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-config</span><br><span class="line">  namespace: kube-system </span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">data:</span><br><span class="line">  # 存放prometheus配置文件</span><br><span class="line">  prometheus.yml: |</span><br><span class="line">    global:</span><br><span class="line">      scrape_interval: 15s</span><br><span class="line">      scrape_timeout: 10s</span><br><span class="line">      evaluation_interval: 15s</span><br><span class="line">    # 配置采集目标</span><br><span class="line">    scrape_configs:    </span><br><span class="line">    - job_name: prometheus</span><br><span class="line">      static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - localhost:9090     </span><br><span class="line">    </span><br><span class="line">    # 采集：Apiserver 生存指标</span><br><span class="line">    # 创建的job name 名称为 kubernetes-apiservers</span><br><span class="line">    - job_name: kubernetes-apiservers</span><br><span class="line">      # 基于k8s的服务发现</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: endpoints</span><br><span class="line">      # 使用通信标记标签</span><br><span class="line">      relabel_configs:</span><br><span class="line">      # 保留正则匹配标签</span><br><span class="line">      - action: keep</span><br><span class="line">        # 已经包含</span><br><span class="line">        regex: default;kubernetes;https</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_namespace</span><br><span class="line">        - __meta_kubernetes_service_name</span><br><span class="line">        - __meta_kubernetes_endpoint_port_name</span><br><span class="line">      # 使用方法为https、默认http</span><br><span class="line">      scheme: https</span><br><span class="line">      tls_config:</span><br><span class="line">        # promethus访问Apiserver使用认证</span><br><span class="line">        ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">        # 跳过https认证</span><br><span class="line">        insecure_skip_verify: true</span><br><span class="line">      # promethus访问Apiserver使用认证</span><br><span class="line">      bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br><span class="line"> </span><br><span class="line">    # 采集：Kubelet 生存指标</span><br><span class="line">    - job_name: kubernetes-nodes-kubelet</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      # 发现集群中所有的Node</span><br><span class="line">      - role: node</span><br><span class="line">      relabel_configs:</span><br><span class="line">      # 通过regex获取关键信息</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      scheme: https</span><br><span class="line">      tls_config:</span><br><span class="line">        ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">        insecure_skip_verify: true</span><br><span class="line">      bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br><span class="line"></span><br><span class="line">    # 采集：nodes-cadvisor 信息</span><br><span class="line">    - job_name: kubernetes-nodes-cadvisor</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: node</span><br><span class="line">      relabel_configs:</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      # 重命名标签</span><br><span class="line">      - target_label: __metrics_path__</span><br><span class="line">        replacement: &#x2F;metrics&#x2F;cadvisor</span><br><span class="line">      scheme: https</span><br><span class="line">      tls_config:</span><br><span class="line">        ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">        insecure_skip_verify: true</span><br><span class="line">      bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br><span class="line"></span><br><span class="line">    # 采集：service-endpoints 信息</span><br><span class="line">    - job_name: kubernetes-service-endpoints</span><br><span class="line">      # 选定指标</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: endpoints</span><br><span class="line">      relabel_configs:</span><br><span class="line">      - action: keep</span><br><span class="line">        regex: true</span><br><span class="line">        # 指定源标签</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_service_annotation_prometheus_io_scrape</span><br><span class="line">      - action: replace</span><br><span class="line">        regex: (https?)</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_service_annotation_prometheus_io_scheme</span><br><span class="line">        # 重命名标签采集</span><br><span class="line">        target_label: __scheme__</span><br><span class="line">      - action: replace</span><br><span class="line">        regex: (.+)</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_service_annotation_prometheus_io_path</span><br><span class="line">        target_label: __metrics_path__</span><br><span class="line">      - action: replace</span><br><span class="line">        regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">        replacement: $1:$2</span><br><span class="line">        source_labels:</span><br><span class="line">        - __address__</span><br><span class="line">        - __meta_kubernetes_service_annotation_prometheus_io_port</span><br><span class="line">        target_label: __address__</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_service_label_(.+)</span><br><span class="line">      - action: replace</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_namespace</span><br><span class="line">        target_label: kubernetes_namespace</span><br><span class="line">      - action: replace</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_service_name</span><br><span class="line">        target_label: kubernetes_name</span><br><span class="line"></span><br><span class="line">    # 采集：kubernetes-services 服务指标</span><br><span class="line">    - job_name: kubernetes-services</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: service</span><br><span class="line">      # 黑盒探测，探测IP与端口是否可用</span><br><span class="line">      metrics_path: &#x2F;probe</span><br><span class="line">      params:</span><br><span class="line">        module:</span><br><span class="line">        - http_2xx</span><br><span class="line">      relabel_configs:</span><br><span class="line">      - action: keep</span><br><span class="line">        regex: true</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_service_annotation_prometheus_io_probe</span><br><span class="line">      - source_labels:</span><br><span class="line">        - __address__</span><br><span class="line">        target_label: __param_target</span><br><span class="line">      # 使用 blackbox进行黑盒探测</span><br><span class="line">      - replacement: blackbox</span><br><span class="line">        target_label: __address__</span><br><span class="line">      - source_labels:</span><br><span class="line">        - __param_target</span><br><span class="line">        target_label: instance</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_service_label_(.+)</span><br><span class="line">      - source_labels:</span><br><span class="line">        - __meta_kubernetes_namespace</span><br><span class="line">        target_label: kubernetes_namespace</span><br><span class="line">      - source_labels:</span><br><span class="line">        - __meta_kubernetes_service_name</span><br><span class="line">        target_label: kubernetes_name</span><br><span class="line"></span><br><span class="line">    # 采集： kubernetes-pods 信息</span><br><span class="line">    - job_name: kubernetes-pods</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: pod</span><br><span class="line">      relabel_configs:</span><br><span class="line">      - action: keep</span><br><span class="line">        regex: true</span><br><span class="line">        source_labels:</span><br><span class="line">        # 只保留采集的信息</span><br><span class="line">        - __meta_kubernetes_pod_annotation_prometheus_io_scrape</span><br><span class="line">      - action: replace</span><br><span class="line">        regex: (.+)</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_pod_annotation_prometheus_io_path</span><br><span class="line">        target_label: __metrics_path__</span><br><span class="line">      - action: replace</span><br><span class="line">        regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">        replacement: $1:$2</span><br><span class="line">        source_labels:</span><br><span class="line">        # 采集地址</span><br><span class="line">        - __address__</span><br><span class="line">        # 采集端口 </span><br><span class="line">        - __meta_kubernetes_pod_annotation_prometheus_io_port</span><br><span class="line">        target_label: __address__</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">      - action: replace</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_namespace</span><br><span class="line">        target_label: kubernetes_namespace</span><br><span class="line">      - action: replace</span><br><span class="line">        source_labels:</span><br><span class="line">        - __meta_kubernetes_pod_name</span><br><span class="line">        target_label: kubernetes_pod_name</span><br><span class="line">    alerting:</span><br><span class="line">      # 告警配置文件</span><br><span class="line">      alertmanagers:</span><br><span class="line">      - kubernetes_sd_configs:</span><br><span class="line">          # 采用动态获取</span><br><span class="line">          - role: pod</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">        bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">          regex: kube-system </span><br><span class="line">          action: keep</span><br><span class="line">        - source_labels: [__meta_kubernetes_pod_label_k8s_app]</span><br><span class="line">          regex: alertmanager</span><br><span class="line">          action: keep</span><br><span class="line">        - source_labels: [__meta_kubernetes_pod_container_port_number]</span><br><span class="line">          regex:</span><br><span class="line">          action: drop</span><br></pre></td></tr></table></figure><blockquote><p>应用 prometheus-statefulset.yaml</p></blockquote><p>在 volumeClaimTemplates 字段绑定了storageclass 动态pv供给，可以参考我的这篇文章</p><p>来使用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  # 部署命名空间 </span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: prometheus</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    version: v2.2.1</span><br><span class="line">spec:</span><br><span class="line">  serviceName: &quot;prometheus&quot;</span><br><span class="line">  replicas: 1</span><br><span class="line">  podManagementPolicy: &quot;Parallel&quot;</span><br><span class="line">  updateStrategy:</span><br><span class="line">   type: &quot;RollingUpdate&quot;</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: prometheus</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: prometheus</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: prometheus</span><br><span class="line">      # 初始化容器</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: &quot;init-chown-data&quot;</span><br><span class="line">        image: &quot;busybox:latest&quot;</span><br><span class="line">        imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">        command: [&quot;chown&quot;, &quot;-R&quot;, &quot;65534:65534&quot;, &quot;&#x2F;data&quot;]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: prometheus-data</span><br><span class="line">          mountPath: &#x2F;data</span><br><span class="line">          subPath: &quot;&quot;</span><br><span class="line">      containers:</span><br><span class="line">        - name: prometheus-server-configmap-reload</span><br><span class="line">          image: &quot;jimmidyson&#x2F;configmap-reload:v0.1&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --volume-dir&#x3D;&#x2F;etc&#x2F;config</span><br><span class="line">            - --webhook-url&#x3D;http:&#x2F;&#x2F;localhost:9090&#x2F;-&#x2F;reload</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 10Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 10m</span><br><span class="line">              memory: 10Mi</span><br><span class="line"></span><br><span class="line">        - name: prometheus-server</span><br><span class="line">          # 主要使用镜像</span><br><span class="line">          image: &quot;prom&#x2F;prometheus:v2.2.1&quot;</span><br><span class="line">          imagePullPolicy: &quot;IfNotPresent&quot;</span><br><span class="line">          args:</span><br><span class="line">            - --config.file&#x3D;&#x2F;etc&#x2F;config&#x2F;prometheus.yml</span><br><span class="line">            - --storage.tsdb.path&#x3D;&#x2F;data</span><br><span class="line">            - --web.console.libraries&#x3D;&#x2F;etc&#x2F;prometheus&#x2F;console_libraries</span><br><span class="line">            - --web.console.templates&#x3D;&#x2F;etc&#x2F;prometheus&#x2F;consoles</span><br><span class="line">            - --web.enable-lifecycle</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9090</span><br><span class="line">          readinessProbe:</span><br><span class="line">            # 健康检查</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;-&#x2F;ready</span><br><span class="line">              port: 9090</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: &#x2F;-&#x2F;healthy</span><br><span class="line">              port: 9090</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          # based on 10 running nodes with 30 pods each</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 200m</span><br><span class="line">              memory: 1000Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 200m</span><br><span class="line">              memory: 1000Mi</span><br><span class="line">          # 数据卷</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">            - name: prometheus-data</span><br><span class="line">              mountPath: &#x2F;data</span><br><span class="line">              subPath: &quot;&quot;</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: prometheus-config</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: prometheus-data</span><br><span class="line">    spec:</span><br><span class="line">      # 使用动态PV、修改为已创建的PV动态存储</span><br><span class="line">      storageClassName: managed-nfs-storage</span><br><span class="line">      accessModes:</span><br><span class="line">        - ReadWriteOnce</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: &quot;5Gi&quot;</span><br></pre></td></tr></table></figure><blockquote><p>应用 prometheus-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  # 指定命名空间</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;name: &quot;Prometheus&quot;</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  # 添加外部访问</span><br><span class="line">  type: NodePort</span><br><span class="line">  # 指定内部访问协议</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 9090</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: prometheus</span><br></pre></td></tr></table></figure><p>应用这些yaml后，查看 kube-system 下的 prometheus service的NodePort来进行访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a1.png"></p><h2 id="部署grafana"><a href="#部署grafana" class="headerlink" title="部署grafana"></a>部署grafana</h2><p>grafana可以部署在K8S内，也可以选择部署在集群外</p><blockquote><p>应用 grafana-statefulset.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: grafana</span><br><span class="line">  serviceName: grafana</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: grafana-data</span><br><span class="line">      spec:</span><br><span class="line">        storageClassName: managed-nfs-storage</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteOnce</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 1Gi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: grafana</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: grafana</span><br><span class="line">          image: grafana&#x2F;grafana</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3000</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 256Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 256Mi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: grafana-data</span><br><span class="line">              mountPath: &#x2F;var&#x2F;lib&#x2F;grafana</span><br><span class="line">              subPath: grafana</span><br></pre></td></tr></table></figure><blockquote><p>应用 grafana-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: grafana</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3000</span><br><span class="line">      targetPort: 3000</span><br></pre></td></tr></table></figure><p>应用yaml后，查看 kube-system 下的 grafana service的NodePort来进行访问</p><p>默认的用户名和密码都是 admin</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a2.png"></p><p>添加数据源</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a3.png"></p><p>填写数据源名称、prometheus地址后保存即可，这边地址是 <a href="http://prometheus:9090/">http://prometheus:9090</a> 是因为我们grafana也在K8S集群内部，可以通过coredns进行访问</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a4.png"></p><h2 id="使用node-exporter采集监控数据并展示"><a href="#使用node-exporter采集监控数据并展示" class="headerlink" title="使用node_exporter采集监控数据并展示"></a>使用node_exporter采集监控数据并展示</h2><blockquote><p>node_exporter不建议部署在K8S集群中</p></blockquote><p>查看这篇文章部署node_exporter：<a href="https://1335402049.github.io/2020/12/07/node-exporter%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/">https://1335402049.github.io/2020/12/07/node-exporter%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</a></p><p>在所有节点部署node_exporter启动后，我们修改 prometheus-configmap.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 存放prometheus配置文件</span><br><span class="line">  prometheus.yml: |</span><br><span class="line">    global:</span><br><span class="line">      scrape_interval: 15s</span><br><span class="line">      scrape_timeout: 10s</span><br><span class="line">      evaluation_interval: 15s</span><br><span class="line">    # 配置采集目标</span><br><span class="line">    scrape_configs:    </span><br><span class="line">    - job_name: node</span><br><span class="line">      static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - 192.168.1.110:9100</span><br><span class="line">        - 192.168.1.111:9100</span><br><span class="line">        - 192.168.1.112:9100       </span><br></pre></td></tr></table></figure><p>重新应用生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prometheus-configmap.yaml</span><br></pre></td></tr></table></figure><p>在prometheus页面的targets里面可以看到监控的node已经生效</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a5.png"></p><p>在grafana添加监控模板，当然你也可以去官网: <a href="https://grafana.com/grafana/dashboards">https://grafana.com/grafana/dashboards</a> 找其他的模板</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a6.png"></p><p>导入进来的模板，有的图表也有可能无法正常显示，根据自己的情况进行修改，主要也就是对prometheus查询语法的修改以及和grafana variables的修改</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a7.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a8.png"></p><p>最后grafana绘制成功的图表</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a9.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a10.png"></p><h2 id="展示cadvisor数据图形"><a href="#展示cadvisor数据图形" class="headerlink" title="展示cadvisor数据图形"></a>展示cadvisor数据图形</h2><p>cadvisor能够帮我们对容器的性能数据进行采集，并且K8S内部也提供了cadvisor采集器，我们无需在单独部署，</p><p>在prometheus-configmap.yaml中也配置了相关的cadvisor的服务发现</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 采集：nodes-cadvisor 信息</span><br><span class="line">    - job_name: kubernetes-nodes-cadvisor</span><br><span class="line">      kubernetes_sd_configs:</span><br><span class="line">      - role: node</span><br><span class="line">      relabel_configs:</span><br><span class="line">      - action: labelmap</span><br><span class="line">        regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      # 重命名标签</span><br><span class="line">      - target_label: __metrics_path__</span><br><span class="line">        replacement: &#x2F;metrics&#x2F;cadvisor</span><br><span class="line">      scheme: https</span><br><span class="line">      tls_config:</span><br><span class="line">        ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">        insecure_skip_verify: true</span><br><span class="line">      bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br></pre></td></tr></table></figure><p>在prometheus的targets页面看到nodes-cadvisor状态</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a11.png"></p><p>在grafana中导入模板ID：3119</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a12.png"></p><h2 id="使用kube-state-metrics收集数据并展示"><a href="#使用kube-state-metrics收集数据并展示" class="headerlink" title="使用kube-state-metrics收集数据并展示"></a>使用kube-state-metrics收集数据并展示</h2><blockquote><p>应用 kube-state-metrics-rbac.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  - secrets</span><br><span class="line">  - nodes</span><br><span class="line">  - pods</span><br><span class="line">  - services</span><br><span class="line">  - resourcequotas</span><br><span class="line">  - replicationcontrollers</span><br><span class="line">  - limitranges</span><br><span class="line">  - persistentvolumeclaims</span><br><span class="line">  - persistentvolumes</span><br><span class="line">  - namespaces</span><br><span class="line">  - endpoints</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups: [&quot;extensions&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - daemonsets</span><br><span class="line">  - deployments</span><br><span class="line">  - replicasets</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups: [&quot;apps&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - statefulsets</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups: [&quot;batch&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - cronjobs</span><br><span class="line">  - jobs</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups: [&quot;autoscaling&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - horizontalpodautoscalers</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics-resizer</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  verbs: [&quot;get&quot;]</span><br><span class="line">- apiGroups: [&quot;extensions&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - deployments</span><br><span class="line">  resourceNames: [&quot;kube-state-metrics&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1 </span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: kube-state-metrics-resizer</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><blockquote><p>应用 kube-state-metrics-deployment.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-state-metrics</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    version: v1.3.0</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-state-metrics</span><br><span class="line">      version: v1.3.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-state-metrics</span><br><span class="line">        version: v1.3.0</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: kube-state-metrics</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-state-metrics</span><br><span class="line">        image: lizhenliang&#x2F;kube-state-metrics:v1.3.0</span><br><span class="line">        ports:</span><br><span class="line">        - name: http-metrics</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        - name: telemetry</span><br><span class="line">          containerPort: 8081</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: &#x2F;healthz</span><br><span class="line">            port: 8080</span><br><span class="line">          initialDelaySeconds: 5</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">      - name: addon-resizer</span><br><span class="line">        image: lizhenliang&#x2F;addon-resizer:1.8.3</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 30Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 30Mi</span><br><span class="line">        env:</span><br><span class="line">          - name: MY_POD_NAME</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: metadata.name</span><br><span class="line">          - name: MY_POD_NAMESPACE</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">          - name: config-volume</span><br><span class="line">            mountPath: &#x2F;etc&#x2F;config</span><br><span class="line">        command:</span><br><span class="line">          - &#x2F;pod_nanny</span><br><span class="line">          - --config-dir&#x3D;&#x2F;etc&#x2F;config</span><br><span class="line">          - --container&#x3D;kube-state-metrics</span><br><span class="line">          - --cpu&#x3D;100m</span><br><span class="line">          - --extra-cpu&#x3D;1m</span><br><span class="line">          - --memory&#x3D;100Mi</span><br><span class="line">          - --extra-memory&#x3D;2Mi</span><br><span class="line">          - --threshold&#x3D;5</span><br><span class="line">          - --deployment&#x3D;kube-state-metrics</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: kube-state-metrics-config</span><br><span class="line">---</span><br><span class="line"># Config map for resource configuration.</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics-config</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-state-metrics</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">data:</span><br><span class="line">  NannyConfiguration: |-</span><br><span class="line">    apiVersion: nannyconfig&#x2F;v1alpha1</span><br><span class="line">    kind: NannyConfiguration</span><br></pre></td></tr></table></figure><blockquote><p>应用 kube-state-metrics-service.yaml</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;name: &quot;kube-state-metrics&quot;</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io&#x2F;scrape: &#39;true&#39;</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http-metrics</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: http-metrics</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: telemetry</span><br><span class="line">    port: 8081</span><br><span class="line">    targetPort: telemetry</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-state-metrics</span><br></pre></td></tr></table></figure><p>应用这些yaml，在prometheus-configmap.yaml中也有kubernetes的服务发现配置，在targets的页面有了apiserver、pod、endpoint等等目标</p><p>在grafana中导入模板ID：6417</p><p>在这里你可以看到pod资源情况、滚动更新、pod数量、pod状态等等</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/a13.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus基于文件的服务发现</title>
      <link href="2020/12/20/Prometheus%E5%9F%BA%E4%BA%8E%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"/>
      <url>2020/12/20/Prometheus%E5%9F%BA%E4%BA%8E%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Prometheus提供服务发现功能，能够从consul、dns、kubernetes等多种来源发现目标。其中，基于文件的服务发现是Prometheus服务发现最简单的。</p><h2 id="编写prometheus-yml"><a href="#编写prometheus-yml" class="headerlink" title="编写prometheus.yml"></a>编写prometheus.yml</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  file_sd_configs:</span><br><span class="line">  # 指定服务发现的目录及配置文件</span><br><span class="line">  - files: [&#39;&#x2F;etc&#x2F;prometheus&#x2F;conf&#x2F;*.yml&#39;]</span><br><span class="line">    # 每过5s动态发现服务配置</span><br><span class="line">    refresh_interval: 5s</span><br></pre></td></tr></table></figure><h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;etc&#x2F;prometheus&#x2F;conf</span><br></pre></td></tr></table></figure><h2 id="写入配置文件"><a href="#写入配置文件" class="headerlink" title="写入配置文件"></a>写入配置文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost conf]# cat test.yml </span><br><span class="line">- targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br><span class="line">  labels:</span><br><span class="line">    area: nj</span><br></pre></td></tr></table></figure><p>更新prometheus配置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 检查配置</span><br><span class="line">.&#x2F;promtool check config prometheus.yml</span><br><span class="line"># 发送hup信号</span><br><span class="line">kill -hup 17386</span><br></pre></td></tr></table></figure><p>刷新浏览器页面，可以看到添加的标签</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/Prometheus%E5%9F%BA%E4%BA%8E%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>frp实现内网穿透</title>
      <link href="2020/12/20/frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
      <url>2020/12/20/frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>frp是一个高性能的反向代理，可以帮助你快速进行内网穿透，frp支持tcp、http、https等多种协议。</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>需要一台外网服务器和一台需要穿透内网的机器</p><p>需要frp相关的包，可以自行去GitHub上下载，我这边也准备了一份</p><blockquote><p>链接：<a href="https://pan.baidu.com/s/1e1G7yRBHA61hYZ02qVvirQ">https://pan.baidu.com/s/1e1G7yRBHA61hYZ02qVvirQ</a><br>提取码：yugx </p></blockquote><h2 id="外网服务器配置"><a href="#外网服务器配置" class="headerlink" title="外网服务器配置"></a>外网服务器配置</h2><p>使用tar解压</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf frp_0.22.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><p>配置frps.ini</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">bind_port &#x3D; 7000</span><br><span class="line">vhost_http_port &#x3D; 6081</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup .&#x2F;frps -c frps.ini &amp;</span><br></pre></td></tr></table></figure><p>查看是否成功运行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef | grep frps</span><br></pre></td></tr></table></figure><h2 id="内网机器配置"><a href="#内网机器配置" class="headerlink" title="内网机器配置"></a>内网机器配置</h2><p>配置frpc.ini</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr &#x3D; xxx.xxx.xxx.xxx #外网服务器地址</span><br><span class="line">server_port &#x3D; 7000 #frps配置的端口bind_port</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">type &#x3D; tcp</span><br><span class="line">local_ip &#x3D; 192.168.1.110 #需要穿透的内网</span><br><span class="line">local_port &#x3D; 22 #ssh连接端口</span><br><span class="line">remote_port &#x3D; 7001</span><br></pre></td></tr></table></figure><p>运行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup .&#x2F;frpc -c .&#x2F;frpc.ini &amp;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>我们在手机端使用termius去连接</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/a1.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/a2.png"></p><p>好了，最后就成功连接上了</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/20/frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/a3.png"></p>]]></content>
      
      
      <categories>
          
          <category> frp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> frp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus告警系统alertmanager之告警收敛</title>
      <link href="2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%91%8A%E8%AD%A6%E6%94%B6%E6%95%9B/"/>
      <url>2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%91%8A%E8%AD%A6%E6%94%B6%E6%95%9B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>告警面临最大的问题就是告警信息太多、信息中混杂着许多重复的告警，因此收件人也会非常头疼。alertmanager告警收敛可以有效地解决此类问题，告警收敛主要有3种手段：分组、抑制、静默。</p><h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><p>将类似性质的告警分类成单个通知，一起发送告警</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">route:</span><br><span class="line">  # 根据alertname进行分组</span><br><span class="line">  group_by: [&#39;alertname&#39;]</span><br></pre></td></tr></table></figure><h2 id="抑制"><a href="#抑制" class="headerlink" title="抑制"></a>抑制</h2><p>当告警发出去后，停止发送由此告警引起的其他告警</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inhibit_rules:</span><br><span class="line">  # 根据 severity: &#39;critical&#39;标签 匹配当前告警</span><br><span class="line">  - source_match:</span><br><span class="line">      severity: &#39;critical&#39;</span><br><span class="line">    # 需要抑制的告警信息</span><br><span class="line">    target_match:</span><br><span class="line">      severity: &#39;warning&#39;</span><br><span class="line">    # 只有包含指定标签才成立规则</span><br><span class="line">    equal: [&#39;alertname&#39;, &#39;dev&#39;, &#39;instance&#39;]</span><br></pre></td></tr></table></figure><h2 id="静默"><a href="#静默" class="headerlink" title="静默"></a>静默</h2><p>在一段特定的时间内禁止告警的机制</p><p>访问alertmanager：<a href="http://192.168.1.113:9093/">http://192.168.1.113:9093/</a></p><p>创建一个new silence</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%91%8A%E8%AD%A6%E6%94%B6%E6%95%9B/a1.png"></p><p>设置静默时间、标签、创建人等</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%91%8A%E8%AD%A6%E6%94%B6%E6%95%9B/a2.png"></p><p>查看静默</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%91%8A%E8%AD%A6%E6%94%B6%E6%95%9B/a3.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus告警系统alertmanager之分配告警到指定接收组</title>
      <link href="2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%88%86%E9%85%8D%E5%91%8A%E8%AD%A6%E5%88%B0%E6%8C%87%E5%AE%9A%E6%8E%A5%E6%94%B6%E7%BB%84/"/>
      <url>2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%88%86%E9%85%8D%E5%91%8A%E8%AD%A6%E5%88%B0%E6%8C%87%E5%AE%9A%E6%8E%A5%E6%94%B6%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>alertmanager中route属性用来设置告警的分发策略。</p><h2 id="配置alertmanager"><a href="#配置alertmanager" class="headerlink" title="配置alertmanager"></a>配置alertmanager</h2><p>我们大致在下面的匹配规则可以看出，当匹配存在标签 service: mysql|redis 就将告警发送到group1（谷歌邮箱），当匹配 service: linux 则将告警发送到 group2（QQ邮箱）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  smtp_smarthost: &#39;smtp.qq.com:465&#39;</span><br><span class="line">  smtp_from: &#39;xxx@qq.com&#39;</span><br><span class="line">  smtp_auth_username: &#39;xxx@qq.com&#39;</span><br><span class="line">  smtp_auth_password: &#39;xxxxxxxxxx&#39;</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line"></span><br><span class="line">route:</span><br><span class="line">  group_by: [&#39;alertname&#39;]</span><br><span class="line">  group_wait: 10s</span><br><span class="line">  group_interval: 10s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  receiver: &#39;group1&#39;</span><br><span class="line">  # 所有不匹配以下的路由，告警都保留在根节点，并发送到根节点的receiver设置的默认路由</span><br><span class="line">  routes:</span><br><span class="line">  - receiver: &#39;group1&#39;</span><br><span class="line">    # 使用正则匹配</span><br><span class="line">    match_re:</span><br><span class="line">      service: mysql|redis</span><br><span class="line">  - receiver: &#39;group2&#39;</span><br><span class="line">    match:</span><br><span class="line">      service: linux</span><br><span class="line">receivers:</span><br><span class="line">- name: &#39;group1&#39;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#39;xxx@gmail.com&#39;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#39;group2&#39;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#39;xxx@qq.com&#39;</span><br><span class="line">    send_resolved: true</span><br><span class="line">inhibit_rules:</span><br><span class="line">  - source_match:</span><br><span class="line">      severity: &#39;critical&#39;</span><br><span class="line">    target_match:</span><br><span class="line">      severity: &#39;warning&#39;</span><br><span class="line">    equal: [&#39;alertname&#39;, &#39;dev&#39;, &#39;instance&#39;]</span><br></pre></td></tr></table></figure><h2 id="配置rules"><a href="#配置rules" class="headerlink" title="配置rules"></a>配置rules</h2><p>为了更加容易触发告警，我们分别选用cpu和内存使用率告警，当cpu使用率大于0.5%告警，当内存使用率大于5%告警。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: general</span><br><span class="line">  rules:</span><br><span class="line">  - alert: CPU usage is more than 75%</span><br><span class="line">    expr: 100 - (avg(irate(node_cpu_seconds_total&#123;job&#x3D;&quot;prometheus&quot;,mode&#x3D;&quot;idle&quot;&#125;[1m])) * 100) &gt; 0.5</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">      service: linux</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;instance &#123;&#123; $labels.instance &#125;&#125; CPU usage is more than 75%&quot;</span><br><span class="line">      description: &quot;&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; CPU usage is more than 75% for more than 1 minutes.&quot;</span><br><span class="line">- name: db</span><br><span class="line">  rules:</span><br><span class="line">  - alert: Memory usage is more than 75%</span><br><span class="line">    expr: ((node_memory_MemTotal_bytes&#123;job&#x3D;&quot;prometheus&quot;&#125; - node_memory_MemFree_bytes&#123;job&#x3D;&quot;prometheus&quot;&#125; - node_memory_Buffers_bytes&#123;job&#x3D;&quot;prometheus&quot;&#125; - node_memory_Cached_bytes&#123;job&#x3D;&quot;prometheus&quot;&#125;) &#x2F; (node_memory_MemTotal_bytes&#123;job&#x3D;&quot;prometheus&quot;&#125; )) * 100 &gt; 5</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">      service: mysql</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;instance &#123;&#123; $labels.instance &#125;&#125; Memory usage is more than 75%&quot;</span><br><span class="line">      description: &quot;&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; Memory usage is more than 75% for more than 1 minute</span><br></pre></td></tr></table></figure><p>可以看到，我们对CPU告警添加了service: linux标签，也就是这个告警信息应该是发送到QQ邮箱的，内存告警添加了service: mysql标签，应该是发到谷歌邮箱的。</p><p>在expr表达式中，我们调低了报警阈值，使得报警更容易触发。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>重启相应的服务后，我们在prometheus页面可以看到alert状态，并且邮箱也收到了告警邮件</p><p>谷歌邮箱收到了memory告警邮件</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%88%86%E9%85%8D%E5%91%8A%E8%AD%A6%E5%88%B0%E6%8C%87%E5%AE%9A%E6%8E%A5%E6%94%B6%E7%BB%84/a1.png"></p><p>QQ邮箱也受到了cpu的告警邮件</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E5%88%86%E9%85%8D%E5%91%8A%E8%AD%A6%E5%88%B0%E6%8C%87%E5%AE%9A%E6%8E%A5%E6%94%B6%E7%BB%84/a2.png"></p><p>根据这个我们可以控制不同服务的告警发送相应负责人，例如DB相关的告警就发送给DBA、Linux系统报警发送给系统运维人员，等等。</p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus告警系统alertmanager之邮件告警</title>
      <link href="2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/"/>
      <url>2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Alertmanager主要用于接收Prometheus发送的告警信息，它支持丰富的告警通知渠道，并且可以对告警信息进行分组、抑制、静默。</p><h2 id="在prometheus配置中配置alertmanager地址"><a href="#在prometheus配置中配置alertmanager地址" class="headerlink" title="在prometheus配置中配置alertmanager地址"></a>在prometheus配置中配置alertmanager地址</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # 这边配置alertmanager地址喝端口，alertmanager默认端口是9093</span><br><span class="line">      - 127.0.0.1:9093</span><br></pre></td></tr></table></figure><h2 id="编写报警规则"><a href="#编写报警规则" class="headerlink" title="编写报警规则"></a>编写报警规则</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rule_files:</span><br><span class="line">- &quot;rules&#x2F;*.yml&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建rules目录</span><br><span class="line">mkdir rules</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost prometheus-2.8.1.linux-amd64]# cat rules&#x2F;test.yml </span><br><span class="line">groups:</span><br><span class="line">- name: general</span><br><span class="line">  rules:</span><br><span class="line">  - alert: instance down</span><br><span class="line">    # 可以在prometheus页面查看up，0表示instance已经down，也就是prometheus无法获取被监控端数据</span><br><span class="line">    expr: up &#x3D;&#x3D; 0</span><br><span class="line">    # 表示持续时长，也就是 该instance已经 down 了1分钟 ，就发送报警信息给alertmanager</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;instance &#123;&#123; $labels.instance &#125;&#125; down&quot;</span><br><span class="line">      description: &quot;&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 5 minutes.&quot;</span><br></pre></td></tr></table></figure><p>使prometheus配置生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看配置文件是否正确</span><br><span class="line">.&#x2F;promtool  check config prometheus.yml</span><br><span class="line"># 发送hup信号</span><br><span class="line">kill -hup 18745</span><br></pre></td></tr></table></figure><h2 id="下载配置alertmanager"><a href="#下载配置alertmanager" class="headerlink" title="下载配置alertmanager"></a>下载配置alertmanager</h2><p>地址：<a href="https://github.com/prometheus/alertmanager">https://github.com/prometheus/alertmanager</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压</span><br><span class="line">tar zxvf alertmanager-0.20.0-rc.0.linux-amd64.tar.gz</span><br><span class="line">cd alertmanager-0.20.0-rc.0.linux-amd64</span><br></pre></td></tr></table></figure><p>配置报警信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost alertmanager-0.20.0-rc.0.linux-amd64]# cat alertmanager.yml </span><br><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  smtp_smarthost: &#39;smtp.qq.com:465&#39;</span><br><span class="line">  smtp_from: &#39;xxxxxxxxx@qq.com&#39;</span><br><span class="line">  smtp_auth_username: &#39;xxxxxxxxx@qq.com&#39;</span><br><span class="line">  smtp_auth_password: &#39;xxxxxxxxxxxxx&#39;</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line">route:</span><br><span class="line">  group_by: [&#39;alertname&#39;]</span><br><span class="line">  group_wait: 10s</span><br><span class="line">  group_interval: 10s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  receiver: &#39;email&#39;</span><br><span class="line">receivers:</span><br><span class="line">- name: &#39;email&#39;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#39;xxxxxxxx@gmail.com&#39;</span><br><span class="line">    send_resolved: true</span><br><span class="line">inhibit_rules:</span><br><span class="line">  - source_match:</span><br><span class="line">      severity: &#39;critical&#39;</span><br><span class="line">    target_match:</span><br><span class="line">      severity: &#39;warning&#39;</span><br><span class="line">    equal: [&#39;alertname&#39;, &#39;dev&#39;, &#39;instance&#39;]</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;alertmanager --config.file&#x3D;alertmanager.yml</span><br></pre></td></tr></table></figure><h3 id="配置文件介绍"><a href="#配置文件介绍" class="headerlink" title="配置文件介绍"></a>配置文件介绍</h3><p>（1）global</p><p>全局配置，包括报警解决后的超时时间、SMTP相关配置、告警通知API接口等</p><ol><li>smtp_smarthost：smtp服务器，以QQ邮箱为例，就是smtp.qq.com</li><li>smtp_from：邮件发送方</li><li>smtp_auth_username：同上，写一样即可</li><li>smtp_auth_password：对应上面邮箱的授权码，需要去qq邮箱那边开通相应的服务</li><li>smtp_require_tls：是否启用tls</li></ol><p>（2）route</p><p>路由，用来设置告警分发策略</p><p>group_by：根据标签的key进行分组</p><p>group_wait：等待时长，告警发送之前的等待时间</p><p>group_interval：当组内已经发送了一个告警，组内若有新增告警需要等待的时间</p><p>repeat_interval：告警已经发送，且无新增告警，若重复告警需要间隔多久</p><p>receiver：通知对象</p><p>（3）receivers</p><p>接收告警的对象</p><p>（4）inhibit_rules</p><p>抑制相关的配置</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>停掉被监控端上的node_exporter，等待告警</p><p>可以看到prometheus的alert上出现了instance down的提示</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a1.png"></p><p>顺便提一下alert告警状态</p><ul><li>Inactive：什么都没发生</li><li>Pending：已触发告警阈值，但是还没有满足rules.for字段告警持续时间</li><li>Firing：已触发阈值并且满足持续告警时间</li></ul><p>邮箱随之也受到了邮件</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/15/Prometheus%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9Falertmanager%E4%B9%8B%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a2.png"></p><p>重新恢复node_exporter也会收到恢复的告警邮件</p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus标签管理</title>
      <link href="2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/"/>
      <url>2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Prometheus监控体系中，标签 label 是一个非常重要的参数，使用标准的标签有利于我们对整个集群进行控制管理，便于我们在复杂的环境中能够精确查询metrics。</p><h2 id="标签管理"><a href="#标签管理" class="headerlink" title="标签管理"></a>标签管理</h2><h3 id="honor-labels"><a href="#honor-labels" class="headerlink" title="honor_labels"></a>honor_labels</h3><p>在之前，我们使用pushgateway上报监控数据，在shell脚本里面我们发送数据给pushgateway时，其实标签也一并发了出去。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/a1.png"></p><p>在element那里，有2个exported_*开头的labels，其实就是我们定义的labels。</p><p>honor_labels主要用于解决prometheus server的label与exporter端用户自定义label冲突的问题。honor_labels默认是false，当出现冲突，会将冲突的标签以exported重新命名；当honor_labels为true，只保留用户自定义的label。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br></pre></td></tr></table></figure><h3 id="添加新标签"><a href="#添加新标签" class="headerlink" title="添加新标签"></a>添加新标签</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br><span class="line">    labels:</span><br><span class="line">      area: &#39;nj&#39;</span><br></pre></td></tr></table></figure><p>prometheus支持热更新，使用 kill -hup 发送信号给prometheus进程</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 检查怕配置文件</span><br><span class="line">.&#x2F;promtool check config prometheus.yml</span><br><span class="line"># 发送hup信号</span><br><span class="line">kill -hup 13070</span><br></pre></td></tr></table></figure><p>等待一会，刷新prometheus页面，观察增加的标签</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/a2.png"></p><h3 id="relabel-configs"><a href="#relabel-configs" class="headerlink" title="relabel_configs"></a>relabel_configs</h3><p>relabel_configs字段支持更多的标签操作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">relable_configs:</span><br><span class="line">  # 源标签</span><br><span class="line">  [ source_labels: &#39;[&#39; &lt;labelname&gt; [, ...] &#39;]&#39; ]</span><br><span class="line">  </span><br><span class="line">  # 多个源标签时连接的分隔符</span><br><span class="line">  [ separator: &lt;string&gt; | default &#x3D; ; ]</span><br><span class="line">  </span><br><span class="line">  # 重新标记的标签</span><br><span class="line">  [ target_label: &lt;labelname&gt; ]</span><br><span class="line">  </span><br><span class="line">  # 整则表达式匹配源标签的值</span><br><span class="line">  [ regex: &lt;regex&gt; | default &#x3D; (.*) ]</span><br><span class="line">  </span><br><span class="line">  # 用的少,占时略</span><br><span class="line">  [ modulus: &lt;uint64&gt; ]</span><br><span class="line">  </span><br><span class="line">  # 替换正则表达式匹配的分组，分组引用 $1,$2,$3,....</span><br><span class="line">  [ replacement: &lt;string&gt; | default &#x3D; $1 ]</span><br><span class="line">  </span><br><span class="line">  # 基于正则表达式匹配执行的操作</span><br><span class="line">  [ action: &lt;relabel_action&gt; | default &#x3D; replace ]</span><br></pre></td></tr></table></figure><p>action支持的标签动作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">replace：默认，通过regex匹配source_label的值，使用replacement来引用表达式匹配的分组</span><br><span class="line">keep：删除regex与连接不匹配的目标 source_labels</span><br><span class="line">drop：删除regex与连接匹配的目标 source_labels</span><br><span class="line">labeldrop：删除regex匹配的标签</span><br><span class="line">labelkeep：删除regex不匹配的标签</span><br><span class="line">hashmod：设置target_label为modulus连接的哈希值source_labels</span><br><span class="line">labelmap：匹配regex所有标签名称。然后复制匹配标签的值进行分组，replacement分组引用（$&#123;1&#125;,$&#123;2&#125;,…）替代</span><br></pre></td></tr></table></figure><p>（1）我们将刚刚添加的 area: ‘nj’ 替换成 areas: ‘nj’</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br><span class="line">    labels:</span><br><span class="line">      area: &#39;nj&#39;</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: replace</span><br><span class="line">    source_labels: [&#39;area&#39;]</span><br><span class="line">    target_label: areas</span><br><span class="line">    regex: (.*)</span><br><span class="line">    replacement: $1</span><br></pre></td></tr></table></figure><p>更新prometheus配置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 检查怕配置文件</span><br><span class="line">.&#x2F;promtool check config prometheus.yml</span><br><span class="line"># 发送hup信号</span><br><span class="line">kill -hup 13070</span><br></pre></td></tr></table></figure><p>刷新浏览器prometheus页面</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/a3.png"></p><p>（2）我们将 area: ‘nj’ 标签删掉</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br><span class="line">    labels:</span><br><span class="line">      area: &#39;nj&#39;</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: replace</span><br><span class="line">    source_labels: [&#39;area&#39;]</span><br><span class="line">    target_label: areas</span><br><span class="line">    regex: (.*)</span><br><span class="line">    replacement: $1</span><br><span class="line">  - action: labeldrop</span><br><span class="line">    regex: area</span><br></pre></td></tr></table></figure><p>labeldrop会将regex匹配的标签删掉；labelkeep则相反，删除regex不匹配的标签</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/a4.png"></p><p>（3）根据某个标签删除我们不想监控的数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">  honor_labels: true</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br><span class="line">    labels:</span><br><span class="line">      area: &#39;nj&#39;</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: replace</span><br><span class="line">    source_labels: [&#39;area&#39;]</span><br><span class="line">    target_label: areas</span><br><span class="line">    regex: (.*)</span><br><span class="line">    replacement: $1</span><br><span class="line">  - action: labeldrop</span><br><span class="line">    regex: area</span><br><span class="line">  - action: drop</span><br><span class="line">    source_labels: [&#39;areas&#39;]</span><br><span class="line">    regex: (.*)</span><br></pre></td></tr></table></figure><p>drop会删除regex与连接匹配的目标 source_labels，keep则相反。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/a5.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus使用PushGateway上报数据采集</title>
      <link href="2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
      <url>2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="下载PushGateway"><a href="#下载PushGateway" class="headerlink" title="下载PushGateway"></a>下载PushGateway</h2><p>地址：<a href="https://github.com/prometheus/pushgateway">https://github.com/prometheus/pushgateway</a></p><h2 id="启动PushGateway"><a href="#启动PushGateway" class="headerlink" title="启动PushGateway"></a>启动PushGateway</h2><p>PushGateway不需要安装的被监控的机器上，只需要安装在任意机器启动即可</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf pushgateway-1.0.1.linux-amd64.tar.gz</span><br><span class="line">cd pushgateway-1.0.1.linux-amd64</span><br><span class="line">.&#x2F;pushgateway</span><br></pre></td></tr></table></figure><h2 id="使用PushGateway上报采集数据"><a href="#使用PushGateway上报采集数据" class="headerlink" title="使用PushGateway上报采集数据"></a>使用PushGateway上报采集数据</h2><p>首先先在prometheus.yml添加job，然后重新启动prometheus</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;pushgateway&#39;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#39;localhost:9091&#39;,&#39;localhost:9092&#39;]</span><br></pre></td></tr></table></figure><p>编写shell脚本监控机器内网延迟和丢包率</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">hostname&#x3D;$(hostname | awk -F &#39;.&#39; &#39;&#123;print $1&#125;&#39;)</span><br><span class="line">prometheus_url&#x3D;&#39;192.168.1.113&#39;</span><br><span class="line"></span><br><span class="line">if [ $hostname &#x3D;&#x3D; &quot;localhost&quot; ];then</span><br><span class="line">        echo &quot;机器名不能是localhost&quot;</span><br><span class="line">        exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">label1&#x3D;&quot;node_netstat_ping_delay&quot;</span><br><span class="line">node_netstat_ping_delay&#x3D;$(ping -q -A -s 500 -W 1000 -c 100 $prometheus_url | grep &#39;transmitted&#39; | awk  &#39;&#123;print $10&#125;&#39; | sed &#39;s&#x2F;ms&#x2F;&#x2F;&#39;)</span><br><span class="line"></span><br><span class="line">label2&#x3D;&quot;node_netstat_ping_loss&quot;</span><br><span class="line">node_netstat_ping_loss&#x3D;$(ping -q -A -s 500 -W 1000 -c 100 $prometheus_url | grep &#39;transmitted&#39; | awk  &#39;&#123;print $6&#125;&#39; | sed &#39;s&#x2F;%&#x2F;&#x2F;&#39;)</span><br><span class="line"></span><br><span class="line">echo &quot;$label1 $node_netstat_ping_delay&quot; |curl --data-binary @- http:&#x2F;&#x2F;$&#123;prometheus_url&#125;:9091&#x2F;metrics&#x2F;job&#x2F;pushgateway&#x2F;instance&#x2F;$&#123;hostname&#125;</span><br><span class="line"></span><br><span class="line">echo &quot;$label2 $node_netstat_ping_loss&quot; |curl --data-binary @- http:&#x2F;&#x2F;$&#123;prometheus_url&#125;:9091&#x2F;metrics&#x2F;job&#x2F;pushgateway&#x2F;instance&#x2F;$&#123;hostname&#125;</span><br></pre></td></tr></table></figure><p>定义2个metrics监控项名称 node_netstat_ping_delay 和 node_netstat_ping_loss</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">label1&#x3D;&quot;node_netstat_ping_delay&quot;</span><br><span class="line">node_netstat_ping_delay&#x3D;$(ping -q -A -s 500 -W 1000 -c 100 $prometheus_url | grep &#39;transmitted&#39; | awk  &#39;&#123;print $10&#125;&#39; | sed &#39;s&#x2F;ms&#x2F;&#x2F;&#39;)</span><br><span class="line"></span><br><span class="line">label2&#x3D;&quot;node_netstat_ping_loss&quot;</span><br><span class="line">node_netstat_ping_loss&#x3D;$(ping -q -A -s 500 -W 1000 -c 100 $prometheus_url | grep &#39;transmitted&#39; | awk  &#39;&#123;print $6&#125;&#39; | sed &#39;s&#x2F;%&#x2F;&#x2F;&#39;)</span><br></pre></td></tr></table></figure><p>下面将 $label1 $node_netstat_ping_delay 使用curl发送到gateway</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;$label1 $node_netstat_ping_delay&quot; |curl --data-binary @- http:&#x2F;&#x2F;$&#123;prometheus_url&#125;:9091&#x2F;metrics&#x2F;job&#x2F;pushgateway&#x2F;instance&#x2F;$&#123;hostname&#125;</span><br></pre></td></tr></table></figure><p>${prometheus_url}:9091指向的是pushgateway地址，因为我的pushgateway是放在prometheus机器上的。</p><p>metrics是固定的</p><p>/job/pushgateway 指向的是我们prometheus.yml刚刚配置的job，这里job是固定的，然后pushgateway是我配置文件里面的job名称</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/a1.png"></p><p>/instance/${hostname} 指定我们命名的instance，这里我们就以脚本所在的hostname命名instance</p><p>添加crontab定时任务</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/a2.png"></p><p>重新刷新浏览器prometheus页面</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/a3.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E4%BD%BF%E7%94%A8PushGateway%E4%B8%8A%E6%8A%A5%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控磁盘</title>
      <link href="2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E7%A3%81%E7%9B%98/"/>
      <url>2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E7%A3%81%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="监控磁盘使用率"><a href="#监控磁盘使用率" class="headerlink" title="监控磁盘使用率"></a>监控磁盘使用率</h2><p>磁盘使用率=100*(node_filesystem_size_bytes{mountpoint=”/“} - node_filesystem_free_bytes{mountpoint=”/“} )/node_filesystem_size_bytes{mountpoint=”/“}</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E7%A3%81%E7%9B%98/a1.png"></p><h2 id="predict-linear函数"><a href="#predict-linear函数" class="headerlink" title="predict_linear函数"></a>predict_linear函数</h2><p>predict_linear函数可以对曲线变化速率进行计算，然后根据这个变化速度推测未来的变化走向。</p><p>predict_linear( node_filesystem_free_bytes{mountpoint=”/“}[1h],4*3600 )  &lt; 0 </p><p>上面的这个公式表示对过去1小时的曲线进行计算，然后推测未来4小时的趋势，可以通过 &lt;0 来实现提前报警</p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控内存</title>
      <link href="2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E5%86%85%E5%AD%98/"/>
      <url>2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E5%86%85%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>内存是系统重要的指标之一，内存是监控必不可少的指标之一。</p><h2 id="监控内存使用率"><a href="#监控内存使用率" class="headerlink" title="监控内存使用率"></a>监控内存使用率</h2><p>内存使用率=100*(total-free-buffers-cached)/total</p><p>100*(node_memory_MemTotal_bytes-node_memory_MemFree_bytes-node_memory_Cached_bytes-node_memory_Buffers_bytes)/node_memory_MemTotal_bytes</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7%E5%86%85%E5%AD%98/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus监控CPU</title>
      <link href="2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/"/>
      <url>2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>CPU是我们系统最重要的指标之一，它主要提供系统计算功能，所有CPU的状态能够反映了系统的健康状态，CPU是监控必不可少的指标之一。</p><h2 id="CPU概念"><a href="#CPU概念" class="headerlink" title="CPU概念"></a>CPU概念</h2><p>user time：cpu执行用户进程消耗的时间</p><p>system time：cpu在内核运行的时间</p><p>io wait：cpu在等待I/O操作完成的时间</p><p>idle time：系统处于空闲的时间</p><p>nice time：系统调整进程优先级的时间</p><p>lrq time：系统处理赢中断花费的时间</p><p>softlrq time：系统处理软中断花费的时间</p><p>steal time：被强制等待虚拟cpu时间</p><h2 id="监控CPU使用率"><a href="#监控CPU使用率" class="headerlink" title="监控CPU使用率"></a>监控CPU使用率</h2><p>在上面8个CPU时间中，除了idle time反映的是CPU空闲时间，其余7个都包含在CPU使用时间里面，也就是CPU使用率=100*（1-idle time/CPU时间）</p><p>在之前我们已经部署了prometheus和node_exporter了，node_exporter需要部署在被监控端。</p><p>我们先查询 node_cpu_seconds_total ，这个可以统计cpu时间,因为是2核的，所以可以看到labels里面是有cpu=”0”和cpu=”1”标签的，我们这边也是计算总cpu的使用率，当然也可以根据自己具体的需要，计算单个cpu的使用率。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a1.png"></p><p>我们查询出空闲时间 node_cpu_seconds_total{mode=”idle”} </p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a2.png"></p><p>上图，这个value的值反映的是截至目前为止，cpu空闲时间的和，我们必须要统计最近cpu的状态，统计cpu idle time最近1分钟的时间 increase(node_cpu_seconds_total{mode=”idle”}[1m])</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a3.png"></p><p>上图，我们统计了cpu0和cpu1的idle time 最近一分钟的时间</p><p>我们需要计算他们的和，sum(increase(node_cpu_seconds_total{mode=”idle”}[1m]))</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a4.png"></p><p>但是，其实还有一个注意的点，我们来看下面这张图片，这张图片是还没有使用sum计算和的输出，sum函数会把我们这边的输出项都累加计算求和，因为我们现在至少监控一台机器，所以instance都是一样的，也就是都是一台机器，如果监控了很多机器，这边会输出很多机器的cpu最近一分钟的idle time，如果这样，就会导致把所有机器idle time求和了，我们需要使用 by 根据instance来求和</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a5.png"></p><p>sum(increase(node_cpu_seconds_total{mode=”idle”}[1m])) by(instance)</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a6.png"></p><p>下面我们计算所有cpu时间，node_cpu_seconds_total 反映了所有cpu时间</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a7.png"></p><p>我们计算最近1分钟所有cpu time，increase(node_cpu_seconds_total[1m])</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a8.png"></p><p>在根据instance求和，sum(increase(node_cpu_seconds_total[1m])) by(instance)</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a9.png"></p><p>最后我们组合2个公式得到CPU使用率  100*(1-sum(increase(node_cpu_seconds_total{mode=”idle”}[1m])) by(instance) / sum(increase(node_cpu_seconds_total[1m])) by(instance))</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E7%9B%91%E6%8E%A7CPU/a10.png"></p><p>同理其他cpu time也是差不多算法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;iowait&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;irq&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;nice&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;softirq&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;steal&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;system&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;user&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br><span class="line">100*sum(increase(node_cpu_seconds_total&#123;mode&#x3D;&quot;idle&quot;&#125;[1m])) by(instance) &#x2F; sum(increase(node_cpu_seconds_total[1m])) by(instance)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>node_exporter安装和配置</title>
      <link href="2020/12/07/node-exporter%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"/>
      <url>2020/12/07/node-exporter%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>地址：<a href="https://github.com/prometheus/node_exporter/releases">https://github.com/prometheus/node_exporter/releases</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf node_exporter-1.0.0-rc.0.linux-amd64.tar.gz</span><br><span class="line">cd node_exporter-1.0.0-rc.0.linux-amd64</span><br><span class="line">#运行</span><br><span class="line">.&#x2F;node_exporter</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p>通过curl访问采集的数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl 192.168.1.114:9100&#x2F;metrics</span><br></pre></td></tr></table></figure><p>在prometheus.yml配置node_exporter目标地址，使得prometheus搜集到node_exporter采集的数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static_configs:</span><br><span class="line">    - targets: [&#39;localhost:9090&#39;,&#39;192.168.1.114:9100&#39;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus安装部署</title>
      <link href="2020/12/07/Prometheus%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>2020/12/07/Prometheus%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Prometheus基本概念"><a href="#Prometheus基本概念" class="headerlink" title="Prometheus基本概念"></a>Prometheus基本概念</h2><p>Prometheus是使用Go语言开发的一款开源监控报警系统，它存储的是时序数据，简单的说就是按照相同的名称盒标签以时间维度存储连续的数据集合</p><p>时序（time series）以名称（metric）和一组key/value标签定义</p><h2 id="Prometheus架构"><a href="#Prometheus架构" class="headerlink" title="Prometheus架构"></a>Prometheus架构</h2><p>Prometheus通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。输出被监控组件信息的HTTP接口叫做exporter，目前互联网已经有很多exporter可以直接使用，比如node、nginx、mysql等等。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Prometheus%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a1.png"></p><h2 id="安装prometheus"><a href="#安装prometheus" class="headerlink" title="安装prometheus"></a>安装prometheus</h2><p>下载地址：<a href="https://github.com/prometheus/prometheus/releases">https://github.com/prometheus/prometheus/releases</a></p><p>下载 prometheus-2.8.1.linux-amd64.tar.gz 二进制包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#解压</span><br><span class="line">tar zxvf prometheus-2.8.1.linux-amd64.tar.gz</span><br><span class="line">#进入目录</span><br><span class="line">cd prometheus-2.8.1.linux-amd64</span><br><span class="line">#启动</span><br><span class="line">.&#x2F;prometheus --config.file&#x3D;prometheus.yml</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># .&#x2F;prometheus 启动项选择</span><br><span class="line"># 指定配置文件,默认当前prometheus命令同级的yml</span><br><span class="line">--config.file&#x3D;&quot;prometheus.yml&quot;</span><br><span class="line"># 指定监听地址端口</span><br><span class="line">--web.listen-address&#x3D;&quot;0.0.0.0:9090&quot;</span><br><span class="line"># 最大连接数</span><br><span class="line">--web.max-connection&#x3D;512</span><br><span class="line"># tsdb数据存储目录,默认当前data</span><br><span class="line">--storage.tsdb.path&#x3D;&quot;data&#x2F;&quot;</span><br><span class="line"># premetheus存储数据时间，默认15天</span><br><span class="line">--storage.tsdb.retention&#x3D;15d</span><br></pre></td></tr></table></figure><h2 id="prometheus-yml"><a href="#prometheus-yml" class="headerlink" title="prometheus.yml"></a>prometheus.yml</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># my global config</span><br><span class="line">global:</span><br><span class="line">  scrape_interval:     15s # 默认情况下，每15s拉取一次目标采样数据</span><br><span class="line">  evaluation_interval: 15s # 默认情况下，每15s对告警规则做计算，更新告警状态</span><br><span class="line">  # scrape_timeout is set to the global default (10s). # 抓取超时时间</span><br><span class="line"></span><br><span class="line"># 告警配置</span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # - alertmanager:9093</span><br><span class="line"></span><br><span class="line"># Load rules once and periodically evaluate them according to the global &#39;evaluation_interval&#39;.</span><br><span class="line">rule_files:</span><br><span class="line">  # - &quot;first_rules.yml&quot;</span><br><span class="line">  # - &quot;second_rules.yml&quot;</span><br><span class="line"></span><br><span class="line"># A scrape configuration containing exactly one endpoint to scrape:</span><br><span class="line"># Here it&#39;s Prometheus itself.</span><br><span class="line">scrape_configs:</span><br><span class="line">  # job名称会增加到所有采样点上</span><br><span class="line">  - job_name: &#39;prometheus&#39;</span><br><span class="line"></span><br><span class="line">    # metrics_path defaults to &#39;&#x2F;metrics&#39;</span><br><span class="line">    # scheme defaults to &#39;http&#39;.</span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">    # 抓取的目标地址</span><br><span class="line">    - targets: [&#39;localhost:9090&#39;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-Kiali</title>
      <link href="2020/12/07/Istio-Kiali/"/>
      <url>2020/12/07/Istio-Kiali/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kiali为网格管理和可观察性提供了良好的用户体验的可视化工具。</p><h2 id="Kiali访问"><a href="#Kiali访问" class="headerlink" title="Kiali访问"></a>Kiali访问</h2><p>查看Kiali服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n istio-system</span><br><span class="line">kubectl get svc -n istio-system</span><br></pre></td></tr></table></figure><p>修改kiali的svc类型为NodePort,修改type字段为type: NodePort</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kiali -n istio-system</span><br></pre></td></tr></table></figure><p>通过浏览器访问，username和password均为admin</p><p>登录后进入首页，Overview页面展示了所有名称空间下的应用数量、服务流量、配置状态以及监控检查状态</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a1.png"></p><p>点击一个名称空间进入Applications页面，kiali独有的概念</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a2.png"></p><p>下面就是Workloads页面，它展示了各个名称空间下的pods的状态</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a3.png"></p><p>Services对应的就是Kubernetes中的svc</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a4.png"></p><p>最后Istio Config页面展示了服务网格下的各个类型的资源配置信息</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a5.png"></p><h2 id="给bookinfo注入流量"><a href="#给bookinfo注入流量" class="headerlink" title="给bookinfo注入流量"></a>给bookinfo注入流量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while true; do curl http:&#x2F;&#x2F;192.168.1.110:31514&#x2F;productpage; done</span><br></pre></td></tr></table></figure><p>可以在Graph清晰的看到网格中流量的走向</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a6.png"></p><h2 id="kiali组件分析"><a href="#kiali组件分析" class="headerlink" title="kiali组件分析"></a>kiali组件分析</h2><p>kiali pod内有个kiali容器，该容器在启动的时候会运行kiali进程，进程会加载/kiali-configuration/config.yaml 配置文件，config.yaml 配置文件是通过ConfigMap挂载的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">istio_component_namespaces:</span><br><span class="line">  grafana: istio-system</span><br><span class="line">  tracing: istio-system</span><br><span class="line">  pilot: istio-system</span><br><span class="line">  prometheus: istio-system</span><br><span class="line">istio_namespace: istio-system</span><br><span class="line">auth:</span><br><span class="line">  strategy: login</span><br><span class="line">deployment:</span><br><span class="line">  accessible_namespaces: [&#39;**&#39;]</span><br><span class="line">server:</span><br><span class="line">  port: 20001</span><br><span class="line">  web_root: &#x2F;kiali</span><br><span class="line">external_services:</span><br><span class="line">  istio:</span><br><span class="line">    url_service_version: http:&#x2F;&#x2F;istio-pilot.istio-system:8080&#x2F;version</span><br><span class="line">  tracing:</span><br><span class="line">    url: </span><br><span class="line">    in_cluster_url: http:&#x2F;&#x2F;tracing&#x2F;jaeger</span><br><span class="line">  grafana:</span><br><span class="line">    url: </span><br><span class="line">    in_cluster_url: http:&#x2F;&#x2F;grafana:3000</span><br><span class="line">  prometheus:</span><br><span class="line">    url: http:&#x2F;&#x2F;prometheus.istio-system:9090</span><br></pre></td></tr></table></figure><blockquote><p>定义一些资源的名称空间</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a7.png"></p><blockquote><p>定义istio本身的名称空间</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a8.png"></p><blockquote><p>鉴权方式，通过login登录的方式</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a9.png"></p><blockquote><p>kialia pod 可以访问的名称空间，这边表示不受限制</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a10.png"></p><blockquote><p>定义端口和访问路径</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a11.png"></p><blockquote><p>定义一些资源的真实访问路径</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="/2020/12/07/Istio-Kiali/a12.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-Egress发起HTTPS请求</title>
      <link href="2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/"/>
      <url>2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="创建sleep客户端"><a href="#创建sleep客户端" class="headerlink" title="创建sleep客户端"></a>创建sleep客户端</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">  labels:</span><br><span class="line">    app: sleep</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      name: http</span><br><span class="line">  selector:</span><br><span class="line">    app: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: sleep</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: sleep</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: sleep</span><br><span class="line">      containers:</span><br><span class="line">        - name: sleep</span><br><span class="line">          image: pstauffer&#x2F;curl</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          command:</span><br><span class="line">            - &quot;&#x2F;bin&#x2F;sleep&quot;</span><br><span class="line">            - &quot;3650d&quot;</span><br></pre></td></tr></table></figure><h2 id="创建ServiceEntry"><a href="#创建ServiceEntry" class="headerlink" title="创建ServiceEntry"></a>创建ServiceEntry</h2><p>创建一个ServiceEntry，允许流量直接访问外部服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: cnn</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - edition.cnn.com</span><br><span class="line">  ports:</span><br><span class="line">    - number: 443</span><br><span class="line">      name: tls</span><br><span class="line">      protocol: TLS</span><br><span class="line">  resolution: DNS</span><br></pre></td></tr></table></figure><p>我们通过在sleep客户端发送请求验证下ServiceEntry是否正确应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-t42hv -- sh</span><br><span class="line">curl -sL -o &#x2F;dev&#x2F;null -D - https:&#x2F;&#x2F;edition.cnn.com&#x2F;politics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/a1.png"></p><p>我们可以看下访问egress pod的日志，发现是没有这个访问日志的输出的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl log -f istio-egressgateway-7c9f7d5bd6-hcf2x -n istio-system</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/a2.png"></p><h2 id="配置egress-Gateway和destination-rule"><a href="#配置egress-Gateway和destination-rule" class="headerlink" title="配置egress Gateway和destination rule"></a>配置egress Gateway和destination rule</h2><p>我们为edition.cnn.com端口443创建一个egress gateway ，并且为egress gateway指向一个destination rule</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: Gateway</span><br><span class="line">metadata:</span><br><span class="line">  name: istio-egressgateway</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    istio: egressgateway</span><br><span class="line">  servers:</span><br><span class="line">    - port:</span><br><span class="line">        number: 443</span><br><span class="line">        name: tls</span><br><span class="line">        protocol: TLS</span><br><span class="line">      hosts:</span><br><span class="line">        - edition.cnn.com</span><br><span class="line">      tls:</span><br><span class="line">        mode: PASSTHROUGH</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: egressgateway-for-cnn</span><br><span class="line">spec:</span><br><span class="line">  host: istio-egressgateway.istio-system.svc.cluster.local</span><br><span class="line">  subsets:</span><br><span class="line">    - name: cnn</span><br></pre></td></tr></table></figure><h2 id="配置VirtualService"><a href="#配置VirtualService" class="headerlink" title="配置VirtualService"></a>配置VirtualService</h2><p>将流量从sidercar引导到egress gateway，在从egress gateway引导到外部</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: direct-cnn-through-egress-gateway</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - edition.cnn.com</span><br><span class="line">  gateways:</span><br><span class="line">    - mesh # 内置 Gateway，代表网格中的所有 Sidecar</span><br><span class="line">    - istio-egressgateway</span><br><span class="line">  tls:</span><br><span class="line">    - match: # 这一条规格匹配的是 “mesh” Gateway的流量</span><br><span class="line">        - gateways:</span><br><span class="line">            - mesh</span><br><span class="line">          port: 443</span><br><span class="line">          sni_hosts:</span><br><span class="line">            - edition.cnn.com</span><br><span class="line">      route: # 如果是 “mesh” Gateway 的流量，则转发到egress网关服务</span><br><span class="line">        - destination:</span><br><span class="line">            host: istio-egressgateway.istio-system.svc.cluster.local</span><br><span class="line">            subset: cnn</span><br><span class="line">            port:</span><br><span class="line">              number: 443</span><br><span class="line">    - match:</span><br><span class="line">        - gateways:</span><br><span class="line">            - istio-egressgateway</span><br><span class="line">          port: 443</span><br><span class="line">          sni_hosts:</span><br><span class="line">            - edition.cnn.com</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: edition.cnn.com</span><br><span class="line">            port:</span><br><span class="line">              number: 443</span><br><span class="line">          weight: 100</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过sleep客户端访问 <a href="https://edition.cnn.com/politics">https://edition.cnn.com/politics</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-t42hv -- sh</span><br><span class="line">curl -sL -o &#x2F;dev&#x2F;null -D - https:&#x2F;&#x2F;edition.cnn.com&#x2F;politics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/a3.png"></p><p>可以看到egress pod的日志中有访问输出</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl log -f istio-egressgateway-7c9f7d5bd6-hcf2x -n istio-system</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTPS%E8%AF%B7%E6%B1%82/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-Egress发起HTTP请求</title>
      <link href="2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/"/>
      <url>2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="创建sleep客户端"><a href="#创建sleep客户端" class="headerlink" title="创建sleep客户端"></a>创建sleep客户端</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">  labels:</span><br><span class="line">    app: sleep</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      name: http</span><br><span class="line">  selector:</span><br><span class="line">    app: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: sleep</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: sleep</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: sleep</span><br><span class="line">      containers:</span><br><span class="line">        - name: sleep</span><br><span class="line">          image: pstauffer&#x2F;curl</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          command:</span><br><span class="line">            - &quot;&#x2F;bin&#x2F;sleep&quot;</span><br><span class="line">            - &quot;3650d&quot;</span><br></pre></td></tr></table></figure><h2 id="创建ServiceEntry"><a href="#创建ServiceEntry" class="headerlink" title="创建ServiceEntry"></a>创建ServiceEntry</h2><p>创建一个ServiceEntry，允许流量直接访问外部服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: cnn</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - edition.cnn.com</span><br><span class="line">  ports:</span><br><span class="line">    - number: 80</span><br><span class="line">      name: http</span><br><span class="line">      protocol: HTTP</span><br><span class="line">  resolution: DNS</span><br></pre></td></tr></table></figure><p>我们通过在sleep客户端发送请求验证下ServiceEntry是否正确应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-t42hv -- sh</span><br><span class="line">curl -sL -o &#x2F;dev&#x2F;null -D - http:&#x2F;&#x2F;edition.cnn.com&#x2F;politics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/a1.png"></p><p>我们可以看下访问egress pod的日志，发现是没有这个访问日志的输出的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl log -f istio-egressgateway-7c9f7d5bd6-hcf2x -n istio-system</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/a2.png"></p><h2 id="配置egress-Gateway和destination-rule"><a href="#配置egress-Gateway和destination-rule" class="headerlink" title="配置egress Gateway和destination rule"></a>配置egress Gateway和destination rule</h2><p>我们为edition.cnn.com端口80创建一个egress gateway ，并且为egress gateway指向一个destination rule</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: Gateway</span><br><span class="line">metadata:</span><br><span class="line">  name: istio-egressgateway</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    istio: egressgateway</span><br><span class="line">  servers:</span><br><span class="line">    - port:</span><br><span class="line">        number: 80</span><br><span class="line">        name: http</span><br><span class="line">        protocol: HTTP</span><br><span class="line">      hosts:</span><br><span class="line">        - edition.cnn.com</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: egressgateway-for-cnn</span><br><span class="line">spec:</span><br><span class="line">  host: istio-egressgateway.istio-system.svc.cluster.local</span><br><span class="line">  subsets:</span><br><span class="line">    - name: cnn</span><br></pre></td></tr></table></figure><h2 id="配置VirtualService"><a href="#配置VirtualService" class="headerlink" title="配置VirtualService"></a>配置VirtualService</h2><p>将流量从sidercar引导到egress gateway，在从egress gateway引导到外部</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: direct-cnn-through-egress-gateway</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - edition.cnn.com</span><br><span class="line">  gateways:</span><br><span class="line">    - istio-egressgateway</span><br><span class="line">    - mesh # 内置 Gateway，代表网格中的所有 Sidecar</span><br><span class="line">  http:</span><br><span class="line">    - match: # 这一条规格匹配的是 “mesh” Gateway的流量</span><br><span class="line">        - gateways:</span><br><span class="line">            - mesh</span><br><span class="line">          port: 80</span><br><span class="line">      route: # 如果是 “mesh” Gateway 的流量，则转发到egress网关服务</span><br><span class="line">        - destination:</span><br><span class="line">            host: istio-egressgateway.istio-system.svc.cluster.local</span><br><span class="line">            subset: cnn</span><br><span class="line">    - match:</span><br><span class="line">        - gateways:</span><br><span class="line">            - istio-egressgateway</span><br><span class="line">          port: 80</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: edition.cnn.com</span><br><span class="line">            port:</span><br><span class="line">              number: 80</span><br><span class="line">          weight: 100</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过sleep客户端访问 <a href="http://edition.cnn.com/politics">http://edition.cnn.com/politics</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-t42hv -- sh</span><br><span class="line">curl -sL -o &#x2F;dev&#x2F;null -D - http:&#x2F;&#x2F;edition.cnn.com&#x2F;politics</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/a3.png"></p><p>可以看到egress pod的日志中有访问输出</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl log -f istio-egressgateway-7c9f7d5bd6-hcf2x -n istio-system</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/25/Istio-Egress%E5%8F%91%E8%B5%B7HTTP%E8%AF%B7%E6%B1%82/a4.png"></p><blockquote><p>会有人疑问，我直接通过ServiceEntry也可以直接访问外部服务，为什么还要如此麻烦将出站流量都经过egress gateway呢？其实，我个人觉得有以下原因：第一，并不是所有节点都可以访问外网的，如果pod所在的节点无法访问外网，直接通过ServerEntry是无法访问外网的，那么egress gateway可以统一管理出站流量，所有出站流量都经由egress gateway发送；第二，通过egress gateway管理出站流量，可以配置一些网络策略，例如Kubernetes网络策略可以禁止所有不是从 egress gateway 发起的出站流量。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-ServiceEntry</title>
      <link href="2020/11/19/Istio-ServiceEntry/"/>
      <url>2020/11/19/Istio-ServiceEntry/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>添加服务条目（ServiceEntry）后，Envoy代理可以将流量发送到该服务，简单的理解，就是将外部的服务加入到网格一样，从而实现针对外部服务，也可以利用一些Istio流量策略。</p><h2 id="ServiceEntry样例"><a href="#ServiceEntry样例" class="headerlink" title="ServiceEntry样例"></a>ServiceEntry样例</h2><p>部署sleep资源</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">  labels:</span><br><span class="line">    app: sleep</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      name: http</span><br><span class="line">  selector:</span><br><span class="line">    app: sleep</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: sleep</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: sleep</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: sleep</span><br><span class="line">      containers:</span><br><span class="line">        - name: sleep</span><br><span class="line">          image: pstauffer&#x2F;curl</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          command:</span><br><span class="line">            - &quot;&#x2F;bin&#x2F;sleep&quot;</span><br><span class="line">            - &quot;3650d&quot;</span><br></pre></td></tr></table></figure><p>配置ServiceEntry</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  ports:</span><br><span class="line">    - number: 80</span><br><span class="line">      name: http</span><br><span class="line">      protocol: HTTP</span><br><span class="line">  resolution: DNS</span><br><span class="line">  location: MESH_EXTERNAL</span><br></pre></td></tr></table></figure><p>进入sleep容器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-8lxvb -c sleep -- sh</span><br><span class="line">curl http:&#x2F;&#x2F;httpbin.org&#x2F;headers</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/19/Istio-ServiceEntry/a1.png"></p><p>有人会说这不就是访问外网嘛，确实是这样子，我们刚刚的YAML中配置了DNS解析，下面我们在修改下YAML看看</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  ports:</span><br><span class="line">    - number: 80</span><br><span class="line">      name: http</span><br><span class="line">      protocol: HTTP</span><br><span class="line">  resolution: STATIC</span><br><span class="line">  location: MESH_EXTERNAL</span><br><span class="line">  endpoints:</span><br><span class="line">    - address: 192.168.1.116</span><br></pre></td></tr></table></figure><p>我们这回设置了静态域名解析，endpoints随意指向了一个内网ip，当我们内部访问 httpbin.org 的时候，Envoy就会把流量路由到我们指定的 192.168.1.116 地址去</p><blockquote><p>ServiceEntry不仅仅是访问外网这么简单，他更像是通过ServiceEntry服务条目，让我们的服务访问外部服务时，就好像外部服务是网格中一样，从而让我们可以管理这部分流量。</p></blockquote><p>为了验证我们这个样例，我们需要一个这样子的场景：当我们访问 <a href="http://httpbin.org/delay/5">http://httpbin.org/delay/5</a> ，本身这个地址会有5秒的延迟，我们在VirtualService中定义一个timeout字段，设定超时时长为3秒，看看是否能够正常管理ServiceEntry服务条目的流量</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  ports:</span><br><span class="line">    - number: 80</span><br><span class="line">      name: http</span><br><span class="line">      protocol: HTTP</span><br><span class="line">  resolution: DNS</span><br><span class="line">  location: MESH_EXTERNAL</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: httpbin.org</span><br><span class="line">            port:</span><br><span class="line">              number: 80</span><br><span class="line">          weight: 100</span><br><span class="line">      timeout: 3s</span><br></pre></td></tr></table></figure><p>进入sleep容器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-8lxvb -c sleep -- sh</span><br><span class="line">curl http:&#x2F;&#x2F;httpbin.org&#x2F;delay&#x2F;5</span><br></pre></td></tr></table></figure><p>可以看出来大概3秒的时候会返回给我们超时的信息</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/19/Istio-ServiceEntry/a2.png"></p><h2 id="配置外部HTTPS服务"><a href="#配置外部HTTPS服务" class="headerlink" title="配置外部HTTPS服务"></a>配置外部HTTPS服务</h2><p>对于HTTPS的外部服务，除了ServiceEntry，还需要VirtualService，VirtualService中必须定义tls匹配规则和sniHosts</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: ServiceEntry</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  ports:</span><br><span class="line">    - number: 443</span><br><span class="line">      name: https</span><br><span class="line">      protocol: HTTPS</span><br><span class="line">  resolution: DNS</span><br><span class="line">  location: MESH_EXTERNAL</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-ext</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - httpbin.org</span><br><span class="line">  tls:</span><br><span class="line">    - match:</span><br><span class="line">        - port: 443</span><br><span class="line">          sniHosts:</span><br><span class="line">            - httpbin.org</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: httpbin.org</span><br><span class="line">            port:</span><br><span class="line">              number: 443</span><br><span class="line">          weight: 100</span><br></pre></td></tr></table></figure><p>进入sleep容器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it sleep-f67b89b64-8lxvb -c sleep -- sh</span><br><span class="line">curl https:&#x2F;&#x2F;httpbin.org&#x2F;headers</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-ingressgateway配置HTTPS</title>
      <link href="2020/11/19/Istio-ingressgateway%E9%85%8D%E7%BD%AEHTTPS/"/>
      <url>2020/11/19/Istio-ingressgateway%E9%85%8D%E7%BD%AEHTTPS/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>通过配置443端口的ingress网关以处理HTTPS流量</p><h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;etc&#x2F;istio&#x2F;ingressgateway-certs</span><br><span class="line">cd &#x2F;etc&#x2F;istio&#x2F;ingressgateway-certs</span><br><span class="line">openssl genrsa -out &quot;ca.key&quot; 2048</span><br><span class="line"># Common Name 填写域名</span><br><span class="line">openssl req -new -key &quot;ca.key&quot; -out &quot;ca.csr&quot;</span><br><span class="line">openssl x509 -req -days 365 -in &quot;ca.csr&quot; -signkey &quot;&#x2F;ca.key&quot; -out &quot;ca.crt&quot;</span><br></pre></td></tr></table></figure><h2 id="生成secret"><a href="#生成secret" class="headerlink" title="生成secret"></a>生成secret</h2><blockquote><p>该 secret <strong>必须</strong>在 <code>istio-system</code> 命名空间下，且名为 <code>istio-ingressgateway-certs</code></p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -n istio-system secret tls istio-ingressgateway-certs --key ca.key --cert ca.crt</span><br></pre></td></tr></table></figure><h2 id="生成Deployment资源"><a href="#生成Deployment资源" class="headerlink" title="生成Deployment资源"></a>生成Deployment资源</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">  labels:</span><br><span class="line">    app: httpbin</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 8000</span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: httpbin</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: httpbin</span><br><span class="line">      version: v1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: httpbin</span><br><span class="line">        version: v1</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: httpbin</span><br><span class="line">      containers:</span><br><span class="line">      - image: docker.io&#x2F;kennethreitz&#x2F;httpbin</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: httpbin</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure><h2 id="配置Gateway"><a href="#配置Gateway" class="headerlink" title="配置Gateway"></a>配置Gateway</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: Gateway</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-gateway</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    istio: ingressgateway # use Istio default gateway implementation</span><br><span class="line">  servers:</span><br><span class="line">  - port:</span><br><span class="line">      number: 443</span><br><span class="line">      name: https</span><br><span class="line">      protocol: HTTPS</span><br><span class="line">    tls:</span><br><span class="line">      mode: SIMPLE</span><br><span class="line">      serverCertificate: &#x2F;etc&#x2F;istio&#x2F;ingressgateway-certs&#x2F;tls.crt</span><br><span class="line">      privateKey: &#x2F;etc&#x2F;istio&#x2F;ingressgateway-certs&#x2F;tls.key</span><br><span class="line">    hosts:</span><br><span class="line">    - &quot;httpbin.twf.com&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - &quot;httpbin.twf.com&quot;</span><br><span class="line">  gateways:</span><br><span class="line">  - httpbin-gateway</span><br><span class="line">  http:</span><br><span class="line">  - match:</span><br><span class="line">    - uri:</span><br><span class="line">        prefix: &#x2F;headers</span><br><span class="line">    - uri:</span><br><span class="line">        prefix: &#x2F;status</span><br><span class="line">    - uri:</span><br><span class="line">        prefix: &#x2F;delay</span><br><span class="line">    route:</span><br><span class="line">    - destination:</span><br><span class="line">        port:</span><br><span class="line">        number: 8000</span><br><span class="line">        host: httpbin</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过 kubectl get svc -n istio-system 查看443端口对应的NodePort端口</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v -HHost:httpbin.twf.com --resolve httpbin.twf.com:30276:192.168.1.110 --cacert ca.crt https:&#x2F;&#x2F;httpbin.twf.com:30276&#x2F;status&#x2F;418</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/19/Istio-ingressgateway%E9%85%8D%E7%BD%AEHTTPS/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-ingressgateway</title>
      <link href="2020/11/19/Istio-ingressgateway/"/>
      <url>2020/11/19/Istio-ingressgateway/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kubernetes Ingress资源在具有简单的HTTP流量的各种场景下相对易于使用，但是在复杂的场景中存在其缺点，主要是因为其围绕路由规则的功能非常有限。使用Istio进行入口时，最明显的优势是获得了与Istio提供的路由流量相同级别的配置选项。通过自定义资源以及TLS终止、监视、跟踪和其他一些功能，可以轻松地重写各种匹配规则、重定向路由等。</p><p>在Kubernetes Ingress中，入口控制器负责监视入口资源并配置入口代理。在Istio中，控制器（istiod）是控制层面的东西，它监视上述Kubernetes定制资源，并相应地配置istio入口代理。当然，处理所有传入流量的istio入口代理就是Envoy，它在单独的部署中运行。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>我们先部署一个httpbin服务，包括ServiceAccount、Service、Deployment资源</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">  labels:</span><br><span class="line">    app: httpbin</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 8000</span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: httpbin</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: httpbin</span><br><span class="line">      version: v1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: httpbin</span><br><span class="line">        version: v1</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: httpbin</span><br><span class="line">      containers:</span><br><span class="line">      - image: docker.io&#x2F;kennethreitz&#x2F;httpbin</span><br><span class="line">           imagePullPolicy: IfNotPresent</span><br><span class="line">        name: httpbin</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure><p>应用Gateway和VirtualService资源</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: Gateway</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin-gateway</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    istio: ingressgateway # use Istio default gateway implementation</span><br><span class="line">  servers:</span><br><span class="line">  - port:</span><br><span class="line">      number: 80</span><br><span class="line">      name: http</span><br><span class="line">      protocol: HTTP</span><br><span class="line">    hosts:</span><br><span class="line">    - &quot;*&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: httpbin</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - &quot;*&quot;</span><br><span class="line">  gateways:</span><br><span class="line">  - httpbin-gateway</span><br><span class="line">  http:</span><br><span class="line">  - match:</span><br><span class="line">    - uri:</span><br><span class="line">        prefix: &#x2F;headers</span><br><span class="line">    route:</span><br><span class="line">    - destination:</span><br><span class="line">        port:</span><br><span class="line">          number: 8000</span><br><span class="line">        host: httpbin</span><br></pre></td></tr></table></figure><p>首先gateway监听80端口，将匹配规则下的流量都路由到目标地址</p><blockquote><p>获取NodePort端口</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get svc -n istio-system</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/19/Istio-ingressgateway/a1.png"></p><p>通过任意node地址加上端口访问，例如我的是<a href="http://192.168.1.110:31514/headers">http://192.168.1.110:31514/headers</a></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/19/Istio-ingressgateway/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio流量镜像</title>
      <link href="2020/11/12/Istio%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/"/>
      <url>2020/11/12/Istio%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Istio的流量镜像也叫影子流量，是将生产的流量镜像拷贝到测试集群或者其他版本中去，简单地说也就是引导实时流量到另一个微服务的版本中去。</p><h2 id="将流量路由到reviews-v1版本"><a href="#将流量路由到reviews-v1版本" class="headerlink" title="将流量路由到reviews:v1版本"></a>将流量路由到reviews:v1版本</h2><p>我们先应用之前的virtual-service-all-v1.yaml，将流量路由到微服务的v1版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - productpage</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: productpage</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - details</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: details</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ratings</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - reviews</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>我们刷新下/productage页面，发现流量确实都路由到reviews:v1版本了,看下reviews:v1日志</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/12/Istio%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/a1.png"></p><p>reviews:v1日志中确实有访问日志，一会我们将流量镜像到reviews:v2版本，目前reviews:v2是没有访问日志的</p><h2 id="将流量镜像到reviews-v2版本"><a href="#将流量镜像到reviews-v2版本" class="headerlink" title="将流量镜像到reviews:v2版本"></a>将流量镜像到reviews:v2版本</h2><blockquote><p>应用virtualservice规则</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - reviews</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v1</span><br><span class="line">      mirror:</span><br><span class="line">        host: reviews</span><br><span class="line">        subset: v2</span><br></pre></td></tr></table></figure><p>刷新/productage页面，查看reviews的v1和v2版本的日志</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/12/Istio%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/a2.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/12/Istio%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/a3.png"></p><p>我们发现2个版本的微服务版本日志中都有访问日志的输出，v1访问的流量确实被镜像到了v2版本中去</p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio断路器</title>
      <link href="2020/11/08/Istio%E6%96%AD%E8%B7%AF%E5%99%A8/"/>
      <url>2020/11/08/Istio%E6%96%AD%E8%B7%AF%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Istio提供熔断的功能来使你的微服务具有应对故障、潜在峰值和其他网络因素影响的能力。比如熔断器可以允许你限制服务并发连接的次数、调用失败的次数，一旦达到限制的次数，流量就会被Envoy拦截。</p><h2 id="部署Deployment资源"><a href="#部署Deployment资源" class="headerlink" title="部署Deployment资源"></a>部署Deployment资源</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br></pre></td></tr></table></figure><h2 id="定义DestinationRule"><a href="#定义DestinationRule" class="headerlink" title="定义DestinationRule"></a>定义DestinationRule</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-dr</span><br><span class="line">spec:</span><br><span class="line">  host: nginx</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    connectionPool:</span><br><span class="line">      http:</span><br><span class="line">        http1MaxPendingRequests: 1</span><br><span class="line">        maxRequestsPerConnection: 1</span><br><span class="line">      tcp:</span><br><span class="line">        maxConnections: 1</span><br><span class="line">    outlierDetection:</span><br><span class="line">      consecutiveErrors: 1</span><br><span class="line">      intercal: 10s</span><br><span class="line">      baseEjectionTime: 10s</span><br><span class="line">      masEjectionPercent: 100</span><br></pre></td></tr></table></figure><h2 id="使用fortio测试"><a href="#使用fortio测试" class="headerlink" title="使用fortio测试"></a>使用fortio测试</h2><h3 id="安装fortio"><a href="#安装fortio" class="headerlink" title="安装fortio"></a>安装fortio</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -L https:&#x2F;&#x2F;github.com&#x2F;fortio&#x2F;fortio&#x2F;releases&#x2F;download&#x2F;v1.3.1&#x2F;fortio-1.3.1-1.x86_64.rpm -o fortio-1.3.1-1.x86_64.rpm</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -ivh fortio-1.3.1-1.x86_64.rpm</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -c表示并发数 -n表示总请求数 -qps表示每秒查询数，0表示不限制 地址是svc的CLUSTER-IP</span><br><span class="line">fortio load -c 3 -n 30 -qps 0 http:&#x2F;&#x2F;10.1.248.193</span><br></pre></td></tr></table></figure><p>可以从下图看出只有33%的请求成功了</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/08/Istio%E6%96%AD%E8%B7%AF%E5%99%A8/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio设置请求超时</title>
      <link href="2020/11/08/Istio%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B6%85%E6%97%B6/"/>
      <url>2020/11/08/Istio%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B6%85%E6%97%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>istio允许用户通过路由规则来设置请求超时，默认情况下，超时是禁用的。</p><p>下面我们将reviews的服务超时设置为1秒，然后我们对ratings服务引入2秒的故障延迟。</p><blockquote><p>应用virtualservice规则</p></blockquote><p>由于v1版本的reviews不调用ratings，因为后面需要引入ratings的故障注入，所以我们将请求路由到v2版本的reviews</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - productpage</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: productpage</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - details</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: details</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - reviews</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v2</span><br></pre></td></tr></table></figure><p>然后我们给ratings注入2秒的延迟</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - ratings</span><br><span class="line">  http:</span><br><span class="line">    - fault:</span><br><span class="line">        delay:</span><br><span class="line">          percent: 100</span><br><span class="line">          fixedDelay: 2s</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>然后我们请求/produage页面，大概能看到有2秒的延迟</p><p>现在再给reviews服务增加0.5秒的请求超时</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - reviews</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v2</span><br><span class="line">      timeout: 0.5s</span><br></pre></td></tr></table></figure><p>刷新/productage页面，可以发现大概半秒钟就有错误了</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/08/Istio%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B6%85%E6%97%B6/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio流量转移</title>
      <link href="2020/11/08/Istio%E6%B5%81%E9%87%8F%E8%BD%AC%E7%A7%BB/"/>
      <url>2020/11/08/Istio%E6%B5%81%E9%87%8F%E8%BD%AC%E7%A7%BB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="基于权重的路由"><a href="#基于权重的路由" class="headerlink" title="基于权重的路由"></a>基于权重的路由</h2><p>首先应用所有流量到各个微服务的v1版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - productpage</span><br><span class="line">  http:</span><br><span class="line">  - route:</span><br><span class="line">    - destination:</span><br><span class="line">        host: productpage</span><br><span class="line">        subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - reviews</span><br><span class="line">  http:</span><br><span class="line">  - route:</span><br><span class="line">    - destination:</span><br><span class="line">        host: reviews</span><br><span class="line">        subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ratings</span><br><span class="line">  http:</span><br><span class="line">  - route:</span><br><span class="line">    - destination:</span><br><span class="line">        host: ratings</span><br><span class="line">        subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - details</span><br><span class="line">  http:</span><br><span class="line">  - route:</span><br><span class="line">    - destination:</span><br><span class="line">        host: details</span><br><span class="line">        subset: v1</span><br></pre></td></tr></table></figure><p>然后把50%的流量从reviews:v1转移到reviews:v3</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - reviews</span><br><span class="line">  http:</span><br><span class="line">  - route:</span><br><span class="line">    - destination:</span><br><span class="line">        host: reviews</span><br><span class="line">        subset: v1</span><br><span class="line">      weight: 50</span><br><span class="line">    - destination:</span><br><span class="line">        host: reviews</span><br><span class="line">        subset: v3</span><br><span class="line">      weight: 50</span><br></pre></td></tr></table></figure><p>刷新浏览器中的 <code>/productpage</code> 页面，大约有 50% 的几率会看到页面中出带 <em>红色</em> 星级的评价内容。</p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio故障注入</title>
      <link href="2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/"/>
      <url>2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="注入HTTP延迟故障"><a href="#注入HTTP延迟故障" class="headerlink" title="注入HTTP延迟故障"></a>注入HTTP延迟故障</h2><p>我们对ratings服务注入7s的延迟，当jason用户访问时，有7s的延迟故障</p><blockquote><p>定义VirtualService</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - ratings</span><br><span class="line">  http:</span><br><span class="line">    - match:</span><br><span class="line">        - headers:</span><br><span class="line">            end-user:</span><br><span class="line">              exact: jason</span><br><span class="line">      fault:</span><br><span class="line">        delay:</span><br><span class="line">          fixedDelay: 7s</span><br><span class="line">          percentage:</span><br><span class="line">            value: 100</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>我们登录jason用户，刷新页面发现，请求完成大概时6s多</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/a1.png"></p><p>根据官方文档所说，reviews和ratings服务间的超时时长是10s，但是productage和reviews之间只有3s的超时时长，再加上1次重试，一共6s，也就是说整个完整的请求，一旦超过6s就会返回超时错误，从上图也可以看出，页面确实返回了超时，而且图片右半部分可以看出整个请求是6s完成的。</p><blockquote><p>注：有的时候发现不是所有的请求都在6s完成，有的时候是能够很快返回的，具体原因是因为我们是对ratings注入7s的故障的，在bookinfo部署那篇文章，一开始我们有提到，reviews只有v2、v3版本是调用ratings的，如果请求经过v1版本的reviews，那么他不会调用ratings，也就不会有这个故障。</p></blockquote><h2 id="注入HTTP-abort故障"><a href="#注入HTTP-abort故障" class="headerlink" title="注入HTTP abort故障"></a>注入HTTP abort故障</h2><p>为用户jason创建一个故障中止规则</p><blockquote><p>定义VirtualService</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - ratings</span><br><span class="line">  http:</span><br><span class="line">    - match:</span><br><span class="line">        - headers:</span><br><span class="line">            end-user:</span><br><span class="line">              exact: jason</span><br><span class="line">      fault:</span><br><span class="line">        abort:</span><br><span class="line">          httpStatus: 500</span><br><span class="line">          percentage:</span><br><span class="line">            value: 100</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>我们登录jason用户，刷新页面，ratings显示 <em>Ratings service is currently unavailable</em></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/a2.png"></p><p>我们查看v2和v3版本reviews的log，v1版本不调用ratings，所有不存在abort故障问题</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl log reviews-v2-685867965b-njhzz -c reviews</span><br><span class="line">kubectl log reviews-v3-5d6778fd88-t76fz -c reviews</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/a3.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio%E6%95%85%E9%9A%9C%E6%B3%A8%E5%85%A5/a4.png"></p><p>可以看出返回的日志全是500状态，说明故障注入成功了。</p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-配置请求路由</title>
      <link href="2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/"/>
      <url>2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前言已经部署好了微服务bookinfo，下面开始配置请求路由。</p><h2 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h2><p>首先一共4个微服务，分别是productpage（version=v1）、ratings（version=v1）、reviews（version=v1 v2 v3）、details（version=v1），我们需要先应用一个默认的目标规则。</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/a1.png"></p><blockquote><p>定义DestinationRule</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  host: productpage</span><br><span class="line">  subsets:</span><br><span class="line">    - name: v1</span><br><span class="line">      labels:</span><br><span class="line">        version: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  host: details</span><br><span class="line">  subsets:</span><br><span class="line">    - name: v1</span><br><span class="line">      labels:</span><br><span class="line">        version: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  host: reviews</span><br><span class="line">  subsets:</span><br><span class="line">    - name: v1</span><br><span class="line">      labels:</span><br><span class="line">        version: v1</span><br><span class="line">    - name: v2</span><br><span class="line">      labels:</span><br><span class="line">        version: v2</span><br><span class="line">    - name: v3</span><br><span class="line">      labels:</span><br><span class="line">        version: v3</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  host: ratings</span><br><span class="line">  subsets:</span><br><span class="line">    - name: v1</span><br><span class="line">      labels:</span><br><span class="line">        version: v1</span><br></pre></td></tr></table></figure><p>我们在应用一个流量策略，控制所有的流量走v1版本的reviews</p><blockquote><p>定义VirtualService</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - details</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: details</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - ratings</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: ratings</span><br><span class="line">            subset: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - reviews</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>浏览器访问<a href="http://192.168.1.110:31514/productpage%EF%BC%8C%E5%A4%9A%E6%AC%A1%E5%88%B7%E6%96%B0%E9%A1%B5%E9%9D%A2%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%8F%91%E7%8E%B0%EF%BC%8Creviews%E9%83%BD%E6%98%AF%E6%98%BE%E7%A4%BA%E7%9A%84v1%E7%89%88%E6%9C%AC">http://192.168.1.110:31514/productpage，多次刷新页面，可以发现，reviews都是显示的v1版本</a></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/a2.png"></p><h2 id="基于用户身份的路由"><a href="#基于用户身份的路由" class="headerlink" title="基于用户身份的路由"></a>基于用户身份的路由</h2><p>productpage服务请求reviews服务时，会在请求中自定义一个end-user，可以模拟下面这个场景的实验</p><p>我们模拟一个场景，当jason用户访问，将所有流量路由到v2版本的reviews，其他路由到v1版本的reviews</p><blockquote><p>定义VirtualService</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - reviews</span><br><span class="line">  http:</span><br><span class="line">    - match:</span><br><span class="line">        - headers:</span><br><span class="line">            end-user:</span><br><span class="line">              exact: jason</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v2</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: reviews</span><br><span class="line">            subset: v1</span><br></pre></td></tr></table></figure><p>我们验证一下，当不登陆的时候，始终请求的是v1版本的reviews</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/a3.png"></p><p>点击右上角Sign in，username填jason，password可以不填，右上角显示jason后，一直刷新页面，发现一直请求的确实是v2版本的reviews</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/11/03/Istio-%E9%85%8D%E7%BD%AE%E8%AF%B7%E6%B1%82%E8%B7%AF%E7%94%B1/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-VirtualService</title>
      <link href="2020/11/03/Istio-VirtualService/"/>
      <url>2020/11/03/Istio-VirtualService/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>虚拟服务（Virtual Service）以及目标规则（Destination Rule）是istio流量路由最核心的部分，虚拟服务规定了流量路由到istio服务中，每个虚拟服务都是由一组路由规则组成的。</p><h2 id="示例1"><a href="#示例1" class="headerlink" title="示例1"></a>示例1</h2><p>定义一个客户端，用来发送请求</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: client</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: client</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: client</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: busybox</span><br><span class="line">          image: busybox</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          command:</span><br><span class="line">            - &#x2F;bin&#x2F;sh</span><br><span class="line">            - -c</span><br><span class="line">            - sleep 3600</span><br></pre></td></tr></table></figure><p>为了方便一会看出效果，我们弄2个服务，一个httpd、一个nginx</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: test-httpd</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: app-httpd</span><br><span class="line">      name: web</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: app-httpd</span><br><span class="line">        name: web</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: httpd</span><br><span class="line">          image: httpd</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: test-nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: app-nginx</span><br><span class="line">      name: web</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: app-nginx</span><br><span class="line">        name: web</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br></pre></td></tr></table></figure><p>创建service关联pod</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: test-web</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    name: web</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br></pre></td></tr></table></figure><p>我们先看下效果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#进入client容器</span><br><span class="line">kubectl exec -it client-59785d99f9-zd5hb -- &#x2F;bin&#x2F;sh</span><br><span class="line">#访问test-web svc，可以发现基本是轮询访问到后端的nginx和httpd服务的</span><br><span class="line">wget -q -O - http:&#x2F;&#x2F;test-web:80</span><br></pre></td></tr></table></figure><p>然后我们在弄个DestinationRule，这边host指向的是test-web的svc，subsets包含svc下pods的集合，通过labels确定pods</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: web-rule</span><br><span class="line">spec:</span><br><span class="line">  host: test-web</span><br><span class="line">  subsets:</span><br><span class="line">    - name: nginx</span><br><span class="line">      labels:</span><br><span class="line">        app: app-nginx</span><br><span class="line">    - name: httpd</span><br><span class="line">      labels:</span><br><span class="line">        app: app-httpd</span><br></pre></td></tr></table></figure><p>定义一个VirtualService，指定流量策略</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: web-vs</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - test-web</span><br><span class="line">  http:</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: test-web</span><br><span class="line">            subset: nginx</span><br><span class="line">          weight: 20</span><br><span class="line">        - destination:</span><br><span class="line">            host: test-web</span><br><span class="line">            subset: httpd</span><br><span class="line">          weight: 80</span><br></pre></td></tr></table></figure><p>此处hosts字段指向一个kubernetes svc，是一个短名称，会被替换成test-web.default.svc.cluster.local</p><p>这里subset就是指向DestinationRule的subsets定义的name，也就是80%的流量分配给httpd服务，20%流量分配给nginx服务</p><p>可以进入client容器看下效果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#进入client容器</span><br><span class="line">kubectl exec -it client-59785d99f9-zd5hb -- &#x2F;bin&#x2F;sh</span><br><span class="line">#访问test-web svc，基本可以发现是1：4的比例分配流量的</span><br><span class="line">wget -q -O - http:&#x2F;&#x2F;test-web:80</span><br></pre></td></tr></table></figure><h2 id="示例2"><a href="#示例2" class="headerlink" title="示例2"></a>示例2</h2><p>前面基本不改动，我们修改下virtualservice资源文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: VirtualService</span><br><span class="line">metadata:</span><br><span class="line">  name: vs-demo1</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">    - test-web</span><br><span class="line">  http:</span><br><span class="line">    - match:</span><br><span class="line">        - headers:</span><br><span class="line">            end-user:</span><br><span class="line">              exact: jack</span><br><span class="line">      route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: test-web</span><br><span class="line">            subset: nginx</span><br><span class="line">    - route:</span><br><span class="line">        - destination:</span><br><span class="line">            host: test-web</span><br><span class="line">            subset: httpd</span><br></pre></td></tr></table></figure><p>virtualservice还支持根据匹配条件来将流量路由到具体服务的相关配置</p><p>这个示例演示了基于身份验证的路由匹配，当我们请求的headers中携带end-user=jack，将流量路由到nginx，否则就路由到httpd</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#进入client容器</span><br><span class="line">kubectl exec -it client-59785d99f9-zd5hb -- &#x2F;bin&#x2F;sh</span><br><span class="line">#访问test-web svc</span><br><span class="line">wget -q -O - http:&#x2F;&#x2F;test-web:80</span><br><span class="line">wget -q -O - http:&#x2F;&#x2F;test-web:80 --header &#39;end-user:jack&#39;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-DestinationRule</title>
      <link href="2020/10/28/Istio-DestinationRule/"/>
      <url>2020/10/28/Istio-DestinationRule/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在此之前，我们以及成功部署了Istio官方的bookinfo微服务。在做请求路由的示例之前，我们先来看一个名词-DestinationRule。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>DestinationRule是Istio流量路由功能的关键部分，DestinationRule规定了流量如何路由到目标地址，你可以这么理解它，比如你现在在家，一会需要出发去公司，你使用百度导航查看从家如何去公司，结果百度导航搜索出来三条线路，也就是说从家到公司可以有3种路线，其实DestinationRule也一样，他就是定义了流量到达目标地址的路线，这么比喻是不是觉得可以理解DestinationRule了。</p><h2 id="示例1"><a href="#示例1" class="headerlink" title="示例1"></a>示例1</h2><p>我们先拿出一个DestionationRule的资源文件看一下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  host: reviews</span><br><span class="line">  subsets:</span><br><span class="line">    - name: v1</span><br><span class="line">      labels:</span><br><span class="line">        version: v1</span><br><span class="line">    - name: v2</span><br><span class="line">      labels:</span><br><span class="line">        version: v2</span><br><span class="line">    - name: v3</span><br><span class="line">      labels:</span><br><span class="line">        version: v3</span><br></pre></td></tr></table></figure><ul><li>host字段</li></ul><p>使用Kubernetes service的短名称，上面reviews，将会被reviews.default.svc.cluster.local代替，如果你需要使用其他名称空间下的svc，你可以 <service name>.<namespace>.svc.cluster.local 配置，当然service一定要存在名称空间下，否则将被忽略</namespace></service></p><ul><li>subsets字段</li></ul><p>subsets是服务端的集合，每个子集都必须是在host对应服务的基础上的，说的简单点也就是subsets子集是kubernetes的svc关联的pods，subsets的labels可以关联到svc下pods的labels</p><h2 id="示例2"><a href="#示例2" class="headerlink" title="示例2"></a>示例2</h2><p>DestinationRule还允许你调整特定服务子集的Envoy流量策略。</p><p>再来看一个示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.istio.io&#x2F;v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: my-destination-rule</span><br><span class="line">spec:</span><br><span class="line">  host: my-svc</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    loadBalancer:</span><br><span class="line">      simple: ROUND_ROBIN</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">    trafficPolicy:</span><br><span class="line">      loadBalancer:</span><br><span class="line">        simple: LEAST_CONN</span><br><span class="line">  - name: v3</span><br><span class="line">    labels:</span><br><span class="line">      version: v3</span><br></pre></td></tr></table></figure><ul><li>trafficPolicy</li></ul><p>流量策略，主要包含负载均衡、连接池策略、异常检查等</p><blockquote><p>为子集指定的策略只有在路由规则明确向该子集发送流量后才会生效。</p></blockquote><p>具体可以查阅相关文档 <a href="https://www.bookstack.cn/read/istio-1.4-zh/46098cf8d0d7f17d.md">https://www.bookstack.cn/read/istio-1.4-zh/46098cf8d0d7f17d.md</a></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio-bookinfo部署</title>
      <link href="2020/10/28/Istio-bookinfo%E9%83%A8%E7%BD%B2/"/>
      <url>2020/10/28/Istio-bookinfo%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Istio官方提供了一个非常好的实战项目，来使开发者能够更加快速上手Istio，以及通过示例来了解Istio的特性。</p><h2 id="bookinfo介绍"><a href="#bookinfo介绍" class="headerlink" title="bookinfo介绍"></a>bookinfo介绍</h2><p>这是Istio官方提供的一个bookinfo微服务项目，bookinfo使用了python、java、ruby、node四种语言开发了四个微服务，充分证明Istio可以在不受限于语言的环境下工作。</p><p>bookinfo微服务分为四个单独的微服务：</p><ul><li><p>productpage：这个微服务主要调用details和reviews微服务，用来生成页面</p></li><li><p>details：包含书籍信息</p></li><li><p>reviews：书籍相关评论，调用ratings微服务</p></li><li><p>ratings：书籍评级信息</p></li></ul><p>reviews微服务有3个版本：</p><p>v1版本不会调用ratings服务，也就是页面不会显示星级评分</p><p>v2版本调用ratings服务，使用黑色星级图标评分</p><p>v3版本调用ratings服务，使用红色星级图标评分</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/28/Istio-bookinfo%E9%83%A8%E7%BD%B2/a1.png"></p><h2 id="实行注入"><a href="#实行注入" class="headerlink" title="实行注入"></a>实行注入</h2><p>我们这边来使用默认名称空间default来部署我们的bookinfo微服务，所以我们需要对default名称空间下的资源实行istio注入，我们就使用自动注入把，当然你也可以手工的注入这些资源。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl label namespace default istio-injection&#x3D;enabled</span><br></pre></td></tr></table></figure><h2 id="部署bookinfo"><a href="#部署bookinfo" class="headerlink" title="部署bookinfo"></a>部署bookinfo</h2><p>在istio的安装目录下samples/bookinfo/platform/kube/bookinfo.yaml，我们需要使用kubectl部署应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f bookinfo.yaml</span><br></pre></td></tr></table></figure><p>等待一会，等pod和svc起来</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods</span><br><span class="line">kubectl get svc</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/28/Istio-bookinfo%E9%83%A8%E7%BD%B2/a2.png"></p><p>查看bookinfo微服务是否正在运行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -it $(kubectl get pod -l app&#x3D;ratings -o jsonpath&#x3D;&#39;&#123;.items[0].metadata.name&#125;&#39;) -c ratings -- curl productpage:9080&#x2F;productpage | grep -o &quot;&lt;title&gt;.*&lt;&#x2F;title&gt;&quot;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/28/Istio-bookinfo%E9%83%A8%E7%BD%B2/a3.png"></p><h2 id="部署ingress网关"><a href="#部署ingress网关" class="headerlink" title="部署ingress网关"></a>部署ingress网关</h2><p>在istio的安装目录下samples/bookinfo/networking/bookinfo-gateway.yaml，我们需要使用kubectl部署应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f samples&#x2F;bookinfo&#x2F;networking&#x2F;bookinfo-gateway.yaml</span><br></pre></td></tr></table></figure><p>确定NodePort端口</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export INGRESS_PORT&#x3D;$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath&#x3D;&#39;&#123;.spec.ports[?(@.name&#x3D;&#x3D;&quot;http2&quot;)].nodePort&#125;&#39;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#查看端口</span><br><span class="line">env | grep &#39;INGRESS_PORT&#39;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>通过k8s的一个node ip + INGRESS_PORT访问，例如<a href="http://192.168.1.110:31514/productpage">http://192.168.1.110:31514/productpage</a></p><p>可以发现现在页面是正常轮询显示 review1、 review2、 review3的</p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux挂载windows共享文件夹</title>
      <link href="2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/"/>
      <url>2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="创建windows共享文件夹"><a href="#创建windows共享文件夹" class="headerlink" title="创建windows共享文件夹"></a>创建windows共享文件夹</h2><p>首先先在一个磁盘创建一个文件夹，我们这里就命名win-volumes，然后鼠标右击win-volumes，选择属性，在共享里面点击共享</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/a1.png"></p><p>然后添加相应的用户，设置不同的权限，这边我们就用Administrator，最后点击共享</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/a2.png"></p><p>我们需要记住这个网络路径</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/a3.png"></p><h2 id="挂载共享目录"><a href="#挂载共享目录" class="headerlink" title="挂载共享目录"></a>挂载共享目录</h2><p>在linux上安装CIFS</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install cifs-utils</span><br></pre></td></tr></table></figure><p>在根目录创建一个app目录作为挂载点</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;app</span><br></pre></td></tr></table></figure><p>挂载刚刚创建的共享目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -t cifs -o username&#x3D;Administrator,password&#x3D;&quot;abc123&quot; &#x2F;&#x2F;QAIN2DZP76PK1NC&#x2F;win-volumes &#x2F;app</span><br></pre></td></tr></table></figure><p>查看挂载情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -hT</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Linux%E6%8C%82%E8%BD%BDwindows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rancher集成Harbor</title>
      <link href="2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/"/>
      <url>2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>选择 Default项目<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/a1.png"><br>选择 资源-密文<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/a2.png"><br>选择 镜像库凭证列表，然后点击 添加凭证<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/a3.png"><br>取个名称，然后选择 自定义，修改harbor地址，填写用户名和密码<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E9%9B%86%E6%88%90Harbor/a4.png"><br>自此，rancher 跟 harbor 镜像仓库就关联成功了。</p>]]></content>
      
      
      <categories>
          
          <category> Rancher </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Rancher </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rancher导入Kubernetes集群</title>
      <link href="2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>如果你已经安装好了Kubernetes集群，并且安装了Rancher，那么我们就将k8s集群导入到rancher里来</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>点击右上角 添加集群<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a1.png"><br>点击 导入<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a2.png"><br>起个名称 ，然后点击 创建<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a3.png"><br>这边我们先看最后一行，箭头标记的那个，其实他就是使用curl下载rancher相关的资源文件，然后将他交给 kubectl 去执行<br>复制最后一行到k8s-master主机上执行，等待资源pod起来<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a4.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n cattle-system</span><br></pre></td></tr></table></figure><p>最后可以看到rancher界面显示集群已经添加成功<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a5.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AF%BC%E5%85%A5Kubernetes%E9%9B%86%E7%BE%A4/a6.png"></p>]]></content>
      
      
      <categories>
          
          <category> Rancher </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Rancher </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rancher安装</title>
      <link href="2020/10/25/Rancher%E5%AE%89%E8%A3%85/"/>
      <url>2020/10/25/Rancher%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><blockquote><p>请保证已经安装好docker</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull rancher/rancher:v2.3.3</span><br></pre></td></tr></table></figure><h2 id="启动rancher"><a href="#启动rancher" class="headerlink" title="启动rancher"></a>启动rancher</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#rancher目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/rancher</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --restart=unless-stopped \</span><br><span class="line">--name=rancher \</span><br><span class="line">-p 80:80 -p 443:443 \</span><br><span class="line">-v /usr/<span class="built_in">local</span>/rancher:/usr/<span class="built_in">local</span>/rancher \</span><br><span class="line">rancher/rancher:v2.3.3</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>设置admin的密码<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AE%89%E8%A3%85/a1.png"><br>进去之后右下角还可以设置语言<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Rancher%E5%AE%89%E8%A3%85/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Rancher </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Rancher </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Filebeat收集tomcat日志</title>
      <link href="2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/"/>
      <url>2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>首先tomcat对我们有用的日志文件主要是catalina和localhost_access_log,下面主要介绍如何收集这2种日志</p><h2 id="tomcat使用log4j日志输出"><a href="#tomcat使用log4j日志输出" class="headerlink" title="tomcat使用log4j日志输出"></a>tomcat使用log4j日志输出</h2><p>先去这个地址下载对应tomcat版本的相关jar包：<a href="http://archive.apache.org/dist/tomcat/">http://archive.apache.org/dist/tomcat/</a></p><p>就是我下面图片红框标注的2个jar</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/a1.png"></p><p>我们进入tomcat的lib目录下，将tomcat-juli-adapters.jar放入到里面</p><p>然后在lib目录下执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;logging&#x2F;log4j&#x2F;1.2.17&#x2F;log4j-1.2.17.jar</span><br></pre></td></tr></table></figure><p>接着进入tomcat的bin目录,先将原本里面的tomcat-juli.jar重命名备份，然后再将我们刚刚下载的tomcat-juli.jar放入到里面</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mv tomcat-juli.jar tomcat-juli.jar.bak</span><br><span class="line">#将刚刚下载的tomcat-juli.jar放进bin目录</span><br></pre></td></tr></table></figure><p>进入tomcat的conf目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mv logging.properties  logging.properties.bak</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在&lt;Context&gt;标签中添加 swallowOutput 属性 ，即 &lt;Context swallowOutput&#x3D;&quot;true&quot;&gt;</span><br><span class="line">vim context.xml</span><br></pre></td></tr></table></figure><p>进入tomcat的lib目录</p><blockquote><p>vim log4j.properties</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log4j.rootLogger &#x3D; INFO, CATALINA</span><br><span class="line"></span><br><span class="line"># Define all the appenders</span><br><span class="line">log4j.appender.CATALINA&#x3D;org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.CATALINA.File&#x3D;$&#123;catalina.base&#125;&#x2F;logs&#x2F;catalina</span><br><span class="line">log4j.appender.CATALINA.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.CATALINA.layout.ConversionPattern&#x3D;&#123;&quot;time&quot;:&quot;%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125;&quot;,&quot;logtype&quot;:&quot;%p&quot;,&quot;loginfo&quot;:&quot;%c:%m&quot;&#125;%n</span><br><span class="line">log4j.appender.CATALINA.MaxFileSize&#x3D;2MB</span><br><span class="line">log4j.appender.CATALINA.MaxBackupIndex&#x3D;10</span><br><span class="line"></span><br><span class="line">log4j.appender.LOCALHOST &#x3D; org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.LOCALHOST.File &#x3D; $&#123;catalina.base&#125;&#x2F;logs&#x2F;localhost</span><br><span class="line">log4j.appender.LOCALHOST.Append &#x3D; true</span><br><span class="line">log4j.appender.LOCALHOST.Encoding &#x3D; UTF-8</span><br><span class="line">log4j.appender.LOCALHOST.DatePattern &#x3D; &#39;.&#39;yyyy-MM-dd&#39;.log&#39;</span><br><span class="line">log4j.appender.LOCALHOST.layout &#x3D; org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.LOCALHOST.layout.ConversionPattern &#x3D; %d [%t] %-5p %c- %m%n</span><br><span class="line"></span><br><span class="line">log4j.appender.MANAGER &#x3D; org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.MANAGER.File &#x3D; $&#123;catalina.base&#125;&#x2F;logs&#x2F;manager</span><br><span class="line">log4j.appender.MANAGER.Append &#x3D; true</span><br><span class="line">log4j.appender.MANAGER.Encoding &#x3D; UTF-8</span><br><span class="line">log4j.appender.MANAGER.DatePattern &#x3D; &#39;.&#39;yyyy-MM-dd&#39;.log&#39;</span><br><span class="line">log4j.appender.MANAGER.layout &#x3D; org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.MANAGER.layout.ConversionPattern &#x3D; %d [%t] %-5p %c- %m%n</span><br><span class="line"></span><br><span class="line">log4j.appender.HOST-MANAGER &#x3D; org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.HOST-MANAGER.File &#x3D; $&#123;catalina.base&#125;&#x2F;logs&#x2F;host-manager</span><br><span class="line">log4j.appender.HOST-MANAGER.Append &#x3D; true</span><br><span class="line">log4j.appender.HOST-MANAGER.Encoding &#x3D; UTF-8</span><br><span class="line">log4j.appender.HOST-MANAGER.DatePattern &#x3D; &#39;.&#39;yyyy-MM-dd&#39;.log&#39;</span><br><span class="line">log4j.appender.HOST-MANAGER.layout &#x3D; org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.HOST-MANAGER.layout.ConversionPattern &#x3D; %d [%t] %-5p %c- %m%n</span><br><span class="line"></span><br><span class="line">log4j.appender.CONSOLE &#x3D; org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.CONSOLE.Encoding &#x3D; UTF-8</span><br><span class="line">log4j.appender.CONSOLE.layout &#x3D; org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.CONSOLE.layout.ConversionPattern &#x3D; %d [%t] %-5p %c- %m%n</span><br><span class="line"></span><br><span class="line"># Configure which loggers log to which appenders</span><br><span class="line">log4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost] &#x3D; INFO, LOCALHOST</span><br><span class="line">log4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[&#x2F;manager] &#x3D;\</span><br><span class="line">  INFO, MANAGER</span><br><span class="line">log4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[&#x2F;host-manager] &#x3D;\</span><br><span class="line">  INFO, HOST-MANAGER</span><br></pre></td></tr></table></figure><p>到此为止，我们已经成功使用log4j来输出tomcat日志了，并且是json格式的，方便filebeat收集</p><p>下面我们来将localhost_access_log来转成json格式的日志输出</p><p>通过vim打开conf/server.xml文件，拉到文件最后面</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#修改此处内容</span><br><span class="line">&lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot;</span><br><span class="line">               prefix&#x3D;&quot;localhost_access_log&quot; suffix&#x3D;&quot;.log&quot;</span><br><span class="line">               pattern&#x3D;&quot;&#123;&quot;client&quot;:&quot;%h&quot;,  &quot;client user&quot;:&quot;%l&quot;,   &quot;authenticated&quot;:&quot;%u&quot;,   &quot;access time&quot;:&quot;%t&quot;,     &quot;method&quot;:&quot;%r&quot;,   &quot;status&quot;:&quot;%s&quot;,  &quot;send bytes&quot;:&quot;%b&quot;,  &quot;Query?string&quot;:&quot;%q&quot;,  &quot;partner&quot;:&quot;%&#123;Referer&#125;i&quot;,  &quot;Agent version&quot;:&quot;%&#123;User-Agent&#125;i&quot;&#125;&quot; &#x2F;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>启动tomcat，可以发现我们成功的将catalina和localhost_access_log以json格式输出日志了</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/a2.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/a3.png"></p><h2 id="filebeat收集日志"><a href="#filebeat收集日志" class="headerlink" title="filebeat收集日志"></a>filebeat收集日志</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- input_type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;usr&#x2F;local&#x2F;apache-tomcat-9.0.36&#x2F;logs&#x2F;localhost_access_log*.log</span><br><span class="line">  fields:</span><br><span class="line">    source: localhost_access_log</span><br><span class="line">- input_type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;usr&#x2F;local&#x2F;apache-tomcat-9.0.36&#x2F;logs&#x2F;catalina</span><br><span class="line">  fields:</span><br><span class="line">    source: catalina</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line">  # Array of hosts to connect to.</span><br><span class="line">  hosts: [&quot;192.168.203.133:9200&quot;]</span><br><span class="line">  indices:</span><br><span class="line">    - index: &quot;localhost_access_log-%&#123;+yyyy.MM.dd&#125;&quot;</span><br><span class="line">      when.contains:</span><br><span class="line">        source: &quot;localhost_access_log&quot;</span><br><span class="line">    - index: &quot;catalina-%&#123;+yyyy.MM.dd&#125;&quot;</span><br><span class="line">      when.contains:</span><br><span class="line">        source: &quot;catalina&quot;</span><br></pre></td></tr></table></figure><p>启动filebeat</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;filebeat -e -c filebeat.yml</span><br></pre></td></tr></table></figure><p>配置好index后，可以在discover看到收集的日志</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/a4.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86tomcat%E6%97%A5%E5%BF%97/a5.png"></p>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Filebeat收集Nginx日志</title>
      <link href="2020/10/25/Filebeat%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/"/>
      <url>2020/10/25/Filebeat%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="配置nginx日志输出格式"><a href="#配置nginx日志输出格式" class="headerlink" title="配置nginx日志输出格式"></a>配置nginx日志输出格式</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log_format access_json_log  &#39;&#123;&quot;@timestamp&quot;:&quot;$time_local&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;http_host&quot;:&quot;$http_host&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;clinetip&quot;:&quot;$remote_addr&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;request&quot;:&quot;$request&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;status&quot;:&quot;$status&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;size&quot;:&quot;$body_bytes_sent&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;upstream_addr&quot;:&quot;$upstream_addr&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;upstream_status&quot;:&quot;$upstream_status&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;upstream_response_time&quot;:&quot;$upstream_response_time&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;request_time&quot;:&quot;$request_time&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;http_referer&quot;:&quot;$http_referer&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&#39;</span><br><span class="line">                                  &#39;&quot;http_x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;&#125;&#39;;</span><br><span class="line"></span><br><span class="line">    access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log  access_json_log;</span><br></pre></td></tr></table></figure><h2 id="配置filebeat"><a href="#配置filebeat" class="headerlink" title="配置filebeat"></a>配置filebeat</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- input_type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  # Paths that should be crawled and fetched. Glob based paths.</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log</span><br><span class="line">  fields:</span><br><span class="line">    source: nginx</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line">  # Array of hosts to connect to.</span><br><span class="line">  hosts: [&quot;192.168.203.133:9200&quot;]</span><br><span class="line">  indices:</span><br><span class="line">    - index: &quot;nginx-%&#123;+yyyy.MM.dd&#125;&quot;</span><br><span class="line">      when.contains:</span><br><span class="line">        source: &quot;nginx&quot;</span><br></pre></td></tr></table></figure><h2 id="启动filebeat加载配置文件"><a href="#启动filebeat加载配置文件" class="headerlink" title="启动filebeat加载配置文件"></a>启动filebeat加载配置文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;filebeat -e -c filebeat.yml</span><br></pre></td></tr></table></figure><h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><p>kibana配置index</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/a1.png"></p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/a2.png"></p><p>discover里面可以查看到采集的日志了</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/10/25/Filebeat%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/a3.png"></p>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐一款写Kubernetes的YAML的利器</title>
      <link href="2020/10/12/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%86%99Kubernetes%E7%9A%84YAML%E7%9A%84%E5%88%A9%E5%99%A8/"/>
      <url>2020/10/12/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%86%99Kubernetes%E7%9A%84YAML%E7%9A%84%E5%88%A9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Kubernetes运维工作中，需要经常编写各种YAML资源文件，如果一个一个手敲，效率不但低下，而且容易出错，下面推荐一款工具+插件给大家，可以非常快速、有效的编写资源文件。<br>我这边使用的是JetBrains的WebStorm2020.1.1版本编写Kubernetes资源文件的，当然你也可以使用他的其他产品PyCharm、IDEA等等</p><h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p><a href="https://www.jetbrains.com/webstorm/download/">https://www.jetbrains.com/webstorm/download/</a></p><h2 id="安装Kubernetes插件"><a href="#安装Kubernetes插件" class="headerlink" title="安装Kubernetes插件"></a>安装Kubernetes插件</h2><p>点击WebStorm左上角 File - Setting<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/12/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%86%99Kubernetes%E7%9A%84YAML%E7%9A%84%E5%88%A9%E5%99%A8/a1.png"></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>使用起来也非常简单，创建项目后，我们新建一个yaml文件，然后就可以开始编写资源文件了<br>我们只需要输入字母就可以看到提示啦，直接回车就是补全<br><img src= "/img/loading.gif" data-lazy-src="/2020/10/12/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E5%86%99Kubernetes%E7%9A%84YAML%E7%9A%84%E5%88%A9%E5%99%A8/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio注入</title>
      <link href="2020/09/29/Istio%E6%B3%A8%E5%85%A5/"/>
      <url>2020/09/29/Istio%E6%B3%A8%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>简单的说，Istio注入其实就是将一些额外的容器、配置添加到我们的Pod模板中。注入的方式有两种，一种是手工注入，还有一个自动注入。下面这张图我们明显可以看出来相对于注入前的Pod，注入后的Pod多了2个容器,其实还有写入了一些iptables规则。<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a1.png"></p><h2 id="手工注入"><a href="#手工注入" class="headerlink" title="手工注入"></a>手工注入</h2><p>我们先创建一个namespace</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create ns injection</span><br></pre></td></tr></table></figure><p>我们编写一个pod的yaml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-injection</span><br><span class="line">  namespace: injection</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:1.14-alpine</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">            </span><br><span class="line">kubectl apply -f nginx-demo.yaml</span><br></pre></td></tr></table></figure><p>执行注入，注入本身并不是在原来的pod资源上注入的，而是先生成一个新的注入过的deployment，然后再杀死原来的deployment</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">istioctl kube-inject -f nginx-demo.yaml | kubectl apply -f -</span><br></pre></td></tr></table></figure><p>可以从下面图片看出，注入的deployment pod已经再生成了<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a2.png"><br>我们对比之前的pod，注入后的pod现在是2个容器，在之前我们说会多2个容器，其实有一个容器定义在initC里面，也就是他在执行写初始化操作后就会死亡，所以总共就是2个容器<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a3.png"><br>我们导出注入后的pod的yaml看一下发生了哪些变化</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n injection -o yaml &gt; <span class="built_in">test</span>-injection.yaml</span><br></pre></td></tr></table></figure><p>首先我们看到的是第一个我们定义的nginx容器<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a4.png"><br>第二个容器istio-proxy<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a5.png"><br>第三个就是我们说的初始化后就死亡的容器istio-init<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a6.png"><br>下面，我们来看看istio-init初始化到底做了什么</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">log</span> <span class="built_in">test</span>-injection-568487774c-jwgxk -c istio-init -n injection</span><br></pre></td></tr></table></figure><p>一开始，istio-init设置了定义了一些环境和变量<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a7.png"><br>然后主要就是写入一些iptables策略<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a8.png"><br>我们进入istio-proxy容器看看</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it <span class="built_in">test</span>-injection-568487774c-jwgxk -c istio-proxy -n injection -- /bin/sh</span><br></pre></td></tr></table></figure><p>可以看到容器里面有2个进程，pilot-agent和envoy，还开放了一些端口<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a9.png"><br>pilot-agent其实是polot-discovery的代理，它负责生成envoy启动配置、启动envoy、监控并管理envoy的运行情况。<br>从下面这张图我们看下下注入的原理<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/29/Istio%E6%B3%A8%E5%85%A5/a10.png"><br>首先API Server接收到客户端传来关于istio流控的资源文件请求，然后将集群状态写入到Etcd中去，API Server会解析istio流控资源文件，生成一些istio流控的规则，Istiod Pod中的discovery容器有个Pilot-discovery进程会一直监听API Server，一旦有新的规则写入，它会将规则解析成envoy的配置，然后下发给pilot-agent，pilot-agent会重新应用envoy配置文件，envoy会根据配置文件做一些流量的限制</p><h2 id="自动注入"><a href="#自动注入" class="headerlink" title="自动注入"></a>自动注入</h2><p>自动注入其实就是给namespace打上一个标签istio-injection=enabled</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl label ns injection istio-injection=enabled</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio升级</title>
      <link href="2020/09/28/Istio%E5%8D%87%E7%BA%A7/"/>
      <url>2020/09/28/Istio%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前言已经安装好了istio-1.4.5,我们下面将升级成istio-1.5.0,升级前有以下注意事项：<br>（1）版本之间不能跨度太大<br>（2）本次升级是基于istioctl，请确保当前istio是通过istioctl安装的<br>（3）确保升级前后的profile是一致的</p><h2 id="下载istio-1-5-0"><a href="#下载istio-1-5-0" class="headerlink" title="下载istio-1.5.0"></a>下载istio-1.5.0</h2><p>Istio官网：<a href="https://istio.io/latest/zh/">https://istio.io/latest/zh/</a><br>可能由于网络原因，无法在官网下载，我这边准备了istio-1.5.0</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">链接：https://pan.baidu.com/s/1ksgp8kRgtmnFTLpldoKAGw </span><br><span class="line">提取码：7tka</span><br></pre></td></tr></table></figure><h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf istio-1.5.0-linux.tar.gz</span><br><span class="line">mv istio-1.5.0 ../</span><br></pre></td></tr></table></figure><h3 id="修改环境变量"><a href="#修改环境变量" class="headerlink" title="修改环境变量"></a>修改环境变量</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /etc/profile</span></span><br><span class="line">ISTIO_HOME=/usr/<span class="built_in">local</span>/istio-1.5.0</span><br><span class="line">MAVEN_HOME=/usr/<span class="built_in">local</span>/maven</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin:<span class="variable">$&#123;ISTIO_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH MAVEN_HOME ISTIO_HOME</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=`<span class="built_in">echo</span> <span class="variable">$PATH</span> | sed <span class="string">&#x27;s#:/usr/local/istio-1.4.5/bin##g&#x27;</span>`</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#查看版本，可以看到客户端版本已经变换了，但是kubernetes集群里面的版本号还没改变</span></span><br><span class="line">istioctl version</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/09/28/Istio%E5%8D%87%E7%BA%A7/a1.png"></p><h3 id="升级kubernetes的istio"><a href="#升级kubernetes的istio" class="headerlink" title="升级kubernetes的istio"></a>升级kubernetes的istio</h3><p>（1）dump下1.5.0的profile</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">istioctl profile dump demo &gt; demo.yaml</span><br></pre></td></tr></table></figure><p>（2）修改jwt的策略</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim demo.yaml,修改jwtPolicy</span></span><br><span class="line">jwtPolicy: first-party-jwt</span><br></pre></td></tr></table></figure><p>（3）升级</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">istioctl upgrade -f demo.yaml</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/09/28/Istio%E5%8D%87%E7%BA%A7/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/28/Istio%E5%8D%87%E7%BA%A7/a3.png"><br>注：对于老版本的注入的资源，如果是自动注入的方式使用 kubectl rollout restart deployment –namespace <namespace with auto injection> 升级，如果是手工注入方式使用 kubectl apply -f &lt; (istioctl kube-inject -f <original application deployment yaml>) 升级</original></namespace></p>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Istio安装与卸载</title>
      <link href="2020/09/28/Istio%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/"/>
      <url>2020/09/28/Istio%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Istio官网：<a href="https://istio.io/latest/zh/">https://istio.io/latest/zh/</a></p><h2 id="下载istio-1-4-5"><a href="#下载istio-1-4-5" class="headerlink" title="下载istio-1.4.5"></a>下载istio-1.4.5</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">链接：https://pan.baidu.com/s/1WtvRTeih_6PumGp2Q2D3UA </span><br><span class="line">提取码：lxce</span><br></pre></td></tr></table></figure><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>解压后在/etc/profile配置环境变量 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ISTIO_HOME=/usr/<span class="built_in">local</span>/istio-1.4.5</span><br><span class="line">MAVEN_HOME=/usr/<span class="built_in">local</span>/maven</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin:<span class="variable">$&#123;ISTIO_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH MAVEN_HOME ISTIO_HOME</span><br><span class="line"></span><br><span class="line"><span class="comment">#使环境变量生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#查看版本号</span></span><br><span class="line">istioctl version --remote=<span class="literal">false</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看istio的profile</span></span><br><span class="line">istioctl profile list</span><br><span class="line"><span class="comment">#安装istio</span></span><br><span class="line">istioctl manifest apply --<span class="built_in">set</span> profile=demo</span><br></pre></td></tr></table></figure><p>查看pod启动情况<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/28/Istio%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/28/Istio%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/a2.png"></p><h2 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">istioctl manifest generate --<span class="built_in">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Istio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes中command、args和Dockerfile中entrypoint、cmd之间的作用</title>
      <link href="2020/09/28/Kubernetes%E4%B8%ADcommand%E3%80%81args%E5%92%8CDockerfile%E4%B8%ADentrypoint%E3%80%81cmd%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BD%9C%E7%94%A8/"/>
      <url>2020/09/28/Kubernetes%E4%B8%ADcommand%E3%80%81args%E5%92%8CDockerfile%E4%B8%ADentrypoint%E3%80%81cmd%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BD%9C%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="当用户同时在kubernetes中的yaml文件中写了command和args的时候自然是可以覆盖DockerFile中ENTRYPOINT的命令行和参数-完整的情况分类如下："><a href="#当用户同时在kubernetes中的yaml文件中写了command和args的时候自然是可以覆盖DockerFile中ENTRYPOINT的命令行和参数-完整的情况分类如下：" class="headerlink" title="当用户同时在kubernetes中的yaml文件中写了command和args的时候自然是可以覆盖DockerFile中ENTRYPOINT的命令行和参数,完整的情况分类如下："></a>当用户同时在kubernetes中的yaml文件中写了command和args的时候自然是可以覆盖DockerFile中ENTRYPOINT的命令行和参数,完整的情况分类如下：</h2><p>如果command和args均没有写，那么用Docker默认的配置。<br>如果command写了，但args没有写，那么Docker默认的配置会被忽略而且仅仅执行.yaml文件的command（不带任何参数的）。<br>如果command没写，但args写了，那么Docker默认配置的ENTRYPOINT的命令行会被执行，但是调用的参数是.yaml中的args。<br>如果如果command和args都写了，那么Docker默认的配置被忽略，使用.yaml的配置。</p><p>转载：<a href="https://www.orchome.com/1438">https://www.orchome.com/1438</a></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix仪表盘显示邮件发送成功,Mailx日志出现Error initializing NSS Unknown error -8015</title>
      <link href="2020/09/28/Zabbix%E4%BB%AA%E8%A1%A8%E7%9B%98%E6%98%BE%E7%A4%BA%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E6%88%90%E5%8A%9F-Mailx%E6%97%A5%E5%BF%97%E5%87%BA%E7%8E%B0Error-initializing-NSS-Unknown-error-8015/"/>
      <url>2020/09/28/Zabbix%E4%BB%AA%E8%A1%A8%E7%9B%98%E6%98%BE%E7%A4%BA%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E6%88%90%E5%8A%9F-Mailx%E6%97%A5%E5%BF%97%E5%87%BA%E7%8E%B0Error-initializing-NSS-Unknown-error-8015/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>zabbix显示邮件发送成功，但是并未收到邮件，mailx日志出现Error initializing NSS Unknown error -8015错误</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>查看/etc/mail.rc的set nss-config-dir配置项</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> nss-config-dir=/tmp/.certs</span><br></pre></td></tr></table></figure><p>查看证书是否存在，zabbix是否对/tmp/.certs有权限</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chown -R zabbix:zabbix /tmp/.certs</span><br></pre></td></tr></table></figure><p>最后测试可以正常收到邮件</p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过ingress-nginx暴露apache服务</title>
      <link href="2020/09/23/%E9%80%9A%E8%BF%87ingress-nginx%E6%9A%B4%E9%9C%B2apache%E6%9C%8D%E5%8A%A1/"/>
      <url>2020/09/23/%E9%80%9A%E8%BF%87ingress-nginx%E6%9A%B4%E9%9C%B2apache%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在之前的文章中已经介绍了ingress-nginx的部署，本文介绍下怎么使用ingress-nginx去暴露我们的服务</p><h2 id="部署服务"><a href="#部署服务" class="headerlink" title="部署服务"></a>部署服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: my-httpd</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myapp</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myapp</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: httpd</span><br><span class="line">          image: httpd</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: my-httpd</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br></pre></td></tr></table></figure><p>将tomcat的svc添加至ingress-nginx中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: my-httpd</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: <span class="string">&quot;nginx&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">    - host: tomcat.twf.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - backend:</span><br><span class="line">              serviceName: my-httpd</span><br><span class="line">              servicePort: 80</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p>在C:\Windows\System32\drivers\etc\hosts 添加一行 192.168.70.128 tomcat.twf.com ,ip和域名根据自己的ip修改<br>浏览器访问 <a href="http://tomcat.twf.com:32080/">http://tomcat.twf.com:32080/</a><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/23/%E9%80%9A%E8%BF%87ingress-nginx%E6%9A%B4%E9%9C%B2apache%E6%9C%8D%E5%8A%A1/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署ingress-nginx</title>
      <link href="2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/"/>
      <url>2020/09/23/Kubernetes%E9%83%A8%E7%BD%B2ingress-nginx/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文主要介绍nodeport方式部署ingress-nginx</p><h2 id="下载mandatory-yaml"><a href="#下载mandatory-yaml" class="headerlink" title="下载mandatory.yaml"></a>下载mandatory.yaml</h2><p>地址：<a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</a></p><h2 id="在node节点下载镜像"><a href="#在node节点下载镜像" class="headerlink" title="在node节点下载镜像"></a>在node节点下载镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载所需镜像</span></span><br><span class="line">docker pull tangweifeng/defaultbackend-amd64:1.5</span><br><span class="line">docker pull tangweifeng/nginx-ingress-controller:0.20.0</span><br><span class="line"><span class="comment">#重命名，改成mandatory.yaml里面镜像的名称</span></span><br><span class="line">docker tag tangweifeng/defaultbackend-amd64:1.5 k8s.gcr.io/defaultbackend-amd64:1.5</span><br><span class="line">docker tag tangweifeng/nginx-ingress-controller:0.20.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.20.0</span><br></pre></td></tr></table></figure><h2 id="创建service-nodeport-yaml"><a href="#创建service-nodeport-yaml" class="headerlink" title="创建service-nodeport.yaml"></a>创建service-nodeport.yaml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      nodePort: 32080  <span class="comment">#http</span></span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      nodePort: 32443  <span class="comment">#https</span></span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/part-of: ingress-nginx</span><br></pre></td></tr></table></figure><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mandatory.yaml</span><br><span class="line">kubectl apply -f service-nodeport.yaml</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看组件状态</span></span><br><span class="line">kubectl get pods -n ingress-nginx</span><br><span class="line">kubectl get svc -n ingress-nginx</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署redis-cluster集群</title>
      <link href="2020/09/18/Kubernetes%E9%83%A8%E7%BD%B2redis-cluster%E9%9B%86%E7%BE%A4/"/>
      <url>2020/09/18/Kubernetes%E9%83%A8%E7%BD%B2redis-cluster%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装NFS"><a href="#安装NFS" class="headerlink" title="安装NFS"></a>安装NFS</h2><p>NFS安装可以参照我前面的几篇文章，这边就略过了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/exports</span><br><span class="line">/redis/pv *(async,insecure,no_root_squash,no_subtree_check,rw)</span><br><span class="line"></span><br><span class="line">mkdir -p /redis</span><br><span class="line">systemctl restart rpcbind</span><br><span class="line">systemctl restart nfs</span><br></pre></td></tr></table></figure><h2 id="创建名称空间"><a href="#创建名称空间" class="headerlink" title="创建名称空间"></a>创建名称空间</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-cluster</span><br><span class="line">  labels:</span><br><span class="line">    name: redis-cluster</span><br></pre></td></tr></table></figure><h2 id="创建configmap"><a href="#创建configmap" class="headerlink" title="创建configmap"></a>创建configmap</h2><p>准备一份redis.conf文件放到/redis目录下，修改redis.conf下面配置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">bind</span> 0.0.0.0</span><br><span class="line">dir /data </span><br><span class="line">pidfile /data/redis_6379.pid</span><br><span class="line">logfile <span class="string">&quot;/data/redis.log&quot;</span></span><br><span class="line">cluster-enabled yes </span><br><span class="line">cluster-config-file nodes-6379.conf </span><br><span class="line">cluster-node-timeout 15000</span><br><span class="line">appendonly yes </span><br><span class="line">protected-mode no </span><br><span class="line">requirepass 123456 </span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create configmap redis-conf --from-file=/redis/redis.conf -n redis-cluster</span><br></pre></td></tr></table></figure><h2 id="创建headless"><a href="#创建headless" class="headerlink" title="创建headless"></a>创建headless</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: myredis</span><br><span class="line">  namespace: redis-cluster</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: myredis</span><br><span class="line">  ports:</span><br><span class="line">    - port: 6379</span><br></pre></td></tr></table></figure><h2 id="创建statefulset"><a href="#创建statefulset" class="headerlink" title="创建statefulset"></a>创建statefulset</h2><p>我这边是使用基于storageclass的nfs，动态提供pv，基于storageclass的nfs-client请查看前面的文章</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-cluster</span><br><span class="line">  namespace: redis-cluster</span><br><span class="line">spec:</span><br><span class="line">  replicas: 6</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myredis</span><br><span class="line">  serviceName: myredis</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: redis-data</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">      spec:</span><br><span class="line">        accessModes: [<span class="string">&quot;ReadWriteOnce&quot;</span>]</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 1Gi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myredis</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: redis-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: redis-conf</span><br><span class="line">      containers:</span><br><span class="line">        - name: redis</span><br><span class="line">          image: redis:5.0.5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 6379</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /data/redis.conf</span><br><span class="line">              name: redis-conf</span><br><span class="line">              subPath: redis.conf</span><br><span class="line">            - mountPath: /data</span><br><span class="line">              name: redis-data</span><br><span class="line">          <span class="built_in">command</span>:</span><br><span class="line">            - redis-server</span><br><span class="line">            - /data/redis.conf</span><br></pre></td></tr></table></figure><h2 id="构建集群"><a href="#构建集群" class="headerlink" title="构建集群"></a>构建集群</h2><p>可以看出来我们的6个redis都起来了，并且每个redis都有自己的存储<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/18/Kubernetes%E9%83%A8%E7%BD%B2redis-cluster%E9%9B%86%E7%BE%A4/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/18/Kubernetes%E9%83%A8%E7%BD%B2redis-cluster%E9%9B%86%E7%BE%A4/a2.png"><br>下面我们在创建一个基础centos7的容器，通过redis-cli去构建集群</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run -it centos7 --image=centos:7 --restart=Never -n redis-cluster /bin/bash</span><br></pre></td></tr></table></figure><p>安装redis</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y gcc vim wget make <span class="built_in">bind</span>-utils</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">wget http://download.redis.io/releases/redis-5.0.3.tar.gz</span><br><span class="line"><span class="built_in">cd</span> redis-5.0.5</span><br><span class="line">make</span><br><span class="line"><span class="built_in">cd</span> src</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>使用redis-cli构建集群</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./redis-cli  -a 123456 --cluster create --cluster-replicas 1 \</span><br><span class="line">`dig +short redis-cluster-0.myredis.redis-cluster.svc.cluster.local`:6379 \</span><br><span class="line">`dig +short redis-cluster-1.myredis.redis-cluster.svc.cluster.local`:6379 \</span><br><span class="line">`dig +short redis-cluster-2.myredis.redis-cluster.svc.cluster.local`:6379 \</span><br><span class="line">`dig +short redis-cluster-3.myredis.redis-cluster.svc.cluster.local`:6379 \</span><br><span class="line">`dig +short redis-cluster-4.myredis.redis-cluster.svc.cluster.local`:6379 \</span><br><span class="line">`dig +short redis-cluster-5.myredis.redis-cluster.svc.cluster.local`:6379 </span><br></pre></td></tr></table></figure><p>如上，命令 dig +short redis-cluster-0.myredis.redis-cluster.svc.cluster.local 用于将pod的域名转化为ip<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/18/Kubernetes%E9%83%A8%E7%BD%B2redis-cluster%E9%9B%86%E7%BE%A4/a3.png"><br>到此为止，我们的redis cluster集群已经创建完毕</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">redis-cli -c -a 123456</span><br><span class="line">Warning: Using a password with <span class="string">&#x27;-a&#x27;</span> or <span class="string">&#x27;-u&#x27;</span> option on the <span class="built_in">command</span> line interface may not be safe.</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; cluster info</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:6</span><br><span class="line">cluster_size:3</span><br><span class="line">cluster_current_epoch:6</span><br><span class="line">cluster_my_epoch:1</span><br><span class="line">cluster_stats_messages_ping_sent:895</span><br><span class="line">cluster_stats_messages_pong_sent:845</span><br><span class="line">cluster_stats_messages_sent:1740</span><br><span class="line">cluster_stats_messages_ping_received:840</span><br><span class="line">cluster_stats_messages_pong_received:895</span><br><span class="line">cluster_stats_messages_meet_received:5</span><br><span class="line">cluster_stats_messages_received:1740</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; cluster nodes</span><br><span class="line">b1d33e5a9d30c2c6e698e67eb0bee8a6cf81713b 10.244.2.72:6379@16379 myself,master - 0 1600394683000 1 connected 0-5460</span><br><span class="line">eac16b517d15281bbd9519ae7e30225734fba776 10.244.1.108:6379@16379 master - 0 1600394684000 2 connected 5461-10922</span><br><span class="line">c17c159a5eacc2ff856b7237e100f1ae6fd62f83 10.244.2.74:6379@16379 slave eac16b517d15281bbd9519ae7e30225734fba776 0 1600394685000 5 connected</span><br><span class="line">72827e742cb17b844794b78ef1874551ee14358d 10.244.2.73:6379@16379 master - 0 1600394685791 3 connected 10923-16383</span><br><span class="line">353c8a0f85491bfb3f7347281846ae99bd072b2b 10.244.1.110:6379@16379 slave 72827e742cb17b844794b78ef1874551ee14358d 0 1600394684000 6 connected</span><br><span class="line">e15013580f59ce4f0f197ffdc69b6c86ceea5185 10.244.1.109:6379@16379 slave b1d33e5a9d30c2c6e698e67eb0bee8a6cf81713b 0 1600394684000 4 connected</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署Prometheus</title>
      <link href="2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/"/>
      <url>2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="获取prometheus"><a href="#获取prometheus" class="headerlink" title="获取prometheus"></a>获取prometheus</h2><p>注意下载的prometheus版本是否支持自己的kubernetes版本<br>下载地址：<a href="https://github.com/prometheus-operator/kube-prometheus/archive/v0.2.0.zip">https://github.com/prometheus-operator/kube-prometheus/archive/v0.2.0.zip</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir prometheus</span><br><span class="line"><span class="built_in">cd</span> prometheus</span><br></pre></td></tr></table></figure><h2 id="Prometheus部署"><a href="#Prometheus部署" class="headerlink" title="Prometheus部署"></a>Prometheus部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /k8s/prometheus/kube-prometheus-0.2.0/manifests</span><br></pre></td></tr></table></figure><p>vim grafana-service.yaml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 3000</span><br><span class="line">    nodePort: 30100</span><br><span class="line">    targetPort: http</span><br><span class="line">  selector:</span><br><span class="line">    app: grafana</span><br></pre></td></tr></table></figure><p>vim prometheus-service.yaml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    prometheus: k8s</span><br><span class="line">  name: prometheus-k8s</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9090</span><br><span class="line">    nodePort: 30200</span><br><span class="line">    targetPort: web</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus</span><br><span class="line">    prometheus: k8s</span><br><span class="line">  sessionAffinity: ClientIP</span><br></pre></td></tr></table></figure><p>vim alertmanager-service.yaml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    alertmanager: main</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9093</span><br><span class="line">    nodePort: 30300</span><br><span class="line">    targetPort: web</span><br><span class="line">  selector:</span><br><span class="line">    alertmanager: main</span><br><span class="line">    app: alertmanager</span><br><span class="line">  sessionAffinity: ClientIP</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f manifests/</span><br></pre></td></tr></table></figure><h2 id="访问prometheus"><a href="#访问prometheus" class="headerlink" title="访问prometheus"></a>访问prometheus</h2><p>prometheus：<a href="http://ip:30200/">http://ip:30200</a><br>grafana：<a href="http://ip:30100/">http://ip:30100</a><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/a1.png"><br>导入模板<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/16/Kubernetes%E9%83%A8%E7%BD%B2Prometheus/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes中使用NFS的StorageClass</title>
      <link href="2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/"/>
      <url>2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装NFS"><a href="#安装NFS" class="headerlink" title="安装NFS"></a>安装NFS</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装nfs</span></span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line"><span class="comment">#创建nfs共享目录及设置权限</span></span><br><span class="line">mkdir /nfs/renren -p</span><br><span class="line">chmod 755 /nfs/renren -R</span><br><span class="line"><span class="comment">#配置nfs</span></span><br><span class="line">cat /etc/exports</span><br><span class="line">/nfs/renren *(async,insecure,no_root_squash,no_subtree_check,rw)</span><br></pre></td></tr></table></figure><h2 id="启动NFS"><a href="#启动NFS" class="headerlink" title="启动NFS"></a>启动NFS</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl status rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">systemctl status nfs</span><br></pre></td></tr></table></figure><p>客户端在使用NFS时，需要安装NFS</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在客户端上安装启动nfs</span></span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line"><span class="comment">#查看nfs共享</span></span><br><span class="line">showmount -e k8s-master</span><br></pre></td></tr></table></figure><h2 id="创建基于NFS的StorageClass"><a href="#创建基于NFS的StorageClass" class="headerlink" title="创建基于NFS的StorageClass"></a>创建基于NFS的StorageClass</h2><p><a href="https://github.com/kubernetes-retired/external-storage.git">https://github.com/kubernetes-retired/external-storage.git</a><br>主要部署下面这些资源清单，只有deployment.yaml需要修改nfs相关配置<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/16/Kubernetes%E4%B8%AD%E4%BD%BF%E7%94%A8NFS%E7%9A%84StorageClass/a1.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部署deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-client-provisioner</span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: quay.io/external_storage/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 192.168.126.130  <span class="comment">#修改nfs服务器地址</span></span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /nfs/renren       <span class="comment">#nfs目录</span></span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.126.130  <span class="comment">#修改nfs服务器地址</span></span><br><span class="line">            path: /nfs/renren        <span class="comment">#nfs目录</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f deployment.yaml</span><br><span class="line"><span class="comment">#部署rbac</span></span><br><span class="line">kubectl apply -f rbac.yaml</span><br><span class="line"><span class="comment">#部署storageclass</span></span><br><span class="line">kubectl apply -f class.yaml</span><br><span class="line"><span class="comment">#查看创建的资源</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><h2 id="在pvc中调用storageclass动态提供pv"><a href="#在pvc中调用storageclass动态提供pv" class="headerlink" title="在pvc中调用storageclass动态提供pv"></a>在pvc中调用storageclass动态提供pv</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi</span><br><span class="line"></span><br><span class="line">kubectl apply -f pvc-mysql.yaml</span><br></pre></td></tr></table></figure><h2 id="在pod控制器中使用storageclass"><a href="#在pod控制器中使用storageclass" class="headerlink" title="在pod控制器中使用storageclass"></a>在pod控制器中使用storageclass</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: statefulset-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: statefulset-mysql</span><br><span class="line">  serviceName: headless-mysql</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: pvc-mysql</span><br><span class="line">        annotations:</span><br><span class="line">          volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">      spec:</span><br><span class="line">        accessModes: [<span class="string">&quot;ReadWriteOnce&quot;</span>]</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 1Gi</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: statefulset-mysql</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: mysql-configmap</span><br><span class="line">            items:</span><br><span class="line">              - key: mysql.cnf</span><br><span class="line">                path: mysql.cnf</span><br><span class="line">              - key: mysqld.cnf</span><br><span class="line">                path: mysqld.cnf</span><br><span class="line">              - key: mysqldump.cnf</span><br><span class="line">                path: mysqldump.cnf</span><br><span class="line">              - key: docker.cnf</span><br><span class="line">                path: docker.cnf</span><br><span class="line">      containers:</span><br><span class="line">        - name: mysql</span><br><span class="line">          image: mysql:5.6</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: secret-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /var/lib/mysql</span><br><span class="line">              name: mysql-data</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/mysql.cnf</span><br><span class="line">              subPath: mysql.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/mysqldump.cnf</span><br><span class="line">              subPath: mysqldump.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/docker.cnf</span><br><span class="line">              subPath: docker.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">              subPath: mysqld.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">              </span><br><span class="line">kubectl apply -f statefulset-mysql.yaml</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署renren-fast开源项目</title>
      <link href="2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
      <url>2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>renren-fast是一个开源的前后端分离项目，前端使用vue框架，后端采用springboot。<br>在刚接触完Kubernetes后，使用Kubernetes部署renren-fast项目练练手。</p><h2 id="获取renren-fast"><a href="#获取renren-fast" class="headerlink" title="获取renren-fast"></a>获取renren-fast</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#获取后端</span></span><br><span class="line">git <span class="built_in">clone</span> https://git.oschina.net/renrenio/renren-fast.git</span><br><span class="line"><span class="comment">#获取前端</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/daxiongYang/renren-fast-vue.git</span><br></pre></td></tr></table></figure><h2 id="部署后端"><a href="#部署后端" class="headerlink" title="部署后端"></a>部署后端</h2><h3 id="修改mysql配置"><a href="#修改mysql配置" class="headerlink" title="修改mysql配置"></a>修改mysql配置</h3><p>修改application-dev.yml的mysql配置项，我主要修改了以下几项,此处headless-mysql是我的无头服务的名称，renren-fast是库名</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">url: jdbc:mysql://headless-mysql:3306/renren-fast?useUnicode=<span class="literal">true</span>&amp;characterEncoding=UTF-8&amp;serverTimezone=Asia/Shanghai</span><br><span class="line">username: root</span><br><span class="line">password: 123456</span><br></pre></td></tr></table></figure><h3 id="修改redis配置"><a href="#修改redis配置" class="headerlink" title="修改redis配置"></a>修改redis配置</h3><p>修改application.yml的redis配置项，我主要修改了以下几处，此处headless-redis是我的无头服务名称，password是客户端连接密码</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">host: headless-redis</span><br><span class="line">password: 123456</span><br></pre></td></tr></table></figure><h3 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn clean install</span><br></pre></td></tr></table></figure><h3 id="部署nfs的storageclass"><a href="#部署nfs的storageclass" class="headerlink" title="部署nfs的storageclass"></a>部署nfs的storageclass</h3><p>（1）安装nfs</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装nfs</span></span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line"><span class="comment">#创建nfs共享目录及设置权限</span></span><br><span class="line">mkdir /nfs/renren -p</span><br><span class="line">chmod 755 /nfs/renren -R</span><br><span class="line"><span class="comment">#配置nfs</span></span><br><span class="line">cat /etc/exports</span><br><span class="line">/nfs/renren *(async,insecure,no_root_squash,no_subtree_check,rw)</span><br></pre></td></tr></table></figure><p>（2）启动nfs</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl status rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">systemctl status nfs</span><br></pre></td></tr></table></figure><p>（3）客户端配置<br>客户端在使用nfs时，需要安装nfs</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在客户端上安装启动nfs</span></span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line"><span class="comment">#查看nfs共享</span></span><br><span class="line">showmount -e k8s-master</span><br></pre></td></tr></table></figure><p>（4）创建基于nfs的storageclass</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kubernetes-retired/external-storage.git</span><br></pre></td></tr></table></figure><p>主要部署下面这些资源清单，只有deployment.yaml需要修改nfs相关配置<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a1.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部署deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-client-provisioner</span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: quay.io/external_storage/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 192.168.126.130  <span class="comment">#修改nfs服务器地址</span></span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /nfs/renren       <span class="comment">#nfs目录</span></span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.126.130  <span class="comment">#修改nfs服务器地址</span></span><br><span class="line">            path: /nfs/renren        <span class="comment">#nfs目录</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f deployment.yaml</span><br><span class="line"><span class="comment">#部署rbac</span></span><br><span class="line">kubectl apply -f rbac.yaml</span><br><span class="line"><span class="comment">#部署storageclass</span></span><br><span class="line">kubectl apply -f class.yaml</span><br><span class="line"><span class="comment">#查看创建的资源</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><h3 id="部署mysql"><a href="#部署mysql" class="headerlink" title="部署mysql"></a>部署mysql</h3><p>需要提前创建好namespace，我创建的是renren-fast<br>（1）创建pvc</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi</span><br><span class="line"></span><br><span class="line">kubectl apply -f pvc-mysql.yaml</span><br></pre></td></tr></table></figure><p>（2）创建secret</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: secret-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">data:</span><br><span class="line">  password: dGFuZzE2MTE=</span><br><span class="line">stringData:</span><br><span class="line">  username: root</span><br><span class="line"></span><br><span class="line">kubectl apply -f secret-mysql.yaml</span><br></pre></td></tr></table></figure><p>（3）创建configmap</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /nfs/renren/conf_mysql</span><br><span class="line">kubectl create configmap mysql-configmap --from-file=/nfs/renren/conf_mysql -n renren-fast</span><br></pre></td></tr></table></figure><p>需要提前将mysql容器中的配置文件准备好<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a2.png"><br>（4）创建headless</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: headless-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: statefulset-mysql</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">    </span><br><span class="line">kubectl apply -f headless-mysql.yaml</span><br></pre></td></tr></table></figure><p>（5）创建statefulset</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: statefulset-mysql</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: statefulset-mysql</span><br><span class="line">  serviceName: headless-mysql</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: statefulset-mysql</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: mysql-data</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: pvc-mysql</span><br><span class="line">        - name: mysql-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: mysql-configmap</span><br><span class="line">            items:</span><br><span class="line">              - key: mysql.cnf</span><br><span class="line">                path: mysql.cnf</span><br><span class="line">              - key: mysqld.cnf</span><br><span class="line">                path: mysqld.cnf</span><br><span class="line">              - key: mysqldump.cnf</span><br><span class="line">                path: mysqldump.cnf</span><br><span class="line">              - key: docker.cnf</span><br><span class="line">                path: docker.cnf</span><br><span class="line">      containers:</span><br><span class="line">        - name: mysql</span><br><span class="line">          image: mysql:5.6</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3306</span><br><span class="line">          env:</span><br><span class="line">            - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  name: secret-mysql</span><br><span class="line">                  key: password</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /var/lib/mysql</span><br><span class="line">              name: mysql-data</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/mysql.cnf</span><br><span class="line">              subPath: mysql.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/mysqldump.cnf</span><br><span class="line">              subPath: mysqldump.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/conf.d/docker.cnf</span><br><span class="line">              subPath: docker.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">            - mountPath: /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">              subPath: mysqld.cnf</span><br><span class="line">              name: mysql-conf</span><br><span class="line">              </span><br><span class="line">kubectl apply -f statefulset-mysql.yaml</span><br></pre></td></tr></table></figure><p>部署完成mysql后，可以登录进去，将mysql.sql导入进去，库名是renren-fast，mysql.sql文件在renren-fast\db里面</p><h3 id="部署redis"><a href="#部署redis" class="headerlink" title="部署redis"></a>部署redis</h3><p>（1）创建pvc</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-redis</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br><span class="line">      </span><br><span class="line">kubectl apply -f pvc-redis.yaml</span><br></pre></td></tr></table></figure><p>（2）创建configmap</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /nfs/renren/conf_redis</span><br><span class="line">kubectl create configmap redis-configmap --from-file=redis.conf -n renren-fast</span><br></pre></td></tr></table></figure><p>需要提前将redis.conf准备好，相关pid、log、rdb、aof相关的文件我都放到了容器的/data目录下，redis密码记得改成与项目配置文件的一致<br>（3）创建headless</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: headless-redis</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: statefulset-redis</span><br><span class="line">  ports:</span><br><span class="line">    - port: 6379</span><br><span class="line">    </span><br><span class="line">kubectl apply -f headless-redis.yaml</span><br></pre></td></tr></table></figure><p>（4）创建statefulset</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: statefulset-redis</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: statefulset-redis</span><br><span class="line">  serviceName: headless-redis</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: statefulset-redis</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: redis-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: redis-configmap</span><br><span class="line">        - name: redis-data</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: pvc-redis</span><br><span class="line">      containers:</span><br><span class="line">        - name: redis</span><br><span class="line">          image: redis:5.0.5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 6379</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /data/redis.conf</span><br><span class="line">              name: redis-conf</span><br><span class="line">              subPath: redis.conf</span><br><span class="line">            - mountPath: /data</span><br><span class="line">              name: redis-data</span><br><span class="line">          <span class="built_in">command</span>:</span><br><span class="line">            - redis-server</span><br><span class="line">            - /data/redis.conf</span><br><span class="line">              </span><br><span class="line">kubectl apply -f statefulset-redis.yaml</span><br></pre></td></tr></table></figure><h3 id="部署java环境"><a href="#部署java环境" class="headerlink" title="部署java环境"></a>部署java环境</h3><p>（1）我这边制作了一个简单的dockerfile，将打包的renren-fast.jar与dockerfile放在同级目录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM openjdk:8</span><br><span class="line">RUN mkdir -p /app</span><br><span class="line">WORKDIR /app</span><br><span class="line">COPY renren-fast.jar .</span><br><span class="line">EXPOSE 8080</span><br><span class="line">CMD java -jar renren-fast.jar &gt;&gt; renren.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#build</span></span><br><span class="line">docker build -t my-java-app .</span><br></pre></td></tr></table></figure><p>（2）创建pvc<br>需要将打包好的renren-fast.jar放入这个pvc生成的目录下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-java</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">      </span><br><span class="line">kubectl apply -f pvc-java.yaml</span><br></pre></td></tr></table></figure><p>（3）创建deployment-java</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: deployment-java</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myapp</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myapp</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: myapp-jar</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: pvc-java</span><br><span class="line">      containers:</span><br><span class="line">        - name: java</span><br><span class="line">          image: my-java-app</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /app</span><br><span class="line">              name: myapp-jar</span><br><span class="line">        </span><br><span class="line">kubectl apply -f deployment-java.yaml</span><br></pre></td></tr></table></figure><p>（4）部署service-java</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: service-java</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">    </span><br><span class="line">kubectl apply -f service-java.yaml</span><br><span class="line"><span class="comment">#获取svc,拿到nodeport暴露的端口</span></span><br><span class="line">kubectl get svc -n renren-fast</span><br></pre></td></tr></table></figure><h3 id="测试后端部署是否成功"><a href="#测试后端部署是否成功" class="headerlink" title="测试后端部署是否成功"></a>测试后端部署是否成功</h3><p>在浏览器输入 宿主机ip:nodeport/renren-fast/swagger/index.html,例如<a href="http://192.168.126.130:31375/renren-fast/swagger/index.html">http://192.168.126.130:31375/renren-fast/swagger/index.html</a><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a3.png"></p><h2 id="部署前端"><a href="#部署前端" class="headerlink" title="部署前端"></a>部署前端</h2><p>修改renren-fast-vue\static\config\index-prod.js，修改下面配置，将ip、port改成对应的即可</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// api接口请求地址</span><br><span class="line">window.SITE_CONFIG[<span class="string">&#x27;baseUrl&#x27;</span>] = <span class="string">&#x27;http://192.168.126.130:31375/renren-fast&#x27;</span>;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装依赖，可能由于网络原因，部份依赖安装失败，可以尝试安装cnpm，然后使用cnpm安装依赖</span></span><br><span class="line">npm install</span><br><span class="line"><span class="comment">#打包</span></span><br><span class="line">npm run build</span><br></pre></td></tr></table></figure><p>打包成功后会生成一个dist目录<br>（1）创建pvc<br>需要将打包出来的dist目录放入这个pvc生成的目录下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-nginx</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">      </span><br><span class="line">kubectl apply -f pvc-nginx.yaml</span><br></pre></td></tr></table></figure><p>（2）创建configmap</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /nfs/renren/conf_nginx</span><br><span class="line">kubectl create configmap nginx-configmap --from-file=/nfs/renren/conf_nginx -n renren-fast</span><br></pre></td></tr></table></figure><p>需要提前准备nginx配置文件，我这边就是要nginx.conf和default.conf，修改default.conf<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a4.png"><br>（3）deployment-nginx</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: deployment-nginx</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: deployment-nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: deployment-nginx</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nginx-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: nginx-configmap</span><br><span class="line">            items:</span><br><span class="line">              - key: nginx.conf</span><br><span class="line">                path: nginx.conf</span><br><span class="line">              - key: default.conf</span><br><span class="line">                path: default.conf</span><br><span class="line">        - name: nginx-data</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: pvc-nginx</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/nginx/conf.d/default.conf</span><br><span class="line">              name: nginx-conf</span><br><span class="line">              subPath: default.conf</span><br><span class="line">            - mountPath: /etc/nginx/nginx.conf</span><br><span class="line">              name: nginx-conf</span><br><span class="line">              subPath: nginx.conf</span><br><span class="line">            - mountPath: /usr/share/nginx/html</span><br><span class="line">              name: nginx-data</span><br><span class="line">              </span><br><span class="line">kubectl apply -f deployment-nginx.yaml</span><br></pre></td></tr></table></figure><p>（4）创建service-nginx</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: service-nginx</span><br><span class="line">  namespace: renren-fast</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: deployment-nginx</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">    </span><br><span class="line">kubectl apply -f service-nginx.yaml</span><br><span class="line"><span class="comment">#获取svc,拿到nodeport暴露的端口</span></span><br><span class="line">kubectl get svc -n renren-fast</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>到此整个项目都部署完成了，浏览器输入 ip:nodeport 即可访问<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a5.png"><br>用户名 admin 密码 admin<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/Kubernetes%E9%83%A8%E7%BD%B2renren-fast%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/a6.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kuboard部署</title>
      <link href="2020/09/15/Kuboard%E9%83%A8%E7%BD%B2/"/>
      <url>2020/09/15/Kuboard%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kuboard是一款免费的Kubernetes图形化管理工具</p><h2 id="安装Kuboard"><a href="#安装Kuboard" class="headerlink" title="安装Kuboard"></a>安装Kuboard</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://kuboard.cn/install-script/kuboard.yaml</span><br><span class="line">wget https://addons.kuboard.cn/metrics-server/0.3.6/metrics-server.yaml</span><br><span class="line">kubectl apply -f kuboard.yaml</span><br><span class="line">kubectl apply -f metrics-server.yaml</span><br></pre></td></tr></table></figure><h2 id="获取Token"><a href="#获取Token" class="headerlink" title="获取Token"></a>获取Token</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> $(kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>) -o go-template=<span class="string">&#x27;&#123;&#123;.data.token&#125;&#125;&#x27;</span> | base64 -d)  </span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p>通过任意节点 IP:32567 即可访问</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JIRA部署</title>
      <link href="2020/09/15/JIRA%E9%83%A8%E7%BD%B2/"/>
      <url>2020/09/15/JIRA%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>JIRA广泛应用于任务跟踪、需求分析、流程审批、项目跟踪和敏捷管理领域。</p><h2 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk-*</span><br></pre></td></tr></table></figure><h2 id="安装mariadb"><a href="#安装mariadb" class="headerlink" title="安装mariadb"></a>安装mariadb</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum  -y install mariadb-server</span><br><span class="line">service mariadb start</span><br></pre></td></tr></table></figure><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql</span><br><span class="line">create database jira default character <span class="built_in">set</span> utf8 collate utf8_bin;</span><br><span class="line">use mysql;</span><br><span class="line">UPDATE mysql.user SET password = PASSWORD(<span class="string">&#x27;123456&#x27;</span>) WHERE user = <span class="string">&#x27;root&#x27;</span>;</span><br><span class="line">update user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span>  user=<span class="string">&#x27;root&#x27;</span> and host=<span class="string">&#x27;127.0.0.1&#x27;</span>;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h2 id="下载jira和破解jar"><a href="#下载jira和破解jar" class="headerlink" title="下载jira和破解jar"></a>下载jira和破解jar</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget  https://downloads.atlassian.com/software/jira/downloads/atlassian-jira-software-7.3.7-x64.bin</span><br><span class="line">链接：https://pan.baidu.com/s/1CLmY1B3MzBtPQiQqQvXBIA </span><br><span class="line">提取码：kmp1</span><br></pre></td></tr></table></figure><h2 id="安装jira"><a href="#安装jira" class="headerlink" title="安装jira"></a>安装jira</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod 755 /opt/atlassian-jira-software-7.3.7-x64.bin</span><br><span class="line">./atlassian-jira-software-7.3.7-x64.bin</span><br></pre></td></tr></table></figure><h2 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h2><p>将atlassian-extras-3.2.jar破解文件复制到/opt/atlassian/jira/atlassian-jira/WEB-INF/lib/目录下<br>将破解包里面的mysql-connector-java-5.1.46-bin.jar文件复制到/opt/atlassian/jira/lib/目录下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重新启动jira</span></span><br><span class="line"><span class="built_in">cd</span> /opt/atlassian/jira/bin</span><br><span class="line">sh shutdown.sh</span><br><span class="line">sh startup.sh</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>通过 ip:8080 访问web界面，选择l’ll set it up myself 配置数据源<br>生成许可证，需要注册<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/JIRA%E9%83%A8%E7%BD%B2/a1.png"><br>拿到许可证复制进去即可<br>这个表示即破解成功<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/15/JIRA%E9%83%A8%E7%BD%B2/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> JIRA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JIRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes部署有状态服务-Redis</title>
      <link href="2020/09/10/Kubernetes%E9%83%A8%E7%BD%B2%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-Redis/"/>
      <url>2020/09/10/Kubernetes%E9%83%A8%E7%BD%B2%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-Redis/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装nfs"><a href="#安装nfs" class="headerlink" title="安装nfs"></a>安装nfs</h2><p>我这边就选择k8s-master作为nfs存储了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br><span class="line"><span class="comment">#在 /etc/exports 添加</span></span><br><span class="line">/nfs/volumes *(async,insecure,no_root_squash,no_subtree_check,rw)</span><br><span class="line"><span class="comment"># 创建nfs挂载目录</span></span><br><span class="line">mkdir -p /nfs/volumes</span><br><span class="line"><span class="comment">#启动服务</span></span><br><span class="line">systemctl start rpcbind &amp; systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start nfs-server &amp; systemctl <span class="built_in">enable</span> nfs-server</span><br><span class="line"><span class="comment">#查看nfs状态</span></span><br><span class="line">showmount -e k8s-master</span><br><span class="line"><span class="comment">#创建存储</span></span><br><span class="line"><span class="built_in">cd</span> /nfs/volumes</span><br><span class="line">mkdir data_redis</span><br><span class="line">mkdir conf_redis  <span class="comment">#需要准备一份redis配置文件，配置文件里面相关的存储数据、pid、log等我是放在容器的/data下的</span></span><br></pre></td></tr></table></figure><h2 id="创建PV"><a href="#创建PV" class="headerlink" title="创建PV"></a>创建PV</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv-redis</span><br><span class="line">spec:</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 2Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  nfs:</span><br><span class="line">    path: /nfs/volumes/data_redis</span><br><span class="line">    server: k8s-master</span><br></pre></td></tr></table></figure><p>创建PV</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f pv-redis.yaml</span><br></pre></td></tr></table></figure><h2 id="创建pvc"><a href="#创建pvc" class="headerlink" title="创建pvc"></a>创建pvc</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-redis</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br></pre></td></tr></table></figure><p>创建pvc</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f pvc-redis.yaml</span><br></pre></td></tr></table></figure><h2 id="创建configmap"><a href="#创建configmap" class="headerlink" title="创建configmap"></a>创建configmap</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create configmap redis-configmap --from-file=/nfs/volumes/conf_redis/redis.conf</span><br></pre></td></tr></table></figure><h2 id="创建headless"><a href="#创建headless" class="headerlink" title="创建headless"></a>创建headless</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: headless-redis</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: statefulset-redis</span><br><span class="line">  ports:</span><br><span class="line">    - port: 6379</span><br></pre></td></tr></table></figure><p>创建headless</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f headless-redis.yaml</span><br></pre></td></tr></table></figure><h2 id="创建statefulset"><a href="#创建statefulset" class="headerlink" title="创建statefulset"></a>创建statefulset</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: statefulset-redis</span><br><span class="line">spec:</span><br><span class="line">  serviceName: headless-redis</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: statefulset-redis</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: statefulset-redis</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">        - name: redis-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: redis-configmap</span><br><span class="line">        - name: data-redis</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: pvc-redis</span><br><span class="line">      containers:</span><br><span class="line">        - name: redis</span><br><span class="line">          image: redis:5.0.5</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 6379</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /data/redis.conf</span><br><span class="line">              name: redis-conf</span><br><span class="line">              subPath: redis.conf</span><br><span class="line">            - mountPath: /data</span><br><span class="line">              name: data-redis</span><br><span class="line">          <span class="built_in">command</span>:</span><br><span class="line">            - redis-server</span><br><span class="line">            - /data/redis.conf</span><br></pre></td></tr></table></figure><p>创建headless</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f statefulset-redis.yaml</span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在部署statefulset的时候出现下面这个问题，pod的状态一会completed，一会CrashLoopBackOff<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Kubernetes%E9%83%A8%E7%BD%B2%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-Redis/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Kubernetes%E9%83%A8%E7%BD%B2%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-Redis/a2.png"><br>解决：花了很多时间去研究，describe和log指令也没有提供有用的报错信息，最后发现是配置文件的daemonize配置项的问题，因为redis.conf是我之前改过的，daemonize默认是no，我改成了yes会出现这种问题，所以daemonize保持默认的no即可。</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins启动tomcat后，随着job结束，tomcat进程也结束</title>
      <link href="2020/09/10/Jenkins%E5%90%AF%E5%8A%A8tomcat%E5%90%8E%EF%BC%8C%E9%9A%8F%E7%9D%80job%E7%BB%93%E6%9D%9F%EF%BC%8Ctomcat%E8%BF%9B%E7%A8%8B%E4%B9%9F%E7%BB%93%E6%9D%9F/"/>
      <url>2020/09/10/Jenkins%E5%90%AF%E5%8A%A8tomcat%E5%90%8E%EF%BC%8C%E9%9A%8F%E7%9D%80job%E7%BB%93%E6%9D%9F%EF%BC%8Ctomcat%E8%BF%9B%E7%A8%8B%E4%B9%9F%E7%BB%93%E6%9D%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在使用jenkins构建项目时，执行shell脚本启动tomcat，但是随着jenkins job的结束，tomcat进程也会被杀死</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在shell脚本最上面加上 export BUILD_ID=DONTKILLME<br>如果你是pipeline job，那么请使用 JENKINS_NODE_COOKIE 代替 BUILD_ID</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Jenkins%E5%90%AF%E5%8A%A8tomcat%E5%90%8E%EF%BC%8C%E9%9A%8F%E7%9D%80job%E7%BB%93%E6%9D%9F%EF%BC%8Ctomcat%E8%BF%9B%E7%A8%8B%E4%B9%9F%E7%BB%93%E6%9D%9F/a1.png"><br>在使用jenkins构建另一个项目，在日志中找到这个报错，最后发现是由于我使用nohup启动项目大概需要40秒，但是启动项目时最后一个stage，可能在项目还没启动成功，jenkins已经结束了这次构建，最后我在shell脚本末尾加了sleep 60，测试了确实时这个原因导致的报错，而且也可以解决这个问题。</p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix告警后远程执行shell命令</title>
      <link href="2020/09/10/Zabbix%E5%91%8A%E8%AD%A6%E5%90%8E%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"/>
      <url>2020/09/10/Zabbix%E5%91%8A%E8%AD%A6%E5%90%8E%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>有的时候我们的服务意外宕掉，需要在报警后自动尝试重新启动，zabbix可以在告警后执行shell命令实现重新启动服务</p><h2 id="增加远程执行命令配置"><a href="#增加远程执行命令配置" class="headerlink" title="增加远程执行命令配置"></a>增加远程执行命令配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /etc/zabbix/zabbix_agentd.conf</span></span><br><span class="line">EnableRemoteCommands=1    <span class="comment">#允许远程执行命令</span></span><br><span class="line">LogRemoteCommands=1      <span class="comment">#开启远程执行命令的日志</span></span><br></pre></td></tr></table></figure><h2 id="配置zabbix用户sudo权限"><a href="#配置zabbix用户sudo权限" class="headerlink" title="配置zabbix用户sudo权限"></a>配置zabbix用户sudo权限</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Zabbix%E5%91%8A%E8%AD%A6%E5%90%8E%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/a1.png"></p><h2 id="zabbix动作配置"><a href="#zabbix动作配置" class="headerlink" title="zabbix动作配置"></a>zabbix动作配置</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Zabbix%E5%91%8A%E8%AD%A6%E5%90%8E%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx做反向代理时浏览器加载大文件失败ERR_CONTENT_LENGTH_MISMATCH</title>
      <link href="2020/09/10/Nginx%E5%81%9A%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8A%A0%E8%BD%BD%E5%A4%A7%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5ERR-CONTENT-LENGTH-MISMATCH/"/>
      <url>2020/09/10/Nginx%E5%81%9A%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8A%A0%E8%BD%BD%E5%A4%A7%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5ERR-CONTENT-LENGTH-MISMATCH/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Nginx做后端代理，后端是tomcat，浏览器请求项目时加载大文件失败<br>查看nginx日志<br><img src= "/img/loading.gif" data-lazy-src="/2020/09/10/Nginx%E5%81%9A%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8A%A0%E8%BD%BD%E5%A4%A7%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5ERR-CONTENT-LENGTH-MISMATCH/a1.png"><br>日志中会提示具体的大文件</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>ps -ef | grep nginx 查看 work process 的nginx进程<br>nginx会对大文件进行缓存，存放在proxy_temp目录下，可能由于权限问题，导致无法访问<br>在配置文件中加入 user root; 重启nginx即可。</p>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat运行时出现Invalid-character-found-in-the-HTTP-protocol</title>
      <link href="2020/08/22/Tomcat%E8%BF%90%E8%A1%8C%E6%97%B6%E5%87%BA%E7%8E%B0Invalid-character-found-in-the-HTTP-protocol/"/>
      <url>2020/08/22/Tomcat%E8%BF%90%E8%A1%8C%E6%97%B6%E5%87%BA%E7%8E%B0Invalid-character-found-in-the-HTTP-protocol/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这段时间tomcat日志中出现Invalid character found in the HTTP protocol,还有Invalid character found in method name.HTTP method names must be tokens<br>下面是具体报错信息，试了很久，找到了原因</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level.</span><br><span class="line">       java.lang.IllegalArgumentException: Invalid character found <span class="keyword">in</span> the HTTP protocol [HTTP/1.10x0aHost:]</span><br><span class="line">               at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:560)</span><br><span class="line">               at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:260)</span><br><span class="line">               at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)</span><br><span class="line">               at org.apache.coyote.AbstractProtocol<span class="variable">$ConnectionHandler</span>.process(AbstractProtocol.java:868)</span><br><span class="line">               at org.apache.tomcat.util.net.NioEndpoint<span class="variable">$SocketProcessor</span>.doRun(NioEndpoint.java:1590)</span><br><span class="line">               at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)</span><br><span class="line">               at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">               at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:624)</span><br><span class="line">               at org.apache.tomcat.util.threads.TaskThread<span class="variable">$WrappingRunnable</span>.run(TaskThread.java:61)</span><br><span class="line">               at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level.</span><br><span class="line">       java.lang.IllegalArgumentException: Invalid character found <span class="keyword">in</span> method name. HTTP method names must be tokens</span><br><span class="line">               at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:418)</span><br><span class="line">               at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:260)</span><br><span class="line">               at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)</span><br><span class="line">               at org.apache.coyote.AbstractProtocol<span class="variable">$ConnectionHandler</span>.process(AbstractProtocol.java:868)</span><br><span class="line">               at org.apache.tomcat.util.net.NioEndpoint<span class="variable">$SocketProcessor</span>.doRun(NioEndpoint.java:1590)</span><br><span class="line">               at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)</span><br><span class="line">               at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">               at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:624)</span><br><span class="line">               at org.apache.tomcat.util.threads.TaskThread<span class="variable">$WrappingRunnable</span>.run(TaskThread.java:61)</span><br><span class="line">               at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在网上查了很久，找到很多解决方法，下面我们来看<br>（1）在server.xml的Connector添加maxHttpHeaderSize=”8192”<br>这个参数是设置请求头长度的，不过貌似没有解决问题<br>（2）删除server.xml的监听<br>看到stackOverflow中说删除server.xml下面的监听，不过我试过了，并没有解决，我的日志中还是会出此类错误</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;Listener className=<span class="string">&quot;org.apache.catalina.core.AprLifecycleListener&quot;</span> SSLEngine=<span class="string">&quot;on&quot;</span> /&gt;</span><br></pre></td></tr></table></figure><p>（3）涉及非法字符的原因<br>tomcat在7.0.73, 8.0.39, 8.5.7 版本后，对http解析时做了严格限制。RFC3986文档规定，请求url中只允许包含字母（a-zA-Z）、数字（0-9）和 -_.~ 4个特殊字符，以及保留字符! * ’ ( ) ; : @ &amp; = + $ , / ? # [ ])<br>如果你的url请求中包含这些以外的特殊字符，可以在conf/catalina.properties中最后添加2行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tomcat.util.http.parser.HttpParser.requestTargetAllow=|&#123;&#125;</span><br><span class="line">org.apache.tomcat.util.buf.UDecoder.ALLOW_ENCODED_SLASH=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p>在conf/server.xml的Connector添加</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">relaxedPathChars=<span class="string">&quot;[]|&#123;&#125;^&amp;#x5c;&amp;#x60;&amp;quot;&amp;lt;&amp;gt;&quot;</span> </span><br><span class="line">relaxedQueryChars=<span class="string">&quot;[]|&#123;&#125;^&amp;#x5c;&amp;#x60;&amp;quot;&amp;lt;&amp;gt;&quot;</span></span><br></pre></td></tr></table></figure><p>（4）还有一种说法是跟https有关<br>说是原本是http的请求，然后错误使用https访问导致的，首先我这个http和https都是可以访问的，不存在这种情况，然后代码里面有一些第三方的调用，也是没有问题的<br>（5）非法访问<br>网上看到一篇博客有说可能一些非法访问的请求也会导致这种问题，我找到了报错信息的具体时间，然后找到localhost_access_log.2020-08-20.txt<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/22/Tomcat%E8%BF%90%E8%A1%8C%E6%97%B6%E5%87%BA%E7%8E%B0Invalid-character-found-in-the-HTTP-protocol/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/08/22/Tomcat%E8%BF%90%E8%A1%8C%E6%97%B6%E5%87%BA%E7%8E%B0Invalid-character-found-in-the-HTTP-protocol/a2.png"><br>这种情况导致这种错误也是不可避免的</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决logrotate日志切割后继续输出在原日志的问题</title>
      <link href="2020/08/22/%E8%A7%A3%E5%86%B3logrotate%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%90%8E%E7%BB%A7%E7%BB%AD%E8%BE%93%E5%87%BA%E5%9C%A8%E5%8E%9F%E6%97%A5%E5%BF%97%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>2020/08/22/%E8%A7%A3%E5%86%B3logrotate%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%90%8E%E7%BB%A7%E7%BB%AD%E8%BE%93%E5%87%BA%E5%9C%A8%E5%8E%9F%E6%97%A5%E5%BF%97%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>如果线上使用logrotate切割日志会出现切割后，新的日志输出还是会写在老的日志</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>网上查下来有两种解决方法，两种方式我都尝试了切割nginx日志，但是只成功了第一种<br>（1）通过copytruncate参数<br>copytruncate参数的原理：将之前的日志内容拷贝走作为备份，接着清空当前文件。这个方法会存在丢失部分日志数据的可能</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/app/nginx/logs/access.log &#123;</span><br><span class="line">        daily</span><br><span class="line">        dateext</span><br><span class="line">        rotate 14</span><br><span class="line">        compress</span><br><span class="line">        delaycompress</span><br><span class="line">        missingok</span><br><span class="line">        notifempty</span><br><span class="line">        copytruncate</span><br><span class="line">        create 0664 root root</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）给rsyslog发信号<br>这个方法我试过了，但是没有成功，新的日志还是输出在老的日志文件中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/app/nginx/logs/access.log &#123;</span><br><span class="line">        daily</span><br><span class="line">        dateext</span><br><span class="line">        rotate 14</span><br><span class="line">        compress</span><br><span class="line">        delaycompress</span><br><span class="line">        missingok</span><br><span class="line">        notifempty</span><br><span class="line">        create 0664 root root</span><br><span class="line">        postrotate</span><br><span class="line">            /bin/<span class="built_in">kill</span> -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || <span class="literal">true</span></span><br><span class="line">        endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logrotate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7搭建Harbor私有仓库</title>
      <link href="2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"/>
      <url>2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在生产环境中，我们肯定需要使用docker的私有仓库，下面介绍HarBor私有仓库的搭建</p><h2 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新yum</span></span><br><span class="line">yum update</span><br><span class="line"><span class="comment">#安装需要的软件包</span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data 1vm2</span><br><span class="line"><span class="comment">#设置yum源</span></span><br><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment">#安装docker</span></span><br><span class="line">yum install docker-ce-17.12.1.ce</span><br><span class="line"><span class="comment">#设置开机自启，启动docker</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><h2 id="安装docker-compose"><a href="#安装docker-compose" class="headerlink" title="安装docker-compose"></a>安装docker-compose</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载</span></span><br><span class="line">curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-<span class="subst">$(uname -s)</span>-<span class="subst">$(uname -m)</span>&quot;</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"><span class="comment">#授权</span></span><br><span class="line">chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"><span class="comment">#验证</span></span><br><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure><h2 id="下载Harbor"><a href="#下载Harbor" class="headerlink" title="下载Harbor"></a>下载Harbor</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载</span></span><br><span class="line">wget https://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.5.3.tgz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar -zxvf harbor-offline-installer-v1.5.3.tgz</span><br><span class="line">mv harbor /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改harbor.cfg配置</span></span><br><span class="line">hostname = 192.168.37.148</span><br><span class="line">harbor_admin_password = Harbor12345  <span class="comment">#密码</span></span><br></pre></td></tr></table></figure><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置</span></span><br><span class="line">./prepare</span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure><p>当出现这个表示已经成功了<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/a1.png"><br>浏览器输入ip 即可访问，用户名：admin  密码是配置文件 harbor_admin_password 所对应的<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/21/CentOS7%E6%90%AD%E5%BB%BAHarbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Harbor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitLab数据备份与恢复</title>
      <link href="2020/08/13/GitLab%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"/>
      <url>2020/08/13/GitLab%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>GitLab需要备份的数据有2块，一个是/etc/gitlab下的配置文件，还有一个是使用gitlab-rake指令备份的相关文件</p><h2 id="GitLab配置文件"><a href="#GitLab配置文件" class="headerlink" title="GitLab配置文件"></a>GitLab配置文件</h2><p>GitLab默认的配置文件路径：/etc/gitlab/，需要手工备份</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar cvf /opt/backup/gitlab/conf/`date +%Y%m%d`-gitlab.tar.gz  /etc/gitlab</span><br></pre></td></tr></table></figure><h2 id="编辑备份参数"><a href="#编辑备份参数" class="headerlink" title="编辑备份参数"></a>编辑备份参数</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/gitlab/gitlab.rb</span><br><span class="line"></span><br><span class="line"><span class="comment">#备份路径</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;backup_path&#x27;</span>] = <span class="string">&quot;/opt/nas/gitlabback/data&quot;</span></span><br><span class="line"><span class="comment">#备份包权限</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;backup_archive_permissions&#x27;</span>] = 0644</span><br><span class="line"><span class="comment">#备份保留时间，单位秒，默认7天</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;backup_keep_time&#x27;</span>] = 604800</span><br><span class="line"></span><br><span class="line"><span class="comment">#重载配置，使之生效</span></span><br><span class="line">gitlab-ctl stop</span><br><span class="line">gitlab-ctl reconfigure</span><br><span class="line">gitlab-ctl start</span><br></pre></td></tr></table></figure><h2 id="执行备份"><a href="#执行备份" class="headerlink" title="执行备份"></a>执行备份</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitlab-rake gitlab:backup:create</span><br></pre></td></tr></table></figure><h2 id="还原数据"><a href="#还原数据" class="headerlink" title="还原数据"></a>还原数据</h2><p>保证GitLab版本号是一致的<br>（1）还原配置文件<br>将配置文件上传至服务器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">\mv gitlab.rb gitlab-secrets.json /etc/gitlab/</span><br></pre></td></tr></table></figure><p>修改配置文件里面关于url地址 external_url</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重载gitlab配置</span></span><br><span class="line">gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure><p>（2）还原GitLab数据<br>将gitlab-rake打包的文件放到 gitlab_rails[‘backup_path’] 对应目录下<br>gitlab_rails[‘backup_path’] = “/opt/nas/gitlabback/data”</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 恢复数据，注意BACKUP=后面只要 _gitlab_backup.tar 前面的版本号，如下</span></span><br><span class="line">gitlab-rake gitlab:backup:restore BACKUP=1597282053_2020_08_13_10.0.6</span><br><span class="line"><span class="comment">#重载gitlab配置</span></span><br><span class="line">gitlab-ctl reconfigure</span><br><span class="line">gitlab-ctl start</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GitLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitLab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins数据备份与恢复</title>
      <link href="2020/08/13/Jenkins%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"/>
      <url>2020/08/13/Jenkins%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>生产环境我们肯定会考虑jenkins的数据备份和恢复问题，ThinBackup插件方便我们通过界面方式快速备份数据与恢复</p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>在jenkins插件市场搜索ThinBackup，并下载安装</p><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p>在Manage Jenkins -&gt; ThinBackup -&gt; setting 配置备份信息<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/13/Jenkins%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/a1.png"><br>各参数说明</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#备份目录，用于存储备份的文件</span></span><br><span class="line">Backup directory</span><br><span class="line"><span class="comment">#全量备份计划，跟crontab一样</span></span><br><span class="line">Backup schedule <span class="keyword">for</span> full backups</span><br><span class="line"><span class="comment">#进行差异化备份的计划任务，同上</span></span><br><span class="line">Backup schedule <span class="keyword">for</span> differential backups</span><br><span class="line"><span class="comment">#备份的最大数量</span></span><br><span class="line">Max number of backup sets</span><br><span class="line"><span class="comment">#不需要进行备份的文件的正则表达式</span></span><br><span class="line">Files excluded from backup (regular expression)</span><br><span class="line"><span class="comment">#等待jenkins空闲多长时间后进行备份</span></span><br><span class="line">Wait until Jenkins/Hudson is idle to perform a backup</span><br><span class="line"><span class="comment">#备份构建结果</span></span><br><span class="line">Backup build results</span><br><span class="line"><span class="comment">#备份`$&#123;jenkins_home&#125;/userContent `目录下的文件</span></span><br><span class="line">Backup <span class="string">&#x27;userContent&#x27;</span> folder</span><br><span class="line"><span class="comment">#备份jenkins构建的build id文件</span></span><br><span class="line">Backup next build number file</span><br><span class="line"><span class="comment">#备份插件</span></span><br><span class="line">Backup plugins archives</span><br><span class="line"><span class="comment">#完成备份以后清除所有的差异备份</span></span><br><span class="line">Clean up differential backups</span><br><span class="line"><span class="comment">#将老的文件压缩</span></span><br><span class="line">Move old backups to ZIP files</span><br></pre></td></tr></table></figure><p>可以通过点击 Backup Now 立即备份<br>注：记得授权备份存储路径：chown -R jenkins:jenkins /opt/nas/jenkinsbackup</p><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p>点击Restore，选择要恢复的时间点<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/13/Jenkins%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/a2.png"><br>在点击 Manage Jenkins -&gt; Reload Configuration from Disk 重载配置，恢复完成</p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL通过binlog日志恢复数据</title>
      <link href="2020/08/13/MySQL%E9%80%9A%E8%BF%87binlog%E6%97%A5%E5%BF%97%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE/"/>
      <url>2020/08/13/MySQL%E9%80%9A%E8%BF%87binlog%E6%97%A5%E5%BF%97%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>如果是云数据库，一般可以通过控制台看到binlog日志记录时间等信息，如果是本地数据库可以通过一下命令查看信息</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看所有binlog日志列表</span></span><br><span class="line">show master logs;</span><br><span class="line"><span class="comment">#查看最后一个binlog日志编号及其最后一个操作事件pos结束点的值</span></span><br><span class="line">show master status;</span><br><span class="line"><span class="comment">#查看mysql-bin.000003具体信息</span></span><br><span class="line">show binlog events <span class="keyword">in</span> ‘mysql-bin.000003’; </span><br></pre></td></tr></table></figure><p>将二进制日志转成可阅读的文档</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/mysql/bin/mysqlbinlog --base64-output=decode-rows -v  mysql-bin.000003 &gt; mysql-bin.000003.txt</span><br></pre></td></tr></table></figure><p>查看二进制文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># at 30857945</span></span><br><span class="line"><span class="comment">#200812  3:17:00 server id 2798978092  end_log_pos 30858334</span></span><br><span class="line"><span class="comment">### UPDATE `staff`.`info`</span></span><br><span class="line"><span class="comment">###   @1=&#x27;1&#x27;</span></span><br><span class="line"><span class="comment">### SET</span></span><br><span class="line"><span class="comment">###   @1=&#x27;2&#x27;</span></span><br><span class="line"><span class="comment"># at 30858334</span></span><br></pre></td></tr></table></figure><p>第一行at表示起始pos点，end_log_pos表示该事件结束的pos点,最后一行at表示下个事件的起始pos点</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#--start-position表示起始pos点，--stop-position表示结束pos点 --database表示数据库  |表示将输出交给mysql命令  -v表示执行</span></span><br><span class="line">/usr/<span class="built_in">local</span>/mysql/bin/mysqlbinlog --start-position=30857945 --stop-position=30858334 --database=staff mysql-bin.000003 | /usr/<span class="built_in">local</span>/mysql/bin/mysql -uroot -p<span class="string">&#x27;123456&#x27;</span> -v staff</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HAProxy+PXC实现负载均衡</title>
      <link href="2020/08/12/HAProxy-PXC%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
      <url>2020/08/12/HAProxy-PXC%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>PXC集群搭建请参考之前的文章</p><h2 id="安装HAProxy"><a href="#安装HAProxy" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h2><p>下载：<a href="https://src.fedoraproject.org/repo/pkgs/haproxy/%EF%BC%8C%E6%88%91%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AF1.8.20%E7%89%88%E6%9C%AC">https://src.fedoraproject.org/repo/pkgs/haproxy/，我使用的是1.8.20版本</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar zxvf haproxy-1.8.20.tar.gz</span><br><span class="line"><span class="built_in">cd</span> haproxy-1.8.20</span><br><span class="line"><span class="comment">#编译</span></span><br><span class="line">make TARGET=linux31</span><br><span class="line">make install PREFIX=/usr/<span class="built_in">local</span>/haproxy</span><br><span class="line"><span class="comment">#复制配置文件到指定目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/haproxy/conf</span><br><span class="line">cp /usr/<span class="built_in">local</span>/haproxy-1.8.20/examples/option-http_proxy.cfg /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># demo config for Proxy mode</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"></span><br><span class="line">global</span><br><span class="line">    maxconn         20000</span><br><span class="line">    <span class="built_in">ulimit</span>-n        16384</span><br><span class="line">    <span class="built_in">log</span>             127.0.0.1 local0 info</span><br><span class="line">    uid             200</span><br><span class="line">    gid             200</span><br><span class="line">    chroot          /var/empty</span><br><span class="line">    nbproc            4</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    <span class="built_in">log</span>            global</span><br><span class="line">    mode        http</span><br><span class="line">    <span class="comment">#日志格式</span></span><br><span class="line">    option        httplog</span><br><span class="line">    <span class="comment">#日志中不记录负载均衡的心跳检测记录</span></span><br><span class="line">    option        dontlognull</span><br><span class="line">    <span class="comment">#连接超时（毫秒）</span></span><br><span class="line">    timeout connect 5000</span><br><span class="line">    <span class="comment">#客户端超时（毫秒）</span></span><br><span class="line">    timeout client  5000</span><br><span class="line">    <span class="comment">#服务器超时（毫秒）</span></span><br><span class="line">    timeout server  5000</span><br><span class="line">    <span class="comment">#尝试次数</span></span><br><span class="line">    retries         2</span><br><span class="line"></span><br><span class="line">listen  admin_stats</span><br><span class="line">    <span class="comment">#监控界面的访问ip和port</span></span><br><span class="line">    <span class="built_in">bind</span>        0.0.0.0:8888</span><br><span class="line">    <span class="comment">#访问协议</span></span><br><span class="line">    mode        http</span><br><span class="line">    <span class="comment">#URI相对地址</span></span><br><span class="line">    stats uri    /dbs</span><br><span class="line">    <span class="comment">#统计报告格式</span></span><br><span class="line">    stats realm    Global\ statistics</span><br><span class="line">    <span class="comment">#登录账户信息</span></span><br><span class="line">    stats auth    admin:123456</span><br><span class="line">    </span><br><span class="line">listen proxy-mysql        </span><br><span class="line">    <span class="built_in">bind</span>        0.0.0.0:3306</span><br><span class="line">    mode        tcp</span><br><span class="line">    <span class="comment">#负载均衡算法</span></span><br><span class="line">    <span class="comment">#轮询：roundrobin  权重：static-rr  最少连接：leastconn  请求ip：source</span></span><br><span class="line">    balance        roundrobin</span><br><span class="line">    <span class="comment">#日志格式</span></span><br><span class="line">    option        tcplog</span><br><span class="line">    <span class="comment">#在MySQL中创建一个没有权限的haproxy用户，密码为空. Haproxy使用这个账户对MySQL数据库心跳检测</span></span><br><span class="line">    <span class="comment"># CREATE USER &#x27;haproxy&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;&#x27;; </span></span><br><span class="line">    option        mysql-check user haproxy</span><br><span class="line">    <span class="comment">#使用keepalive检测死链</span></span><br><span class="line">    option        tcpka</span><br><span class="line">    server        server1 192.168.37.142:3306 check maxconn 2000</span><br><span class="line">    server      server2 192.168.37.143:3306 check maxconn 2000</span><br><span class="line">    server      server3 192.168.37.144:3306 check maxconn 2000</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>1.浏览器输入ip:8888/dbs,通过配置的用户名和密码登录<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/12/HAProxy-PXC%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/a1.png"><br>2.使用navicat连接数据库<br>通过HAProxy的 ip 加上 listen proxy-mysql 配置的端口连接，在创建数据库，查看pxc各个节点的数据库</p>]]></content>
      
      
      <categories>
          
          <category> HAProxy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HAProxy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HAProxy配置参数详解</title>
      <link href="2020/08/12/HAProxy%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/"/>
      <url>2020/08/12/HAProxy%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>HAProxy配置文件分成五个部分，主要介绍常用配置<br>    1.global：设置全局配置参数，主要是进程、操作系统相关的配置<br>    2.defaults：配置默认参数，这些参数可以被用到frontend、backend、listen组件<br>    3.frontend：接收请求的前端虚拟节点，可以添加相应的规则匹配到后端backend<br>    4.backend：后端真实服务器集群配置<br>    5.listen：frontend和backend的组合</p><h2 id="global组件"><a href="#global组件" class="headerlink" title="global组件"></a>global组件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">global</span><br><span class="line">    <span class="comment">#以守护进程方式启动</span></span><br><span class="line">    daemon</span><br><span class="line">    <span class="comment">#设置运行haproxy的用户和组</span></span><br><span class="line">    user        haproxy</span><br><span class="line">    group        haproxy</span><br><span class="line">    <span class="comment">#设置haproxy启动时的进程数</span></span><br><span class="line">    nbproc        4</span><br><span class="line">    <span class="comment">#每个进程支持的最大并发连接数</span></span><br><span class="line">    maxconn        20000</span><br><span class="line">    <span class="comment">#设置最大打开文件描述符</span></span><br><span class="line">    <span class="built_in">ulimit</span>-n    16384</span><br><span class="line">    <span class="comment">#设置haproxy的pid文件</span></span><br><span class="line">    pidfile /var/run/haproxy.pid</span><br><span class="line">    <span class="comment">#设置日志配置</span></span><br><span class="line">    <span class="built_in">log</span> 127.0.0.1 local0 info</span><br></pre></td></tr></table></figure><h2 id="defaults组件"><a href="#defaults组件" class="headerlink" title="defaults组件"></a>defaults组件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">defaults</span><br><span class="line">    <span class="comment">#访问协议,mode &#123;http|tcp|health&#125;,http是七层模式    tcp是四层模式 health是健康检测</span></span><br><span class="line">    mode        http</span><br><span class="line">    <span class="comment">#日志配置，也可以使用 log  global 引入全局配置    </span></span><br><span class="line">    <span class="built_in">log</span> 127.0.0.1 local0 error</span><br><span class="line">    <span class="comment">#设置连接后端服务器失败重连次数，超过该值将会将对应服务器标记为不可用</span></span><br><span class="line">    retries    3</span><br><span class="line">    <span class="comment">#启动日志记录HTTP请求，默认haproxy是不记录HTTP请求的</span></span><br><span class="line">    option     httplog</span><br><span class="line">    <span class="comment">#当使用了cookie时，haproxy将会将其请求的后端服务器的serverID插入到cookie中，以保证会话的SESSION持久性；</span></span><br><span class="line">    <span class="comment">#而此时，如果后端的服务器宕掉了，但是客户端的cookie是不会刷新的，如果设置此参数，将会将客户的请求强制定向到另外一个后端server上，以保证服务的正常。</span></span><br><span class="line">    option  redispatch</span><br><span class="line">    <span class="comment">#当服务器负载很高的时候，自动结束当前队列处理比较久的连接</span></span><br><span class="line">    option     abortonclose</span><br><span class="line">    <span class="comment">#启用该项，日志将不会记录空连接。官方建议如果上游服务器没有其他负载均衡器，建议不要使用该参数</span></span><br><span class="line">    option  dontlognull</span><br><span class="line">    <span class="comment">#客户端与服务端完成一次连接请求后，自动关闭此TCP连接</span></span><br><span class="line">    option    httpclose</span><br><span class="line">    <span class="comment">#连接超时（毫秒）</span></span><br><span class="line">    timeout connect 5000</span><br><span class="line">    <span class="comment">#客户端超时（毫秒）</span></span><br><span class="line">    timeout client  5000</span><br><span class="line">    <span class="comment">#服务器超时（毫秒）</span></span><br><span class="line">    timeout server  5000</span><br><span class="line">    <span class="comment">#检查超时时间（毫秒）</span></span><br><span class="line">    timeout check    5000</span><br></pre></td></tr></table></figure><h2 id="frontend组件"><a href="#frontend组件" class="headerlink" title="frontend组件"></a>frontend组件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义一个web前端部分</span></span><br><span class="line">frontend myweb</span><br><span class="line">    <span class="comment">#监听的端口</span></span><br><span class="line">    <span class="built_in">bind</span>    0.0.0.0:80</span><br><span class="line">    <span class="comment">#访问协议</span></span><br><span class="line">    mode    http</span><br><span class="line">    <span class="comment">#日志配置</span></span><br><span class="line">    <span class="built_in">log</span>        global</span><br><span class="line">    <span class="comment">#允许插入X_forward_for数据包头给后端server，可让后端server获得客户端的真实IP</span></span><br><span class="line">    option    forwardfor</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#定义一个web_static_req的acl，当请求的url末尾是以.css .jpg .png .jpeg .js .gif结尾时，将会匹配</span></span><br><span class="line">    acl web_static_req /*.(css|jpg|png|jpeg|js|gif)$</span><br><span class="line">    <span class="comment">#定义一个realserver_req的acl，当 static_server 中存活机器小于1时将会被匹配</span></span><br><span class="line">    acl realserver_req nbsrv(static_server) lt 1</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#默认规则</span></span><br><span class="line">    default_backend  web_server</span><br><span class="line">    <span class="comment">#如果realserver_req满足，走backend web_server</span></span><br><span class="line">    use_backend web_server <span class="keyword">if</span> realserver_req</span><br><span class="line">    <span class="comment">#如果web_static_req满足，走backend static_server</span></span><br><span class="line">    use_backend static_server <span class="keyword">if</span> web_static_req</span><br></pre></td></tr></table></figure><h2 id="backend组件"><a href="#backend组件" class="headerlink" title="backend组件"></a>backend组件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">backend web_server</span><br><span class="line">    mode http</span><br><span class="line">    <span class="comment">#轮询算法：roundrobin 权重算法：static-rr 最少连接算法：leastconn 请求源IP算法：source</span></span><br><span class="line">    balance  roundrobin</span><br><span class="line">    <span class="comment">#开启对后端服务器的健康检测</span></span><br><span class="line">    option httpchk GET /<span class="built_in">test</span>/index.php</span><br><span class="line">    <span class="comment">#后端真实服务器</span></span><br><span class="line">    check表示接受健康检测  inter表示健康检测间隔  rise表示检测成功多少次正常才算正常 fail表示检测多少次失败才算失败 weight表示分发权重 maxconn表示最大连接</span><br><span class="line">    server  server1 172.18.0.2:3306 check inter 2000 rise 3 fall 3  weight 1 maxconn 2000</span><br><span class="line">    server  server2 172.18.0.3:3306 check inter 2000 rise 3 fall 3 weight 1 maxconn 2000</span><br><span class="line">    server  server3 172.18.0.4:3306 check inter 2000 rise 3 fall 3 weight 1 maxconn 2000</span><br></pre></td></tr></table></figure><h2 id="listen组件"><a href="#listen组件" class="headerlink" title="listen组件"></a>listen组件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">listen admin_stats</span><br><span class="line">    <span class="built_in">bind</span>    0.0.0.0:8888</span><br><span class="line">    mode     http</span><br><span class="line">    <span class="built_in">log</span>     global</span><br><span class="line">    <span class="comment">#haproxy统计页面刷新间隔</span></span><br><span class="line">    stats refresh    30s    </span><br><span class="line">    <span class="comment">#URI相对地址</span></span><br><span class="line">    stats uri     /dbs</span><br><span class="line">    <span class="comment">#统计报告格式</span></span><br><span class="line">    stats realm     Global\ statistics</span><br><span class="line">    <span class="comment">#登陆帐户信息  用户名:密码</span></span><br><span class="line">    stats auth  admin:admin</span><br><span class="line">    <span class="comment">#隐藏统计页面上的haproxy版本信息</span></span><br><span class="line">    stats hide-version</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据库负载均衡</span></span><br><span class="line">listen  proxy-mysql</span><br><span class="line">    <span class="comment">#访问的IP和端口</span></span><br><span class="line">    <span class="built_in">bind</span>  0.0.0.0:3306</span><br><span class="line">    <span class="comment">#网络协议</span></span><br><span class="line">    mode  tcp</span><br><span class="line">    <span class="comment">#负载均衡算法（轮询算法）</span></span><br><span class="line">    <span class="comment">#轮询算法：roundrobin</span></span><br><span class="line">    <span class="comment">#权重算法：static-rr</span></span><br><span class="line">    <span class="comment">#最少连接算法：leastconn</span></span><br><span class="line">    <span class="comment">#请求源IP算法：source</span></span><br><span class="line">    balance  roundrobin</span><br><span class="line">    <span class="comment">#日志格式</span></span><br><span class="line">    option  tcplog</span><br><span class="line">    <span class="comment">#在MySQL中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL数据库心跳检测</span></span><br><span class="line">    option  mysql-check user haproxy</span><br><span class="line">    <span class="comment">#使用keepalive检测死链</span></span><br><span class="line">    option  tcpka</span><br><span class="line">    <span class="comment">#后端真实服务器    </span></span><br><span class="line">    server  MySQL_1 192.168.37.100:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_2 192.168.37.101:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_3 192.168.37.102:3306 check weight 1 maxconn 2000</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> HAProxy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HAProxy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL之高可用PXC集群搭建</title>
      <link href="2020/08/12/MySQL%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8PXC%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>2020/08/12/MySQL%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8PXC%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Percona XtraDB Cluster是MySQL高可用的一种方案,PXC集群是以节点组成（建议至少3个节点）,每个节点都是常规的MySQL或者Percona Server,并且所有节点都是可读可写的,集群中的每个节点都保留着完整的数据,相对于主从架构，PXC更加体现出数据的强一致性。</p><a id="more"></a><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>（1）服务高可用：所有节点数据是相同的，所有节点可读可写，只要存在一个节点可用，整个服务还能正常运行<br>（2）同步复制：当请求过来，只有所有节点成功提交，否则算提交失败<br>（3）多主复制：所有节点可读可写<br>总结来说PXC最大的优势：强一致性、所有节点可读可写、无同步时延</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>（1）仅支持InnoDB事务控制<br>（2）数据重复，所有节点都保留一份完整的数据<br>（3）PXC具有强一致性，必须所有节点执行成功才算提交成功，写入效率取决于节点最弱的一台<br>（4）新加入节点需要复制一份完整的数据,采用全量数据传输（SST）代价高<br>（5）所有表都要有主键<br>（6）存在较多的锁冲突、死锁问题<br>（7）不支持LOCK TABLE<br>（8）不支持XA</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node1:192.168.37.142</span><br><span class="line">node2:192.168.37.143</span><br><span class="line">node3:192.168.37.144</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27;</span> /etc/sysconfig/selinux</span><br><span class="line"><span class="comment">#设置hostname,三台机器分别对应node1 node2 node3</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname node1</span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname node2</span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname node3</span><br><span class="line"><span class="comment">#重启</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h2 id="安装Percona-XtraDB-Cluster-5-7"><a href="#安装Percona-XtraDB-Cluster-5-7" class="headerlink" title="安装Percona XtraDB Cluster 5.7"></a>安装Percona XtraDB Cluster 5.7</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#所有机器配置yum源 vim /etc/yum.repos.d/pxc.repo</span></span><br><span class="line">[percona]</span><br><span class="line">name=percona_repo</span><br><span class="line">baseurl =https://mirrors.tuna.tsinghua.edu.cn/percona/release/<span class="variable">$releasever</span>/RPMS/<span class="variable">$basearch</span></span><br><span class="line">enabled = 1</span><br><span class="line">gpgcheck = 0</span><br><span class="line"></span><br><span class="line"><span class="comment">#所有机器安装</span></span><br><span class="line">yum -y install Percona-XtraDB-Cluster-57</span><br></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wsrep_provider：指定Gelera库的路径</span><br><span class="line">wsrep_cluster_address：Galera集群各节点地址</span><br><span class="line">binlog_format：二进制日志格式，仅支持row格式的二进制日志</span><br><span class="line">default_storage_engine：指定默认存储引擎，仅支持InnoDB</span><br><span class="line">wsrep_slave_threads：用于设置读节点执行写集的线程个数</span><br><span class="line">wsrep_log_conflicts：启用时输出的错误日志将包含产生冲突的表和schema</span><br><span class="line">innodb_autoinc_lock_mode：只能设置为2，设置0或1时无法正确处理死锁问题</span><br><span class="line">wsrep_node_address：本节点IP</span><br><span class="line">wsrep_cluster_name：集群名称</span><br><span class="line">wsrep_node_name：本节点hostname</span><br><span class="line">pxc_strict_mode：是否限制pxc启动正在试用阶段的功能，默认值ENFORCING，表示不启用</span><br><span class="line">wsrep_sst_method：全量传输SST，可用方法有mysqldump、rsync和xtrabackup，前2者在传输时都需要对Donor加全局只读锁，xtrabackup不需要，推荐使用xtrabackup</span><br><span class="line">wsrep_sst_auth：在SST传输时需要用到的认证凭据，格式为：<span class="string">&quot;用户:密码&quot;</span></span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件都放在/etc/percona-xtradb-cluster.conf.d目录里，包括mysqld.cnf，mysqld_safe.cnf，wsrep.cnf 三个文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat mysqld.cnf </span></span><br><span class="line"><span class="comment"># Template my.cnf for PXC</span></span><br><span class="line"><span class="comment"># Edit to your requirements.</span></span><br><span class="line">[client]</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line"><span class="comment">#server-id必须保证不一样</span></span><br><span class="line">server-id=3</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line"><span class="built_in">log</span>-error=/var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"><span class="built_in">log</span>-bin</span><br><span class="line">log_slave_updates</span><br><span class="line">expire_logs_days=7</span><br><span class="line"></span><br><span class="line"><span class="comment"># Disabling symbolic-links is recommended to prevent assorted security risks</span></span><br><span class="line">symbolic-links=0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat mysqld_safe.cnf </span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The Percona Server 5.7 configuration file.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># One can use all long options that the program supports.</span></span><br><span class="line"><span class="comment"># Run program with --help to get a list of available options and with</span></span><br><span class="line"><span class="comment"># --print-defaults to see which it would actually understand and use.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For explanations see</span></span><br><span class="line"><span class="comment"># http://dev.mysql.com/doc/mysql/en/server-system-variables.html</span></span><br><span class="line"><span class="comment">#不需要改变</span></span><br><span class="line">[mysqld_safe]</span><br><span class="line">pid-file = /var/run/mysqld/mysqld.pid</span><br><span class="line">socket   = /var/lib/mysql/mysql.sock</span><br><span class="line">nice     = 0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"><span class="comment"># Path to Galera library</span></span><br><span class="line">wsrep_provider=/usr/lib64/galera3/libgalera_smm.so</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cluster connection URL contains IPs of nodes</span></span><br><span class="line"><span class="comment">#If no IP is found, this implies that a new cluster needs to be created,</span></span><br><span class="line"><span class="comment">#in order to do that you need to bootstrap this node</span></span><br><span class="line"><span class="comment">#集群内所有节点IP，保证本地节点IP在最后</span></span><br><span class="line">wsrep_cluster_address=gcomm://192.168.37.142,192.168.37.143,192.168.37.144</span><br><span class="line"></span><br><span class="line"><span class="comment"># In order for Galera to work correctly binlog format should be ROW</span></span><br><span class="line">binlog_format=ROW</span><br><span class="line"></span><br><span class="line"><span class="comment"># MyISAM storage engine has only experimental support</span></span><br><span class="line">default_storage_engine=InnoDB</span><br><span class="line"></span><br><span class="line"><span class="comment"># Slave thread to use</span></span><br><span class="line">wsrep_slave_threads= 8</span><br><span class="line"></span><br><span class="line">wsrep_log_conflicts</span><br><span class="line"></span><br><span class="line"><span class="comment"># This changes how InnoDB autoincrement locks are managed and is a requirement for Galera</span></span><br><span class="line">innodb_autoinc_lock_mode=2</span><br><span class="line"></span><br><span class="line"><span class="comment"># Node IP address</span></span><br><span class="line"><span class="comment">#指定自己节点的IP</span></span><br><span class="line">wsrep_node_address=192.168.37.144</span><br><span class="line"><span class="comment"># Cluster name</span></span><br><span class="line"><span class="comment">#集群名称，三台一样</span></span><br><span class="line">wsrep_cluster_name=pxc-cluster</span><br><span class="line"></span><br><span class="line"><span class="comment">#If wsrep_node_name is not specified,  then system hostname will be used</span></span><br><span class="line"><span class="comment">#每台机器对应的hostname</span></span><br><span class="line">wsrep_node_name=node3</span><br><span class="line"></span><br><span class="line"><span class="comment">#pxc_strict_mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER</span></span><br><span class="line">pxc_strict_mode=ENFORCING</span><br><span class="line"></span><br><span class="line"><span class="comment"># SST method</span></span><br><span class="line"><span class="comment">#推荐使用xtrabackup</span></span><br><span class="line">wsrep_sst_method=xtrabackup-v2</span><br><span class="line"></span><br><span class="line"><span class="comment">#Authentication for SST method</span></span><br><span class="line"><span class="comment">#SST复制所需要使用的mysql用户名和密码</span></span><br><span class="line">wsrep_sst_auth=<span class="string">&quot;admin:admin&quot;</span></span><br></pre></td></tr></table></figure><h2 id="启动PXC集群第一个节点"><a href="#启动PXC集群第一个节点" class="headerlink" title="启动PXC集群第一个节点"></a>启动PXC集群第一个节点</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动</span></span><br><span class="line">systemctl  start  mysql@bootstrap.service</span><br><span class="line"><span class="comment">#获取初始密码</span></span><br><span class="line">grep <span class="string">&quot;temporary password&quot;</span> /var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line"><span class="comment">#登录mysql</span></span><br><span class="line">mysql -uroot -p<span class="string">&#x27;密码&#x27;</span></span><br><span class="line"><span class="comment">#修改密码</span></span><br><span class="line">ALTER user root@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;123456&#x27;</span>;</span><br><span class="line"><span class="comment">#授予远程登录权限</span></span><br><span class="line">use mysql;</span><br><span class="line">update mysql.user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user=<span class="string">&#x27;root&#x27;</span>;</span><br><span class="line"><span class="comment">#刷新权限</span></span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建SST传输需要的用户</span></span><br><span class="line">CREATE user admin@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;admin&#x27;</span>;</span><br><span class="line">GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO admin@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line">//刷新权限</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h2 id="启动其他节点"><a href="#启动其他节点" class="headerlink" title="启动其他节点"></a>启动其他节点</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动其他PXC节点与第一个节点命令不同</span></span><br><span class="line">service mysql start</span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">show status like <span class="string">&#x27;%wsrep%&#x27;</span></span><br><span class="line"></span><br><span class="line">wsrep_cluster_size表示集群节点数量</span><br><span class="line"><span class="comment">#当wsrep_local_state 为4，wsrep_local_state_comment为Synced 时，表示数据同步完成     </span></span><br><span class="line">wsrep_local_state  <span class="comment">#本地状态</span></span><br><span class="line">wsrep_local_state_comment <span class="comment">#本地状态评论</span></span><br><span class="line"><span class="comment">#当wsrep_cluster_status为Primary表示当前节点已经完成连接并准备好</span></span><br><span class="line">wsrep_cluster_status</span><br></pre></td></tr></table></figure><h2 id="验证集群是否成功"><a href="#验证集群是否成功" class="headerlink" title="验证集群是否成功"></a>验证集群是否成功</h2><p>使用navicat连接三个节点<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/12/MySQL%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8PXC%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/a1.png"><br>在其中一个节点创建数据库staff，刷新下其他节点<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/12/MySQL%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8PXC%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/a2.png"><br>可以发现其他节点也创建了staff数据库，整个集群状态是正常的</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用GitLab的webhook来实现触发Jenkins自动操作</title>
      <link href="2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/"/>
      <url>2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文主要介绍GitLab、jenkins配置，以实现当GitLab提交事务时触发jenkins相应的操作</p><a id="more"></a><h2 id="下载jenkins插件"><a href="#下载jenkins插件" class="headerlink" title="下载jenkins插件"></a>下载jenkins插件</h2><p>在jenkins插件中心下载Gitlab Hook、GitLab、Gitlab Authentication 插件</p><h2 id="配置jenkins触发器"><a href="#配置jenkins触发器" class="headerlink" title="配置jenkins触发器"></a>配置jenkins触发器</h2><p>首先记录图片上面的地址，点击Generate生成Secret token并记录<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/a1.png"></p><h2 id="配置GitLab"><a href="#配置GitLab" class="headerlink" title="配置GitLab"></a>配置GitLab</h2><p>找到对应的仓库，点击Settings - Integrations 粘贴刚刚记录的 URL 和Secret token，点击Add webhook<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/a2.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/08/11/%E5%88%A9%E7%94%A8GitLab%E7%9A%84webhook%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%A7%A6%E5%8F%91Jenkins%E8%87%AA%E5%8A%A8%E6%93%8D%E4%BD%9C/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> GitLab </category>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitLab </tag>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins配置邮件通知</title>
      <link href="2020/08/11/Jenkins%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5/"/>
      <url>2020/08/11/Jenkins%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要介绍通过Extreme Notification Plugin插件来配置邮件通知功能</p><a id="more"></a><h2 id="下载插件"><a href="#下载插件" class="headerlink" title="下载插件"></a>下载插件</h2><p>在插件市场下载安装 Extreme Notification Plugin</p><h2 id="配置邮件服务"><a href="#配置邮件服务" class="headerlink" title="配置邮件服务"></a>配置邮件服务</h2><p>在系统管理 - 系统配置里面找到 Extended E-mail Notification<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/11/Jenkins%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5/a1.png"></p><h2 id="pipeline发送邮件"><a href="#pipeline发送邮件" class="headerlink" title="pipeline发送邮件"></a>pipeline发送邮件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">post&#123;</span><br><span class="line">  always &#123;</span><br><span class="line">    script &#123;</span><br><span class="line">      emailext body: <span class="string">&#x27;&#x27;</span><span class="string">&#x27;&lt;html&gt;</span></span><br><span class="line"><span class="string">        &lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot;</span></span><br><span class="line"><span class="string">          offset=&quot;0&quot;&gt;</span></span><br><span class="line"><span class="string">          &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;</span></span><br><span class="line"><span class="string">              style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt;</span></span><br><span class="line"><span class="string">              &lt;tr&gt;</span></span><br><span class="line"><span class="string">                  &lt;td&gt;&lt;br /&gt;</span></span><br><span class="line"><span class="string">                  &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建信息&lt;/font&gt;&lt;/b&gt;</span></span><br><span class="line"><span class="string">                  &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;</span></span><br><span class="line"><span class="string">              &lt;/tr&gt;</span></span><br><span class="line"><span class="string">              &lt;tr&gt;</span></span><br><span class="line"><span class="string">                  &lt;td&gt;</span></span><br><span class="line"><span class="string">                      &lt;ul&gt;</span></span><br><span class="line"><span class="string">                          &lt;li&gt;构建名称：$&#123;JOB_NAME&#125;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                          &lt;li&gt;构建结果: &lt;span style=&quot;color:green&quot;&gt; $&#123;BUILD_STATUS&#125;&lt;/span&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                          &lt;li&gt;构建编号：$&#123;BUILD_NUMBER&#125;  &lt;/li&gt;</span></span><br><span class="line"><span class="string">                          &lt;li&gt;构建者: $&#123;CAUSE&#125;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                          &lt;li&gt;变更记录: $&#123;CHANGES,showPaths=true,showDependencies=true,format=&quot;&lt;pre&gt;&lt;ul&gt;&lt;li&gt;提交ID: %r&lt;/li&gt;&lt;li&gt;提交人：%a&lt;/li&gt;&lt;li&gt;提交时间：%d&lt;/li&gt;&lt;li&gt;提交信息：%m&lt;/li&gt;&lt;li&gt;提交文件：&lt;br /&gt;%p&lt;/li&gt;&lt;/ul&gt;&lt;/pre&gt;&quot;,pathFormat=&quot;         %p &lt;br /&gt;&quot;&#125;</span></span><br><span class="line"><span class="string">                      &lt;/ul&gt;</span></span><br><span class="line"><span class="string">                  &lt;/td&gt;</span></span><br><span class="line"><span class="string">              &lt;/tr&gt;</span></span><br><span class="line"><span class="string">          &lt;/table&gt;</span></span><br><span class="line"><span class="string">        &lt;/body&gt;</span></span><br><span class="line"><span class="string">      &lt;/html&gt;&#x27;</span><span class="string">&#x27;&#x27;</span>, subject: <span class="string">&#x27;$&#123;PROJECT_NAME&#125;&#x27;</span>, to: <span class="string">&#x27;xxxxxx@qq.com&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL如何通过binlog日志排查问题</title>
      <link href="2020/08/09/MySQL%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87binlog%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/"/>
      <url>2020/08/09/MySQL%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87binlog%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>binary log中记录了数据库内容的变化,这些变化是以二进制的方式存储到</p><a id="more"></a><p>1.通过mysqlbinlog工具，将binlog日志以文本形式显示</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/mysql/bin/mysqlbinlog mysql-bin.000183 &gt; mysql-bin.000183.txt</span><br></pre></td></tr></table></figure><p>2.这边转成文本后，里面记录的sql语句是经过64位编码转换后的内容，使用mysqlbinlog对应的参数即可查看具体sql内容</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/mysql/bin/mysqlbinlog --base64-output=decode-rows -v --start-datetime=<span class="string">&quot;2017-08-12 15:00:19&quot;</span> --stop-datetime=<span class="string">&quot;2017-08-12 15:30:19&quot;</span> mysql-bin.000183 &gt; mysql-bin.000183.txt</span><br></pre></td></tr></table></figure><p>经过解码后，在mysql-bin.000183.txt文件中，以 ### 开头的就是具体的sql语句</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RDS全量数据恢复至本地MySQL</title>
      <link href="2020/08/09/RDS%E5%85%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E8%87%B3%E6%9C%AC%E5%9C%B0MySQL/"/>
      <url>2020/08/09/RDS%E5%85%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E8%87%B3%E6%9C%AC%E5%9C%B0MySQL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>从RDS备份与恢复下载需要恢复的数据（_qp.xb 后缀）</p><a id="more"></a><h2 id="版本问题"><a href="#版本问题" class="headerlink" title="版本问题"></a>版本问题</h2><p>MySQL 5.6及之前的版本需要安装 Percona XtraBackup 2.3<br>MySQL 5.7版本需要安装 Percona XtraBackup 2.4<br>MySQL 8.0版本需要安装 Percona XtraBackup 8.0</p><h2 id="安装innobackupex"><a href="#安装innobackupex" class="headerlink" title="安装innobackupex"></a>安装innobackupex</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装依赖库</span></span><br><span class="line">yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL libev-devel</span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.12/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm</span><br><span class="line">yum -y install percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p>恢复前，停止本地mysql服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#解包</span></span><br><span class="line">cat &lt;数据备份文件名&gt;_qp.xb | xbstream -x -v -C /usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">innobackupex --decompress --remove-original /usr/<span class="built_in">local</span>/mysql/data</span><br></pre></td></tr></table></figure><p>如果出现这个报错 sh: qpress: 未找到命令，请到<a href="http://www.quicklz.com/">http://www.quicklz.com/</a> 这里下载 qpress-11-linux-x64.tar</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar xvf qpress-11-linux-x64.tar</span><br><span class="line">cp qpress /usr/bin</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">innobackupex --defaults-file=/usr/<span class="built_in">local</span>/mysql/data/backup-my.cnf --apply-log /usr/<span class="built_in">local</span>/mysql/data</span><br></pre></td></tr></table></figure><p>当出现 innobackupex: completed OK！ 代表恢复成功<br>记得授权</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chown -R mysql:mysql /usr/<span class="built_in">local</span>/mysql/data</span><br></pre></td></tr></table></figure><p>最后启动mysql即可</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins集成SonarQube</title>
      <link href="2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/"/>
      <url>2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文主要介绍jenkins与sonarQube的集成，以及使用pipeline去调用sonarqube检测我们的代码质量</p><a id="more"></a><h2 id="sonarqube设置"><a href="#sonarqube设置" class="headerlink" title="sonarqube设置"></a>sonarqube设置</h2><p>1.打开Force user authentication<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a1.png"><br>2.创建token，并复制下来<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a2.png"><br>3.添加Webhooks(格式 http://[ip]:[port]/sonarqube-webhook/)，注意地址最后面要有 /<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a3.png"></p><h2 id="jenkins设置"><a href="#jenkins设置" class="headerlink" title="jenkins设置"></a>jenkins设置</h2><h3 id="下载插件"><a href="#下载插件" class="headerlink" title="下载插件"></a>下载插件</h3><p>在插件中心下载安装 SonarQube Scanner for Jenkins</p><h3 id="配置凭据"><a href="#配置凭据" class="headerlink" title="配置凭据"></a>配置凭据</h3><p><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a4.png"></p><h3 id="配置sonarqube-servers"><a href="#配置sonarqube-servers" class="headerlink" title="配置sonarqube servers"></a>配置sonarqube servers</h3><p>在 系统配置 里找到 SonarQube servers，Server authentication token选择刚刚添加的凭据<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a5.png"></p><h3 id="配置sonarqube-scanner"><a href="#配置sonarqube-scanner" class="headerlink" title="配置sonarqube scanner"></a>配置sonarqube scanner</h3><p>在 全局工具配置 中配置sonarqube scanner<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/09/Jenkins%E9%9B%86%E6%88%90SonarQube/a6.png"></p><h2 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a>pipeline</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        label <span class="string">&#x27;tomcatVM&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">        //git仓库地址</span><br><span class="line">        git_url = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        //git凭据id</span><br><span class="line">        credentialsId = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        //分支</span><br><span class="line">        git_branch = <span class="string">&#x27;master&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">        //清理工作空间</span><br><span class="line">        stage(<span class="string">&#x27;clean workspace&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                cleanWs()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //拉取代码</span><br><span class="line">        stage(<span class="string">&#x27;push git code&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                git credentialsId:<span class="string">&quot;<span class="variable">$&#123;credentialsId&#125;</span>&quot;</span>,url:<span class="string">&quot;<span class="variable">$&#123;git_url&#125;</span>&quot;</span>,branch: <span class="string">&quot;<span class="variable">$&#123;git_branch&#125;</span>&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //打包</span><br><span class="line">        stage(<span class="string">&#x27;mvn build&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;/usr/local/maven/bin/mvn clean install&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //sonarqube分析代码</span><br><span class="line">        stage(<span class="string">&#x27;sonarqube analysis&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                //这边withSonarQubeEnv的参数就是系统配置sonarqube servers中配置的name</span><br><span class="line">                withSonarQubeEnv(<span class="string">&#x27;sonarServer&#x27;</span>) &#123;</span><br><span class="line">                    sh <span class="string">&quot;/usr/local/sonar-scanner-4.4.0.2170-linux/bin/sonar-scanner &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.projectKey=myproject &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.projectName=myproject &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.projectVersion=1.0 &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.sources=. &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.java.binaries=target/classes &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.login=admin &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.password=admin &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.pdf.username=admin &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.pdf.password=admin &quot;</span>+</span><br><span class="line">                       <span class="string">&quot;-Dsonar.pdf.skip=false&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">                script &#123;</span><br><span class="line">                    //等待webhook返回代码检查结果</span><br><span class="line">                    //这里设置超时时间1分钟</span><br><span class="line">                    timeout(1) &#123;</span><br><span class="line">                        //获取结果，waitForQualityGate()中的参数也要与之前SonarQube servers中Name的配置相同</span><br><span class="line">                        def qg = waitForQualityGate(<span class="string">&#x27;sonarServer&#x27;</span>)</span><br><span class="line">                        <span class="keyword">if</span> (qg.status != <span class="string">&#x27;OK&#x27;</span>) &#123;</span><br><span class="line">                            error <span class="string">&quot;未通过Sonarqube的代码质量阈检查，请及时修改！failure: <span class="variable">$&#123;qg.status&#125;</span>&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">&#x27;copy war to tomcat&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;cp target/myproject.war /usr/local/apache-tomcat-9.0.36/webapps/ROOT.war&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">&#x27;excute shell&#x27;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;/usr/local/apache-tomcat-9.0.36/bin/startup.sh&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    post&#123;</span><br><span class="line">          success &#123;</span><br><span class="line">            script &#123;</span><br><span class="line">                cleanWs()</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          always &#123;</span><br><span class="line">            script &#123;</span><br><span class="line">              emailext body: <span class="string">&#x27;&#x27;</span><span class="string">&#x27;&lt;html&gt;</span></span><br><span class="line"><span class="string">                &lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot;</span></span><br><span class="line"><span class="string">                  offset=&quot;0&quot;&gt;</span></span><br><span class="line"><span class="string">                  &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;</span></span><br><span class="line"><span class="string">                      style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt;</span></span><br><span class="line"><span class="string">                      &lt;tr&gt;</span></span><br><span class="line"><span class="string">                          &lt;td&gt;&lt;br /&gt;</span></span><br><span class="line"><span class="string">                          &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建信息&lt;/font&gt;&lt;/b&gt;</span></span><br><span class="line"><span class="string">                          &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt;</span></span><br><span class="line"><span class="string">                      &lt;/tr&gt;</span></span><br><span class="line"><span class="string">                      &lt;tr&gt;</span></span><br><span class="line"><span class="string">                          &lt;td&gt;</span></span><br><span class="line"><span class="string">                              &lt;ul&gt;</span></span><br><span class="line"><span class="string">                                  &lt;li&gt;构建名称：$&#123;JOB_NAME&#125;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                                  &lt;li&gt;构建结果: &lt;span style=&quot;color:green&quot;&gt; $&#123;BUILD_STATUS&#125;&lt;/span&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                                  &lt;li&gt;构建编号：$&#123;BUILD_NUMBER&#125;  &lt;/li&gt;</span></span><br><span class="line"><span class="string">                                  &lt;li&gt;构建者: $&#123;CAUSE&#125;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                                  &lt;li&gt;变更记录: $&#123;CHANGES,showPaths=true,showDependencies=true,format=&quot;&lt;pre&gt;&lt;ul&gt;&lt;li&gt;提交ID: %r&lt;/li&gt;&lt;li&gt;提交人：%a&lt;/li&gt;&lt;li&gt;提交时间：%d&lt;/li&gt;&lt;li&gt;提交信息：%m&lt;/li&gt;&lt;li&gt;提交文件：&lt;br /&gt;%p&lt;/li&gt;&lt;/ul&gt;&lt;/pre&gt;&quot;,pathFormat=&quot;         %p &lt;br /&gt;&quot;&#125;</span></span><br><span class="line"><span class="string">                              &lt;/ul&gt;</span></span><br><span class="line"><span class="string">                          &lt;/td&gt;</span></span><br><span class="line"><span class="string">                      &lt;/tr&gt;</span></span><br><span class="line"><span class="string">                  &lt;/table&gt;</span></span><br><span class="line"><span class="string">                &lt;/body&gt;</span></span><br><span class="line"><span class="string">              &lt;/html&gt;&#x27;</span><span class="string">&#x27;&#x27;</span>, subject: <span class="string">&#x27;$&#123;PROJECT_NAME&#125;&#x27;</span>, to: <span class="string">&#x27;xxxxxx@qq.com&#x27;</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
          <category> SonarQube </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
            <tag> SonarQube </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下安装SonarQube</title>
      <link href="2020/08/09/Linux%E4%B8%8B%E5%AE%89%E8%A3%85SonarQube/"/>
      <url>2020/08/09/Linux%E4%B8%8B%E5%AE%89%E8%A3%85SonarQube/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>SonarQube是管理代码质量的开放平台，可以快速的定位代码中潜在的或者明显的错误</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>下载sonar：<a href="https://www.sonarqube.org/downloads/%EF%BC%8C%E6%88%91%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AF7.0%E7%89%88%E6%9C%AC">https://www.sonarqube.org/downloads/，我使用的是7.0版本</a></p><h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><p>需要事先装好mysql，需要5.6以上版本，我这边安装的是5.7.30</p><h2 id="创建sonar用户"><a href="#创建sonar用户" class="headerlink" title="创建sonar用户"></a>创建sonar用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE USER <span class="string">&#x27;sonar&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;sonar&#x27;</span>;</span><br><span class="line">CREATE DATABASE sonar CHARACTER SET UTF8;</span><br><span class="line">GRANT ALL PRIVILEGES ON sonar.* TO <span class="string">&#x27;sonar&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure><h2 id="创建sonar系统用户"><a href="#创建sonar系统用户" class="headerlink" title="创建sonar系统用户"></a>创建sonar系统用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd sonar</span><br><span class="line">passwd sonar</span><br></pre></td></tr></table></figure><h2 id="安装sonar"><a href="#安装sonar" class="headerlink" title="安装sonar"></a>安装sonar</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#解压</span></span><br><span class="line">unzip sonarqube-7.0.zip</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改配置文件conf/sonar.properties</span></span><br><span class="line">sonar.jdbc.username=sonar</span><br><span class="line">sonar.jdbc.password=sonar</span><br><span class="line">sonar.jdbc.url=jdbc:mysql://192.168.37.137:3306/sonar?useUnicode=<span class="literal">true</span>&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=<span class="literal">true</span>&amp;useConfigs=maxPerformance&amp;useSSL=<span class="literal">false</span></span><br><span class="line">sonar.web.host=0.0.0.0</span><br><span class="line">sonar.web.context=</span><br></pre></td></tr></table></figure><h2 id="启动sonar"><a href="#启动sonar" class="headerlink" title="启动sonar"></a>启动sonar</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#改变权限</span></span><br><span class="line">chown -R sonar:sonar /usr/<span class="built_in">local</span>/sonarqube-7.0</span><br><span class="line">su sonar</span><br><span class="line">/usr/<span class="built_in">local</span>/sonarqube-7.0/bin/linux-x86-64/sonar.sh start</span><br></pre></td></tr></table></figure><p>最后通过ip:9000访问，默认用户名admin，密码admin</p><h2 id="安装中文插件"><a href="#安装中文插件" class="headerlink" title="安装中文插件"></a>安装中文插件</h2><p>下载sonar-l10n-zh-plugin-1.16.jar插件 <a href="https://github.com/SonarQubeCommunity/sonar-l10n-zh/releases/tag/sonar-l10n-zh-plugin-1.16">https://github.com/SonarQubeCommunity/sonar-l10n-zh/releases/tag/sonar-l10n-zh-plugin-1.16</a><br>将插件放到/usr/local/sonarqube-7.0/extensions/plugins目录下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/sonarqube-7.0/bin/linux-x86-64/sonar.sh restart</span><br></pre></td></tr></table></figure><h2 id="安装SonarScanner"><a href="#安装SonarScanner" class="headerlink" title="安装SonarScanner"></a>安装SonarScanner</h2><p>下载 <a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/">https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip sonar-scanner-cli-4.4.0.2170-linux.zip</span><br><span class="line"><span class="comment">#/etc/profile 配置环境变量</span></span><br><span class="line"><span class="built_in">export</span> SONAR_SCANNER_HOME=/usr/<span class="built_in">local</span>/sonar-scanner-4.4.0.2170-linux</span><br><span class="line">PATH=<span class="variable">$&#123;SONAR_SCANNER_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH</span><br><span class="line"><span class="comment">#使生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#查看版本</span></span><br><span class="line">sonar-scanner -v</span><br></pre></td></tr></table></figure><h2 id="配置sonar-scanner，关联sonarqube"><a href="#配置sonar-scanner，关联sonarqube" class="headerlink" title="配置sonar-scanner，关联sonarqube"></a>配置sonar-scanner，关联sonarqube</h2><p>在/usr/local/sonar-scanner-4.4.0.2170-linux/conf/sonar-scanner.properties中添加如下内容</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sonar.host.url=http://127.0.0.1:9000</span><br><span class="line">sonar.login=admin</span><br><span class="line">sonar.password=admin</span><br><span class="line">sonar.jdbc.username=sonar</span><br><span class="line">sonar.jdbc.password=sonar</span><br><span class="line">sonar.jdbc.url=jdbc:mysql://192.168.37.137:3306/sonar?useUnicode=<span class="literal">true</span>&amp;characterEncoding=utf8</span><br></pre></td></tr></table></figure><h2 id="扫描代码"><a href="#扫描代码" class="headerlink" title="扫描代码"></a>扫描代码</h2><p>在此之前需要安装需要的插件，例如sonar-java-plugin、sonar-findbugs-plugin、sonar-pdfreport-plugin-3.0.2等<br>在需要扫描的项目根目录下创建sonar-project.properties</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># must be unique in a given SonarQube instance</span></span><br><span class="line">sonar.projectKey=myproject</span><br><span class="line"><span class="comment"># this is the name displayed in the SonarQube UI</span></span><br><span class="line">sonar.projectName=myproject</span><br><span class="line">sonar.projectVersion=1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Path is relative to the sonar-project.properties file. Replace &quot;\&quot; by &quot;/&quot; on Windows.</span></span><br><span class="line"><span class="comment"># Since SonarQube 4.2, this property is optional if sonar.modules is set. </span></span><br><span class="line"><span class="comment"># If not set, SonarQube starts looking for source code from the directory containing </span></span><br><span class="line"><span class="comment"># the sonar-project.properties file.</span></span><br><span class="line">sonar.sources=.</span><br><span class="line">sonar.java.binaries=target/classes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding of the source code. Default is default system encoding</span></span><br><span class="line"><span class="comment">#sonar.sourceEncoding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#pdf</span></span><br><span class="line"><span class="comment">#sonar.pdf.username=admin</span></span><br><span class="line"><span class="comment">#sonar.pdf.password=admin</span></span><br><span class="line"><span class="comment">#sonar.pdf.skip=false</span></span><br></pre></td></tr></table></figure><p>执行sonar-scanner，完成后在sonarqube的web界面查看</p>]]></content>
      
      
      <categories>
          
          <category> SonarQube </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SonarQube </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7配置阿里云yum源</title>
      <link href="2020/08/09/CentOS7%E9%85%8D%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91yum%E6%BA%90/"/>
      <url>2020/08/09/CentOS7%E9%85%8D%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91yum%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="关闭selinux"><a href="#关闭selinux" class="headerlink" title="关闭selinux"></a>关闭selinux</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#临时关闭</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#永久关闭，将SELINUX=disabled ，需要重启后生效</span></span><br><span class="line">vi /etc/selinux/config</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="配置yum源"><a href="#配置yum源" class="headerlink" title="配置yum源"></a>配置yum源</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y wget</span><br><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d</span><br><span class="line">mv CentOS-Base.repo CentOS-Base.repo.bak</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line">yum update</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次生产内存泄漏问题</title>
      <link href="2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/"/>
      <url>2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>早上收到生产服务器JVM堆内存占用率达到80%的邮件报警,来到公司用Java VisualVM分析。</p><a id="more"></a><p><img src= "/img/loading.gif" data-lazy-src="/2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/a1.png"><br>从图上可以看到有个idle_connection_reaper的线程占用内存达到79%<br>然后我们dump下hprof文件分析看看<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/a2.png"><br>这个线程应该跟阿里云oss代码相关</p><p><img src= "/img/loading.gif" data-lazy-src="/2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/a3.png"><br>用MemoryAnalyzer工具再次分析一下hprof文件<br><img src= "/img/loading.gif" data-lazy-src="/2020/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/a4.png"><br>这个org.apache.http.impl.conn.PoolingHttpClientConnectionManager实例占用过多的内存<br>从com.aliyun.oss.ClientBuilderConfiguration可以判断跟oss连接有关，找了oss相关的连接代码<br>果然开发在new OSSClient的时候，没有调用ossClient.shutdown,造成内存泄漏</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mailx通过465端口发送邮件</title>
      <link href="2020/08/05/Mailx%E9%80%9A%E8%BF%87465%E7%AB%AF%E5%8F%A3%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/"/>
      <url>2020/08/05/Mailx%E9%80%9A%E8%BF%87465%E7%AB%AF%E5%8F%A3%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>由于阿里云关闭了25端口，所以需要修改mailx端口改为465发送邮件</p><a id="more"></a><h2 id="安装Mailx"><a href="#安装Mailx" class="headerlink" title="安装Mailx"></a>安装Mailx</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y mailx</span><br></pre></td></tr></table></figure><h2 id="开启SMTP服务并获取授权码"><a href="#开启SMTP服务并获取授权码" class="headerlink" title="开启SMTP服务并获取授权码"></a>开启SMTP服务并获取授权码</h2><p>登录邮箱-设置-账户<br>1、开启SMTP服务<br>2、获取授权码</p><h2 id="设置mail-rc"><a href="#设置mail-rc" class="headerlink" title="设置mail.rc"></a>设置mail.rc</h2><p>在/etc/mailx.rc最后一行添加</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> from=XXXXXXXX@qq.com</span><br><span class="line"><span class="built_in">set</span> smtp=smtps://smtp.qq.com:465</span><br><span class="line"><span class="built_in">set</span> smtp-auth-user=XXXXXXXXX@qq.com</span><br><span class="line"><span class="comment">#邮箱SMTP授权码</span></span><br><span class="line"><span class="built_in">set</span> smtp-auth-password=*********</span><br><span class="line"><span class="built_in">set</span> smtp-auth-login</span><br><span class="line"><span class="built_in">set</span> ssl-verify=ignore</span><br><span class="line"><span class="built_in">set</span> nss-config-dir=/tmp/.certs</span><br></pre></td></tr></table></figure><h2 id="设置证书"><a href="#设置证书" class="headerlink" title="设置证书"></a>设置证书</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/.certs/</span><br><span class="line"><span class="built_in">echo</span> -n | openssl s_client -connect smtp.qq.com:465 | sed -ne <span class="string">&#x27;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#x27;</span> &gt; ~/.certs/qq.crt</span><br><span class="line">certutil -A -n <span class="string">&quot;GeoTrust SSL CA&quot;</span> -t <span class="string">&quot;C,,&quot;</span> -d ~/.certs -i ~/.certs/qq.crt</span><br><span class="line">certutil -A -n <span class="string">&quot;GeoTrust Global CA&quot;</span> -t <span class="string">&quot;C,,&quot;</span> -d ~/.certs -i ~/.certs/qq.crt</span><br><span class="line"><span class="built_in">cd</span>  /root/.certs/</span><br><span class="line">certutil -A -n <span class="string">&quot;GeoTrust SSL CA - G3&quot;</span> -t <span class="string">&quot;Pu,Pu,Pu&quot;</span> -d ~/.certs/./ -i qq.crt</span><br><span class="line">certutil -L -d /root/.certs</span><br><span class="line">cp -a /root/.certs/ /tmp/</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;content&quot;</span> | mail -s <span class="string">&quot;title&quot;</span> XXXXXXXX@qq.com</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mailx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitLab配置邮箱</title>
      <link href="2020/07/13/GitLab%E9%85%8D%E7%BD%AE%E9%82%AE%E7%AE%B1/"/>
      <url>2020/07/13/GitLab%E9%85%8D%E7%BD%AE%E9%82%AE%E7%AE%B1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="开启相应的邮箱服务"><a href="#开启相应的邮箱服务" class="headerlink" title="开启相应的邮箱服务"></a>开启相应的邮箱服务</h2><p>我这边使用的qq邮箱，获取授权码</p><a id="more"></a><p><img src= "/img/loading.gif" data-lazy-src="/2020/07/13/GitLab%E9%85%8D%E7%BD%AE%E9%82%AE%E7%AE%B1/a1.png"></p><h2 id="配置gitlab-rb"><a href="#配置gitlab-rb" class="headerlink" title="配置gitlab.rb"></a>配置gitlab.rb</h2><p>vim /etc/gitlab/gitlab.rb</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#第一处</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_enable&#x27;</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_address&#x27;</span>] = <span class="string">&quot;smtp.qq.com&quot;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_port&#x27;</span>] = 465</span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_user_name&#x27;</span>] = <span class="string">&quot;你的邮箱@qq.com&quot;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_password&#x27;</span>] = <span class="string">&quot;授权码&quot;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_domain&#x27;</span>] = <span class="string">&quot;qq.com&quot;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_authentication&#x27;</span>] = <span class="string">&quot;login&quot;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_enable_starttls_auto&#x27;</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;smtp_tls&#x27;</span>] = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#第二处</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;gitlab_email_enabled&#x27;</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;gitlab_email_from&#x27;</span>] = <span class="string">&#x27;你的邮箱@qq.com&#x27;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;gitlab_email_display_name&#x27;</span>] = <span class="string">&#x27;gitlab server&#x27;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;gitlab_email_reply_to&#x27;</span>] = <span class="string">&#x27;你的邮箱@qq.com&#x27;</span></span><br><span class="line">gitlab_rails[<span class="string">&#x27;gitlab_email_subject_suffix&#x27;</span>] = <span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>配置完成后</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitlab-ctl stop</span><br><span class="line">gitlab-ctl reconfigure</span><br><span class="line">gitlab-ctl start</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>输入 gitlab-rails console 进入控制台</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Notify.test_email(<span class="string">&#x27;接收方邮件地址&#x27;</span>,<span class="string">&#x27;邮件标题&#x27;</span>,<span class="string">&#x27;邮件内容&#x27;</span>).deliver_now</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GitLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitLab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ERROR Maven JVM terminated unexpectedly with exit code 137</title>
      <link href="2020/07/13/ERROR-Maven-JVM-terminated-unexpectedly-with-exit-code-137/"/>
      <url>2020/07/13/ERROR-Maven-JVM-terminated-unexpectedly-with-exit-code-137/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>jenkins利用maven打包，job控制台出现ERROR Maven JVM terminated unexpectedly with exit code 137<br>这是由于机器内存不足导致的</p>]]></content>
      
      
      <categories>
          
          <category> Maven </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云PTS压测大量请求出现502、503</title>
      <link href="2020/07/13/%E9%98%BF%E9%87%8C%E4%BA%91PTS%E5%8E%8B%E6%B5%8B%E5%A4%A7%E9%87%8F%E8%AF%B7%E6%B1%82%E5%87%BA%E7%8E%B0502%E3%80%81503/"/>
      <url>2020/07/13/%E9%98%BF%E9%87%8C%E4%BA%91PTS%E5%8E%8B%E6%B5%8B%E5%A4%A7%E9%87%8F%E8%AF%B7%E6%B1%82%E5%87%BA%E7%8E%B0502%E3%80%81503/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>在阿里云文档那边找到了一篇类似的文档说这种情况可能是由于SLB单IP限流导致的，我在压测的时候来源IP大概有5个，然后提了工单问了技术，看看是不是SLB限流导致的，但阿里云那边说不是SLB导致的。接着我就一边压测一边看后端应用服务器日志，我的整个项目是SLB分发到ECS服务器的tomcat上。</p><a id="more"></a><h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>压测的时候发现日志输出错误日志了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">javax.servlet.ServletException: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisExhaustedPoolException: Could not get a resource since the pool is exhausted</span><br><span class="line">    at org.apache.jsp.api.cand.intv.ajaxHandInInfo_jsp._jspService(ajaxHandInInfo_jsp.java:651)</span><br><span class="line">    at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:71)</span><br><span class="line">    at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)</span><br><span class="line">    at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:477)</span><br><span class="line">    at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:385)</span><br><span class="line">    at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:329)</span><br><span class="line">    at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at com.up72.filter.ParamFilter.doFilter(ParamFilter.java:25)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.tuckey.web.filters.urlrewrite.RuleChain.handleRewrite(RuleChain.java:176)</span><br><span class="line">    at org.tuckey.web.filters.urlrewrite.RuleChain.doRules(RuleChain.java:145)</span><br><span class="line">    at org.tuckey.web.filters.urlrewrite.UrlRewriter.processRequest(UrlRewriter.java:92)</span><br><span class="line">    at org.tuckey.web.filters.urlrewrite.UrlRewriteFilter.doFilter(UrlRewriteFilter.java:389)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)</span><br><span class="line">    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)</span><br><span class="line">    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:151)</span><br><span class="line">    at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81)</span><br><span class="line">    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)</span><br><span class="line">    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)</span><br><span class="line">    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)</span><br><span class="line">    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)</span><br><span class="line">    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)</span><br><span class="line">    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)</span><br><span class="line">    at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:690)</span><br><span class="line">    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)</span><br><span class="line">    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)</span><br><span class="line">    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373)</span><br><span class="line">    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)</span><br><span class="line">    at org.apache.coyote.AbstractProtocol<span class="variable">$ConnectionHandler</span>.process(AbstractProtocol.java:868)</span><br><span class="line">    at org.apache.tomcat.util.net.NioEndpoint<span class="variable">$SocketProcessor</span>.doRun(NioEndpoint.java:1590)</span><br><span class="line">    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:624)</span><br><span class="line">    at org.apache.tomcat.util.threads.TaskThread<span class="variable">$WrappingRunnable</span>.run(TaskThread.java:61)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><p>大概从第一行就可以看出jedis在连接redis的时候获取不到资源。然后我看了一下阿里云redis连接数远远没有达到最大连接数的上限，有很长一段时间停留在1000，基本可以判断是代码那边设置了最大连接数。<br>找了redis配置，redis.pool.maxTotal=1000是这个配置导致的</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PTS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes笔记二(pod控制器的创建与管理)</title>
      <link href="2020/06/03/Kubernetes%E7%AC%94%E8%AE%B0%E4%BA%8C-pod%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E7%AE%A1%E7%90%86/"/>
      <url>2020/06/03/Kubernetes%E7%AC%94%E8%AE%B0%E4%BA%8C-pod%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>pod控制器由控制器管理器kube-controller-manager组件提供，pod控制器主要用于对pod创建、修改、删除等操作。常见的pod控制器有Replication Controller、ReplicaSet、Deployment、DaemonSet、StatefulSet、Job、CronJob。</p><a id="more"></a><h2 id="ReplicaSet控制器"><a href="#ReplicaSet控制器" class="headerlink" title="ReplicaSet控制器"></a>ReplicaSet控制器</h2><p>ReplicaSet控制器主要用于保证pod的副本数在任何时候都能精确满足我们的期望值<br>（1）ReplicaSet控制器主要功能<br>    1）保证pod的副本数满足期望值<br>    2）保证pod健康运行<br>    3）弹性伸缩<br>（2）资源清单<br>ReplicaSet控制器资源定义与pod相似，其spec字段嵌套的子字段及作用如下<br>    replicas：期望的pod副本数目<br>    selector：当前控制器匹配pod对象的标签选择器，支持matchLabels和matchExpressions两种匹配机制<br>    template：用于创建pod时使用的pod资源模版<br>    minReadySeconds：新建的pod在启动多长时间后，容器未发生崩溃等异常情况，则视为就绪，默认为0</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: ReplicaSet</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-replicaset</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: twf/nginx:v1</span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 80</span><br></pre></td></tr></table></figure><p>（3）维护期望的pod副本数目<br>修改一个pod的label后，ReplicaSet发现pod副本数目减上了，会重新再创建一个</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改期望数</span></span><br><span class="line">kubectl scale rs <span class="built_in">test</span>-replicaset --replicas=3</span><br><span class="line">kubectl label pods <span class="built_in">test</span>-replicaset-t6lr6 app=twf --overwrite</span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p>（4）删除replicaset控制器资源<br>使用“kubectl delete”命令删除replicaset对象时默认会一并删除其管控的pod对象，有时，这些pod资源可能不是replicaset控制器创建的，此时可以使用“–cascade=false”选项，取消级联，删除相关的pod对象。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除名称为test-replicaset的replicaset控制器，并取消与pod的级联</span></span><br><span class="line">kubectl delete replicaset <span class="built_in">test</span>-replicaset --cascade=<span class="literal">false</span></span><br><span class="line"><span class="comment">#kubectl get pods -l app=test-rep</span></span><br></pre></td></tr></table></figure><h2 id="Deployment控制器"><a href="#Deployment控制器" class="headerlink" title="Deployment控制器"></a>Deployment控制器</h2><p>Deployment是在RS控制器之上的，可为Pod和ReplicaSet资源提供声明式更新的一种控制器；Deployment控制器的主要作用还是为了Pod资源的健康运行，但大部分功能可以通过调节ReplicaSet控制器来实现，同时还添加了事件和状态查看、回滚、版本记录、暂停和启动、多种自动更新方案等特性。<br>（1）创建Deployment控制器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: twf/nginx:v2</span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 80</span><br></pre></td></tr></table></figure><p>（2）Deployment控制器更新策略<br>相对于RS控制器，Deployment控制器更新只需要用于指定在pod模版中需要修改的内容，剩下的步骤由其自动完成<br>Deployment控制器也支持两种更新策略，重新创建和滚动更新，默认更新策略是滚动更新<br>    1）重新创建（recreate）：重新创建是先删除现有的pod对象，然后由控制器基于新模版重新创建出新版本的资源对象<br>    2）滚动更新（rolling update）：在删除一部分旧版本pod的同时。补充新建一部分新版本的pod对象。<br>（3）更新</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新镜像</span></span><br><span class="line">kubectl <span class="built_in">set</span> image deployment <span class="built_in">test</span>-deployment nginx=twf/nginx:v1 --record</span><br><span class="line"><span class="comment">#暂停更新</span></span><br><span class="line">kubectl rollout pause deployments <span class="built_in">test</span>-deployment</span><br><span class="line"><span class="comment">#查看更新过程中的状态信息</span></span><br><span class="line">kubectl rollout status deployments <span class="built_in">test</span>-deployment</span><br><span class="line"><span class="comment">#继续之前的更新</span></span><br><span class="line">kubectl rollout resume deployments <span class="built_in">test</span>-deployment</span><br></pre></td></tr></table></figure><p>（4）回滚<br>在更新过程中，如果更新失败时，可能需要回滚到之前的版本或者指定的版本</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#回滚到上个版本</span></span><br><span class="line">kubectl rollout undo deployments <span class="built_in">test</span>-deployment</span><br><span class="line"><span class="comment">#查看历史版本</span></span><br><span class="line">kubectl rollout <span class="built_in">history</span> deployments <span class="built_in">test</span>-deployment</span><br><span class="line"><span class="comment">#回退指定版本</span></span><br><span class="line">kubectl rollout undo deployments <span class="built_in">test</span>-deployment --to-revision=1</span><br></pre></td></tr></table></figure><h2 id="DaemonSet控制器"><a href="#DaemonSet控制器" class="headerlink" title="DaemonSet控制器"></a>DaemonSet控制器</h2><p>DaemonSet确保全部（或者一些）Node上运行一个pod副本，当有Node加入集群时，也会为他们新增一个pod，当Node从集群中剔除时，也会回收这些pod。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-daemonset</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: twf/nginx:v1</span><br></pre></td></tr></table></figure><h2 id="Job控制器"><a href="#Job控制器" class="headerlink" title="Job控制器"></a>Job控制器</h2><p>job负责处理任务，即仅执行一次的任务，它保证处理任务的一个或多个pod成功结束<br>job的RestartPolicy仅支持Never和OnFailure两种</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-job</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: job-demo</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: Never</span><br><span class="line">      containers:</span><br><span class="line">      - name: busybox</span><br><span class="line">        image: busybox</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - <span class="string">&quot;bin/sh&quot;</span></span><br><span class="line">        - <span class="string">&quot;-c&quot;</span></span><br><span class="line">        - <span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo <span class="variable">$1</span>; done&quot;</span></span><br></pre></td></tr></table></figure><h2 id="CronJob控制器"><a href="#CronJob控制器" class="headerlink" title="CronJob控制器"></a>CronJob控制器</h2><p>CronJob其实就是在Job的基础上加了时间调度，也就是周期性的在给定时间执行。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-cronjob</span><br><span class="line">spec:</span><br><span class="line">  schedule: <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  successfulJobsHistoryLimit: 2</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          containers:</span><br><span class="line">          - name: busybox</span><br><span class="line">            image: busybox</span><br><span class="line">            <span class="built_in">command</span>:</span><br><span class="line">            - <span class="string">&quot;bin/sh&quot;</span></span><br><span class="line">            - <span class="string">&quot;-c&quot;</span></span><br><span class="line">            - <span class="string">&quot;for i in 9 8 7 ; do echo <span class="variable">$i</span>; done&quot;</span></span><br></pre></td></tr></table></figure><p>spec.successfulJobsHistoryLimit和spec.failedJobHistoryLimit表示历史限制，可选字段，它们指定了可以保留多少完成和失败的Job，默认没有限制，建议设置</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes笔记一(pod资源创建与管理)</title>
      <link href="2020/05/30/Kubernetes%E7%AC%94%E8%AE%B0%E4%B8%80-pod%E8%B5%84%E6%BA%90%E5%88%9B%E5%BB%BA%E4%B8%8E%E7%AE%A1%E7%90%86/"/>
      <url>2020/05/30/Kubernetes%E7%AC%94%E8%AE%B0%E4%B8%80-pod%E8%B5%84%E6%BA%90%E5%88%9B%E5%BB%BA%E4%B8%8E%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  pod是kubernetes最重要的基本概念，它是kubernetes系统中最小的调度单位。每一个pod都有一个特殊的pause根容器，kubernetes为每个pod都提供了一个根容器，如果单独对一组容器进行管理，那么一个容器死亡，到底算不算整体死亡，为了解决这个难题，巧妙的设计了pause根容器对业务容器进行管理，所有的业务容器共享pause容器的IP、挂载的volume，简化了容器之间的通信问题。<br>  pod分为普通的pod和静态pod。普通pod一旦被创建，就会被放入etcd中存储，随后被kubernetes master调度到node上进行绑定，接着pod被node上的kubelet进程实例化成一组相关的docker容器并启动。静态pod比较特殊，它并不存储在etcd里，而是被保存在某个具体node上的一个具体文件中。</p><a id="more"></a><h2 id="pod管理"><a href="#pod管理" class="headerlink" title="pod管理"></a>pod管理</h2><p>Pod在kubernetes中也是一种资源，pod资源的定义是通过“apiVersion”、“kind”、“metadata”、“spec”、“status”五个部分组成，除了“status”字段中的信息是系统自动生成外，其余各字段都需要管理员定义。<br>（1）Containers中关于容器的字段常用字段有：<br>    1）name：必选字段，用于指定容器名称<br>    2）image：可选字段，定义容器运行时的镜像，但是自助式pod不能省略此字段<br>    3）imagePullPolicy：用于指定镜像的获取策略，主要的值有：<br>        Always：当镜像不存在或不是最新镜像时，则从指定仓库中拉取镜像<br>        IfNotPresent：当需要运行的镜像在本地不存在时，则从指定的仓库中下载镜像<br>        Nerver：仅使用本地镜像，不去仓库中下载镜像<br>（2）暴露pod中服务的端口<br>    Containers字段中的ports字段用于暴露容器的端口，容器的ports字段的值是一个列表，由一到多个端口对象组成，常用的嵌套字段如下：<br>        1）containerPort：必选字段，指定在Pod对象的ip地址上暴露的容器端口<br>        2）name：当前容器端口的名称，需在当前pod中唯一，此端口可以被Service资源调用<br>        3）protocol：端口相关的协议，值为tcp或udp<br>    Pod对象的ip地址仅可在当前集群内可达，集群外是无法访问的，当集群外需要访问pod中的服务时，可定义node节点的IP地址及端口，将pod中的服务端口映射到node上，外部通过node节点访问，一般都不建议这样做，常用的做法是通过service的NodePort模式访问pod内的服务<br>        4）hostPort：主机端口<br>        5）hostIP：主机端口要绑定主机ip</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myweb</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: twf/nginx:v1</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 80</span><br><span class="line">      protocol: TCP</span><br></pre></td></tr></table></figure><p>（3）为pod的容器定义环境变量</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: env-test</span><br><span class="line">  labels:</span><br><span class="line">    app: env</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx-env</span><br><span class="line">    image: twf/nginx:v1</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 80</span><br><span class="line">    env:</span><br><span class="line">    - name: NGINX_ENV</span><br><span class="line">      value: <span class="string">&#x27;twf-v1&#x27;</span></span><br><span class="line">    - name: NGINX_PORT</span><br><span class="line">      value: <span class="string">&#x27;80&#x27;</span></span><br></pre></td></tr></table></figure><p>（4）为pod容器共享节点的网络名称空间<br>通过hostNetwork设置true</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: hostnetwork</span><br><span class="line">  labels:</span><br><span class="line">    app: hostnetwork</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx-hostnetwork</span><br><span class="line">    image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">  hostNetwork: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#node节点查看暴露的服务</span></span><br><span class="line">netstat -anpt |grep 80</span><br></pre></td></tr></table></figure><p>（5）pod资源中安全设置<br>Pod对象的安全定义在spec.securityContext字段中，容器的安全定义在spec.containers.securityContext字段中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-busybox</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    <span class="built_in">command</span>: [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;sleep 3600&quot;</span>]</span><br><span class="line">    securityContext:</span><br><span class="line">      runAsNonRoot: <span class="literal">true</span></span><br><span class="line">      runAsUser: 1000</span><br><span class="line">      allowPrivilegeEscalation: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">kubectl <span class="built_in">exec</span> <span class="built_in">test</span>-busybox -it -- ps</span><br></pre></td></tr></table></figure><h2 id="pod中标签与标签选择器的定义与管理"><a href="#pod中标签与标签选择器的定义与管理" class="headerlink" title="pod中标签与标签选择器的定义与管理"></a>pod中标签与标签选择器的定义与管理</h2><p>Pod中标签（label）的主要功能就是对pod进行分类管理，从而提升运维及管理效率；而标签选择器（label selector）则可以挑选出符合过滤条件的资源完成需要的操作。<br>标签是键值类型的数据，能够附加于kubernetes的任何资源对象上，标签可以在创建资源时指定也可以按需添加，一个对象可以拥有多个标签。<br>（1）pod资源的标签管理<br>Pod资源的标签在metadata.labels中定义</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在pod资源中定义标签</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-nginx</span><br><span class="line">  labels:</span><br><span class="line">    env: dev</span><br><span class="line">    version: v1.0</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line"><span class="comment">#查看所有的标签</span></span><br><span class="line">kubectl get pods --show-labels</span><br><span class="line"><span class="comment">#列出有指定标签的资源信息</span></span><br><span class="line">kubectl get pods -L env</span><br></pre></td></tr></table></figure><p>当pod创建好之后，也可以通过“kubectl label”命令为pod资源添加标签，如果pod中已经有了指定键名的标签，可以通过“–overwrite”命令强制覆盖原有标签</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#为指定pod资源添加标签</span></span><br><span class="line">kubectl label pods <span class="built_in">test</span>-nginx app=cache</span><br><span class="line"><span class="comment">#修改指定pod资源标签</span></span><br><span class="line">kubectl label pods <span class="built_in">test</span>-nginx env=pro --overwrite</span><br></pre></td></tr></table></figure><p>（2）标签选择器的使用<br>标签选择器用于表达标签的查询条件或选择标准，在使用标签选择器时，要注意多个选择器之间的关系为“与”操作，使用空值的标签选择器意味着每个资源对象都被选中，空的标签选择器无法选出任何内容。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出app不等于cache的资源</span></span><br><span class="line">kubectl get pods -l <span class="string">&quot;app!=cache&quot;</span> --show-labels</span><br><span class="line"><span class="comment">#列出标签app不等于cache且run等于nginx-deploy的pod资源</span></span><br><span class="line">kubectl get pods -l <span class="string">&quot;app!=cache,run=nginx-deploy&quot;</span> -L run,app</span><br></pre></td></tr></table></figure><p>kubernetes api支持基于等值关系和集合关系的选择器，基于集合关系的标签选择器支持in、notin、exists三种操作符。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出标签app为cache或者backend的pod资源</span></span><br><span class="line">kubectl get pods -l <span class="string">&quot;app in (cache,backend)&quot;</span> -L app</span><br><span class="line"><span class="comment">#列出不等于env标签的pod资源</span></span><br><span class="line">kubectl get pods -l <span class="string">&quot;!env&quot;</span> --show-labels</span><br></pre></td></tr></table></figure><h2 id="Pod节点选择器"><a href="#Pod节点选择器" class="headerlink" title="Pod节点选择器"></a>Pod节点选择器</h2><p>Pod节点选择器nodeSelector能够让pod对象基于集群中的工作节点的标签来挑选运行pod的node节点。在使用pod节点选择器之前，需要为node资源添加标签，添加标签的方法同为pod资源添加标签方法相同。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#为两个node节点分别添加标签</span></span><br><span class="line">kubectl label nodes k8s-node1 server=nginx</span><br></pre></td></tr></table></figure><p>Pod资源中定义节点选择器时通过spec.nodeSelector字段定义</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义一个pod资源，让其运行在node1节点上</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata: </span><br><span class="line">  name: <span class="built_in">test</span>-nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx:1.12</span><br><span class="line">  nodeSelector:</span><br><span class="line">    server: nginx</span><br></pre></td></tr></table></figure><h2 id="Pod资源注解"><a href="#Pod资源注解" class="headerlink" title="Pod资源注解"></a>Pod资源注解</h2><p>除了标签之外，Pod与其他各种资源还能使用资源注解（annotation）；与标签类似，注解也是通过键值类型的数据，注解仅用于为资源提供元数据信息。而资源的注解可由用户手动添加，也可由工具程序自动附加使用。<br>（1）管理资源注解<br>资源注解的创建可在定义资源时使用metadata.annotations字段指定，也可在资源创建后通过“kubectl annotate”命令进行附加。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义资源时添加资源注解</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-annotation</span><br><span class="line">  labels:</span><br><span class="line">    env: dev</span><br><span class="line">  annotations:</span><br><span class="line">    server-explain: nginx server is node1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx:1.12</span><br><span class="line">  nodeSelector:</span><br><span class="line">    server: nginx</span><br><span class="line">    </span><br><span class="line"><span class="comment">#为创建好的资源添加资源注解</span></span><br><span class="line">kubectl annotate pods <span class="built_in">test</span>-annotation auth=<span class="string">&quot;123&quot;</span> </span><br></pre></td></tr></table></figure><p>（2）查看资源注解<br>资源注解的查看可以通过“kubectl describe”查看，或者pod导出为yaml格式查看</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看资源注解</span></span><br><span class="line">kubectl describe pods <span class="built_in">test</span>-annotation</span><br></pre></td></tr></table></figure><h2 id="Pod资源存活性检测"><a href="#Pod资源存活性检测" class="headerlink" title="Pod资源存活性检测"></a>Pod资源存活性检测</h2><p>kubernetes对容器的存活性检测能够发现不可能用状态的容器，并对该容器进行重启等操作。jubernetes存活性探测的主要方法有ExecAction、TCPSocketAction、HTTPGetAction。<br>（1）使用exec探针检测容器的存活性<br>Exec探针通过在目标容器中执行由用户自定义的命令来判断容器的健康状态，exec探针由“spec.containers.livenessProbe.exec”字段组成，该字段只有一个“command”属性来定义要执行的命令。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args: [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tem/test123;sleep 60;rm -rf /tem/test123;sleep 300&quot;</span>]</span><br><span class="line">    livenessProbe:</span><br><span class="line">      <span class="built_in">exec</span>:</span><br><span class="line">        <span class="built_in">command</span>: [<span class="string">&quot;test&quot;</span>,<span class="string">&quot;-f&quot;</span>,<span class="string">&quot;/tem/test123&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#一段时间后查看pod重启情况</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p>（2）使用http探针<br>基于http的探测是向目标容器发起一个http请求，根据其相应码进行结果的判定，该字段通过“spec.containers.livenessProbe.httpGet”字段定义，相关的字段有：<br>    1）port：必选字段，用于定义请求的端口<br>    2）httpHeaders：自定义的请求报文首部<br>    3）path：请求http资源的路径<br>    4）scheme：建立连接使用的协议，默认为http</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-http</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 80</span><br><span class="line">    lifecycle:</span><br><span class="line">      portStart:</span><br><span class="line">        <span class="built_in">exec</span>:</span><br><span class="line">          <span class="built_in">command</span>: [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;echo testhttp &gt; /usr/share/nginx/html/testhttp&quot;</span>]</span><br><span class="line">  livenessProbe:</span><br><span class="line">    httpGet:</span><br><span class="line">      port: http</span><br><span class="line">      path: /testhttp</span><br><span class="line">      scheme: HTTP</span><br></pre></td></tr></table></figure><p>（3）使用TCP探针<br>基于TCP的存活性探测是用于向容器的特定端口发起TCP请求并尝试建立连接建立结果判定。该探针的使用主要是通过“spec.containers.livenessProbe.tcpSocket”字段来定义。主要字段有：<br>    1）host：请求连接的目标IP地址，默认为Pod ip<br>    2）port：必选字段，请求连接的目标端口</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myweb</span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">    livenessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: 80</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      periodSeconds: 20</span><br></pre></td></tr></table></figure><p>（4）存活性探测的行为属性<br>除了探测器自身字段属性行为，还可以配置一些其他的行为属性，其他的行为属性字段在“spec.containers.livenessProbe”字段下设置，主要有：<br>    1）initialDelySeconds：设置存活性探测的延迟时长，即容器启动多久之后开始第一次探测，默认为0。<br>    2）timeoutSeconds：存活性探测的超时时长，默认为1s，最小值也为1s。<br>    3）periodSeconds：存活性探测的频度，默认为10s，最小值可设置为1s。<br>    4）successThreshold：处于失败状态时，探测器操作连续多少次的成功才被认为是通过检测，默认为1。<br>    5）failureThreshold：处于成功状态时，探测器操作至少连续多少次的失败才被视为是检测不通过。默认为3。<br>这些属性设置后都可以通过“kubectl describe”命令查看，各项设置在命令输出的liveness字段中，delay为存活性探测的延迟时长，timeout为存活性探测的超时时长，period为存活性探测的频率，success为失败状态转为成功状态的探测成功次数，failure为成功状态转为失败状态时的探测失败次数。</p><h2 id="Pod的就绪性探测"><a href="#Pod的就绪性探测" class="headerlink" title="Pod的就绪性探测"></a>Pod的就绪性探测</h2><p>Pod的就绪性探测主要用于在探测到容器尚未就绪时，触发依赖于其就绪状态的操作，确保不会有客户端请求接入此pod操作。就绪性探测也支持Exec、HTTP GET和TCP Socket三种探测方式。就绪性探测的使用方法同存活性探测使用方法基本相同，就绪性探测主要通过“pod.spec.containers.readinessProbe”字段设置<br>在未定义就绪性的Pod对象在Pod进入Running状态后将立即就绪</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myweb</span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">    readinessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: 80</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 10</span><br><span class="line">    livenessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: 80</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      periodSeconds: 20</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logrotate使用简介</title>
      <link href="2020/05/29/logrotate%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B/"/>
      <url>2020/05/29/logrotate%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>  随着时间的增长和业务的扩张，对于忙碌的服务器来说，日志文件的大小会增长极快，服务器会很快消耗磁盘空间，而且系统人员查看单个庞大的文件也及其困难。<br>  logrotate是一个日志管理工具，它可以对日志进行切割、轮替、压缩等。</p><a id="more"></a><h2 id="配置文件介绍"><a href="#配置文件介绍" class="headerlink" title="配置文件介绍"></a>配置文件介绍</h2><p>1）/etc/logrotate.conf<br>logrotate主要配置文件<br>2)/etc/logrotate.d<br>是个目录，我们可以将自己需要滚动的日志配置放到这个下面<br>3)/var/lib/logrotate/logrotate.status<br>记录logrotate滚动状态的信息</p><h2 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h2><table><thead><tr><th align="left">配置参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">monthly</td><td align="left">指定日志按月轮替，可选”daily”,”weekly”,”yearly”</td></tr><tr><td align="left">rotate 5</td><td align="left">一次将存储5个归档日志，当出现第6个日志，删除时间最久的归档日志</td></tr><tr><td align="left">compress</td><td align="left">在轮替完成后，将以轮替的归档日志进行压缩</td></tr><tr><td align="left">delaycompress</td><td align="left">经常与compress一起使用，delaycompress指示logrotate不要将最近的归档压缩，压缩将在下一次轮替周期进行</td></tr><tr><td align="left">missingok</td><td align="left">日志轮替期间，任何错误都被忽略</td></tr><tr><td align="left">notifempty</td><td align="left">如果日志为空，轮替不进行</td></tr><tr><td align="left">create 644 root root</td><td align="left">指定新创建日志的权限，同时logrotate也会重命名原始文件</td></tr><tr><td align="left">postrotate/endscript</td><td align="left">在所有指令完成后，postrotate和endscript里面指定的命令将被执行</td></tr></tbody></table><h2 id="对redis日志进行切割、轮替"><a href="#对redis日志进行切割、轮替" class="headerlink" title="对redis日志进行切割、轮替"></a>对redis日志进行切割、轮替</h2><p>vim /etc/logrotate.d/redis</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/src/redis-5.0.3/logs/redis.log &#123;</span><br><span class="line">        rotate 5</span><br><span class="line">        create</span><br><span class="line">        daily</span><br><span class="line">        dateext</span><br><span class="line">        postrotate</span><br><span class="line">                /bin/<span class="built_in">kill</span> -HUP `cat /var/run/redis_6379.pid`</span><br><span class="line">        endscript</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#手动强制切割</span></span><br><span class="line">logrotate -v -f /etc/logrotate.d/redis</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logrotate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LVM逻辑卷管理</title>
      <link href="2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/"/>
      <url>2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="什么是LVM"><a href="#什么是LVM" class="headerlink" title="什么是LVM"></a>什么是LVM</h2><p>  LVM是逻辑卷管理的简称，它可以对linux下的磁盘进行管理，LVM是建立在硬盘分区之上的一个逻辑层，主要可以对分区进行灵活的扩容、缩减等管理。</p><a id="more"></a><h2 id="为什么要使用LVM"><a href="#为什么要使用LVM" class="headerlink" title="为什么要使用LVM"></a>为什么要使用LVM</h2><p>  在日常工作和学习中，随着时间的增长和业务的扩展，我们的磁盘空间会越来越小，如果是普通分区，是不支持进行扩容的，一些扩容手段即使达到扩容效果，也是有潜在风险的。这时候我们就可以使用LVM，LVM将存储虚拟化，使用逻辑卷，你不会受限于物理磁盘的大小，即使后面磁盘剩余空间快不够了，也可以添加新的硬盘，进行在分区。</p><h2 id="LVM示意图"><a href="#LVM示意图" class="headerlink" title="LVM示意图"></a>LVM示意图</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a1.png"></p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>（1）准备添加一块20G硬盘<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a2.png"><br>（2）分3个分区<br>默认分区要改成LVM（8e）<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a3.png"><br>（3）物理卷管理</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建物理卷</span></span><br><span class="line">pvcreate /dev/sdb5</span><br><span class="line">pvcreate /dev/sdb6</span><br><span class="line">pvcreate /dev/sdb7</span><br><span class="line"><span class="comment">#查看物理卷</span></span><br><span class="line">pvscan</span><br><span class="line">pvdisplay</span><br><span class="line"><span class="comment">#删除物理卷</span></span><br><span class="line">pvremove /dev/sdb5</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a4.png"><br>（4）卷组管理</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#建立卷组,名称是scvg,将/dev/sdb5 /dev/sdb6 加入卷组</span></span><br><span class="line">vgcreate scvg /dev/sdb5 /dev/sdb6</span><br><span class="line"><span class="comment">#查看卷组</span></span><br><span class="line">vgdisplay</span><br><span class="line"><span class="comment">#扩容，将/dev/sdb7加入scvg卷组</span></span><br><span class="line">vgextend scvg /dev/sdb7</span><br><span class="line"><span class="comment">#缩减（不推荐）</span></span><br><span class="line">vgreduce scvg /dev/sdb7</span><br><span class="line"><span class="comment">#删除卷组</span></span><br><span class="line">vgremove scvg</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a5.png"><br>（5）逻辑卷管理</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建逻辑卷，-L指定大小，-n指定逻辑卷名称</span></span><br><span class="line">lvcreate -L 3G -n sclv scvg</span><br><span class="line">lvcreate -L 2G -n sclv2 scvg</span><br><span class="line"><span class="comment">#查看lv</span></span><br><span class="line">lvdisplay</span><br><span class="line"><span class="comment">#调整逻辑卷大小</span></span><br><span class="line">lvresize -L 5G -n /dev/scvg/sclv</span><br></pre></td></tr></table></figure><p>（6）挂载</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#格式化</span></span><br><span class="line">mkfs -t ext4 /dev/scvg/sclv</span><br><span class="line">mkfs -t ext4 /dev/scvg/sclv2</span><br><span class="line"><span class="comment">#创建文件，挂载</span></span><br><span class="line">mount /dev/scvg/sclv lv1</span><br><span class="line">mount /dev/scvg/sclv2 lv2</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a6.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a7.png"><br>注意：如果分区已经挂载好了,LVM不需要卸载就可以进行扩展分区，使用lvresize调整逻辑卷大小后，使用resize2fs /dev/scvg/sclv2就可以使扩展的分区生效<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/27/LVM%E9%80%BB%E8%BE%91%E5%8D%B7%E7%AE%A1%E7%90%86/a7.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>磁盘配额</title>
      <link href="2020/05/25/%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D/"/>
      <url>2020/05/25/%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="什么是磁盘配额"><a href="#什么是磁盘配额" class="headerlink" title="什么是磁盘配额"></a>什么是磁盘配额</h2><p>  磁盘配额是用来限制用户和用户组的磁盘使用额度，简单的说就是可以限制用户、用户组在该分区下使用的文件大小和文件数量。<br>  注意：磁盘配额无法限制root用户</p><a id="more"></a><h2 id="磁盘配额相关术语"><a href="#磁盘配额相关术语" class="headerlink" title="磁盘配额相关术语"></a>磁盘配额相关术语</h2><p>blocks限制：限制用户、用户组在该分区下使用的文件大小<br>inode限制：限制用户、用户组在该分区下创建的最大文件数量<br>软限制：超出此范围会被警告，但仍可以继续使用和创建，超出部分会保存到宽限时间期<br>硬限制：最高限制，用户使用容量不能超过这个限制<br>宽限时间：当你的磁盘用量处于soft和hard之间时，系统会给予警告，但也会给一段时间让用户自行管理磁盘，这段时间就是宽限时间，如果到了宽限时间，用户没有进行任何磁盘管理，soft限值会被hard限值取代进行限制</p><h2 id="配置磁盘配额"><a href="#配置磁盘配额" class="headerlink" title="配置磁盘配额"></a>配置磁盘配额</h2><p>  我们现在对/dev/sdb5分区进行磁盘配额，对test1用户进行限制，一般对用户组限制的情况并不常见。<br>（1）关闭selinux</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><p>（2）查看系统是否启用了quota</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep CONFIG_QUOTA /boot/config-3.10.0-957.el7.x86_64</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/25/%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D/a1.png"><br>（3）查看系统是否安装了quota服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep quota</span><br><span class="line"><span class="comment">#没有的话，yum安装一下</span></span><br><span class="line">yum install -y quota</span><br></pre></td></tr></table></figure><p>（4）在分区上开启磁盘配额功能</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#临时生效</span></span><br><span class="line">mount -o remount,usrquota,grpquota /disk5</span><br><span class="line"><span class="comment">#永久生效，vim /etc/fstab 添加一行,需要重启系统</span></span><br><span class="line">/dev/sdb5  /disk5  ext4  defaults,usrquota,grpquota  0 0</span><br></pre></td></tr></table></figure><p>（5）建立磁盘配额配置文件<br>| 选项 | 说明 |<br>| :—- | :—- |<br>| -a | 扫描/etc/mtab文件中所有启动磁盘配额的分区，如果加入此参数，命令就不需要加入分区名 |<br>| -c | 不管原有的配置文件，重新扫描创建新的配置文件 |<br>| -u | 建立用户配额的配置文件 |<br>| -g | 建立组配额的配置文件 |<br>| -v | 显示扫描过程 |<br>| -m | 强制以读写方式扫描文件系统，一般扫描根分区时使用 |<br>| -f | 强制扫描文件系统，并写入新的配置文件，一般扫描新添加的硬盘分区时使用 |</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">quotacheck -avug</span><br></pre></td></tr></table></figure><p>（6）设置用户的磁盘配置<br>| 选项 | 说明 |<br>| :—- | :—- |<br>| -u | 指定用户 |<br>| -g | 指定组 |<br>| -t | 设置宽限时间 |<br>| -p | 复制配额限制 |</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">edquota -u test1</span><br></pre></td></tr></table></figure><p>（7）测试</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#记得给test1用户disk5权限</span></span><br><span class="line">chown test1 disk5</span><br><span class="line">切换到test1用户，写入数据</span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=/disk5/<span class="built_in">test</span> bs=1M count=10</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/25/%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/25/%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D/a3.png"><br>（7）其他命令</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查询用户限额</span></span><br><span class="line">quota -vus test1</span><br><span class="line"><span class="comment">#复制配额,将test1的配额复制给test2</span></span><br><span class="line">edquota -p test1 -u test2</span><br><span class="line"><span class="comment">#设置宽限期间</span></span><br><span class="line">edquota -t</span><br><span class="line"><span class="comment">#非交互设定用户配额</span></span><br><span class="line">setquota -u 用户名 容量软限制 容量硬限制 个数软限制 个数硬限制 分区名</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux增加swap分区</title>
      <link href="2020/05/25/Linux%E5%A2%9E%E5%8A%A0swap%E5%88%86%E5%8C%BA/"/>
      <url>2020/05/25/Linux%E5%A2%9E%E5%8A%A0swap%E5%88%86%E5%8C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="准备前工作"><a href="#准备前工作" class="headerlink" title="准备前工作"></a>准备前工作</h2><p>准备好未分配的磁盘空间，由于swap分区必须是主分区，然后使用fdisk命令创建一个主分区</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br><span class="line"><span class="comment">#使用n创建一个主分区，使用t将它改为swap类型，最后w保存</span></span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="格式化swap分区"><a href="#格式化swap分区" class="headerlink" title="格式化swap分区"></a>格式化swap分区</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkswap /dev/sdb1</span><br></pre></td></tr></table></figure><h2 id="使用swap分区"><a href="#使用swap分区" class="headerlink" title="使用swap分区"></a>使用swap分区</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swapon /dev/sdb1</span><br></pre></td></tr></table></figure><h2 id="查看swap空间"><a href="#查看swap空间" class="headerlink" title="查看swap空间"></a>查看swap空间</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#发现swap变多了</span></span><br><span class="line">free -m</span><br></pre></td></tr></table></figure><h2 id="自动挂载"><a href="#自动挂载" class="headerlink" title="自动挂载"></a>自动挂载</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /etc/fstab 添加以下一行</span></span><br><span class="line">/dev/sdb1  swap  swap  defaults  0  0</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux之SSH服务介绍</title>
      <link href="2020/05/23/Linux%E4%B9%8BSSH%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/"/>
      <url>2020/05/23/Linux%E4%B9%8BSSH%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="什么是SSH"><a href="#什么是SSH" class="headerlink" title="什么是SSH"></a>什么是SSH</h2><p>SSH（Secure Shell Protocol）是一种网络协议，用于计算机之间的加密登录。在默认状态下，SSH服务提供两个服务，一个是类似于telnet远程联机的服务，另一个类似于FTP服务的sftp-server。</p><a id="more"></a><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#不指定用户，默认root用户</span></span><br><span class="line">ssh 192.168.186.100</span><br><span class="line"><span class="comment">#指定用户登录</span></span><br><span class="line">ssh root@192.168.186.100</span><br><span class="line"><span class="comment">#修改过端口，指定端口登录</span></span><br><span class="line">ssh -p 520 192.168.186.100</span><br><span class="line">ssh -p 520 root@192.168.186.100</span><br></pre></td></tr></table></figure><h2 id="SSH登录原理"><a href="#SSH登录原理" class="headerlink" title="SSH登录原理"></a>SSH登录原理</h2><h3 id="密码登录"><a href="#密码登录" class="headerlink" title="密码登录"></a>密码登录</h3><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/Linux%E4%B9%8BSSH%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/a1.png"></p><h3 id="密钥对登录"><a href="#密钥对登录" class="headerlink" title="密钥对登录"></a>密钥对登录</h3><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/Linux%E4%B9%8BSSH%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/a2.png"></p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>ssh主要配置文件是/etc/ssh/sshd_config</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#默认监听的端口</span></span><br><span class="line">Port 22</span><br><span class="line"><span class="comment">#默认监听的IP</span></span><br><span class="line">ListenAddress 0.0.0.0</span><br><span class="line"><span class="comment">#允许root登录</span></span><br><span class="line">PermitRootLogin yes</span><br><span class="line"><span class="comment">#客户端登录失败尝试次数</span></span><br><span class="line">MaxAuthTries 6</span><br><span class="line"><span class="comment">#是否进行DNS检测</span></span><br><span class="line">UseDNS no</span><br><span class="line"><span class="comment">#是否允许使用基于GSSAPI的用户认证</span></span><br><span class="line">GSSAPIAuthentication no</span><br><span class="line"><span class="comment">#限制可登录用户的办法</span></span><br><span class="line">AllowUsers user1 user2 user3</span><br><span class="line">DenyUsers user1 user2 user3</span><br><span class="line">AllowGroups user1 user2 user3</span><br><span class="line">DenyGroups user1 user2 user3</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SSH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟机添加硬盘</title>
      <link href="2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/"/>
      <url>2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="添加硬盘"><a href="#添加硬盘" class="headerlink" title="添加硬盘"></a>添加硬盘</h2><p>找到对应的虚拟机，编辑虚拟机，添加新的硬盘,然后开机</p><a id="more"></a><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a4.png"></p><h2 id="对硬盘进行分区"><a href="#对硬盘进行分区" class="headerlink" title="对硬盘进行分区"></a>对硬盘进行分区</h2><p>（1）查看分区情况</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a5.png"><br>（2）对/dev/sdb进行分区</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a6.png"><br>（3）输入m，列出fdisk帮助<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a7.png"><br>（4）输入n进行分区<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a8.png"><br>先分主分区，选择p<br>分区号建议从前往后分，选择1<br>起始柱面从前往后，选择默认<br>柱面大小使用大小分，输入+2G，注意单位一定要加<br>这样主分区就分好了<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a9.png"><br>（5）继续输入n进行分区<br>进行扩展分区，选择e<br>分区号选择2<br>起始柱面选择默认<br>我们把剩余空间全分给扩展分区，柱面大小选择默认即可<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a10.png"><br>（6）继续输入n，进行分区<br>这时候选项就变了，输入l，对扩展分区进行分区<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a11.png"><br>把扩展分区的10G分给sdb5<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a12.png"><br>（7）输入p，查看分区情况<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a13.png"><br>（8）输入w，保存并退出<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a14.png"></p><h2 id="格式化分区"><a href="#格式化分区" class="headerlink" title="格式化分区"></a>格式化分区</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkfs -t xfs /dev/sdb1</span><br><span class="line">mkfs -t xfs /dev/sdb5</span><br></pre></td></tr></table></figure><h2 id="手动挂载"><a href="#手动挂载" class="headerlink" title="手动挂载"></a>手动挂载</h2><p>先在根目录下创建2个目录，disk1和disk5，然后执行挂载</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount /dev/sdb1 /disk1</span><br><span class="line">mount /dev/sdb5 /disk5</span><br></pre></td></tr></table></figure><p>查看磁盘</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">df -hT</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a15.png"></p><h2 id="自动挂载"><a href="#自动挂载" class="headerlink" title="自动挂载"></a>自动挂载</h2><p>vim /ect/fstab</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分区            #挂载的目录                        #文件系统 #挂载选项      #是否备份      #是否使用fsck进行检测</span></span><br><span class="line">/dev/sdb1       /disk1                          xfs     defaults        1             0</span><br><span class="line">/dev/sdb5       /disk5                          xfs     defaults        1             0</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/23/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98/a15.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keepalived简介</title>
      <link href="2020/05/05/Keepalived%E7%AE%80%E4%BB%8B/"/>
      <url>2020/05/05/Keepalived%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>  keepalived是linux下的一个轻量级的高可用解决方案，高可用说的是通过专门的设计，从而减少停工时间，保证了系统的高度可用性。keepalived通过VRRP协议(虚拟路由冗余协议)实现系统的高可用，他的配置非常简单。</p><a id="more"></a><h2 id="VRRP协议工作原理"><a href="#VRRP协议工作原理" class="headerlink" title="VRRP协议工作原理"></a>VRRP协议工作原理</h2><p>  在网络环境中，主机间的通信都是通过静态路由或者网关来完成的，而主机之间的路由器一旦发生故障，通信就会断开，为了解决这个问题，就引入了CRRP协议。<br>  VRRP可以将两台或者多台物理路由器虚拟成一个虚拟路由，这个虚拟路由器通过虚拟ip对外提供服务。在虚拟路由内部多个路由器协同工作，同一时间只有一个路由器对外提供服务。对外提供服务的路由器被称为MASTER，其他路由器是BACKUP，当MASTER发生故障时，通过选举算法选出一个BACKUP成为新的MASTER，继续对外提供服务，整个故障切换对用户来说完全是透明的。<br>  每个虚拟路由器都有一个唯一的标识号VRID，在VRRP协议中，MASTER会通过广播方式发送VRRP数据包，BACKUP都会接受数据包信息，用来监控MASTER的监控状态，当MASTER发生故障时，BACKUP就无法接受到MASTER发过来的信息，于是就认定MASTER出现故障，然后多台BACKUP就会进行选举，优先级高的BACKUP就会成为新的MASTER，继续对外提供服务，保证系统的高可用。</p><h2 id="keepalived工作原理"><a href="#keepalived工作原理" class="headerlink" title="keepalived工作原理"></a>keepalived工作原理</h2><p>  在网络层，keepalived通过ICMP协议（互联网可控制报文协议）向服务器集群中的每个节点发送ICMP数据包（类似ping功能），如果某个节点没有返回响应数据包，那么就认为该节点发生了故障，keepalived就会报告这个节点失效，并且从集群中剔除故障节点。<br>  在传输层，keepalived利用TCP协议端口连接和扫描来判断集群节点是否正常，一旦在传输层发现这些端口没有数据响应，就认为这些端口发生异常，强制将这些端口对应的服务从集群中剔除。<br>  在应用层，用户可以自定义脚本来检测服务是否正常运行，如果keepalived的检测结果和用户设定的不一致时，keepalived将对应的服务从集群中剔除。  </p><h2 id="keepalived常用配置"><a href="#keepalived常用配置" class="headerlink" title="keepalived常用配置"></a>keepalived常用配置</h2><h3 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">    notification_email &#123;  <span class="comment">#设置报警邮件地址，可配置多个</span></span><br><span class="line">        acassen@firewall.loc  <span class="comment">#接收通知的邮件</span></span><br><span class="line">        failover@firewall.loc</span><br><span class="line">    &#125;</span><br><span class="line">    notification_email_from <span class="built_in">test</span>@163.com  <span class="comment">#设置发送通知的邮件地址</span></span><br><span class="line">    smtp_server smtp.163.com  <span class="comment">#设置smtp server地址</span></span><br><span class="line">    smtp_connect_timeout 30  <span class="comment">#设置连接smtp server超时时间</span></span><br><span class="line">    router_id LVS_DEVEL  <span class="comment">#主机标识，用于邮件通知</span></span><br><span class="line">    vrrp_strict  <span class="comment">#严格执行VRRP协议规范，此模式不支持节点单播</span></span><br><span class="line">    script_user keepalived_script  <span class="comment">#指定运行脚本的用户名和组。默认使用用户的默认组。如未指定，默认为keepalived_script 用户，如无此用户，则使用root</span></span><br><span class="line">    enable_script_security  <span class="comment">#如果脚本路径为非root可写，不要配置脚本为root用户</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="VRRPD配置"><a href="#VRRPD配置" class="headerlink" title="VRRPD配置"></a>VRRPD配置</h3><p>（1）vrrp_script常用配置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vrrp_script chk_nginx  &#123;  <span class="comment">#脚本名称是chk_nginx</span></span><br><span class="line">    script <span class="string">&quot;/usr/local/sbin/check_ng.sh&quot;</span>  <span class="comment">#自定义脚本，指定脚本路径</span></span><br><span class="line">    interval 3  <span class="comment">#指定脚本执行间隔，单位秒，默认1s     </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）vrrp_instance常用配置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER  <span class="comment">#指定实例初始化状态，MASTER和BACKUP</span></span><br><span class="line">    interface ens33  <span class="comment">#指定实例绑定的网卡</span></span><br><span class="line">    virtual_router_id 51  <span class="comment">#设置VRID标记，多个集群不可重复，同一集群相同</span></span><br><span class="line">    priority 100  <span class="comment">#设定优先级，优先级越高会被竞选MASTER</span></span><br><span class="line">    advert_int 1  <span class="comment">#检查的时间间隔，默认1s</span></span><br><span class="line">    authentication &#123;  <span class="comment">#设置认证</span></span><br><span class="line">        auth_type PASS  <span class="comment">#认证方式，支持PASS和AH，官方建议PASS</span></span><br><span class="line">        auth_pass 1111  <span class="comment">#认证的密码</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_address &#123;  <span class="comment">#设置VIP</span></span><br><span class="line">        192.168.186.100/24</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="lvs配置"><a href="#lvs配置" class="headerlink" title="lvs配置"></a>lvs配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virtual_server 192.168.186.100 80 &#123;</span><br><span class="line">    delay_loop 6  <span class="comment">#健康检查时间间隔</span></span><br><span class="line">    lb_algo rr  <span class="comment">#设置lvs采用轮询算法</span></span><br><span class="line">    lb_kind DR  <span class="comment">#设置lvs采用直接路由模式</span></span><br><span class="line">    protocol TCP  <span class="comment">#使用的协议</span></span><br><span class="line">    real_server 192.168.186.137 80 &#123;  <span class="comment">#真实服务器地址，可配置多个</span></span><br><span class="line">        weight 1  <span class="comment">#权重，默认为1，0为失效</span></span><br><span class="line">        inhibit_on_failure  <span class="comment">#在服务健康检查失效时，将其设为0，而不是直接剔除</span></span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 3  <span class="comment">#连接超时时间</span></span><br><span class="line">            nb_get_retry 3  <span class="comment">#重连次数</span></span><br><span class="line">            delay_before_retry 3  <span class="comment">#重连间隔</span></span><br><span class="line">            connect_port 80  <span class="comment">#健康检查的端口</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Keepalived </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keepalived </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins打包GitHub项目</title>
      <link href="2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/"/>
      <url>2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>首先先去Manage Jenkins-&gt;Global Tool Configuration配置好安装的maven</p><a id="more"></a><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/a2.png"><br>然后创建一个freestyle job,我这边名称是renren-fast,<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/05/Jenkins%E6%89%93%E5%8C%85GitHub%E9%A1%B9%E7%9B%AE/a4.png"><br>最后构建成功</p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决Jenkins插件下载慢问题</title>
      <link href="2020/05/04/%E8%A7%A3%E5%86%B3Jenkins%E6%8F%92%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%85%A2%E9%97%AE%E9%A2%98/"/>
      <url>2020/05/04/%E8%A7%A3%E5%86%B3Jenkins%E6%8F%92%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%85%A2%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>jenkins下载的插件可能由于网络的原因下载失败，我们需要配置他插件下载的地址</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#找到default.json文件</span></span><br><span class="line">find / -name default.json</span><br><span class="line"><span class="comment">#进入default.json目录下，执行</span></span><br><span class="line">sed -i <span class="string">&#x27;s/http:\/\/updates.jenkins-ci.org\/download/https:\/\/mirrors.tuna.tsinghua.edu.cn\/jenkins/g&#x27;</span> default.json</span><br><span class="line">sed -i <span class="string">&#x27;s/http:\/\/www.google.com/https:\/\/www.baidu.com/g&#x27;</span> default.json</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins集成GitHub</title>
      <link href="2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/"/>
      <url>2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><p>首先保证jenkins服务器安装git</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y git</span><br></pre></td></tr></table></figure><h2 id="创建repositories，添加一个文本"><a href="#创建repositories，添加一个文本" class="headerlink" title="创建repositories，添加一个文本"></a>创建repositories，添加一个文本</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a0.png"></p><h2 id="生成ssh密钥"><a href="#生成ssh密钥" class="headerlink" title="生成ssh密钥"></a>生成ssh密钥</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;root@example.com&quot;</span></span><br></pre></td></tr></table></figure><h2 id="复制id-rsa-pub文件内容到GitHub的SSH-keys"><a href="#复制id-rsa-pub文件内容到GitHub的SSH-keys" class="headerlink" title="复制id_rsa.pub文件内容到GitHub的SSH keys"></a>复制id_rsa.pub文件内容到GitHub的SSH keys</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a1.png"></p><h2 id="添加jenkins凭据"><a href="#添加jenkins凭据" class="headerlink" title="添加jenkins凭据"></a>添加jenkins凭据</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a3.png"></p><h2 id="构建freestyle-job"><a href="#构建freestyle-job" class="headerlink" title="构建freestyle job"></a>构建freestyle job</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a4.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a5.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a6.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a7.png"></p><p>最后点击Build with Parameters进行job构建<br><img src= "/img/loading.gif" data-lazy-src="/2020/05/01/Jenkins%E9%9B%86%E6%88%90GitHub/a8.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下Maven安装</title>
      <link href="2020/04/19/Linux%E4%B8%8BMaven%E5%AE%89%E8%A3%85/"/>
      <url>2020/04/19/Linux%E4%B8%8BMaven%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>去官网下载maven，<a href="http://maven.apache.org/">http://maven.apache.org/</a></p><a id="more"></a><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxvf apache-maven-3.6.3-bin.tar.gz</span><br></pre></td></tr></table></figure><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">MAVEN_HOME=/usr/<span class="built_in">local</span>/maven</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH MAVEN_HOME</span><br></pre></td></tr></table></figure><p>如果含有多个PATH环境变量需要配置，使用冒号隔开，比如</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/jdk</span><br><span class="line">MAVEN_HOME=/usr/<span class="built_in">local</span>/maven</span><br><span class="line">CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib/</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH JAVA_HOME CLASSPATH MAVEN_HOME</span><br></pre></td></tr></table></figure><h2 id="使环境变量生效"><a href="#使环境变量生效" class="headerlink" title="使环境变量生效"></a>使环境变量生效</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/19/Linux%E4%B8%8BMaven%E5%AE%89%E8%A3%85/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Maven </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL读写分离之Atlas</title>
      <link href="2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/"/>
      <url>2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前言我们已经部署了MySQL高可用MHA架构，本文基于MHA使用Atlas构建mysql读写分离。</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>我们额外选着一台服务器去做Atlas的安装配置<br>下载地址：<a href="https://github.com/Qihoo360/Atlas/releases">https://github.com/Qihoo360/Atlas/releases</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y Atlas*</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>mv test.cnf test.cnf.bak<br>vi test.cnf</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysql-proxy]</span><br><span class="line">admin-username = user</span><br><span class="line">admin-password = <span class="built_in">pwd</span></span><br><span class="line">proxy-backend-addresses = 192.168.186.100:3306</span><br><span class="line">proxy-read-only-backend-addresses = 192.168.186.133:3306,192.168.186.135:3306</span><br><span class="line">pwds = twf:JKEfAH2h9U0a8s/oWZlMvQ==,mha:JKEfAH2h9U0a8s/oWZlMvQ==</span><br><span class="line">daemon = <span class="literal">true</span></span><br><span class="line">keepalive = <span class="literal">true</span></span><br><span class="line">event-threads = 8</span><br><span class="line"><span class="built_in">log</span>-level = message</span><br><span class="line"><span class="built_in">log</span>-path = /usr/<span class="built_in">local</span>/mysql-proxy/<span class="built_in">log</span></span><br><span class="line">sql-log=ON</span><br><span class="line">proxy-address = 0.0.0.0:33060</span><br><span class="line">admin-address = 0.0.0.0:2345</span><br><span class="line">charset=utf8</span><br></pre></td></tr></table></figure><p>这边pwds的值都是加密的，可以使用下面命令查看密码加密后的value</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/mysql-proxy/bin/encrypt  tang1611</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动atlas</span><br><span class="line">/usr/<span class="built_in">local</span>/mysql-proxy/bin/mysql-proxyd <span class="built_in">test</span> start</span><br></pre></td></tr></table></figure><p>启动atlas可能会报错<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/a1.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查找文件</span></span><br><span class="line">find / -name libcrypto*</span><br><span class="line">做软连接</span><br><span class="line">ln -s /usr/lib64/libcrypto.so.10 /usr/lib64/libcrypto.so.6</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/a2.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查找文件</span></span><br><span class="line">find / -name liblemon*</span><br><span class="line">做软连接</span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/lib/liblemon_parser.so /usr/lib64/liblemon_parser.so</span><br></pre></td></tr></table></figure><p>最后启动成功，查看服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -ef |grep proxy</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在另一台机器上执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -umha -p<span class="string">&#x27;tang1611&#x27;</span>  -h 192.168.186.130 -P 33060</span><br><span class="line"><span class="comment">#测试读操作，正常读操作都只会执行在从节点</span></span><br><span class="line">select @@server_id</span><br><span class="line"><span class="comment">#测试写操作</span></span><br><span class="line">begin;select @@server_id;commit;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/a4.png"></p><h2 id="Atlas基本管理"><a href="#Atlas基本管理" class="headerlink" title="Atlas基本管理"></a>Atlas基本管理</h2><h3 id="连接管理接口"><a href="#连接管理接口" class="headerlink" title="连接管理接口"></a>连接管理接口</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -uuser -ppwd -h192.168.186.130 -P2345</span><br></pre></td></tr></table></figure><h3 id="打印帮助"><a href="#打印帮助" class="headerlink" title="打印帮助"></a>打印帮助</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">select * from <span class="built_in">help</span>;</span><br></pre></td></tr></table></figure><h3 id="查询后端所有节点"><a href="#查询后端所有节点" class="headerlink" title="查询后端所有节点"></a>查询后端所有节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">select * from backends;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/18/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B9%8BAtlas/a5.png"></p><h3 id="动态添加删除节点"><a href="#动态添加删除节点" class="headerlink" title="动态添加删除节点"></a>动态添加删除节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ADD SLAVE 192.168.186.136:3306;</span><br><span class="line">REMOVE BACKEND 4;</span><br></pre></td></tr></table></figure><h3 id="保存配置文件"><a href="#保存配置文件" class="headerlink" title="保存配置文件"></a>保存配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SAVE CONFIG;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Atlas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Atlas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins安装部署</title>
      <link href="2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h2><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="下载rpm包"><a href="#下载rpm包" class="headerlink" title="下载rpm包"></a>下载rpm包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src &amp;&amp; wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/redhat-stable/jenkins-2.204.3-1.1.noarch.rpm</span><br></pre></td></tr></table></figure><h2 id="导入jenkins库的key"><a href="#导入jenkins库的key" class="headerlink" title="导入jenkins库的key"></a>导入jenkins库的key</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key  </span><br></pre></td></tr></table></figure><h2 id="安装jdk1-8"><a href="#安装jdk1-8" class="headerlink" title="安装jdk1.8"></a>安装jdk1.8</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk-*</span><br></pre></td></tr></table></figure><h2 id="安装jenkins"><a href="#安装jenkins" class="headerlink" title="安装jenkins"></a>安装jenkins</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y jenkins</span><br></pre></td></tr></table></figure><h2 id="创建jenkins用户"><a href="#创建jenkins用户" class="headerlink" title="创建jenkins用户"></a>创建jenkins用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd deploy</span><br></pre></td></tr></table></figure><h2 id="编辑-etc-sysconfig-jenkins文件"><a href="#编辑-etc-sysconfig-jenkins文件" class="headerlink" title="编辑/etc/sysconfig/jenkins文件"></a>编辑/etc/sysconfig/jenkins文件</h2><p>vim /etc/sysconfig/jenkins</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改以下内容</span></span><br><span class="line">JENKINS_USER=<span class="string">&quot;deploy&quot;</span></span><br><span class="line">JENKINS_PORT=<span class="string">&quot;8080&quot;</span></span><br></pre></td></tr></table></figure><h2 id="更改权限"><a href="#更改权限" class="headerlink" title="更改权限"></a>更改权限</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chown -R deploy:deploy /var/lib/jenkins</span><br><span class="line">chown -R deploy:deploy /var/<span class="built_in">log</span>/jenkins</span><br></pre></td></tr></table></figure><h2 id="启动jenkins"><a href="#启动jenkins" class="headerlink" title="启动jenkins"></a>启动jenkins</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start jenkins &amp;&amp; systemctl <span class="built_in">enable</span> jenkins</span><br></pre></td></tr></table></figure><h2 id="查看是否成功启动"><a href="#查看是否成功启动" class="headerlink" title="查看是否成功启动"></a>查看是否成功启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -ef |grep jenkins</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p>在访问的机器上修改C:\Windows\System32\drivers\etc\hosts文件，最后一行添加</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.186.138 jenkins.example.com</span><br></pre></td></tr></table></figure><p>最后在浏览器访问jenkins</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://jenkins.example.com:8080</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a1.png"><br>等待一会，查看密码<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a2.png"><br>选择安装推荐的插件，安装后配置admin用户密码、邮箱<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a3.png"><br>登陆成功之后<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/15/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitLab安装部署</title>
      <link href="2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h2><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install curl policycoreutils openssh-server openssh-clients postfix -y</span><br></pre></td></tr></table></figure><h2 id="启动postfix服务，并设置开机启动"><a href="#启动postfix服务，并设置开机启动" class="headerlink" title="启动postfix服务，并设置开机启动"></a>启动postfix服务，并设置开机启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start postfix &amp;&amp; systemctl <span class="built_in">enable</span> postfix</span><br></pre></td></tr></table></figure><h2 id="下载rpm包"><a href="#下载rpm包" class="headerlink" title="下载rpm包"></a>下载rpm包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-10.0.6-ce.0.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="本地安装gitlab-ce"><a href="#本地安装gitlab-ce" class="headerlink" title="本地安装gitlab-ce"></a>本地安装gitlab-ce</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y localinstall gitlab-ce-10.0.6-ce.0.el7.x86_64.rpm </span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>（1）创建一个ssl目录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/gitlab/ssl</span><br></pre></td></tr></table></figure><p>（2）使用openssl创建私有密钥</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.key&quot;</span> 2048</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a1.png"><br>（3）使用刚刚创建的私有密钥创建csr证书</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl req -new -key <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.key&quot;</span> -out <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.csr&quot;</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a2.png"><br>（4）创建crt证书</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl x509 -req -days 365 -<span class="keyword">in</span> <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.csr&quot;</span> -signkey <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.key&quot;</span> -out <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.crt&quot;</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a3.png"><br>（5）创建pem证书</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl dhparam -out /etc/gitlab/ssl/dhparams.pem 2048</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a4.png"><br>（6）授权</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod 600 /etc/gitlab/ssl/*</span><br></pre></td></tr></table></figure><p>（7）修改/etc/gitlab/gitlab.rb文件以下内容</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#http改为https</span></span><br><span class="line">external_url <span class="string">&#x27;https://gitlab.example.com&#x27;</span></span><br><span class="line"><span class="comment">#将#nginx[&#x27;redirect_http_to_https&#x27;] = false的注释去掉，修改为nginx[&#x27;redirect_http_to_https&#x27;] = true</span></span><br><span class="line">nginx[<span class="string">&#x27;redirect_http_to_https&#x27;</span>] = <span class="literal">true</span></span><br><span class="line"><span class="comment">#将#nginx[&#x27;ssl_certificate&#x27;] = &quot;/etc/gitlab/ssl/#&#123;node[&#x27;fqdn&#x27;]&#125;.crt&quot;修改为nginx[&#x27;ssl_certificate&#x27;] = &quot;/etc/gitlab/ssl/gitlab.example.com.crt&quot;</span></span><br><span class="line">nginx[<span class="string">&#x27;ssl_certificate&#x27;</span>] = <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.crt&quot;</span></span><br><span class="line"><span class="comment">#将#nginx[&#x27;ssl_certificate_key&#x27;] = &quot;/etc/gitlab/ssl/#&#123;node[&#x27;fqdn&#x27;]&#125;.key&quot;修改为nginx[&#x27;ssl_certificate_key&#x27;] = &quot;/etc/gitlab/ssl/gitlab.example.com.key&quot;</span></span><br><span class="line">nginx[<span class="string">&#x27;ssl_certificate_key&#x27;</span>] = <span class="string">&quot;/etc/gitlab/ssl/gitlab.example.com.key&quot;</span></span><br><span class="line">将<span class="comment">#nginx[&#x27;ssl_dhparam&#x27;] = nil 修改为nginx[&#x27;ssl_dhparam&#x27;] = &quot;/etc/gitlab/ssl/dhparams.pem&quot;</span></span><br><span class="line">nginx[<span class="string">&#x27;ssl_dhparam&#x27;</span>] = <span class="string">&quot;/etc/gitlab/ssl/dhparams.pem&quot;</span></span><br></pre></td></tr></table></figure><p>（8）初始化gitlab所有相关配置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/13/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/a5.png"><br>（9）修改gitlab的代理配置文件（/var/opt/gitlab/nginx/conf/gitlab-http.conf）</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /var/opt/gitlab/nginx/conf/gitlab-http.conf</span><br><span class="line"><span class="comment">#修改配置项在找到listen *:8002;</span></span><br><span class="line"><span class="comment">#修改配置项在找到server_name,在server_name下添加如下配置内容：</span></span><br><span class="line">rewrite ^(.*)$ https://<span class="variable">$host</span><span class="variable">$1</span> permanent;</span><br></pre></td></tr></table></figure><p>重启gitlab，使配置生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab-ctl restart</span><br></pre></td></tr></table></figure><p>（10）在访问的机器上修改C:\Windows\System32\drivers\etc\hosts文件，最后一行添加<br>192.168.186.133 gitlab.example.com<br>将gitlab服务器的地址添加上gitlab.example.com的配置<br>然后访问<a href="https://gitlab.example.com/">https://gitlab.example.com</a></p>]]></content>
      
      
      <categories>
          
          <category> GitLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitLab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix监控Nginx</title>
      <link href="2020/04/12/Zabbix%E7%9B%91%E6%8E%A7Nginx/"/>
      <url>2020/04/12/Zabbix%E7%9B%91%E6%8E%A7Nginx/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="开启nginx-status配置"><a href="#开启nginx-status配置" class="headerlink" title="开启nginx status配置"></a>开启nginx status配置</h2><p>location /ngx_status {<br>    stub_status on;<br>    access_log off;<br>}</p><a id="more"></a><h2 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart nginx</span><br></pre></td></tr></table></figure><h2 id="打开status页面"><a href="#打开status页面" class="headerlink" title="打开status页面"></a>打开status页面</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://localhost:8001/ngx_status</span><br></pre></td></tr></table></figure><h2 id="编写脚本"><a href="#编写脚本" class="headerlink" title="编写脚本"></a>编写脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#author: twf</span></span><br><span class="line"><span class="comment">#description: zabbix监控nginx性能</span></span><br><span class="line"></span><br><span class="line">HOST=<span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">PORT=<span class="string">&quot;8001&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#检测nginx进程是否存在</span></span><br><span class="line"><span class="keyword">function</span> ping &#123;</span><br><span class="line">        ps -ef |grep nginx |grep -v grep |wc -l</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#检测nginx存活的连接数</span></span><br><span class="line"><span class="keyword">function</span> active &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |grep <span class="string">&#x27;Active&#x27;</span> |awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取客户端请求数</span></span><br><span class="line"><span class="keyword">function</span> reading &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |grep <span class="string">&#x27;Reading&#x27;</span> |awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#响应客户端请求数</span></span><br><span class="line"><span class="keyword">function</span> writing &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |grep <span class="string">&#x27;Reading&#x27;</span> |awk <span class="string">&#x27;&#123;print $4&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx已经处理完正在等待下一次请求指令的驻留连接，keepalive开启情况下，该值等于active-reading-writing</span></span><br><span class="line"><span class="keyword">function</span> waiting &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |grep <span class="string">&#x27;Reading&#x27;</span> |awk <span class="string">&#x27;&#123;print $6&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx启动到现在共处理的连接数</span></span><br><span class="line"><span class="keyword">function</span> server &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |awk NR==3 |awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx启动到现在共创建的多少次握手</span></span><br><span class="line"><span class="keyword">function</span> accepts &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |awk NR==3 |awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx总共处理的请求数</span></span><br><span class="line"><span class="keyword">function</span> requests &#123;</span><br><span class="line">        curl http://<span class="variable">$&#123;HOST&#125;</span>:<span class="variable">$&#123;PORT&#125;</span>/ngx_status 2&gt;/dev/null |awk NR==3 |awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable">$1</span></span><br></pre></td></tr></table></figure><h2 id="将自定义的UserParameter加入配置文件"><a href="#将自定义的UserParameter加入配置文件" class="headerlink" title="将自定义的UserParameter加入配置文件"></a>将自定义的UserParameter加入配置文件</h2><p>UserParameter=nginx_status[*],/usr/local/bin/ngx_status.sh $1</p><h2 id="重启zabbix-agent"><a href="#重启zabbix-agent" class="headerlink" title="重启zabbix-agent"></a>重启zabbix-agent</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart zabbix-agent</span><br></pre></td></tr></table></figure><h2 id="zabbix-get获取"><a href="#zabbix-get获取" class="headerlink" title="zabbix-get获取"></a>zabbix-get获取</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/12/Zabbix%E7%9B%91%E6%8E%A7Nginx/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL高可用架构之MHA部署</title>
      <link href="2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/"/>
      <url>2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文是基于mysql主从环境的</p><a id="more"></a><h2 id="MHA组成"><a href="#MHA组成" class="headerlink" title="MHA组成"></a>MHA组成</h2><p>MHA主要有Manager、Node两部分组成<br>Manager：Manager可以部署在单独的服务器上，管理多个主从集群，也可以部署在一个从服务器上。MHA Manager会探测集群中master节点，当master出现故障时，它可以自动将一个slave提升为新的master，然后重新建立主从关系<br>Node：所有机器均需要安装</p><h2 id="MHA工作原理"><a href="#MHA工作原理" class="headerlink" title="MHA工作原理"></a>MHA工作原理</h2><p>当master出现故障后，MHA会挑选一个slave，进行数据补偿，让他做为新的master，并且重新建立主从关系。</p><h2 id="选主策略"><a href="#选主策略" class="headerlink" title="选主策略"></a>选主策略</h2><p>（1）如果从库（GTID）数据有差异，选择数据最接近master的slave成为备选主<br>（2）如果从库数据一致，按照配置文件顺序选主<br>（3）如果设定了权重（candidate_master=1），按照权重选主<br>    1）默认情况下如果一个slave数据落后master大于100M的中继日志数据的话，权重不会生效<br>    2）如果设置check_repl_delay=0，即使落后很多日志，也会成为备选主</p><h2 id="MHA部署"><a href="#MHA部署" class="headerlink" title="MHA部署"></a>MHA部署</h2><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>192.168.186.133 mysql-master node<br>192.168.186.134 mysql-slave node<br>192.168.186.135 mysql-slave node manager</p><h3 id="建立软连接"><a href="#建立软连接" class="headerlink" title="建立软连接"></a>建立软连接</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/mysql/bin/mysqlbinlog  /usr/bin/mysqlbinlog</span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/mysql/bin/mysql  /usr/bin/mysql</span><br></pre></td></tr></table></figure><h3 id="配置ssh登陆无密码登陆"><a href="#配置ssh登陆无密码登陆" class="headerlink" title="配置ssh登陆无密码登陆"></a>配置ssh登陆无密码登陆</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.186.133：</span></span><br><span class="line">rm -rf /root/.ssh </span><br><span class="line">ssh-keygen</span><br><span class="line"><span class="built_in">cd</span> /root/.ssh </span><br><span class="line">mv id_rsa.pub authorized_keys</span><br><span class="line">scp  -r  /root/.ssh  192.168.186.134:/root </span><br><span class="line">scp  -r  /root/.ssh  192.168.186.135:/root </span><br><span class="line"><span class="comment">#各节点验证</span></span><br><span class="line"><span class="comment">#192.168.186.133:</span></span><br><span class="line">ssh 192.168.186.133 date</span><br><span class="line">ssh 192.168.186.134 date</span><br><span class="line">ssh 192.168.186.135 date</span><br><span class="line"><span class="comment">#192.168.186.134:</span></span><br><span class="line">ssh 192.168.186.133 date</span><br><span class="line">ssh 192.168.186.134 date</span><br><span class="line">ssh 192.168.186.135 date</span><br><span class="line"><span class="comment">#192.168.186.135:</span></span><br><span class="line">ssh 192.168.186.133 date</span><br><span class="line">ssh 192.168.186.134 date</span><br><span class="line">ssh 192.168.186.135 date</span><br></pre></td></tr></table></figure><h3 id="下载mha"><a href="#下载mha" class="headerlink" title="下载mha"></a>下载mha</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">github下载地址：https://github.com/yoshinorim/mha4mysql-manager/wiki/Downloads</span><br></pre></td></tr></table></figure><h3 id="所有节点安装node软件依赖包"><a href="#所有节点安装node软件依赖包" class="headerlink" title="所有节点安装node软件依赖包"></a>所有节点安装node软件依赖包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install perl-DBD-MySQL -y</span><br><span class="line">rpm -ivh mha4mysql-node-0.56-0.el6.noarch.rpm</span><br></pre></td></tr></table></figure><h3 id="master节点创建mha用户"><a href="#master节点创建mha用户" class="headerlink" title="master节点创建mha用户"></a>master节点创建mha用户</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grant all privileges on *.* to mha@<span class="string">&#x27;192.168.186.%&#x27;</span> identified by <span class="string">&#x27;tang1611&#x27;</span>;</span><br></pre></td></tr></table></figure><h3 id="Manager软件安装"><a href="#Manager软件安装" class="headerlink" title="Manager软件安装"></a>Manager软件安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes</span><br><span class="line">rpm -ivh mha4mysql-manager-0.56-0.el6.noarch.rpm</span><br></pre></td></tr></table></figure><h3 id="manager配置文件"><a href="#manager配置文件" class="headerlink" title="manager配置文件"></a>manager配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建配置文件目录</span></span><br><span class="line">mkdir -p /etc/mha</span><br><span class="line"><span class="comment">#创建日志目录</span></span><br><span class="line">mkdir -p /var/<span class="built_in">log</span>/mha/app1</span><br><span class="line"><span class="comment">#编辑配置文件</span></span><br><span class="line">vim /etc/mha/app1.cnf</span><br><span class="line">[server default]</span><br><span class="line">manager_log=/var/<span class="built_in">log</span>/mha/app1/manager</span><br><span class="line">manager_workdir=/var/<span class="built_in">log</span>/mha/app1            </span><br><span class="line">master_binlog_dir=/data/binlog       </span><br><span class="line">user=mha                                   </span><br><span class="line">password=tang1611                          </span><br><span class="line">ping_interval=2</span><br><span class="line">repl_password=tang1611</span><br><span class="line">repl_user=twf</span><br><span class="line">ssh_user=root                               </span><br><span class="line">[server1]                                   </span><br><span class="line">hostname=192.168.186.133</span><br><span class="line">port=3306                                  </span><br><span class="line">[server2]            </span><br><span class="line">hostname=192.168.186.134</span><br><span class="line">port=3306</span><br><span class="line">[server3]</span><br><span class="line">hostname=192.168.186.135</span><br><span class="line">port=3306</span><br></pre></td></tr></table></figure><h3 id="ssh通信验证"><a href="#ssh通信验证" class="headerlink" title="ssh通信验证"></a>ssh通信验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">masterha_check_ssh --conf=/etc/mha/app1.cnf</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a1.png"></p><h3 id="主从状态检查"><a href="#主从状态检查" class="headerlink" title="主从状态检查"></a>主从状态检查</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">masterha_check_repl  --conf=/etc/mha/app1.cnf</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a2.png"></p><h3 id="启动MHA"><a href="#启动MHA" class="headerlink" title="启动MHA"></a>启动MHA</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover  &lt; /dev/null&gt; /var/<span class="built_in">log</span>/mha/app1/manager.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h3 id="查看MHA状态"><a href="#查看MHA状态" class="headerlink" title="查看MHA状态"></a>查看MHA状态</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">masterha_check_status --conf=/etc/mha/app1.cnf</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a4.png"></p><h2 id="配置MHA的vip功能"><a href="#配置MHA的vip功能" class="headerlink" title="配置MHA的vip功能"></a>配置MHA的vip功能</h2><p>修改manager配置文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">master_ip_failover_script=/usr/<span class="built_in">local</span>/bin/master_ip_failover</span><br></pre></td></tr></table></figure><p>master_ip_failover脚本内容</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env perl</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  Copyright (C) 2011 DeNA Co.,Ltd.</span></span><br><span class="line"><span class="comment">#  You should have received a copy of the GNU General Public License</span></span><br><span class="line"><span class="comment">#   along with this program; if not, write to the Free Software</span></span><br><span class="line"><span class="comment">#  Foundation, Inc.,</span></span><br><span class="line"><span class="comment">#  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Note: This is a sample script and is not complete. Modify the script based on your environment.</span></span><br><span class="line"></span><br><span class="line">use strict;</span><br><span class="line">use warnings FATAL =&gt; <span class="string">&#x27;all&#x27;</span>;</span><br><span class="line"></span><br><span class="line">use Getopt::Long;</span><br><span class="line">use MHA::DBHelper;</span><br><span class="line"></span><br><span class="line">my (</span><br><span class="line">  <span class="variable">$command</span>,        <span class="variable">$ssh_user</span>,         <span class="variable">$orig_master_host</span>,</span><br><span class="line">  <span class="variable">$orig_master_ip</span>, <span class="variable">$orig_master_port</span>, <span class="variable">$new_master_host</span>,</span><br><span class="line">  <span class="variable">$new_master_ip</span>,  <span class="variable">$new_master_port</span>,  <span class="variable">$new_master_user</span>,</span><br><span class="line">  <span class="variable">$new_master_password</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">my <span class="variable">$vip</span> = <span class="string">&#x27;192.168.186.100/24&#x27;</span>;</span><br><span class="line">my <span class="variable">$key</span> = <span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">my <span class="variable">$ssh_start_vip</span> = <span class="string">&quot;/sbin/ifconfig ens33:<span class="variable">$key</span> <span class="variable">$vip</span>&quot;</span>;</span><br><span class="line">my <span class="variable">$ssh_stop_vip</span> = <span class="string">&quot;/sbin/ifconfig ens33:<span class="variable">$key</span> down&quot;</span>;</span><br><span class="line">GetOptions(</span><br><span class="line">  <span class="string">&#x27;command=s&#x27;</span>             =&gt; \<span class="variable">$command</span>,</span><br><span class="line">  <span class="string">&#x27;ssh_user=s&#x27;</span>            =&gt; \<span class="variable">$ssh_user</span>,</span><br><span class="line">  <span class="string">&#x27;orig_master_host=s&#x27;</span>    =&gt; \<span class="variable">$orig_master_host</span>,</span><br><span class="line">  <span class="string">&#x27;orig_master_ip=s&#x27;</span>      =&gt; \<span class="variable">$orig_master_ip</span>,</span><br><span class="line">  <span class="string">&#x27;orig_master_port=i&#x27;</span>    =&gt; \<span class="variable">$orig_master_port</span>,</span><br><span class="line">  <span class="string">&#x27;new_master_host=s&#x27;</span>     =&gt; \<span class="variable">$new_master_host</span>,</span><br><span class="line">  <span class="string">&#x27;new_master_ip=s&#x27;</span>       =&gt; \<span class="variable">$new_master_ip</span>,</span><br><span class="line">  <span class="string">&#x27;new_master_port=i&#x27;</span>     =&gt; \<span class="variable">$new_master_port</span>,</span><br><span class="line">  <span class="string">&#x27;new_master_user=s&#x27;</span>     =&gt; \<span class="variable">$new_master_user</span>,</span><br><span class="line">  <span class="string">&#x27;new_master_password=s&#x27;</span> =&gt; \<span class="variable">$new_master_password</span>,</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> &amp;main();</span><br><span class="line"></span><br><span class="line">sub main &#123;</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;\n\nIN SCRIPT TEST====<span class="variable">$ssh_stop_vip</span>==<span class="variable">$ssh_start_vip</span>===\n\n&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span> ( <span class="variable">$command</span> eq <span class="string">&quot;stop&quot;</span> || <span class="variable">$command</span> eq <span class="string">&quot;stopssh&quot;</span> ) &#123;</span><br><span class="line">        my <span class="variable">$exit_code</span> = 1;</span><br><span class="line">        <span class="built_in">eval</span> &#123;</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;Disabling the VIP on old master: <span class="variable">$orig_master_host</span> \n&quot;</span>;</span><br><span class="line">            &amp;stop_vip();</span><br><span class="line">            <span class="variable">$exit_code</span> = 0;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$@</span>) &#123;</span><br><span class="line">            warn <span class="string">&quot;Got Error: <span class="variable">$@</span>\n&quot;</span>;</span><br><span class="line">            <span class="built_in">exit</span> <span class="variable">$exit_code</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">exit</span> <span class="variable">$exit_code</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    elsif ( <span class="variable">$command</span> eq <span class="string">&quot;start&quot;</span> ) &#123;</span><br><span class="line">        my <span class="variable">$exit_code</span> = 10;</span><br><span class="line">        <span class="built_in">eval</span> &#123;</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;Enabling the VIP - <span class="variable">$vip</span> on the new master - <span class="variable">$new_master_host</span> \n&quot;</span>;</span><br><span class="line">            &amp;start_vip();</span><br><span class="line">            <span class="variable">$exit_code</span> = 0;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$@</span>) &#123;</span><br><span class="line">            warn <span class="variable">$@</span>;</span><br><span class="line">            <span class="built_in">exit</span> <span class="variable">$exit_code</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">exit</span> <span class="variable">$exit_code</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    elsif ( <span class="variable">$command</span> eq <span class="string">&quot;status&quot;</span> ) &#123;</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Checking the Status of the script.. OK \n&quot;</span>;</span><br><span class="line">        <span class="built_in">exit</span> 0;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        &amp;usage();</span><br><span class="line">        <span class="built_in">exit</span> 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">sub <span class="function"><span class="title">start_vip</span></span>() &#123;</span><br><span class="line">    `ssh <span class="variable">$ssh_user</span>\@<span class="variable">$new_master_host</span> \&quot; <span class="variable">$ssh_start_vip</span> \&quot;`;</span><br><span class="line">&#125;</span><br><span class="line">sub <span class="function"><span class="title">stop_vip</span></span>() &#123;</span><br><span class="line">     <span class="built_in">return</span> 0  unless  (<span class="variable">$ssh_user</span>);</span><br><span class="line">    `ssh <span class="variable">$ssh_user</span>\@<span class="variable">$orig_master_host</span> \&quot; <span class="variable">$ssh_stop_vip</span> \&quot;`;</span><br><span class="line">&#125;</span><br><span class="line">sub usage &#123;</span><br><span class="line">  <span class="built_in">print</span></span><br><span class="line"><span class="string">&quot;Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用dos2unix工具处理脚本</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dos2unix /usr/<span class="built_in">local</span>/bin/master_ip_failover </span><br></pre></td></tr></table></figure><p>赋予可执行权限</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x /usr/<span class="built_in">local</span>/bin/master_ip_failover </span><br></pre></td></tr></table></figure><p>在主库上生成vip</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifconfig ens33:1 192.168.186.100/24</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a5.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>先重启MHA，让之前的配置生效</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">masterha_stop --conf=/etc/mha/app1.cnf</span><br><span class="line">nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover  &lt; /dev/null&gt; /var/<span class="built_in">log</span>/mha/app1/manager.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>查看mha状态</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">masterha_check_status --conf=/etc/mha/app1.cnf</span><br></pre></td></tr></table></figure><p>在master(192.168.186.133)节点pkill掉mysql、mysqld</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill mysql</span><br><span class="line">pkill mysqld</span><br></pre></td></tr></table></figure><p>在192.168.186.134查看虚拟vip<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a6.png"><br>可以看出master已经在192.168.186.134机器上了<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a7.png"><br>可以从app1.cnf看出192.168.186.133已经被MHA剔除了<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA%E9%83%A8%E7%BD%B2/a8.png"></p><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p>在192.168.186.133机器执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">service mysql start</span><br><span class="line">mysql -uroot -p<span class="string">&#x27;tang1611&#x27;</span></span><br><span class="line">CHANGE MASTER TO MASTER_HOST=<span class="string">&#x27;192.168.186.134&#x27;</span>,MASTER_USER=<span class="string">&#x27;twf&#x27;</span>, MASTER_PASSWORD=<span class="string">&#x27;tang1611&#x27;</span>;</span><br><span class="line">start slave;</span><br></pre></td></tr></table></figure><p>在192.168.186.135机器<br>vim /etc/mha/app1.cnf,将server1加进去<br>再次启动mha<br>nohup masterha_manager –conf=/etc/mha/app1.cnf –remove_dead_master_conf –ignore_last_failover  &lt; /dev/null&gt; /var/log/mha/app1/manager.log 2&gt;&amp;1 &amp;</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL主从复制</title>
      <link href="2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="mysql主从复制原理"><a href="#mysql主从复制原理" class="headerlink" title="mysql主从复制原理"></a>mysql主从复制原理</h2><p>mysql中有一种二进制日志，这种日志会记录所有修改数据库的操作，主从复制的原理实际上就是把主服务器的binlog日志复制到从服务器上执行一遍，这样从节点的数据就可以保持与主节点数据一致了。</p><a id="more"></a><h2 id="主从复制过程"><a href="#主从复制过程" class="headerlink" title="主从复制过程"></a>主从复制过程</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a1.png"><br>（1）首先因为从节点需要复制主节点的binlog日志，所以必须保证主节点启用二进制日志（log-bin=mysql-bin）<br>（2）从节点会开启一个I/O线程扮演mysql客户端，去请求主节点的二进制日志的事件<br>（3）主节点启动一个dump线程，检查自己二进制日志中的事件，跟对方请求的位置对比，如果不带请求位置参数，则主节点就会第一个日志文件中的第一个事件一个个发送给从节点<br>（4）从节点收到主节点发送过来的数据，把它放到中继日志（relay log）中，并且记录该次请求到主节点哪个二进制日志文件的哪个位置<br>（5）从节点另外一个SQL线程会把中继日志（relay log）中的事件读取出来，并且在执行一遍</p><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><!--more--><p>192.168.186.133 mysql-master<br>192.168.186.134 mysql-slave<br>192.168.186.135 mysql-slave</p><p>##mysql-master配置<br>vim /etc/my.cnf</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">datadir=/usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line">symbolic-links=0</span><br><span class="line"><span class="built_in">log</span>-bin=mysql-bin</span><br><span class="line">binlog-do-db = db1</span><br><span class="line">binlog_format=mixed</span><br><span class="line">server-id=1</span><br><span class="line">innodb_file_per_table=ON</span><br></pre></td></tr></table></figure><p>查看是否开启log-bin<br>mysql&gt; show global variables like ‘%log%’;<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a2.png"><br>查看master主节点二进制日志<br>show master logs;<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a3.png"><br>查看主节点的server id<br>show global variables like ‘%server_id%’<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a4.png"><br>创建主节点复制权限的用户<br>grant replication slave,replication client on <em>.</em> to ‘twf’@’%’ identified by ‘tang1611’;</p><h2 id="从服务器配置"><a href="#从服务器配置" class="headerlink" title="从服务器配置"></a>从服务器配置</h2><p>vim /etc/my.cnf</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">datadir=/usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line">symbolic-links=0</span><br><span class="line"><span class="built_in">log</span>-bin=mysql-bin</span><br><span class="line">binlog-do-db = db1</span><br><span class="line">relay-log=relay-log</span><br><span class="line">relay-log-index=relay-log.index</span><br><span class="line"><span class="built_in">read</span>-only=1</span><br><span class="line">server_id=3</span><br><span class="line">innodb_file_per_table=ON</span><br></pre></td></tr></table></figure><p>查看中继日志是否开启<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a5.png"><br>在master主节点查看binlog<br>show binary logs;<br>建立主从关系<br>CHANGE MASTER TO MASTER_HOST=’192.168.186.133’,MASTER_USER=’twf’,MASTER_PASSWORD=’tang1611’, MASTER_LOG_FILE=’mysql-bin.000007’,MASTER_LOG_POS=1675;<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a6.png"><br>启动从节点复制线程<br>start slave;<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a7.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>(1)主节点创建数据库</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">create database mydb;</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a8.png"><br>(2)在从节点查看二进制日志，查看是否成功复制成功<br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a9.png"><br><img src= "/img/loading.gif" data-lazy-src="/2020/04/05/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/a10.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK安装和部署</title>
      <link href="2020/03/28/ELK%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/"/>
      <url>2020/03/28/ELK%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>链接：<a href="https://pan.baidu.com/s/18fFb0ZVQyXLxJg1tp9Yi_A">https://pan.baidu.com/s/18fFb0ZVQyXLxJg1tp9Yi_A</a> </p><a id="more"></a><p>提取码：q7gk </p><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>192.168.186.129 centos7</p><h2 id="实验前准备"><a href="#实验前准备" class="headerlink" title="实验前准备"></a>实验前准备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#创建目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/elk</span><br><span class="line"><span class="comment">#解压缩，将文件移动到/usr/local/elk目录下</span></span><br><span class="line">tar zxvf 文件</span><br><span class="line"><span class="comment">#打开/etc/security/limits.conf文件，在末尾追加以下内容，设置更大的打开文件数</span></span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line"><span class="comment">#打开/etc/security/limits.d/20-nproc.conf，修改以下内容</span></span><br><span class="line">*          soft    nproc   4096</span><br><span class="line"><span class="comment">#打开/etc/sysctl.conf文件，在末尾追加以下内容</span></span><br><span class="line">vm.max_map_count=655360</span><br><span class="line">fs.file-max=655360</span><br><span class="line"><span class="comment">#使配置生效</span></span><br><span class="line">sysctl -p</span><br><span class="line"><span class="comment">#重启操作系统</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h2 id="创建用户-并授权"><a href="#创建用户-并授权" class="headerlink" title="创建用户,并授权"></a>创建用户,并授权</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#elk是不允许以root用户运行的</span></span><br><span class="line">useradd elk</span><br><span class="line">passwd elk</span><br><span class="line">chown -R elk:elk /usr/<span class="built_in">local</span>/elk</span><br></pre></td></tr></table></figure><h2 id="elasticsearch部署"><a href="#elasticsearch部署" class="headerlink" title="elasticsearch部署"></a>elasticsearch部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建存放数据的目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/elk/elasticsearch/data</span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/elk/elasticsearch/logs</span><br><span class="line"><span class="comment">#修改elasticsearch/config/elasticsearch.yml配置文件以下内容</span></span><br><span class="line">path.data: /usr/<span class="built_in">local</span>/elk/elasticsearch/data <span class="comment">#数据目录</span></span><br><span class="line">path.logs: /usr/<span class="built_in">local</span>/elk/elasticsearch/logs <span class="comment">#日志目录</span></span><br><span class="line">network.host: 0.0.0.0 <span class="comment">#允许所有ip访问</span></span><br><span class="line">http.port: 9200 <span class="comment">#端口</span></span><br><span class="line">http.cors.enabled: <span class="literal">true</span> <span class="comment">#在末尾添加</span></span><br><span class="line">http.cors.allow-origin: <span class="string">&quot;*&quot;</span> <span class="comment">#在末尾添加</span></span><br><span class="line"><span class="comment">#修改jvm.options以下内容</span></span><br><span class="line">-Xms512m </span><br><span class="line">-Xmx512m<span class="string">&quot; </span></span><br><span class="line"><span class="string">#启动elasticsearch</span></span><br><span class="line"><span class="string">./bin/elasticsearch -d</span></span><br><span class="line"><span class="string">#查看elasticsearch是否启动成功</span></span><br><span class="line"><span class="string">ps -ef |grep elasticsearch</span></span><br></pre></td></tr></table></figure><h2 id="logstash部署"><a href="#logstash部署" class="headerlink" title="logstash部署"></a>logstash部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建文件</span></span><br><span class="line">touch  logstash/config/test.conf</span><br><span class="line"><span class="comment">#写入内容</span></span><br><span class="line">input &#123;</span><br><span class="line">        beats &#123;</span><br><span class="line">                port =&gt; 5044</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">                hosts =&gt; <span class="string">&quot;127.0.0.1:9200&quot;</span></span><br><span class="line">                index =&gt; <span class="string">&quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#启动logstash</span></span><br><span class="line">nohup ./bin/logstash -f config/test.conf </span><br><span class="line"><span class="comment">#查看logstash是否启动成功</span></span><br><span class="line">ps -ef |grep logstash</span><br></pre></td></tr></table></figure><h2 id="kibana部署"><a href="#kibana部署" class="headerlink" title="kibana部署"></a>kibana部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动kibana</span></span><br><span class="line">nohup ./bin/kibana -H 0.0.0.0</span><br><span class="line"><span class="comment">#查看kibana是否启动成功</span></span><br><span class="line">ps -ef |grep kibana</span><br></pre></td></tr></table></figure><h2 id="filebeat部署"><a href="#filebeat部署" class="headerlink" title="filebeat部署"></a>filebeat部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改filebeat.yml以下内容，注意yml文件格式</span></span><br><span class="line">paths:</span><br><span class="line">  - /tmp/test_data</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [<span class="string">&quot;localhost:5044&quot;</span>]</span><br><span class="line"><span class="comment">#启动filebeats</span></span><br><span class="line">./filebeat -e -c filebeat.yml -d <span class="string">&quot;publish&quot;</span></span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>浏览器访问<ip>:5601访问kibana界面，在management页面创建index pattern<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/28/ELK%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/a1.png"><br>在/tmp目录下创建test_data文件<br>echo ‘{“name”: “xili”,”age”: “18”,”sex”: “girl”}’ &gt;&gt; /tmp/test_data<br>查看filebeat控制台<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/28/ELK%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/a2.png"><br>查看kibana<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/28/ELK%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/a3.png"></ip></p>]]></content>
      
      
      
        <tags>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis哨兵模式搭建</title>
      <link href="2020/03/26/Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"/>
      <url>2020/03/26/Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><a id="more"></a><p>192.168.186.129 centos7</p><h2 id="实验前准备"><a href="#实验前准备" class="headerlink" title="实验前准备"></a>实验前准备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#创建目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis/7001</span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis/7002</span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis/7003</span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis/7004</span><br></pre></td></tr></table></figure><h2 id="安装redis-5-0-3"><a href="#安装redis-5-0-3" class="headerlink" title="安装redis-5.0.3"></a>安装redis-5.0.3</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装gcc</span></span><br><span class="line">yum install gcc -y</span><br><span class="line"><span class="comment">#安装wget</span></span><br><span class="line">yum install wget -y</span><br><span class="line"><span class="comment">#下载redis-5.0.3.tar.gz</span></span><br><span class="line">wget http://download.redis.io/releases/redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar zxvf redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#移动到redis-5.0.3目录下，执行</span></span><br><span class="line">make</span><br><span class="line"><span class="comment">#移动到redis-5.0.3/src目录下，执行</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>复制redis-server、redis-cli、redis-sentinel到/usr/local/redis/目录下<br>复制redis.conf、sentinel.conf到/usr/local/redis/目录下<br>在7001、7002、7003、7004文件夹下创建sentinel目录</p><h2 id="修改主redis-conf"><a href="#修改主redis-conf" class="headerlink" title="修改主redis.conf"></a>修改主redis.conf</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改以下项</span></span><br><span class="line">daemonize yes <span class="comment">#后台运行</span></span><br><span class="line">port 7001 <span class="comment">#端口，按照创建的文件夹分配7001-7006端口</span></span><br><span class="line"><span class="built_in">bind</span> <span class="comment">#绑定ip，默认绑定的是本机，只允许本地访问redis-server，注释掉</span></span><br><span class="line">dir /home/bin/redis/7001/ <span class="comment">#redis数据文件存储位置</span></span><br><span class="line">appendonly yes <span class="comment">#持久化</span></span><br><span class="line">protected-mode no <span class="comment">#保护模式</span></span><br><span class="line">requirepass tang1611 <span class="comment">#设置密码，当客户端连接redis-server时，需要使用-a &lt;password&gt; 来连接</span></span><br><span class="line">masterauth tang1611 <span class="comment">#集群通信密码</span></span><br></pre></td></tr></table></figure><h2 id="修改从redis-conf"><a href="#修改从redis-conf" class="headerlink" title="修改从redis.conf"></a>修改从redis.conf</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改以下项</span></span><br><span class="line">daemonize yes <span class="comment">#后台运行</span></span><br><span class="line">port 7002 <span class="comment">#端口，按照创建的文件夹分配7001-7006端口</span></span><br><span class="line"><span class="built_in">bind</span> <span class="comment">#绑定ip，默认绑定的是本机，只允许本地访问redis-server，注释掉</span></span><br><span class="line">dir /home/bin/redis/7002/ <span class="comment">#redis数据文件存储位置</span></span><br><span class="line">appendonly yes <span class="comment">#持久化</span></span><br><span class="line">protected-mode no <span class="comment">#保护模式</span></span><br><span class="line">requirepass tang1611 <span class="comment">#设置密码，当客户端连接redis-server时，需要使用-a &lt;password&gt; 来连接</span></span><br><span class="line">masterauth tang1611 <span class="comment">#集群通信密码</span></span><br><span class="line">replicaof 127.0.0.1 7001 <span class="comment">#表示以127.0.0.1 7001作为主redis</span></span><br></pre></td></tr></table></figure><h2 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动redis</span></span><br><span class="line">./redis-server 7001/redis.conf</span><br><span class="line">./redis-server 7002/redis.conf</span><br><span class="line">./redis-server 7003/redis.conf</span><br><span class="line">./redis-server 7004/redis.conf</span><br><span class="line"><span class="comment">#查看redis启动情况</span></span><br><span class="line">ps -ef |grep redis </span><br></pre></td></tr></table></figure><h2 id="sentinel-conf配置"><a href="#sentinel-conf配置" class="headerlink" title="sentinel.conf配置"></a>sentinel.conf配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改以下配置</span></span><br><span class="line"><span class="comment">#关闭保护模式</span></span><br><span class="line">protected-mode no</span><br><span class="line"><span class="comment">#端口，分配6001、6002、6003、6004端口</span></span><br><span class="line">port 6001</span><br><span class="line"><span class="comment">#后台运行</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="comment">#pid文件目录</span></span><br><span class="line">pidfile <span class="string">&quot;/usr/local/redis/7001/sentinel/redis-sentinel.pid&quot;</span></span><br><span class="line"><span class="comment">#日志目录</span></span><br><span class="line">logfile <span class="string">&quot;/usr/local/redis/7001/sentinel/redis-sentinel.log&quot;</span></span><br><span class="line"><span class="comment">#哨兵sentinel的工作目录</span></span><br><span class="line">dir <span class="string">&quot;/usr/local/redis/7001/sentinel&quot;</span></span><br><span class="line"><span class="comment">#配置master机器ip及端口，2表示必须至少要有2个及以上sentinel认为master挂掉，才认为master挂掉</span></span><br><span class="line">sentinel monitor mymaster 127.0.0.1 7001 2</span><br><span class="line"><span class="comment">#如果redis.conf配置了requirepass,那么该项必须配置，密码与requirepass一致，该项配置必须在sentinel monitor之下</span></span><br><span class="line">sentinel auth-pass mymaster tang1611</span><br></pre></td></tr></table></figure><h2 id="启动sentinel"><a href="#启动sentinel" class="headerlink" title="启动sentinel"></a>启动sentinel</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./redis-sentinel 7001/sentinel.conf</span><br><span class="line">./redis-sentinel 7002/sentinel.conf</span><br><span class="line">./redis-sentinel 7003/sentinel.conf</span><br><span class="line">./redis-sentinel 7004/sentinel.conf</span><br><span class="line"><span class="comment">#查看sentinel启动情况</span></span><br><span class="line">ps -ef |grep redis</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#先确定master是在7001端口的redis上,查看其role</span></span><br><span class="line">./redis.cli -a tang1611 -p 7001 info replication</span><br><span class="line"><span class="comment">#kill掉master节点</span></span><br><span class="line"><span class="built_in">kill</span> -9 &lt;pid&gt;</span><br><span class="line"><span class="comment">#查看redis-sentinel.log,从日志上可以看出来新的master（7003端口的redis）已经选举出来了</span></span><br><span class="line">tail -n 10 redis-sentinel.log</span><br><span class="line">11270:X 26 Mar 2020 16:32:53.542 * +slave slave 127.0.0.1:7004 127.0.0.1 7004 @ mymaster 127.0.0.1 7003</span><br><span class="line">11270:X 26 Mar 2020 16:32:53.542 * +slave slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7003</span><br><span class="line">11270:X 26 Mar 2020 16:32:53.542 * +slave slave 127.0.0.1:7001 127.0.0.1 7001 @ mymaster 127.0.0.1 7003</span><br><span class="line">11270:X 26 Mar 2020 16:33:23.552 <span class="comment"># +sdown slave 127.0.0.1:7001 127.0.0.1 7001 @ mymaster 127.0.0.1 7003</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2020/03/26/Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis简介</title>
      <link href="2020/03/22/Redis%E7%AE%80%E4%BB%8B/"/>
      <url>2020/03/22/Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="redis概念"><a href="#redis概念" class="headerlink" title="redis概念"></a>redis概念</h2><p>redis是一个开源的、使用C语言编写的基于内存可持久化的key-value非关系型数据库。</p><a id="more"></a><h2 id="redis优点"><a href="#redis优点" class="headerlink" title="redis优点"></a>redis优点</h2><p>（1）性能高<br>redis读的速度是110000次/s，写的速度81000次/s。<br>（2）丰富的数据类型<br>redis支持的数据类型有String、List、Set、Hash、sorted set<br>（3）原子性<br>redis操作具有原子性，要么成功执行，要么失败完全不执行<br>（4）丰富的特性<br>支持发布/订阅、数据持久化、key过期等特性</p><h2 id="redis缺点"><a href="#redis缺点" class="headerlink" title="redis缺点"></a>redis缺点</h2><p>（1）持久化<br>redis持久化方案有RDB和AOF。前者redis通过定时快照的方式将数据写入到硬盘上，对于非正常redis关闭的情况下，可能会导致数据丢失，而且这种持久化操作每次都会把所有数据写入硬盘，代价非常高。后者redis只追踪变化的数据，但是追加的log会越来越大，并且所有操作均重新执行一遍，恢复速度慢。<br>（2）耗内存<br>redis是基于内存操作的，对内存的要求较高。</p><h2 id="redis下载"><a href="#redis下载" class="headerlink" title="redis下载"></a>redis下载</h2><p>官方网站：<a href="http://redis.io/download">http://redis.io/download</a> 可以根据需求下载不同版本</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#redis是C语言开发的，所以需要gcc环境</span></span><br><span class="line">yum install gcc -y</span><br><span class="line"><span class="comment">#我这边下载redis-5.0.3</span></span><br><span class="line">wget http://download.redis.io/releases/redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar zxvf redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#移动到redis-5.0.3目录下执行</span></span><br><span class="line">make</span><br><span class="line"><span class="comment">#移动到redis-5.0.3/src目录下执行</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h2 id="redis-conf配置"><a href="#redis-conf配置" class="headerlink" title="redis.conf配置"></a>redis.conf配置</h2><table><thead><tr><th align="left">配置</th><th align="left">默认</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">daemonize</td><td align="left">no</td><td align="left">是否后台运行</td></tr><tr><td align="left">port</td><td align="left">6379</td><td align="left">端口</td></tr><tr><td align="left">bind</td><td align="left">127.0.0.1</td><td align="left">绑定ip，默认只允许本机访问redis-server</td></tr><tr><td align="left">timeout</td><td align="left">0</td><td align="left">客户端连接超时时间，单位为秒，默认0表示关闭此设置</td></tr><tr><td align="left">loglevel</td><td align="left">notice</td><td align="left">redis支持debug、verbose、notice、warning</td></tr><tr><td align="left">tcp-keepalive</td><td align="left">300</td><td align="left">TCP连接保活策略，默认单位为秒，如果设置60秒，则server端会每60秒向连接空闲的客户端发送一次ACK请求，以检查客户端是否存活，对于无响应的客户端则会关闭其连接</td></tr><tr><td align="left">logfile</td><td align="left"></td><td align="left">redis日志文件，默认为空，如果设置了daemonize yes，redis会把日志输出到/dev/null中</td></tr><tr><td align="left">databases</td><td align="left">16</td><td align="left">redis数据库总数量，数据库索引是0-15</td></tr><tr><td align="left">save <seconds> <changes></changes></seconds></td><td align="left">save 900 1 <br> save 300 10 <br> save 60 10000</td><td align="left">RDB持久化策略，默认是当60秒内有10000个key更改，触发一次RDB快照；当300秒内有10个key更改，触发一次RDB快照；当900秒内有1个key更改，触发一次RDB快照</td></tr><tr><td align="left">stop-writes-on-bgsave-error</td><td align="left">yes</td><td align="left">如果用户开启了RDB持久化，那么当redis持久化到硬盘出现失败，redis会停止接受所有的写请求，当下一次持久化成功后，redis会恢复接受写请求</td></tr><tr><td align="left">rdbcompression</td><td align="left">yes</td><td align="left">对于存储在硬盘的快照，redis支持压缩存储，如果不想消耗cpu，可以关闭此配置，但是存储在硬盘的数据会越来越大</td></tr><tr><td align="left">rdbchecksum</td><td align="left">yes</td><td align="left">在存储快照后，redis支持对数据校验，但是会消耗大约10%的性能，如果希望性能最大化，可以关闭此功能</td></tr><tr><td align="left">dbfilename</td><td align="left">dump.rdb</td><td align="left">设置快照文件的名称</td></tr><tr><td align="left">dir</td><td align="left">./</td><td align="left">配置快照存放路径</td></tr><tr><td align="left">replicaof <masterip> <masterport></masterport></masterip></td><td align="left"></td><td align="left">redis提供主从功能，通过slaveof配置一台服务器作为另一台从服务器</td></tr><tr><td align="left">masterauth <master-password></master-password></td><td align="left"></td><td align="left">如果主服务器设置了requirepass,则从redis配置中要使用masterauth来校验密码</td></tr><tr><td align="left">slave-serve-stale-data</td><td align="left">yes</td><td align="left">当从redis失去与主redis连接，或者主从正在同步时，redis是否处理客户端发来的请求</td></tr><tr><td align="left">replica-read-only</td><td align="left">yes</td><td align="left">控制从redis是否接受写请求</td></tr><tr><td align="left">rep-timeout</td><td align="left">60</td><td align="left">主从同步情况可能会发生超时，用户可以设置超时时限，不过一定要确保比repl-ping-replica-period的值要大</td></tr><tr><td align="left">repl-disable-tcp-nodelay</td><td align="left">no</td><td align="left">控制主从同步是否禁用TCP_NODELAY。如果开启TCP_NODELAY，那么主redis会使用更少的TCP包和更少的带宽来向从redis传输数据，但是会增加一些同步的延迟，大概40ms左右。如果关闭了TCP_NODELAY，那么数据同步延迟会降低，但是会消耗更多的带宽</td></tr><tr><td align="left">repl-backlog-size</td><td align="left">1mb</td><td align="left">设置队列长度，队列长度是redis中的一个缓冲区，如果与从redis断开连接后，主redis会用这个缓冲区缓存发送的数据</td></tr><tr><td align="left">repl-backlog-ttl</td><td align="left">3600</td><td align="left">如果主redis等了一段时间后，还是无法与从redis连接，那么缓冲区数据将被清除；如果设置为0表示永不清除</td></tr><tr><td align="left">min-replicas-to-write</td><td align="left">3</td><td align="left">与min-replicas-max-lag配合使用</td></tr><tr><td align="left">min-replicas-max-lag</td><td align="left">10</td><td align="left">表示当主redis发现超过M个连接延迟大于N秒时，那么主redis就停止接受写请求。从redis每秒都会向主redis发出ping，而主redis会记录每一个从redis发来的ping时间点，所以主redis能够了解从redis的运行情况</td></tr><tr><td align="left">replica-priority</td><td align="left">100</td><td align="left">规定从redis优先级，在主redis持续不正常工作时，优先级高的将成为主redis，而编号越小表示优先级越高，当编号被设置为0时表示这个从redis永远不会被选中，默认是100</td></tr><tr><td align="left">requirepass</td><td align="left">foobared</td><td align="left">设置密码验证，当客户端连接redis-server时，需要进行密码验证</td></tr><tr><td align="left">rename-command CONFIG “”</td><td align="left"></td><td align="left">对redis指令进行更名，避免外部调用。这里对CONFIG重命名</td></tr><tr><td align="left">max-clients</td><td align="left">10000</td><td align="left">设置redis-server允许客户端的最大连接数</td></tr><tr><td align="left">maxmemory <bytes></bytes></td><td align="left"></td><td align="left">设置redis可以使用的内存量，当超过此内存上限，redis将根据maxmemory-policy规则移除内部数据</td></tr><tr><td align="left">maxmemory-policy</td><td align="left">noeviction</td><td align="left">指定redis数据淘汰策略，redis提供了volatile-lru、allkeys-lru、volatile-random、allkeys-random、volatile-ttl、noeviction六种数据淘汰策略</td></tr><tr><td align="left">axmemory-samples</td><td align="left">5</td><td align="left">LRU和最小TTL算法都并非是精确算法，而是估算值，可以设置样本大小，redis默认检查5个key并选择其中LRU那个</td></tr><tr><td align="left">appendonly</td><td align="left">no</td><td align="left">redis支持数据持久化，目前redis持久化方案有RDB、AOF</td></tr><tr><td align="left">appendfilename</td><td align="left">“appendonly.aof”</td><td align="left">设置aof文件名称</td></tr><tr><td align="left">appendfsync</td><td align="left">everysec</td><td align="left">一次fsync()调用，操作系统会将缓存指令写入硬盘。redis支持三种模式，no：不调用，让操作系统自行决定sync的时间，redis性能更快；always：每次写请求后都会调用，这种情况redis会相对较慢，但数据最安全；everysec：每秒钟调用一次</td></tr><tr><td align="left">no-appendfsync-on-rewrite</td><td align="left">no</td><td align="left">bgrewriteaof机制，在一个子进程执行aof重写，不会阻塞主进程处理其余指令。但是当bgrewriteaof和主进程写aof时，两种均操作硬盘，bgrewriteaof会涉及大量硬盘操作，这样导致了主进程aof写入的阻塞，当no-appendfsync-on-rewrite设置为yes时表示这就相当于将appendfsync设置为no，不会有磁盘操作，只是写入缓冲区，不会出现阻塞，但是如果这个时候redis挂掉，会丢失数据。如果此参数设置为no，是最安全的方式，但是要忍受阻塞的情形</td></tr><tr><td align="left">auto-aof-rewrite-percentage</td><td align="left">100</td><td align="left">redis记录前一次aof文件大小作为基准值，当当前aof文件超过这个基准100%（默认100）时，触发bgrewriteaof，也就是用一个子进程重写aof。该配置为0时表示禁用重写</td></tr><tr><td align="left">auto-aof-rewrite-min-size</td><td align="left">64mb</td><td align="left">当aof文件大于64mb时，触发bgrewriteaof</td></tr><tr><td align="left">lua-time-limit</td><td align="left">5000</td><td align="left">lua脚本最大运行时间，默认单位ms</td></tr></tbody></table><h2 id="redis数据淘汰策略"><a href="#redis数据淘汰策略" class="headerlink" title="redis数据淘汰策略"></a>redis数据淘汰策略</h2><p>*volatile-lru:使用LRU算法移除过期集合中的key<br>*allkeys-lru:使用LRU算法移除key<br>*volatile-random:在过期集合中随机移除key<br>*allkeys-random:随机移除key<br>volatile-ttl:移除那些ttl值最小的key，即移除最近要过期的key<br>noeviction:不进行移除</p><h2 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h2><p>redis支持RDB和AOF两种持久化机制，redis持久化就是将内存中的数据写入到硬盘中，避免redis挂掉导致数据丢失。</p><h3 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h3><p>RDB持久化是把当前数据生成快照存储到硬盘中。触发方式有手动触发（save【阻塞式】、bgsave【推荐】）和自动触发（redis.conf中配置save）<br>RDB文件存储路径，通过redis.conf中的dir配置<br>（1）优点<br>*RDB文件是压缩的二进制文件，代表redis在某个时间点的快照，空间占用小<br>*redis加载RDB从硬盘中恢复数据远远快于AOF方式<br>（2）缺点<br>RDB没有做到实时数据持久化，如果数据更改没有达到RDB持久化触发的条件，redis在这个时候突然挂掉，那么就会导致数据丢失</p><h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>AOF持久化是以独立日志的方式记录每次的写命令，重启时再次执行AOF文件中的命令达到数据恢复。AOF主要是解决数据持久化的实时性问题<br>（1）AOF开启<br>通过redis.conf中的appendonly yes开启，通过appendfilename配置名称，通过dir配置数据存储路径<br>（2）AOF流程<br>*redis-server启动，如果AOF机制开启，那么初始化AOF状态，并且如果存在AOF文件，读取AOF文件<br>*随着redis不断接受命令，每个写命令都会被添加到AOF文件，AOF文件大小会增加，redis会记录之前aof大小，当目前aof文件大小达到auto-aof-rewrite-percentage、auto-aof-rewrite-min-size设定的值后，就会触发rewrite<br>*fork出一个子进程进行rewrite，重写新的aof文件，而父进程继续接受命令，现在的写命令都会添加aof_rewrite_buf_blocks缓冲区<br>*当子进程rewrite结束后，父进程收到子进程退出信号，把缓冲区的数据添加到rewrite后新的aof文件中，随后rename新的aof文件，覆盖旧的aof文件<br>*至此一个rewrite走完，继续第2步<br>（3）优点<br>*解决了数据持久化实时性的问题<br>*你可以设置不同的fsync策略，比如无fsync，每秒钟一次fsync，或者每次执行写入命令时fsync。AOF的默认策略为每秒钟fsync一次，在这种配置下，redis仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（fsync会在后台线程执行，所以主线程可以继续努力地处理命令请求）<br>（4）缺点<br>相对于RDB文件，AOF文件的大小通常大于RDB文件，根据fsync策略，AOF速度要慢于RDB</p><h2 id="redis-cluster集群"><a href="#redis-cluster集群" class="headerlink" title="redis-cluster集群"></a>redis-cluster集群</h2><p>redis cluster集群是一个由主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis cluster集群不需要sentine哨兵也能完成节点移除和故障转移功能。需要将每个节点设置成集群模式，这种集群没有中心节点，可水平扩展。<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/22/Redis%E7%AE%80%E4%BB%8B/a1.png"><br>（1）无中心化就是客户端直接与节点相连，不需要proxy代理层，客户端只需要连接到集群的任意节点就行<br>（2）集群中所有的redis节点彼此互联<br>（3）cluster集群中内置16384（编号0-16383）个哈希槽，redis根据节点数量均匀的将槽位分到不同节点。当客户端set一个key时，redis对key使用crc16算法算出一个结果，然后把结果对16384取模，这个key都会对应到0-16383之间的槽位。<br>（4）水平扩容-当集群中新增了一个节点，redis会从其他各个节点取出部分槽位分到新加入的节点<br>（5）集群进入fail状态的必要条件<br>*某个主节点和其所有从节点全部挂掉，集群进入fail状态<br>*如果集群超过半数以上master挂掉，无论是否存在slave，集群进入fail状态<br>*如果集群任意master挂掉，且master没有slave，集群进入fail状态<br>（6）redis投票机制-投票是所有master节点参与的，如果半数以上master节点无法与某个master节点通信，则认为此master节点挂掉</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis-cluster集群搭建</title>
      <link href="2020/03/17/Redis-cluster%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>2020/03/17/Redis-cluster%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><a id="more"></a><p>192.168.186.129<br>192.168.186.131<br>192.168.186.132</p><h2 id="实验前准备"><a href="#实验前准备" class="headerlink" title="实验前准备"></a>实验前准备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#在三台服务器分别创建一下目录</span></span><br><span class="line">mkdir -p /home/bin/redis/700&#123;1,4&#125;</span><br><span class="line">mkdir -p /home/bin/redis/700&#123;2,5&#125;</span><br><span class="line">mkdir -p /home/bin/redis/700&#123;3,6&#125;</span><br></pre></td></tr></table></figure><h2 id="安装redis-5-0-3"><a href="#安装redis-5-0-3" class="headerlink" title="安装redis-5.0.3"></a>安装redis-5.0.3</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装gcc</span></span><br><span class="line">yum install gcc -y</span><br><span class="line"><span class="comment">#安装wget</span></span><br><span class="line">yum install wget -y</span><br><span class="line"><span class="comment">#下载redis-5.0.3.tar.gz</span></span><br><span class="line">wget http://download.redis.io/releases/redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar zxvf redis-5.0.3.tar.gz</span><br><span class="line"><span class="comment">#移动到redis-5.0.3目录下，执行</span></span><br><span class="line">make</span><br><span class="line"><span class="comment">#移动到redis-5.0.3/src目录下，执行</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>复制redis-server、redis.conf、redis.cli到7001、7002、7003、7004、7005、7006目录下</p><h2 id="修改redis-conf"><a href="#修改redis-conf" class="headerlink" title="修改redis.conf"></a>修改redis.conf</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改以下项</span></span><br><span class="line">daemonize yes <span class="comment">#后台运行</span></span><br><span class="line">port 7001 <span class="comment">#端口，按照创建的文件夹分配7001-7006端口</span></span><br><span class="line"><span class="built_in">bind</span> <span class="comment">#绑定ip，默认绑定的是本机，只允许本地访问redis-server，要注释掉</span></span><br><span class="line">dir /home/bin/redis/7001/ <span class="comment">#redis数据文件存储位置</span></span><br><span class="line">cluster-enabled yes <span class="comment">#开启集群模式</span></span><br><span class="line">cluster-config-file nodes.conf <span class="comment">#配置集群配置文件</span></span><br><span class="line">cluster-node-timeout <span class="comment">#超时设置</span></span><br><span class="line">appendonly yes <span class="comment">#持久化</span></span><br><span class="line">protected-mode no <span class="comment">#保护模式</span></span><br><span class="line">requirepass 123456 <span class="comment">#设置密码，当客户端连接redis-server时，需要使用-a &lt;password&gt; 来连接</span></span><br><span class="line">masterauth 123456 <span class="comment">#集群通信密码</span></span><br></pre></td></tr></table></figure><h2 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分别进入7001-7006目录下启动redis</span></span><br><span class="line">./redis-server redis.conf</span><br><span class="line"><span class="comment">#查看redis启动情况</span></span><br><span class="line">ps -ef |grep redis  <span class="comment">#每天机器上应该有2个redis服务</span></span><br></pre></td></tr></table></figure><h2 id="redis-cli构建集群"><a href="#redis-cli构建集群" class="headerlink" title="redis-cli构建集群"></a>redis-cli构建集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/home/bin/redis/redis-5.0.3/src/redis.cli -a 123456 --cluster create --cluster-replicas 1 192.168.186.129:7001 192.168.186.131:7002 192.168.186.132:7003 192.168.186.129:7004 192.168.186.131:7005 192.168.186.132:7006</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL备份</title>
      <link href="2020/03/15/MySQL%E5%A4%87%E4%BB%BD/"/>
      <url>2020/03/15/MySQL%E5%A4%87%E4%BB%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>编辑/etc/my.cnf,再[mysqld]板块添加如下，重启服务</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">datadir=/usr/<span class="built_in">local</span>/mysql/data</span><br><span class="line">port=3306</span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">symbolic-links=0</span><br><span class="line">max_connections=400</span><br><span class="line">innodb_file_per_table=1</span><br><span class="line">lower_case_table_names=1</span><br><span class="line"><span class="comment">#开启、并且可以将mysql-bin改为其他的日志名</span></span><br><span class="line"><span class="built_in">log</span>-bin=mysql-bin</span><br><span class="line"><span class="comment">#添加id号，如果做主从，就不能一样</span></span><br><span class="line">server-id=1</span><br><span class="line"><span class="comment">#超过200M将生成新文件，最大和默认值是1GB</span></span><br><span class="line">max_binlog_size=1G</span><br><span class="line"><span class="comment">#表示binlog使用最大内存的数，默认1M</span></span><br><span class="line">max_binlog_cache_size=1M</span><br><span class="line"><span class="comment">#表示binlog日志保留时间，默认单位是天</span></span><br><span class="line">expire_logs_days=7</span><br></pre></td></tr></table></figure><h2 id="创建用户并且授权"><a href="#创建用户并且授权" class="headerlink" title="创建用户并且授权"></a>创建用户并且授权</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建back用户</span></span><br><span class="line">create user <span class="string">&#x27;back&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified by <span class="string">&#x27;tang1611&#x27;</span>;</span><br><span class="line"><span class="comment">#授权</span></span><br><span class="line">grant reload,lock tables,replication client,create tablespace,process,super on *.* to <span class="string">&#x27;back&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> ;</span><br><span class="line">grant create,insert,select on percona_schema.* to <span class="string">&#x27;back&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br><span class="line">use mysql;</span><br><span class="line">update user <span class="built_in">set</span> user.Host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user.User=<span class="string">&#x27;back&#x27;</span>;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h2 id="安装innobackupex"><a href="#安装innobackupex" class="headerlink" title="安装innobackupex"></a>安装innobackupex</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装依赖库</span></span><br><span class="line">yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL libev-devel</span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.12/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm</span><br><span class="line">yum -y install percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="innobackupex全备份"><a href="#innobackupex全备份" class="headerlink" title="innobackupex全备份"></a>innobackupex全备份</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建备份目录</span></span><br><span class="line">mkdir -p /root/bin</span><br><span class="line">mkdir -p /bak/mysql-xback</span><br></pre></td></tr></table></figure><p>编写脚本<br>vim /root/bin/mybak-all.sh</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#全备份</span></span><br><span class="line"><span class="comment">#指定备份目录</span></span><br><span class="line">backup_dir=<span class="string">&quot;/bak/mysql-xback&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#检查目录是否存在，不存在则创建</span></span><br><span class="line">[[ -d <span class="variable">$backup_dir</span> ]] || mkdir -p <span class="variable">$backup_dir</span></span><br><span class="line"><span class="keyword">if</span> [[ -d <span class="variable">$backup_dir</span>/all-backup ]];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;全备份已经存在&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#开始备份</span></span><br><span class="line">innobackupex --defaults-file=/etc/my.cnf --user=back --password=<span class="string">&#x27;tang1611&#x27;</span> --no-timestamp <span class="variable">$backup_dir</span>/all-backup &amp;&gt; /tmp/mysql-backup.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看临时目录</span></span><br><span class="line">tail -n 1 /tmp/mysql-backup.log | grep <span class="string">&#x27;completed OK!&#x27;</span></span><br><span class="line"><span class="keyword">if</span> [[ $? -eq 0 ]];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;备份成功&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;all-backup&quot;</span> &gt; /tmp/mysql-backup.txt</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;备份失败&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h2 id="innobackupex增量备份"><a href="#innobackupex增量备份" class="headerlink" title="innobackupex增量备份"></a>innobackupex增量备份</h2><p>编写脚本<br>vim /root/bin/mybak-section.sh</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#增量备份</span></span><br><span class="line"><span class="comment">#备份目录</span></span><br><span class="line">backup_dir=<span class="string">&quot;/bak/mysql-xback&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#新旧备份</span></span><br><span class="line">old_dir=`cat /tmp/mysql-backup.txt`</span><br><span class="line">new_dir=`date +%F-%H-%M-%S`</span><br><span class="line"></span><br><span class="line"><span class="comment">#检查目录</span></span><br><span class="line"><span class="keyword">if</span> [[ ! -d <span class="variable">$&#123;backup_dir&#125;</span>/all-backup ]];<span class="keyword">then</span> </span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;还没有全备份，请先进行全备份！&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行/usr/bin/innobackupex --user=back --password=&#x27;tang1611&#x27; --no-timestamp --incremental --incremental-basedir=$&#123;backup_dir&#125;/$&#123;old_dir&#125; $&#123;backup_dir&#125;/$&#123;new_dir&#125; &amp;&gt; /tmp/mysql-backup.log</span></span><br><span class="line"></span><br><span class="line">tail -n 1 /tmp/mysql-backup.log | grep <span class="string">&#x27;completed OK!&#x27;</span></span><br><span class="line"><span class="keyword">if</span> [[ $? -eq 0 ]];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;new_dir&#125;</span>&quot;</span> &gt; /tmp/mysql-backup.txt</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;备份失败&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将已提交的事物重放</span></span><br><span class="line">innobackupex --apply-log --redo-only /usr/<span class="built_in">local</span>/back/mysql/all/2020-03-16_11-38-50</span><br><span class="line"><span class="comment">#整合第一个增量备份数据到全量备份数据里面</span></span><br><span class="line">innobackupex --apply-log --redo-only /usr/<span class="built_in">local</span>/back/mysql/all/2020-03-16_11-38-50 --incremental-dir=//usr/<span class="built_in">local</span>/back/mysql/increment/2020-03-16_11-40-50</span><br><span class="line"><span class="comment">#整合第二个增量备份数据到全量备份数据里面</span></span><br><span class="line">innobackupex --apply-log --redo-only /usr/<span class="built_in">local</span>/back/mysql/all/2020-03-16_11-38-50 --incremental-dir=//usr/<span class="built_in">local</span>/back/mysql/increment/2020-03-16_11-45-30</span><br><span class="line"><span class="comment">#此时数据已经是最后一次增量备份的数据了，执行恢复</span></span><br><span class="line">innobackupex --copy-back /usr/<span class="built_in">local</span>/back/mysql/all/2020-03-16_11-38-50</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下MySQL安装(转)</title>
      <link href="2020/03/15/Linux%E4%B8%8BMySQL%E5%AE%89%E8%A3%85-%E8%BD%AC/"/>
      <url>2020/03/15/Linux%E4%B8%8BMySQL%E5%AE%89%E8%A3%85-%E8%BD%AC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://www.jianshu.com/p/276d59cbc529">https://www.jianshu.com/p/276d59cbc529</a></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx笔记四-高可用</title>
      <link href="2020/03/15/Nginx%E7%AC%94%E8%AE%B0%E5%9B%9B-%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>2020/03/15/Nginx%E7%AC%94%E8%AE%B0%E5%9B%9B-%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>nginx+keepalived实现高可用</p><a id="more"></a><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>192.168.186.100 虚拟vip<br>192.168.186.129 centos7 安装nginx、keepalived的服务器<br>192.168.186.130 centos7 安装nginx、keepalived的服务器<br>192.168.186.128 centos7 提供真实服务的httpd服务器<br>192.168.186.131 centos7 提供真实服务的httpd服务器<br>本地windows</p><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="httpd服务器配置"><a href="#httpd服务器配置" class="headerlink" title="httpd服务器配置"></a>httpd服务器配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install httpd -y</span><br><span class="line"><span class="comment">#在/etc/httpd/conf/httpd.conf修改httpd端口</span></span><br><span class="line">listen 8080</span><br><span class="line"><span class="comment">#在192.168.186.128的/var/www/html中创建a.html,向里面写入web1，在192.168.186.131的/var/www/html中创建a.html,向里面写入web2</span></span><br><span class="line"><span class="built_in">echo</span> web1 &gt; a.html</span><br><span class="line"><span class="built_in">echo</span> web2 &gt; a.html</span><br><span class="line"><span class="comment">#启动服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure><h2 id="nginx负载均衡器配置"><a href="#nginx负载均衡器配置" class="headerlink" title="nginx负载均衡器配置"></a>nginx负载均衡器配置</h2><h3 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upstream myserver &#123;</span><br><span class="line">                server 192.168.186.128:8080;</span><br><span class="line">                server 192.168.186.131:8080;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name  192.168.186.100;</span><br><span class="line">        root         /usr/share/nginx/html;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configuration files for the default server block.</span></span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                proxy_pass http://myserver/a.html;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="keepalived配置"><a href="#keepalived配置" class="headerlink" title="keepalived配置"></a>keepalived配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.186.128配置</span></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.186.100</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#192.168.186.131配置</span></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 99</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.186.100</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查看虚拟vip是否生成、是否能够自动漂移"><a href="#查看虚拟vip是否生成、是否能够自动漂移" class="headerlink" title="查看虚拟vip是否生成、是否能够自动漂移"></a>查看虚拟vip是否生成、是否能够自动漂移</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在MASTER主机上使用ip address命令查看ens33网卡下是否存在192.168.186.100</span></span><br><span class="line">ip address</span><br><span class="line"><span class="comment">#ping 192.168.186.100是否通</span></span><br><span class="line">ping 192.168.186.100</span><br><span class="line"><span class="comment">#停止MASTER主机的keepalived，查看虚拟ip是否漂移到BACKUP主机</span></span><br><span class="line">systemctl stop keepalived</span><br><span class="line">ip address</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在windows浏览器输入192.168.186.100:80,成功轮询访问到真实httpd服务器的页面</p>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx笔记三-负载均衡</title>
      <link href="2020/03/15/Nginx%E7%AC%94%E8%AE%B0%E4%B8%89-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
      <url>2020/03/15/Nginx%E7%AC%94%E8%AE%B0%E4%B8%89-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>192.168.186.129 centos7 安装nginx的负载均衡器<br>192.168.186.128 centos7 提供真实服务的httpd服务器<br>192.168.186.130 centos7 提供真实服务的httpd服务器<br>本地windows</p><a id="more"></a><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="httpd服务器配置"><a href="#httpd服务器配置" class="headerlink" title="httpd服务器配置"></a>httpd服务器配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install httpd -y</span><br><span class="line"><span class="comment">#在/etc/httpd/conf/httpd.conf修改httpd端口</span></span><br><span class="line">listen 8080</span><br><span class="line"><span class="comment">#在192.168.186.128的/var/www/html中创建a.html,向里面写入web1，在192.168.186.130的/var/www/html中创建a.html,向里面写入web2</span></span><br><span class="line"><span class="built_in">echo</span> web1 &gt; a.html</span><br><span class="line"><span class="built_in">echo</span> web2 &gt; a.html</span><br><span class="line"><span class="comment">#启动服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure><h2 id="nginx负载均衡器配置"><a href="#nginx负载均衡器配置" class="headerlink" title="nginx负载均衡器配置"></a>nginx负载均衡器配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upstream myserver &#123;</span><br><span class="line">                server 192.168.186.128:8080;</span><br><span class="line">                server 192.168.186.130:8080;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name  192.168.186.129;</span><br><span class="line">        root         /usr/share/nginx/html;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configuration files for the default server block.</span></span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                proxy_pass http://myserver/a.html;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>windows端浏览器输入192.168.186.129:80看是否能正常轮询切换到web1、web2</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如果出现返回页面报400错误，有可能是invalid hostname,也可能是其他http header导致服务器端无法正常解析。</p>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx笔记二(反向代理)</title>
      <link href="2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%BA%8C-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
      <url>2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%BA%8C-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>192.168.186.129 centos7<br>本地windows</p><a id="more"></a><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="安装nginx、httpd"><a href="#安装nginx、httpd" class="headerlink" title="安装nginx、httpd"></a>安装nginx、httpd</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install nginx -y</span><br><span class="line">yum install httpd -y</span><br><span class="line"><span class="comment">#在/etc/httpd/conf/httpd.conf修改httpd端口</span></span><br><span class="line">listen 8080</span><br><span class="line"><span class="comment">#启动服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure><h2 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#打开windows的C:\Windows\System32\drivers\etc的hosts文件，追加一行</span></span><br><span class="line">192.168.186.129  www.abctwf.com</span><br></pre></td></tr></table></figure><h2 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/nginx/nginx.conf</span><br><span class="line">server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name  192.168.186.129;</span><br><span class="line">        root         /usr/share/nginx/html;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configuration files for the default server block.</span></span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                proxy_pass http://127.0.0.1:8080;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">            location = /40x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">            location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>浏览器访问<a href="http://www.abctwf.com,即访问httpd首页/">www.abctwf.com，即访问httpd首页</a><br><img src= "/img/loading.gif" data-lazy-src="/2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%BA%8C-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx笔记一</title>
      <link href="2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/"/>
      <url>2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="nginx概述"><a href="#nginx概述" class="headerlink" title="nginx概述"></a>nginx概述</h2><p>Nginx是一个高性能的HTTP和反向代理服务器，特点占用内存少，并发能力强，常用于负载均衡服务器。</p><a id="more"></a><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>nginx不仅可以做反向代理，实现负载均衡，还可用作正向代理来进行上网等功能。<br>正向代理：例如大陆用户需要访问谷歌，但是一般来说，大陆用户是无法访问谷歌的，这时候需要在浏览器设置代理，通过代理服务器访问谷歌。简单说正向代理代理的是客户端。<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/a1.png"><br>反向代理：其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外暴露的就是一个服务器，暴露的是反向代理服务器，隐藏真实服务器的ip地址。简单的说正向代理即代理的是服务端<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/a2.png"></p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>客户端发送多个请求到服务端，服务端处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回客户端。<br>这种架构模式会造成服务器处理请求日益缓慢，并发特别大的时候，甚至可能导致服务器宕机，一旦服务端宕机，整个系统就直接崩溃了，而负载均衡技术就可以解决这种业务情景。<br>负载均衡就是客户端在发送请求，请求并不直接到达真实服务器，而是最先到达负载均衡器，负载均衡器将请求按照某种算法分配到不同的真实服务器，以减少真实服务器的并发量。如果真实服务器当中某个服务器出现问题，负载均衡器会将其剔除，并不会影响到系统的正常运行。<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/a3.png"></p><h2 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h2><p>为了加快网站的解析速度，可以把动态页面和静态页面由不同服务器来解析，这样加快了解析速度，降低了单个服务器的压力。<br><img src= "/img/loading.gif" data-lazy-src="/2020/03/08/Nginx%E7%AC%94%E8%AE%B0%E4%B8%80/a4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java生产环境下性能监控</title>
      <link href="2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/"/>
      <url>2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文是基于jdk1.8，其他版本稍有不同</p><a id="more"></a><h2 id="JVM参数类型"><a href="#JVM参数类型" class="headerlink" title="JVM参数类型"></a>JVM参数类型</h2><p>（1）标准参数<br>-help<br>-server -client<br>-version -showversion<br>-cp -classpath<br>（2）X参数<br>非标准化参数<br>-Xint:解释执行<br>-Xcomp:第一次使用就编译成本地代码<br>-Xmixed:混合模式，由JVM自己来决定是否编译成本地代码<br><img src= "/img/loading.gif" data-lazy-src="/2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/a1.png"><br>（3）XX参数<br>非标准化参数<br>相对不稳定<br>主要用于JVM调优和Debug</p><h2 id="XX参数分类"><a href="#XX参数分类" class="headerlink" title="XX参数分类"></a>XX参数分类</h2><p>（1）Boolean类型<br>格式：-XX:[+-]<name>表示启动或禁用name属性<br>比如：-XX:+UseConcMarkSweepGC<br>      -XX:+UseG1GC<br>（2）非Boolean类型<br>格式：-XX:<name>=<value>表示name属性的值是value<br>比如：-XX:MaxGCPauseMillis=500<br>      XX:GCTimeRatio=19</value></name></name></p><h2 id="jps工具"><a href="#jps工具" class="headerlink" title="jps工具"></a>jps工具</h2><p>查看java进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#常用指令</span></span><br><span class="line">jps</span><br><span class="line">jps -l</span><br></pre></td></tr></table></figure><h2 id="jinfo工具"><a href="#jinfo工具" class="headerlink" title="jinfo工具"></a>jinfo工具</h2><p>查看Java进程运行的JVM参数</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#常用指令</span></span><br><span class="line">jinfo -flag &lt;JVM参数&gt; pid</span><br></pre></td></tr></table></figure><h2 id="jstat工具"><a href="#jstat工具" class="headerlink" title="jstat工具"></a>jstat工具</h2><p>监控进程的类装载、内存、垃圾收集、JIT编译等运行数据<br>jstat &lt;参数&gt; pid time(ms) count</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#每隔1s显示类装载信息，输出10次</span></span><br><span class="line">jstat -class 14589 1000 10</span><br><span class="line"><span class="comment">#每隔1s显示gc信息，输出10次</span></span><br><span class="line">jstat -gc 14589 1000 10</span><br><span class="line"><span class="comment">#每隔1s显示JIT编译信息，输出10次</span></span><br><span class="line">jstat -compiler 14589 1000 10</span><br><span class="line">jstat -printcompilation 14589 1000 10</span><br></pre></td></tr></table></figure><p>-gc输出结果<br>S0C、S1C、S0U、S1U:S0和S1的总量与使用量<br>EC、EU：Eden区总量与使用量<br>OC、OU：Old区总量与使用量<br>MC、MU：Metaspace区总量与使用量<br>CCSC、CCSU：压缩类空间总量与使用量<br>YGC、YGCT：YoungGC的次数与时间<br>FGC、FGCT：FullGC的次数与时间<br>GCT：总的GC时间</p><h2 id="查看JVM运行时的参数"><a href="#查看JVM运行时的参数" class="headerlink" title="查看JVM运行时的参数"></a>查看JVM运行时的参数</h2><p>（1）PrintFlagsFinal</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">java -XX:+PrintFlagsFinal -version</span><br></pre></td></tr></table></figure><p>（2）jinfo</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jinfo -flag MaxHeapSize 14589</span><br></pre></td></tr></table></figure><h2 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h2><p><img src= "/img/loading.gif" data-lazy-src="/2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/a2.png"></p><h2 id="内存溢出演示"><a href="#内存溢出演示" class="headerlink" title="内存溢出演示"></a>内存溢出演示</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@Controller</span><br><span class="line">public class OutOfMemory &#123;</span><br><span class="line">    List&lt;User&gt; list=new ArrayList&lt;User&gt;();</span><br><span class="line">    @RequestMapping(<span class="string">&quot;/memory&quot;</span>)</span><br><span class="line">    public void <span class="function"><span class="title">memory</span></span>() &#123;</span><br><span class="line">        int i=0;</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">            list.add(new User(i++,UUID.randomUUID().toString()));</span><br><span class="line">        &#125;        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了更快的看出效果，设置JVM参数：-Xmx32M -Xms32M<br><img src= "/img/loading.gif" data-lazy-src="/2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/a3.png"></p><h2 id="导出内存映像文件"><a href="#导出内存映像文件" class="headerlink" title="导出内存映像文件"></a>导出内存映像文件</h2><p>（1）内存溢出时自动导出<br>-XX:+HeapDumpOnOutOfMemoryError<br>-XX:HeapDumpPath=./<br><img src= "/img/loading.gif" data-lazy-src="/2020/01/30/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/a4.png"><br>（2）使用jmap命令手动导出</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jmap -dump:format=b,file=heap &lt;pid&gt;</span><br></pre></td></tr></table></figure><h2 id="Tomcat优化"><a href="#Tomcat优化" class="headerlink" title="Tomcat优化"></a>Tomcat优化</h2><h3 id="线程优化"><a href="#线程优化" class="headerlink" title="线程优化"></a>线程优化</h3><p>相关文档：docs/config/http.html<br>（1）maxConnections：最大连接数，tomcat能够最大处理的最大连接数<br>（2）acceptCount：默认是100，如果请求超过了maxConnections，可以配置一个队列，将连接压到队列里。（不需要太大，太大没有意义）<br>（3）maxThreads：工作线程数，默认值是200，同一个时间点上能够同时处理的并发请求数<br>（4）minSpareThreads：最小空闲的工作线程。不能设置太小，万一请求突然变多，线程数来不及增加。</p><h3 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h3><p>（1）autoDeploy：当tomcat运行时，是否需要周期性检查有新的web应用，来部署新的应用。生产环境，建议设置为false<br>（2）enableLookups：是否需要tomcat进行DNS域名解析。生产环境，建议设置为false<br>（3）reloadable：是否需要tomcat监控/WEB-INF/classes/ and /WEB-INF/lib的变化。生产环境，建议设置为false<br>（4）tomcat有3中方式启动：bio、nio、apr<br>BIO：bio是阻塞式IO操作，使用java io技术，即每一个请求都要创建一个线程来进行处理。缺点：并发量高时，线程数较多，占资源<br>NIO：使用java nio技术，能够通过少量的线程处理大量的请求，nio是基于java中非阻塞IO操作的API实现，比传统的i/o处理方式有更高的并发运行性能<br>APR(Apache Portable Runtime/Apache可移植运行时库)：apr是从操作系统级别解决异步IO问题，大幅度提高服务器的并发处理性能，也是Tomcat生产环境运行的首选方式<br>tomcat低版本是使用BIO的，tomcat8以后默认使用NIO方式，在service.xml文件中找到此处</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=<span class="string">&quot;8091&quot;</span> protocol=<span class="string">&quot;HTTP/1.1&quot;</span></span><br><span class="line">               connectionTimeout=<span class="string">&quot;20000&quot;</span></span><br><span class="line">               redirectPort=<span class="string">&quot;8443&quot;</span> /&gt;</span><br></pre></td></tr></table></figure><p>修改成下面这个，可以使用apr的模式启动</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=<span class="string">&quot;8091&quot;</span> protocol=<span class="string">&quot;org.apache.coyote.http11.Http11AprProtocol&quot;</span> connectionTimeout=<span class="string">&quot;20000&quot;</span> redirectPort=<span class="string">&quot;8443&quot;</span> /&gt;</span><br></pre></td></tr></table></figure><h3 id="Session优化"><a href="#Session优化" class="headerlink" title="Session优化"></a>Session优化</h3><p>如果没有使用原生的Session，并且页面是使用JSP写的，建议禁用Session</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#JSP禁用Session</span></span><br><span class="line">&lt;% page session=<span class="string">&quot;false&quot;</span> %&gt;</span><br></pre></td></tr></table></figure><h2 id="Nginx优化"><a href="#Nginx优化" class="headerlink" title="Nginx优化"></a>Nginx优化</h2><h3 id="配置线程数和并发数"><a href="#配置线程数和并发数" class="headerlink" title="配置线程数和并发数"></a>配置线程数和并发数</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">worker_processes 4; <span class="comment">#cpu</span></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 10240; <span class="comment">#每个进程打开的最大连接数，包含了nginx与客户端和nginx与upsteam之间的连接</span></span><br><span class="line">    multi_accept on; <span class="comment">#可以一次建立多个连接</span></span><br><span class="line">    use epoll;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置后端Server的长连接"><a href="#配置后端Server的长连接" class="headerlink" title="配置后端Server的长连接"></a>配置后端Server的长连接</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upsteam server_pool&#123;</span><br><span class="line">    server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;</span><br><span class="line">    server localhost:8081 weight=1 max_fails=2 fail_timeout=30s;</span><br><span class="line">    keepalive 300; <span class="comment">#300个长连接</span></span><br><span class="line">&#125;</span><br><span class="line">location / &#123;</span><br><span class="line">    proxy_http_version 1.1;</span><br><span class="line">    proxy_set_header Upgrade <span class="variable">$http_upgrade</span>;</span><br><span class="line">    proxy_set_header Connection <span class="string">&quot;upgrade&quot;</span>;</span><br><span class="line">    proxy_pass http://server_pool/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置压缩"><a href="#配置压缩" class="headerlink" title="配置压缩"></a>配置压缩</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gzip on;</span><br><span class="line">gzip_http_version 1.1;</span><br><span class="line">gzip_disable <span class="string">&quot;MSIE [1-6]\.(?!.*SV1)&quot;</span>;</span><br><span class="line">gzip_proxied any;</span><br><span class="line">gzip_types text/plain text/css application/javascript application/x-javascript application/json application/xml application/vnd.ms-fontobject application/x-font-ttf application/svg+xml application/x-icon;</span><br><span class="line">gzip_vary on;</span><br><span class="line">gzip_static on; <span class="comment">#如果有压缩好的，直接使用</span></span><br></pre></td></tr></table></figure><h3 id="操作系统优化"><a href="#操作系统优化" class="headerlink" title="操作系统优化"></a>操作系统优化</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置文件/etc/sysctl.conf</span></span><br><span class="line">sysctl -w net.ipv4.tcp_syncookies=1 <span class="comment">#防止一个套接字在有过多试图连接到达时引起过载</span></span><br><span class="line">sysctl -w net.core.somaxconn=1024 <span class="comment">#默认128，连接队列</span></span><br><span class="line">sysctl -w net.ipv4.tcp_fin_timeout=10 <span class="comment">#timewait的超时时间，系统默认时间较长，可以改小一点</span></span><br><span class="line">sysctl -w net.ipv4.tcp_tw_reuse=1 <span class="comment">#os直接使用tomeout的连接</span></span><br><span class="line">sysctl -w net.ipv4.tcp_tw_recycle=0 <span class="comment">#回收禁用</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置文件/etc/security/limits.conf</span></span><br><span class="line">* hard nofile 204800</span><br><span class="line">* soft nofile 204800</span><br><span class="line">* soft core unlimited</span><br><span class="line">* soft stack 204800</span><br></pre></td></tr></table></figure><h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sendfile on; <span class="comment">#减少文件在应用和内核之间拷贝</span></span><br><span class="line">tcp_nopush on; <span class="comment">#当数据包达到一定大小再发送</span></span><br><span class="line">tcp_nodelay off; <span class="comment">#有数据包随时发送</span></span><br></pre></td></tr></table></figure><h2 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h2><h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><p>-Xms -Xmx：最小堆内存   最大堆内存<br>-XX:NewSize -XX:MaxNewSize:新生代大小   最大新生代大小<br>-XX:NewRatio -XX:SurvivorRatio:young区与old区的比例   Eden区域和Survivor区域<br>-XX:MetaspaceSize -XX:MaxMetaspaceSize:Metaspace区域大小   最大Metaspace区域大小<br>-XX:+UseCompressedClassPointers:是否启用压缩的类指针，启用之后就会产生CCS区域（默认占有1024M大小）<br>-XX:CompressedClassSpaceSize:设置压缩区域大小</p><h3 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h3><p>（1）标记-清除<br>定义：算法分为“标记”和“清除”两个阶段，首先标记出所有需要回收的对象，在标记完成后统一回收所有<br>缺点：效率不高，标记和清除两个过程的效率都不高。产生碎片，碎片太多会导致提前GC。<br>（2）复制<br>定义：它将可用内存按容量分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完时，它将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。<br>优缺点：实现简单，运行高效，但是空间利用率低。<br>（3）标记-整理<br>定义：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存<br>优缺点：没有了内存碎片，但是整理内存比较耗时。</p><h3 id="分带垃圾回收"><a href="#分带垃圾回收" class="headerlink" title="分带垃圾回收"></a>分带垃圾回收</h3><p>Young区用复制算法<br>Old区对象存活时间较长，采用标记清除或标记整理算法</p><h3 id="对象分配"><a href="#对象分配" class="headerlink" title="对象分配"></a>对象分配</h3><p>对象优先在Eden区分配<br>大对象直接进入老年代：-XX:PretenureSizeThreshold<br>长期存活的对象进入老年代：-XX:MaxTenuringThreshold -XX:+PrintTenuringDistribution -XX:TargetSurvivorRatio</p><h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><p>（1）串行收集器Serial：Serial、Serial Old<br>进行垃圾收集时，必须暂停所有工作线程，直到完成，即”Stop The World”；</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-XX:+UseSerialGC -XX:+UseSerialOldGC</span><br></pre></td></tr></table></figure><p>（2）并行收集器Parallel：Parallel Scavenge、Parallel Old，吞吐量优先<br>Server模式下的默认收集器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#开启参数</span></span><br><span class="line">-XX:+UseParallelGC -XX:+UseParallelOldGC</span><br><span class="line"><span class="comment">#开启多少个GC线程</span></span><br><span class="line">-XX:ParallelGCThreads=&lt;N&gt;</span><br><span class="line">CPU&gt;8 N=5/8</span><br><span class="line">CPU&lt;8 N=CPU个数</span><br></pre></td></tr></table></figure><p>（3）并发收集器Concurrent：CMS、G1，响应时间优先</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#开启参数</span></span><br><span class="line">CMS: -XX:+UseConcMarkSweepGC -XX:+UseParNewGC</span><br><span class="line">G1: -XX:+UseG1GC</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#CMS的相关参数</span></span><br><span class="line">-XX:ConcGCThreads:并发的GC线程数</span><br><span class="line">-XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩</span><br><span class="line">-XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次</span><br><span class="line">-XX:CMSInitiatingOccupancyFraction:Old区内存占用多少时触发FullGC，默认92%</span><br><span class="line">-XX:+UseCMSInitiatingOccupancyOnly:是否动态调</span><br><span class="line">-XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC</span><br><span class="line">-XX:+CMSClassUnloadingEnabled:启用回收Perm区</span><br></pre></td></tr></table></figure><h3 id="垃圾收集器的选择"><a href="#垃圾收集器的选择" class="headerlink" title="垃圾收集器的选择"></a>垃圾收集器的选择</h3><p>（1）优先调整堆的大小让服务器自己来选择<br>（2）如果内存小于100M，使用串行收集器<br>（3）如果是单核，并且没有停顿时间的要求，串行或者JVM自己选<br>（4）如果允许停顿时间超过1秒，选择并行或者JVM自己选<br>（5）如果响应时间必须小于1秒，选择并发收集器</p><h3 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h3><p>（1）定义<br>将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此G1天然就是一种压缩方案(局部压缩)；<br>Region：内存分区<br>SATB：它是通过Root Tracing得到的，GC开始时后存活对象的快照<br>RSet：记录了其他Region中对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）<br>（2）YoungGC<br>1）新对象进入Eden区<br>2）存活对象拷贝到Survivor区<br>3）存活时间达到年龄阈值时，对象晋升到Old区<br>而G1垃圾收集器不是FullGC，是MixedGC（回收所有Young和部分Old）<br>（3）MixedGC时机<br>InitiatingHeapOccupancyPercent:堆占有率达到这个值则触发global concurrent marking(全局并发标记)，默认值45%<br>G1HeapWastePercent:在global concurrent marking标记之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生MixedGC之前，会检查垃圾占比是否达到此参数值，只有达到了，下次才会发生MixedGC</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#MixedGC相关参数</span></span><br><span class="line">G1MixedGCLiveThresholdPercent  <span class="comment">#Old区的region被回收时候的存活对象占比</span></span><br><span class="line">G1MixedGCCountTarget  <span class="comment">#一次global concurrent marking之后，最多执行Mixed GC的次数</span></span><br><span class="line">G1OldCSetRegionThresholdPercent  <span class="comment">#一次Mixed GC中能够被选入CSet的最多old区的region数量</span></span><br><span class="line">-XX:+UseG1GC  <span class="comment">#开启G1</span></span><br><span class="line">-XX:G1HeapRegionSize=n  <span class="comment">#region的大小，1-32M，2048个</span></span><br><span class="line">-XX:MaxGCPauseMillis=200  <span class="comment">#最大停顿时间</span></span><br><span class="line">-XX:G1NewSizePercent -XX:G1MaxNewSizePercent  <span class="comment">#young区占比  young区最大占比</span></span><br><span class="line">-XX:G1ReservePercent=10  <span class="comment">#保留防止Survivor区to space溢出</span></span><br><span class="line">-XX:ParallelGCThreads=n  <span class="comment">#SWT线程数</span></span><br><span class="line">-XX:ConcGCThreads=n  <span class="comment">#并发线程数=1/4*并行</span></span><br></pre></td></tr></table></figure><p>（4）注意<br>年轻代大小：避免使用-Xmn、-XX:NewRatio等显式设置Young区大小，会覆盖暂停时间目标<br>暂停时间目标：暂停时间不要太苛刻，其吞吐量是90%的应用程序时间和10%的垃圾回收时间，太苛刻会直接影响到吞吐量</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调优 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix邮件告警</title>
      <link href="2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/"/>
      <url>2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>下面我们对内存使用率进行监控，并设置邮件告警。</p><a id="more"></a><h2 id="设置QQ邮箱"><a href="#设置QQ邮箱" class="headerlink" title="设置QQ邮箱"></a>设置QQ邮箱</h2><p>在设置-&gt;账户里面，开启POP3/IMAP/SMTP/Exchange/CardDAV/CalDAV服务，获取授权码<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a1.png"></p><h2 id="设置自定义监控项的key"><a href="#设置自定义监控项的key" class="headerlink" title="设置自定义监控项的key"></a>设置自定义监控项的key</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#进入被监控主机,打开/etc/zabbix/zabbix-agent.conf，在最后一行添加</span></span><br><span class="line">UserParameter=memory_used,free -m | awk <span class="string">&#x27;/^Mem/ &#123;print $3/$2&#125;&#x27;</span></span><br><span class="line"><span class="comment">#重启agent服务</span></span><br><span class="line">systemctl restart zabbix-agent</span><br><span class="line"><span class="comment">#在zabbix server端测试key</span></span><br><span class="line">zabbix_get -s 192.168.136.135 -p 10050 -k memory_used</span><br></pre></td></tr></table></figure><h2 id="创建监控项"><a href="#创建监控项" class="headerlink" title="创建监控项"></a>创建监控项</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a2.png"></p><h2 id="创建监控图形"><a href="#创建监控图形" class="headerlink" title="创建监控图形"></a>创建监控图形</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a4.png"></p><h2 id="添加触发器"><a href="#添加触发器" class="headerlink" title="添加触发器"></a>添加触发器</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a5.png"></p><h2 id="安装mailx工具，配置Zabbix服务端外部邮箱"><a href="#安装mailx工具，配置Zabbix服务端外部邮箱" class="headerlink" title="安装mailx工具，配置Zabbix服务端外部邮箱"></a>安装mailx工具，配置Zabbix服务端外部邮箱</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装mailx</span></span><br><span class="line">yum install mailx</span><br><span class="line"><span class="comment">#配置/etc/mail.rc文件，在末尾加上smtp相关配置</span></span><br><span class="line"><span class="built_in">set</span> bsdcompat</span><br><span class="line"><span class="built_in">set</span> from=1335402049@qq.com</span><br><span class="line"><span class="built_in">set</span> smtp=smtp.qq.com</span><br><span class="line"><span class="built_in">set</span> smtp-auth-user=1335402049@qq.com</span><br><span class="line"><span class="built_in">set</span> smtp-auth-password=pdicfqdoyvkmhiie  <span class="comment">#授权码</span></span><br><span class="line"><span class="built_in">set</span> smtp-auth-login</span><br></pre></td></tr></table></figure><h2 id="邮件脚本"><a href="#邮件脚本" class="headerlink" title="邮件脚本"></a>邮件脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装dos2unix，解决邮件内容为附件问题</span></span><br><span class="line">yum install dos2unix</span><br><span class="line"></span><br><span class="line"><span class="comment">#在/usr/lib/zabbix/alertscripts目录下编写mail.sh脚本</span></span><br><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line">export.UTF-8</span><br><span class="line">FILE=/tmp/mailtmp.txt </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$3</span>&quot;</span> &gt;<span class="variable">$FILE</span> </span><br><span class="line">dos2unix -k <span class="variable">$FILE</span>   <span class="comment">#解决邮件内容为附件问题</span></span><br><span class="line">/bin/mail -s <span class="string">&quot;<span class="variable">$2</span>&quot;</span> <span class="variable">$1</span> &lt; <span class="variable">$FILE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#给mail.sh授权</span></span><br><span class="line">chmod +x mail.sh</span><br><span class="line"><span class="comment">#创建临时文件并授权</span></span><br><span class="line">touch /tmp/mailtmp.txt</span><br><span class="line">chown zabbix.zabbix /tmp/mailtmp.txt</span><br></pre></td></tr></table></figure><h2 id="添加报警媒介类型"><a href="#添加报警媒介类型" class="headerlink" title="添加报警媒介类型"></a>添加报警媒介类型</h2><p>点击管理-&gt;报警媒介类型-&gt;创建媒体类型<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a6.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a7.png"></p><h2 id="创建用户群组"><a href="#创建用户群组" class="headerlink" title="创建用户群组"></a>创建用户群组</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a8.png"></p><h2 id="创建用户添加到用户组，设置报警媒介"><a href="#创建用户添加到用户组，设置报警媒介" class="headerlink" title="创建用户添加到用户组，设置报警媒介"></a>创建用户添加到用户组，设置报警媒介</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a9.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a10.png"><br>最后添加用户</p><h2 id="创建动作"><a href="#创建动作" class="headerlink" title="创建动作"></a>创建动作</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a11.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a12.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a13.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a14.png"><br>最后添加动作,我这边只是添加了报警操作，也可以添加报警恢复后操作。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在被监控机器上执行,等待报警</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=/<span class="built_in">test</span> count=3 bs=1024M</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/30/Zabbix%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/a15.png"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix安装与部署</title>
      <link href="2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/"/>
      <url>2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>zabbix是一款基于web界面的提供分布式系统监控以及网络监视功能的企业级的开源解决方案<br>zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制让系统管理员快速定位，解决存在的各种问题<br>zabbix由2部分构成，zabbix server与可选组件zabbix agent<br>zabbix server可以通过SNMP、zabbix agent、ping、端口监视等方法提供对远程服务器、网络状态的监视，以及数据收集等功能，它可以运行在Linux、Solaris、HP-UX、ALX、Free BSD、Open BSD，OS X等平台上</p><a id="more"></a><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#临时关闭</span></span><br><span class="line">setenforce 0</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><h2 id="安装httpd服务"><a href="#安装httpd服务" class="headerlink" title="安装httpd服务"></a>安装httpd服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install -y httpd</span><br><span class="line"><span class="comment">#启动httpd，并设置开机自启</span></span><br><span class="line">systemctl start httpd &amp;&amp; systemctl <span class="built_in">enable</span> httpd</span><br><span class="line"><span class="comment">#查看httpd启动情况</span></span><br><span class="line">systemctl status httpd</span><br></pre></td></tr></table></figure><h2 id="安装mariadb数据库"><a href="#安装mariadb数据库" class="headerlink" title="安装mariadb数据库"></a>安装mariadb数据库</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install -y mariadb mariadb-server</span><br><span class="line"><span class="comment">#启动mariadb，并设置开机自启</span></span><br><span class="line">systemctl start mariadb &amp;&amp; systemctl <span class="built_in">enable</span> mariadb</span><br><span class="line"><span class="comment">#查看mariadb启动情况</span></span><br><span class="line">systemctl status mariadb</span><br><span class="line"><span class="comment">#查看是否安装成功</span></span><br><span class="line">mysql</span><br></pre></td></tr></table></figure><h2 id="安装php环境"><a href="#安装php环境" class="headerlink" title="安装php环境"></a>安装php环境</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y php php-mysql</span><br></pre></td></tr></table></figure><h2 id="安装zabbix"><a href="#安装zabbix" class="headerlink" title="安装zabbix"></a>安装zabbix</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载包</span></span><br><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm</span><br><span class="line"><span class="comment">#安装zabbix包</span></span><br><span class="line">yum install -y zabbix-server-mysql zabbix-get zabbix-web zabbix-web-mysql zabbix-agent zabbix-sender</span><br><span class="line"><span class="comment">#创建一个zabbix库，并设置为utf8的字符编码格式</span></span><br><span class="line">mysql</span><br><span class="line">create database zabbix character <span class="built_in">set</span> utf8 collate utf8_bin;</span><br><span class="line"><span class="comment">#查看是否创建成功</span></span><br><span class="line">show databases;</span><br><span class="line"><span class="comment">#创建zabbix数据库账户、设置密码并且授权</span></span><br><span class="line">grant all privileges on zabbix.* to zabbix@localhost identified by <span class="string">&#x27;zabbix&#x27;</span>;</span><br><span class="line"><span class="comment">#刷新</span></span><br><span class="line">flush privileges;</span><br><span class="line"><span class="comment">#退出</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><h2 id="导入表"><a href="#导入表" class="headerlink" title="导入表"></a>导入表</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#切换到此目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/share/doc/zabbix-server-mysql-3.4.15</span><br><span class="line"><span class="comment">#进行解压</span></span><br><span class="line">gunzip create.sql.gz</span><br><span class="line"><span class="comment">#对表进行导入</span></span><br><span class="line">mysql</span><br><span class="line">use zabbix;</span><br><span class="line"><span class="built_in">source</span> create.sql</span><br></pre></td></tr></table></figure><h2 id="配置zabbix文件"><a href="#配置zabbix文件" class="headerlink" title="配置zabbix文件"></a>配置zabbix文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#进入此目录</span></span><br><span class="line"><span class="built_in">cd</span> /etc/zabbix</span><br><span class="line"><span class="comment">#对zabbix_server.conf进行配置，主要修改一下内容</span></span><br><span class="line">DBHost=localhost</span><br><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=zabbix</span><br><span class="line">DBSocket=/var/lib/mysql/mysql.sock</span><br><span class="line"><span class="comment">#运行zabbix-server服务，并设置开机自启</span></span><br><span class="line">systemctl start zabbix-server &amp;&amp; systemctl <span class="built_in">enable</span> zabbix-server</span><br></pre></td></tr></table></figure><h2 id="配置php"><a href="#配置php" class="headerlink" title="配置php"></a>配置php</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#进入此目录</span></span><br><span class="line"><span class="built_in">cd</span> /etc/httpd/conf.d</span><br><span class="line"><span class="comment">#配置时间,编辑zabbix.conf文件，在&lt;IfModule mod_php5.c&gt;标签内增加一行 </span></span><br><span class="line">php_value date.timezone Asia/shanghai</span><br><span class="line"><span class="comment">#重启httpd服务</span></span><br><span class="line">systemctl restart httpd</span><br></pre></td></tr></table></figure><p>##登录zabbix网址设置<br>在浏览器输入zabbix server服务器地址，我的是192.168.136.134/zabbix<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a1.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a2.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a3.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a4.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a5.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a6.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a7.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a8.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a9.png"></p><p>##添加对zabbix server自身的监控<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a10.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动zabbix server主机上的agent，并设置自启</span></span><br><span class="line">systemctl start zabbix-agent &amp;&amp; systemctl <span class="built_in">enable</span> zabbix-agent</span><br></pre></td></tr></table></figure><h2 id="解决中文乱码问题"><a href="#解决中文乱码问题" class="headerlink" title="解决中文乱码问题"></a>解决中文乱码问题</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a11.png"><br>在C:\Windows\Fonts找到黑体文件，复制到zabbix server的/usr/share/zabbix/fonts<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a12.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a13.png"></p><h2 id="在被监控主机安装zabbix-agent"><a href="#在被监控主机安装zabbix-agent" class="headerlink" title="在被监控主机安装zabbix agent"></a>在被监控主机安装zabbix agent</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#临时关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#准备zabbix-repo</span></span><br><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm</span><br><span class="line"><span class="comment">#安装zabbix-agent</span></span><br><span class="line">yum -y install zabbix-agent</span><br><span class="line"><span class="comment">#配置主服务器地址,打开/etc/zabbix/zabbix-agent.conf文件，修改一下内容</span></span><br><span class="line">Server=192.168.136.134</span><br><span class="line">ServerActive=192.168.136.134</span><br><span class="line">Hostname=web1</span><br><span class="line"><span class="comment">#启动zabbix-agent,设置开机自启</span></span><br><span class="line">systemctl start zabbix-agent &amp;&amp; systemctl <span class="built_in">enable</span> zabbix-agent</span><br></pre></td></tr></table></figure><h2 id="使用zabbix-server监控主机"><a href="#使用zabbix-server监控主机" class="headerlink" title="使用zabbix server监控主机"></a>使用zabbix server监控主机</h2><p>（1）点击配置-&gt;主机群组-&gt;创建主机群组<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a14.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a15.png"><br>（2）点击配置-&gt;主机-&gt;创建主机<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a16.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a17.png"><br>（3）点击配置-&gt;模板-&gt;创建模板<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a18.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a19.png"><br>（4）创建自定义key<br>我们来对web1服务器的远程登录数进行监控</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看远程登录数</span></span><br><span class="line">who |wc -l</span><br><span class="line"><span class="comment">#在被监控主机，打开/etc/zabbix/zabbix-agent.conf文件，在最后一行添加一行 </span></span><br><span class="line">UserParameter=user_connect,who|wc -l</span><br><span class="line"><span class="comment">#重启zabbix-agent服务</span></span><br><span class="line">systemctl restart zabbix-agent</span><br><span class="line"><span class="comment">#通过zabbix server主机查看自定义key是否生效</span></span><br><span class="line">zabbix_get -s 192.168.136.135 -p 10050 -k user_connect</span><br></pre></td></tr></table></figure><p>（5）添加监控项<br>重新进入刚刚创建的模板，创建监控项<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a20.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a21.png"><br>（6）为监控项创建图形，点击配置-&gt;主机-&gt;图形<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a22.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a23.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a24.png"><br>（7）查看图形<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/24/Zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/a25.png"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LVS+Keepalived实现高可用</title>
      <link href="2019/11/23/LVS-Keepalived%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>2019/11/23/LVS-Keepalived%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Keepalived是专门针对LVS设计的一款强大的辅助工具，主要用来提供故障切换和健康检查功能–判断LVS负载调度器、节点服务器的可用性，及时隔离并替换新的服务器，当故障主机恢复后将其重新加入集群。</p><a id="more"></a><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>客户端：192.168.136.130<br>虚拟IP：192.168.136.100<br>LVS1：192.168.136.133<br>LVS2: 192.168.136.137<br>RS1： 192.168.136.134<br>RS2： 192.168.136.135</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#临时关闭selinux</span></span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="LVS配置"><a href="#LVS配置" class="headerlink" title="LVS配置"></a>LVS配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载lvs和keepalived</span></span><br><span class="line">yum install -y keepalived -y ipvsadm</span><br><span class="line"><span class="comment">#修改LVS1的/etc/keepalived下的keepalived.conf</span></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;      </span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.136.100</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.136.100 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind DR      </span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server 192.168.136.134 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_port 80</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.136.135 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_port 80</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;    </span><br><span class="line"><span class="comment">#修改LVS2的/etc/keepalived下的keepalived.conf</span></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS-2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 90</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;      </span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.136.100</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.136.100 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind DR      </span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server 192.168.136.134 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_port 80</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.136.135 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_port 80</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">#开机重启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> keepalived &amp;&amp; systemctl <span class="built_in">enable</span> ipvsadm</span><br><span class="line"><span class="comment">#重启</span></span><br><span class="line">reboot </span><br></pre></td></tr></table></figure><h2 id="RS1服务器配置"><a href="#RS1服务器配置" class="headerlink" title="RS1服务器配置"></a>RS1服务器配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装httpd服务</span></span><br><span class="line">yum install -y httpd</span><br><span class="line"><span class="comment">#写页面</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;web1&quot;</span> &gt;  /var/www/html/index.html</span><br><span class="line"><span class="comment">#启动服务，开机自启</span></span><br><span class="line">systemctl start httpd &amp;&amp; systemctl <span class="built_in">enable</span> httpd</span><br><span class="line"><span class="comment">#配置lo:0回管口</span></span><br><span class="line">cp /etc/sysconfig/network-scripts/ifcfg-lo /etc/sysconfig/network-scripts/ifcfg-lo:0</span><br><span class="line"><span class="comment">#修改ifcfg-lo:0文件</span></span><br><span class="line">DEVICE=lo:0</span><br><span class="line">IPADDR=192.168.136.100</span><br><span class="line">NETMASK=255.255.255.255</span><br><span class="line">ONBOOT=yes</span><br><span class="line"><span class="comment">#在/etc/rc.local里面添加</span></span><br><span class="line">/sbin/route add -host 192.168.136.100 dev lo:0</span><br><span class="line"><span class="comment">#在/etc/sysctl.conf添加</span></span><br><span class="line">net.ipv4.conf.all.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.conf.default.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line">net.ipv4.conf.lo.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line"><span class="comment">#重启</span></span><br><span class="line">reboot </span><br></pre></td></tr></table></figure><h2 id="RS2配置"><a href="#RS2配置" class="headerlink" title="RS2配置"></a>RS2配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装httpd服务</span></span><br><span class="line">yum install -y httpd</span><br><span class="line"><span class="comment">#写页面</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;web2&quot;</span> &gt;  /var/www/html/index.html</span><br><span class="line"><span class="comment">#启动服务，开机自启</span></span><br><span class="line">systemctl start httpd &amp;&amp; systemctl <span class="built_in">enable</span> httpd</span><br><span class="line"><span class="comment">#配置lo:0回管口</span></span><br><span class="line">cp /etc/sysconfig/network-scripts/ifcfg-lo /etc/sysconfig/network-scripts/ifcfg-lo:0</span><br><span class="line"><span class="comment">#修改ifcfg-lo:0文件</span></span><br><span class="line">DEVICE=lo:0</span><br><span class="line">IPADDR=192.168.136.100</span><br><span class="line">NETMASK=255.255.255.255</span><br><span class="line">ONBOOT=yes</span><br><span class="line"><span class="comment">#在/etc/rc.local里面添加</span></span><br><span class="line">/sbin/route add -host 192.168.136.100 dev lo:0</span><br><span class="line"><span class="comment">#在/etc/sysctl.conf添加</span></span><br><span class="line">net.ipv4.conf.all.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.conf.default.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line">net.ipv4.conf.lo.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line"><span class="comment">#重启</span></span><br><span class="line">reboot </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Keepalived </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LVS Keepalived </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LVS工作模式实验</title>
      <link href="2019/11/17/LVS%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E5%AE%9E%E9%AA%8C/"/>
      <url>2019/11/17/LVS%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E5%AE%9E%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要演示LVS工作模式的DR模式和NAT模式实战</p><a id="more"></a><h2 id="DR模式"><a href="#DR模式" class="headerlink" title="DR模式"></a>DR模式</h2><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>192.168.136.130 客户机<br>192.168.136.133 LVS负载均衡器   虚拟IP地址 192.168.136.123<br>192.168.136.134 RS真实服务器    虚拟IP地址 192.168.136.123<br>192.168.136.135 RS真实服务器    虚拟IP地址 192.168.136.123</p><h3 id="LVS负载均衡器配置"><a href="#LVS负载均衡器配置" class="headerlink" title="LVS负载均衡器配置"></a>LVS负载均衡器配置</h3><p>（1）LVS准备VIP和路由</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置虚拟ip</span></span><br><span class="line">ifconfig ens33:0 192.168.136.123 broadcast 192.168.136.255 netmask 255.255.255.0</span><br><span class="line"><span class="comment">#配置路由</span></span><br><span class="line">route add -net 192.168.136.123 dev ens33:0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置路由转发</span></span><br><span class="line">vi /etc/sysctl.conf</span><br><span class="line">net.ipv4.ip_forward=1                   <span class="comment">#开启路由转发</span></span><br><span class="line">net.ipv4.conf.all.send_redirects=0      <span class="comment">#禁用路由重定向转发</span></span><br><span class="line">net.ipv4.conf.ens33.send_redirects=0    <span class="comment">#禁用ens33转发重定向报文</span></span><br><span class="line">net.ipv4.conf.default.send_redirects=0  <span class="comment">#禁用转发默认重定向报文</span></span><br></pre></td></tr></table></figure><p>（2）LVS设置负载均衡条目</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装ipvsadm</span></span><br><span class="line">yum install ipvsadm -y</span><br><span class="line"><span class="comment">#擦除虚拟服务器的所有规则</span></span><br><span class="line">ipvsadm -C</span><br><span class="line"><span class="comment">#添加一个虚拟的服务器地址(-A表示添加一个虚拟ip -t表示tcp地址 -s表示调度算法 rr表示轮询)</span></span><br><span class="line">ipvsadm -A -t 192.168.136.123:80 -s rr</span><br><span class="line"><span class="comment">#添加LVS转发规则（-a表示添加一个真实服务器地址 -t表示tcp地址 -r表示真实服务器地址 -g表示dr直接路由）</span></span><br><span class="line">ipvsadm -a -t 192.168.136.123:80 -r 192.168.136.134:80 -g  </span><br><span class="line">ipvsadm -a -t 192.168.136.123:80 -r 192.168.136.135:80 -g  </span><br></pre></td></tr></table></figure><p>（3）LVS让配置永久生效</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将配置写入文件中</span></span><br><span class="line">ipvsadm-save&gt; /etc/sysconfig/ipvsadm</span><br><span class="line"><span class="comment">#开机自启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> ipvsadm</span><br></pre></td></tr></table></figure><h3 id="RS服务器配置"><a href="#RS服务器配置" class="headerlink" title="RS服务器配置"></a>RS服务器配置</h3><p>（1）安装服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装httpd服务</span></span><br><span class="line">yum install httpd -y</span><br><span class="line"><span class="comment">#写页面</span></span><br><span class="line"><span class="built_in">echo</span> web1 &gt; /var/www/html/index.html</span><br><span class="line"><span class="comment">#启动httpd服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure><p>（2）给RS服务器lo网卡配置子网掩码为32位的vip</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#rs1</span></span><br><span class="line">ifconfig lo:0 192.168.136.123/32</span><br><span class="line"><span class="comment">#rs2</span></span><br><span class="line">ifconfig lo:0 192.168.136.123/32  </span><br></pre></td></tr></table></figure><p>（3）给RS服务器设置内核参数</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#忽略arp请求，不允许收</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore </span><br><span class="line"><span class="comment">#为了让vip发包出去，但允许发</span></span><br><span class="line"><span class="built_in">echo</span> 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce </span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#访问虚拟vip</span></span><br><span class="line">curl http://192.168.136.130:80</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/17/LVS%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E5%AE%9E%E9%AA%8C/a1.png"></p><h2 id="NAT模式"><a href="#NAT模式" class="headerlink" title="NAT模式"></a>NAT模式</h2><h3 id="实验环境-1"><a href="#实验环境-1" class="headerlink" title="实验环境"></a>实验环境</h3><p>客户机        VMNET0  192.168.0.101<br>LVS负载均衡器 VMNET0  192.168.0.102<br>              VMNET2  192.168.136.136<br>RS真实服务器  VMNET2  192.168.136.134<br>RS真实服务器  VMNET2  192.168.136.135 </p><h3 id="RS服务器配置-1"><a href="#RS服务器配置-1" class="headerlink" title="RS服务器配置"></a>RS服务器配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写页面</span></span><br><span class="line"><span class="built_in">echo</span> web1 &gt; /var/www/html/index.html</span><br><span class="line"><span class="comment">#启动httpd服务</span></span><br><span class="line">systemctl start httpd</span><br><span class="line">route add -net 192.168.0.0/24 gw 192.168.136.136</span><br></pre></td></tr></table></figure><h3 id="LVS配置"><a href="#LVS配置" class="headerlink" title="LVS配置"></a>LVS配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#开启路由转发</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="comment">#安装ipvsadm</span></span><br><span class="line">yum install ipvsadm -y</span><br><span class="line"><span class="comment">#添加调度算法</span></span><br><span class="line">ipvsadm -A -t 192.168.0.102:80 -s rr</span><br><span class="line">添加LVS转发规则（-a表示添加一个真实服务器地址 -t表示tcp地址 -r表示真实服务器地址 -m表示nat模式）</span><br><span class="line">ipvsadm -a -t 192.168.0.102:80 -r 192.168.136.134:80 -m</span><br><span class="line">ipvsadm -a -t 192.168.0.102:80 -r 192.168.136.135:80 -m</span><br><span class="line"><span class="comment">#将配置写入文件中</span></span><br><span class="line">ipvsadm-save&gt; /etc/sysconfig/ipvsadm</span><br><span class="line"><span class="comment">#开机自启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> ipvsadm</span><br></pre></td></tr></table></figure><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://192.168.0.102:80</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/11/17/LVS%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E5%AE%9E%E9%AA%8C/a2.png"></p>]]></content>
      
      
      <categories>
          
          <category> LVS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LVS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识LVS</title>
      <link href="2019/11/17/%E5%88%9D%E8%AF%86LVS/"/>
      <url>2019/11/17/%E5%88%9D%E8%AF%86LVS/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>LVS（Linux Virtual Server）即Linux虚拟服务器，是章文嵩博士主导的开源负载均衡项目，LVS本身并不提供服务，只是把特定的请求转发给相应的真实服务器（real server），从而实现集群环境中的负载均衡。</p><a id="more"></a><h2 id="LVS工作模式"><a href="#LVS工作模式" class="headerlink" title="LVS工作模式"></a>LVS工作模式</h2><p>LVS工作模式主要有DR直接路由模式、NAT模式、TUN模式、FULL-NAT模式，这边我们主要讲DR模式和NAT模式。</p><h3 id="DR模式"><a href="#DR模式" class="headerlink" title="DR模式"></a>DR模式</h3><p>（1）客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址是VIP<br>（2）负载均衡器收到报文后，发现请求的是规则里面存在的地址，那么它将客户端请求报文的源MAC地址改为自己DIP的MAC地址，将目标MAC地址改为RIP的MAC地址，并将此请求发给RS服务器<br>（3）RS发现请求报文中目的MAC是自己的，就会将此报文接收下来，处理完请求报文后，将响应报文通过lo接口送给eth0网卡直接发送给客户端<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/17/%E5%88%9D%E8%AF%86LVS/a1.png"></p><h3 id="NAT模式"><a href="#NAT模式" class="headerlink" title="NAT模式"></a>NAT模式</h3><p>（1）客户端将请求发往前端的负载均衡器，此请求报文源地址是CIP（客户端IP），目标地址VIP（负载均衡器地址）<br>（2）负载均衡器接收到报文后，发现请求是规则里面存在的地址，那么它将客户端请求报文的目标IP地址改成了RS服务器的地址，并根据算法发送出去<br>（3）RS服务器发现报文的目标地址是自己的，所以就会响应请求，并将响应报文返回给负载均衡器<br>（4）负载均衡器接收到响应的报文，将源地址修改为本机地址并发送给客户端<br><img src= "/img/loading.gif" data-lazy-src="/2019/11/17/%E5%88%9D%E8%AF%86LVS/a2.png"></p><h2 id="LVS负载均衡算法"><a href="#LVS负载均衡算法" class="headerlink" title="LVS负载均衡算法"></a>LVS负载均衡算法</h2><p>根据前面的介绍，我们了解LVS常用的两种工作模式的原理，但不管环境中采用哪种工作模式，调度算法是LVS的核心技术，下面列举了LVS常用的几种调度算法。<br>（1）RR<br>RR即轮询算法，是按依次循环的方式将请求均匀调度到不同的服务器，该算法最大的特点就是实现简单，轮询算法假设所有服务器处理请求的能力都一样，调度器会将所有的请求平均分配至真实服务器。<br>（2）WRR<br>WRR即加权轮询算法，主要是对轮询算法的一种优化，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，权值越大，处理的请求就越多，比如服务器A权值是1，服务器B权值是2，那么调度器调度至B的请求是A的2倍。<br>（3）LC<br>LC即最小连接调度算法，是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过活跃的连接数来估计服务器的情况。<br>（4）WLC<br>WLC即加权最小连接调度算法，是最小连接调度的超集。各个服务器的权值表示处理性能，服务器缺省权值为1，系统管理员可以动态地设置权值。加权最小连接调度在调度新的连接时尽可能使服务器已建立连接数和权值成比例。</p>]]></content>
      
      
      <categories>
          
          <category> LVS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LVS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible role的基本使用</title>
      <link href="2019/11/09/Ansible-role%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>2019/11/09/Ansible-role%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>roles是ansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中</p><a id="more"></a><p>复杂场景：建议使用roles,代码复用性高</p><h2 id="Roles各目录作用"><a href="#Roles各目录作用" class="headerlink" title="Roles各目录作用"></a>Roles各目录作用</h2><p>/roles/project/:项目名称，有以下子目录<br>    1）files/：存放由copy或script模板等调用的文件<br>    2）templates/：template模块查找所需要模板文件的目录<br>    3）tasks/：定义task，role的基本元素，至少应该包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含<br>    4）handlers/：至少包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含<br>    5）vars/：定义变量，至少应该包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含<br>    6）meta/：定义当前角色的特殊设定及其依赖关系，至少应该包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含<br>    7）default/：设定默认变量时使用此目录中的main.yml文件</p><h2 id="role应用示例"><a href="#role应用示例" class="headerlink" title="role应用示例"></a>role应用示例</h2><p>有一个nginx role：<br>    1)group:nginx<br>    2)user:nginx<br>    3)yum:install<br>    4)template:nginx.conf.j2<br>    5)handlers、notify<br>    6)service<br>(1)首先进入/etc/ansible/roles目录里面，创建一个nginx的角色目录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir nginx</span><br></pre></td></tr></table></figure><p>(2)进入nginx角色目录，创建相应的文件夹,将nginx.conf.j2模板放入templates目录下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#templates存放模板，tasks存放任务</span></span><br><span class="line">mkdir templates tasks handlers</span><br></pre></td></tr></table></figure><p>（3）进入tasks,创建任务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建group.yml,写任务</span></span><br><span class="line">- name: create group</span><br><span class="line">  group: name=nginx state=present</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建user.yml,写任务</span></span><br><span class="line">- name: create user</span><br><span class="line">  user: name=nginx group=nginx system=yes shell=/sbin/nologin</span><br><span class="line">  </span><br><span class="line"><span class="comment">#创建yum.yml,写任务</span></span><br><span class="line">- name: install</span><br><span class="line">  yum: name=nginx</span><br><span class="line">  </span><br><span class="line"><span class="comment">#创建copy.yml,写任务</span></span><br><span class="line">- name: copy</span><br><span class="line">  template: src=/etc/ansible/roles/nginx/templates/nginx.conf.j2 dest=/etc/nginx/nginx.conf</span><br><span class="line">  notify: restart</span><br><span class="line">  </span><br><span class="line"><span class="comment">#创建service.yml,写任务</span></span><br><span class="line">- name: start</span><br><span class="line">  service: name=nginx state=started enabled=yes</span><br><span class="line">  </span><br><span class="line"><span class="comment">#创建mian.yml,写任务</span></span><br><span class="line">- include: group.yml</span><br><span class="line">- include: user.yml</span><br><span class="line">- include: yum.yml</span><br><span class="line">- include: copy.yml</span><br><span class="line">- include: service.yml</span><br></pre></td></tr></table></figure><p>（4）进入handlers目录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建restart.yml</span></span><br><span class="line">- name: restart</span><br><span class="line">  service: name=nginx state=restarted</span><br><span class="line">  </span><br><span class="line"><span class="comment">#创建mian.yml</span></span><br><span class="line">- include: restart.yml</span><br></pre></td></tr></table></figure><p>（5）进入/etc/ansible，创建nginx_role.yml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- hosts: 192.168.136.128</span><br><span class="line">  remote_user: root</span><br><span class="line">  roles:</span><br><span class="line">    - role: nginx</span><br></pre></td></tr></table></figure><p>（6）运行nginx_role.yml</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#检查nginx.role.yml</span></span><br><span class="line">ansible-playbook -C nginx_role.yml</span><br><span class="line"><span class="comment">#运行</span></span><br><span class="line">ansible-playbook nginx_role.yml</span><br></pre></td></tr></table></figure><p>此外，nginx_role.yml还可以添加标签，添加多个角色;甚至可以添加when条件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- hosts: 192.168.136.128</span><br><span class="line">  remote_user: root</span><br><span class="line">  roles:</span><br><span class="line">    - &#123; role: nginx, tags: [<span class="string">&#x27;web&#x27;</span>,<span class="string">&#x27;nginx&#x27;</span>] &#125;</span><br><span class="line">    - &#123; role: httpd, tags: [<span class="string">&#x27;web&#x27;</span>,<span class="string">&#x27;httpd&#x27;</span>],when: ansible_distribution_major_version == <span class="string">&quot;7&quot;</span> &#125;</span><br><span class="line">    - &#123; role: app, tags: <span class="string">&quot;app&quot;</span> &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible playbook的基本使用</title>
      <link href="2019/11/09/Ansible-playbook%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>2019/11/09/Ansible-playbook%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>playbook是一个不同于ansible命令行方式的模式，其功能更强大灵活。简单地说，playbook是一个非常适合部署复杂应用程序的基础，它可以定制部署，可以按照指定的操作有序执行，支持同步和异步方式。playbook是通过yaml或者yml格式进行描述定义的。</p><a id="more"></a><h2 id="playbook核心元素"><a href="#playbook核心元素" class="headerlink" title="playbook核心元素"></a>playbook核心元素</h2><p>（1）Hosts   执行远程主机列表<br>（2）Tasks   任务集<br>（3）Varniables   内置变量或自定义变量在playbook中调用<br>（4）Templates   模板，可替代模板文件中的变量并实现一些简单逻辑的文件<br>（5）Handlers和notify   这2个需要结合使用，由特定条件触发的操作，满足条件方才执行<br>（6）tags  标签，指定某条任务执行，用于运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然非常长。此时，如果确定没有变化，可以通过tags跳过一些代码片段</p><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><h3 id="运行playbook的方式"><a href="#运行playbook的方式" class="headerlink" title="运行playbook的方式"></a>运行playbook的方式</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook &lt;filename.yml&gt; ...[options]</span><br></pre></td></tr></table></figure><h3 id="常见选项"><a href="#常见选项" class="headerlink" title="常见选项"></a>常见选项</h3><p>–check  只检查可能会发生的改变，但不真正执行操作<br>–list  列出运行任务的主机<br>–limit  只针对主机列表中的主机执行<br>-v  显示过程 -vv -vvv更详细</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook file.yml --check</span><br><span class="line">ansible-playbook file.yml</span><br><span class="line">ansible-playbook file.yml --<span class="built_in">limit</span> <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="写一个playbook"><a href="#写一个playbook" class="headerlink" title="写一个playbook"></a>写一个playbook</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  </span><br><span class="line">  tasks:</span><br><span class="line">    - name: install httpd package</span><br><span class="line">      yum: name=httpd</span><br><span class="line">      tags: inshttpd</span><br><span class="line">    - name: copy conf file</span><br><span class="line">      copy: src=/home/httpd.conf dest=/etc/httpd/conf backup=yes</span><br><span class="line">    - name:  start service</span><br><span class="line">      service: name=httpd state=started enabled=yes</span><br><span class="line">      tags: shttpd</span><br><span class="line">    </span><br><span class="line"><span class="comment">#检查文件</span></span><br><span class="line">ansible-playbook ansible-playbook.yml --check</span><br><span class="line"><span class="comment">#运行playbook</span></span><br><span class="line">ansible-playbook ansible-playbook.yml</span><br><span class="line"><span class="comment">#执行对应标签的任务</span></span><br><span class="line">ansible-playbook -t inshttpd ansible-playbook.yml </span><br></pre></td></tr></table></figure><p>现在有一种场景：有些服务，我们需要修改它的配置文件，但是它的服务一直是开启状态。当我们修改了配置文件，再次执行这个playbook，那么就会产生一个问题，当进行启动服务的任务时，ansible会因为这个服务已经运行了，而不去重新执行这个任务，就会导致修改的配置没有重启服务而无法生效。handlers和notify就是解决这种场景的方法。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  </span><br><span class="line">  tasks:</span><br><span class="line">    - name: install httpd package</span><br><span class="line">      yum: name=httpd</span><br><span class="line">      tags: inshttpd</span><br><span class="line">    - name: copy conf file</span><br><span class="line">      copy: src=/home/httpd.conf dest=/etc/httpd/conf backup=yes</span><br><span class="line">      notify: restart service</span><br><span class="line">    - name:  start service</span><br><span class="line">      service: name=httpd state=started enabled=yes</span><br><span class="line">      tags: shttpd</span><br><span class="line">  handlers:</span><br><span class="line">    - name: restart service</span><br><span class="line">      service: name=httpd state=restarted</span><br></pre></td></tr></table></figure><h2 id="playbook中变量的使用"><a href="#playbook中变量的使用" class="headerlink" title="playbook中变量的使用"></a>playbook中变量的使用</h2><p>变量名：仅能由字母、数字、下划线组成，且只能以字母开头<br>变量来源：<br>    （1）ansible setup facts远程主机的所有变量都可以直接调用<br>    （2）在/etc/ansible/hosts中定义<br>        1）普通变量：主机组中主机单独定义，优先级高于公共变量<br>        <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.136.128 http_port=80</span><br></pre></td></tr></table></figure><br>        2）公共变量：针对主机组中所有主机统一定义变量<br>        <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[<span class="built_in">test</span>]</span><br><span class="line">192.168.136.128 http_port=80</span><br><span class="line">[<span class="built_in">test</span>:vars]</span><br><span class="line">nodename=www</span><br></pre></td></tr></table></figure><br>    （3）通过命令行指定变量(参数-e)，优先级最高<br>    （4）在playbook中定义<br>        vars:<br>        - var1: value1<br>        - var2: value2<br>    （5）在role中定义</p><h2 id="使用变量文件"><a href="#使用变量文件" class="headerlink" title="使用变量文件"></a>使用变量文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat vars.yml</span><br><span class="line">var1: httpd</span><br><span class="line">var2: nginx</span><br><span class="line"></span><br><span class="line">cat ansible-playbook.yml</span><br><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  vars_files:</span><br><span class="line">    - vars.yml</span><br><span class="line">  tasks:</span><br><span class="line">    - name: create httpd <span class="built_in">log</span></span><br><span class="line">      file: name=/home/&#123;&#123;var1&#125;&#125;.<span class="built_in">log</span> state=touch</span><br><span class="line">    - name: create nginx <span class="built_in">log</span></span><br><span class="line">      file: name=/home/&#123;&#123;var2&#125;&#125;.<span class="built_in">log</span> state=touch</span><br></pre></td></tr></table></figure><h2 id="templates"><a href="#templates" class="headerlink" title="templates"></a>templates</h2><p>（1）文本文件，嵌套有脚本（使用模板编程语言编写）<br>（2）Jinja2语言，使用字面量，有下面形式<br>    字符串：使用单引号或双引号<br>    数字：整数，浮点数<br>    列表：[item1,item2,…]<br>    元祖：(item1,item2,…)<br>    字典：{key1:value1,key2:value2,…}<br>    布尔型：true/false<br>（3）算术运算：+,-,*，/,//,%,**<br>（4）比较操作：==,!=,&gt;,&gt;=,&lt;,&lt;=<br>（5）逻辑运算：and,or,not<br>（6）流表达式：For If When</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  tasks:</span><br><span class="line">    - name: install</span><br><span class="line">      yum: name=nginx</span><br><span class="line">    - name: copy template</span><br><span class="line">      template: src=/home/nginx.conf.j2 dest=/etc/nginx/nginx.conf</span><br><span class="line">    - name: start service</span><br><span class="line">      service: name=nginx state=started enabled=yes</span><br></pre></td></tr></table></figure><h2 id="when"><a href="#when" class="headerlink" title="when"></a>when</h2><p>条件测试：如果需要根据变量、facts或者此前任务的执行结果来做某task执行与否的前提时要用条件测试，通过when语句实现，在task中使用，jinja2的语法格式</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ansible_os_family是系统的变量</span></span><br><span class="line">tasks:</span><br><span class="line">  - name: <span class="string">&quot;shutdown RedHat flavored systems&quot;</span></span><br><span class="line">    <span class="built_in">command</span>: /sbin/shutdown -h now</span><br><span class="line">    when: ansible_os_family == <span class="string">&quot;RedHat&quot;</span></span><br></pre></td></tr></table></figure><h2 id="with-items"><a href="#with-items" class="headerlink" title="with_items"></a>with_items</h2><p>迭代：当有需要重复性执行的任务时，可以使用迭代机制<br>对迭代项的引用，固定变量名为“item”<br>要在task中使用with_items给定要迭代的元素列表</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  tasks:</span><br><span class="line">    - name: create some files</span><br><span class="line">      file: name=/home/&#123;&#123; item &#125;&#125; state=touch</span><br><span class="line">      with_items:</span><br><span class="line">        - file1</span><br><span class="line">        - file2</span><br><span class="line">        - file3</span><br></pre></td></tr></table></figure><p>with_items还可以做到迭代嵌套自变量的情况<br>现在有一种情景：（1）创建user1、user2、user3三个用户（2）创建group1、group2、group3（3）user1所属组是group1，user2所属组是group2，user3所属组是group3</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  tasks:</span><br><span class="line">    - name: add some groups</span><br><span class="line">      group: name=&#123;&#123; item &#125;&#125; state=present</span><br><span class="line">      with_items:</span><br><span class="line">        - group1</span><br><span class="line">        - group2</span><br><span class="line">        - group3</span><br><span class="line">    - name: add some users</span><br><span class="line">      user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present</span><br><span class="line">      with_items:</span><br><span class="line">        - &#123;name: <span class="string">&#x27;user1&#x27;</span>, group: <span class="string">&#x27;group1&#x27;</span>&#125;</span><br><span class="line">        - &#123;name: <span class="string">&#x27;user2&#x27;</span>, group: <span class="string">&#x27;group2&#x27;</span>&#125;</span><br><span class="line">        - &#123;name: <span class="string">&#x27;user3&#x27;</span>, group: <span class="string">&#x27;group3&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="For"><a href="#For" class="headerlink" title="For"></a>For</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat ansible-playbook.yml</span><br><span class="line">- hosts: <span class="built_in">test</span></span><br><span class="line">  remote_user: root</span><br><span class="line">  vars:</span><br><span class="line">    ports:</span><br><span class="line">      - 81</span><br><span class="line">      - 82</span><br><span class="line">      - 83</span><br><span class="line">  tasks:</span><br><span class="line">    - name: copy template</span><br><span class="line">      template: src=/home/nginx.conf.j2 dest=/etc/nginx/nginx.conf</span><br><span class="line"></span><br><span class="line">cat nginx.conf.j2</span><br><span class="line">&#123;% <span class="keyword">for</span> port <span class="keyword">in</span> ports %&#125;</span><br><span class="line">server&#123;</span><br><span class="line">  listen: &#123;&#123; port &#125;&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;% endfor %&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible的基本使用</title>
      <link href="2019/11/07/Ansible%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>2019/11/07/Ansible%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本章主要介绍ansible基本模块的使用</p><a id="more"></a><h2 id="Command"><a href="#Command" class="headerlink" title="Command"></a>Command</h2><p>在远程主机执行命令，默认模块，可忽略-m选项</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动远程主机vsftpd服务</span></span><br><span class="line">ansible <span class="built_in">test</span> -m <span class="built_in">command</span> -a <span class="string">&#x27;service vsftpf start&#x27;</span></span><br><span class="line"><span class="comment">#此命令不支持$VARNAME &lt;&gt; | ; &amp;等，建议使用shell模块实现</span></span><br><span class="line">ansible <span class="built_in">test</span> -m <span class="built_in">command</span> -a <span class="string">&#x27;echo tang1611 | passwd --stdin tang&#x27;</span> 不成功</span><br></pre></td></tr></table></figure><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><p>和command相似</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible <span class="built_in">test</span> -m shell -a <span class="string">&#x27;echo tang1611 | passwd --stdin tang&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h2><p>运行脚本</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible <span class="built_in">test</span> -m script -a f1.sh</span><br></pre></td></tr></table></figure><h2 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h2><p>从控制端复制文件到被控端</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#src指向的是要复制的文件，dest指向目标的目录，owner是所属组，mode是权限,backup是备份。如果目标存在，默认是覆盖的</span></span><br><span class="line">ansible <span class="built_in">test</span> -m copy -a <span class="string">&quot;src=/root/f1.sh dest=/tem/f2.sh owner=tang mode=600 backup=yes&quot;</span></span><br><span class="line"><span class="comment">#也可以利用content向文件写内容</span></span><br><span class="line">ansible <span class="built_in">test</span> -m copy -a <span class="string">&quot;content=&#x27;hello world\n&#x27; dest=/tem/f1.txt&quot;</span></span><br></pre></td></tr></table></figure><h2 id="Fetch"><a href="#Fetch" class="headerlink" title="Fetch"></a>Fetch</h2><p>从被控端取文件到控制端</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#src是被控端需要复制的文件，dest是目标目录</span></span><br><span class="line">ansible <span class="built_in">test</span> -m fetch -a <span class="string">&quot;src=/root/a.sh dest=/data/scripts&quot;</span></span><br></pre></td></tr></table></figure><h2 id="File"><a href="#File" class="headerlink" title="File"></a>File</h2><p>设置文件属性</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible <span class="built_in">test</span> -m file -a <span class="string">&quot;name=/home/var.log state=touch&quot;</span></span><br><span class="line">ansible <span class="built_in">test</span> -m file -a <span class="string">&quot;path=/root/a.sh owner=tang mode=755&quot;</span></span><br><span class="line">ansible <span class="built_in">test</span> -m file -a <span class="string">&#x27;src=/app/testfile dest/app/testfile-link state=link&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="Hostname"><a href="#Hostname" class="headerlink" title="Hostname"></a>Hostname</h2><p>管理主机名</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible <span class="built_in">test</span> -m hostname -a <span class="string">&quot;name=webhost&quot;</span></span><br></pre></td></tr></table></figure><h2 id="Cron"><a href="#Cron" class="headerlink" title="Cron"></a>Cron</h2><p>计划任务，支持时间：minute,hour,day,month,weekday</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#开启任务</span></span><br><span class="line">ansible <span class="built_in">test</span> -m cron -a <span class="string">&quot;minute=* weekday=1,3,5 job=&#x27;/usr/sbin/ntpdate 192.168.136.128 &amp;&gt;/dev/null&#x27; name=Synctime&quot;</span></span><br><span class="line"><span class="comment">#禁用任务</span></span><br><span class="line">ansible <span class="built_in">test</span> -m cron -a <span class="string">&#x27;disabled=yes job=&#x27;</span>/usr/sbin/ntpdate 192.168.136.128 &amp;&gt;/dev/null<span class="string">&#x27; name=Synctime&#x27;</span></span><br><span class="line"><span class="comment">#删除任务</span></span><br><span class="line">ansible <span class="built_in">test</span> -m cron -a <span class="string">&#x27;state=absent job=&#x27;</span>/usr/sbin/ntpdate 192.168.136.128 &amp;&gt;/dev/null<span class="string">&#x27; name=Synctime&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="Yum"><a href="#Yum" class="headerlink" title="Yum"></a>Yum</h2><p>管理包</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">ansible <span class="built_in">test</span> -m yum -a <span class="string">&quot;name=httpd state=latest&quot;</span></span><br><span class="line"><span class="comment">#删除</span></span><br><span class="line">ansible <span class="built_in">test</span> -m yum -a <span class="string">&quot;name=httpd state=absent&quot;</span></span><br></pre></td></tr></table></figure><h2 id="ansible-doc"><a href="#ansible-doc" class="headerlink" title="ansible-doc"></a>ansible-doc</h2><p>ansible模块文档说明</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出支持的模块</span></span><br><span class="line">ansible-doc -l</span><br><span class="line"><span class="comment">#ping模块功能说明</span></span><br><span class="line">ansible-doc ping</span><br></pre></td></tr></table></figure><h2 id="ansible-galaxy"><a href="#ansible-galaxy" class="headerlink" title="ansible-galaxy"></a>ansible-galaxy</h2><p>连接<a href="https://galaxy.ansible.com下载相应的roles/">https://galaxy.ansible.com下载相应的roles</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出所以已安装的galaxy</span></span><br><span class="line">ansible-galaxy list</span><br><span class="line"><span class="comment">#安装galaxy</span></span><br><span class="line">ansible-galaxy install geerlingguy.redis</span><br><span class="line"><span class="comment">#删除galaxy</span></span><br><span class="line">ansible-galaxy remove geerlingguy.redis</span><br></pre></td></tr></table></figure><h2 id="ansible-console"><a href="#ansible-console" class="headerlink" title="ansible-console"></a>ansible-console</h2><p>可交互执行命令，支持tab</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#连接交互式工具,会提示输入一个密码，随便输入后回车即可，不允许空值</span></span><br><span class="line">ansible-console</span><br><span class="line"><span class="comment">#切换到test组</span></span><br><span class="line"><span class="built_in">cd</span> <span class="built_in">test</span></span><br><span class="line"><span class="comment">#列出组中主机</span></span><br><span class="line">list</span><br><span class="line"><span class="comment">#查询每个主机的网卡信息</span></span><br><span class="line">ifconfig ens33</span><br><span class="line"><span class="comment">#退出ansible-console环境</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible安装</title>
      <link href="2019/11/07/Ansible%E5%AE%89%E8%A3%85/"/>
      <url>2019/11/07/Ansible%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要介绍自动化运维工具ansible的安装</p><a id="more"></a><h2 id="查看ansible软件包信息"><a href="#查看ansible软件包信息" class="headerlink" title="查看ansible软件包信息"></a>查看ansible软件包信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum info ansible</span><br></pre></td></tr></table></figure><h2 id="安装ansible"><a href="#安装ansible" class="headerlink" title="安装ansible"></a>安装ansible</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install ansible -y</span><br></pre></td></tr></table></figure><h2 id="设置ssh连接"><a href="#设置ssh连接" class="headerlink" title="设置ssh连接"></a>设置ssh连接</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#修改被控主机的etc/ssh/sshd_config,GSSAPIAuthentication设置为no,UseDNS 设置为no</span></span><br><span class="line">vi /etc/ssh/sshd_config</span><br><span class="line"><span class="comment">#重启服务</span></span><br><span class="line">systemctl restart sshd</span><br><span class="line"><span class="comment">#在主控机上生成ssh公钥，直接回车即可</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="comment">#将公钥拷贝到被控机</span></span><br><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.136.128</span><br><span class="line"><span class="comment">#测试是否可以连接</span></span><br><span class="line">ssh root@192.168.136.128</span><br></pre></td></tr></table></figure><h2 id="使用ansible连接被控机"><a href="#使用ansible连接被控机" class="headerlink" title="使用ansible连接被控机"></a>使用ansible连接被控机</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#建议将/etc/ansible/ansible.cfg下的host_key_checking取消注释</span></span><br><span class="line"><span class="comment">#日志功能，将/etc/ansible/ansible.cfg下的log_path注释取消</span></span><br><span class="line"><span class="comment">#添加被控主机到/etc/ansible/hosts文件</span></span><br><span class="line">cat &gt; /etc/ansible/hosts &lt;&lt; EOF</span><br><span class="line">192.168.136.128</span><br><span class="line">EOF</span><br><span class="line"><span class="comment">#使用ansible连接</span></span><br><span class="line">ansible 192.168.136.128 -m ping</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ansibleble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubeadm部署Kubernetes集群</title>
      <link href="2019/10/26/Kubeadm%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/"/>
      <url>2019/10/26/Kubeadm%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>kubeadm是官方社区推出的快速部署kubernetes集群的工具</p><a id="more"></a><h2 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h2><p>（1）一台或多台CentOS7.x-86_x64操作系统<br>（2）硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多<br>（3）集群中所有机器之间网络互通，可以访问外网，需要拉取镜像</p><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config</span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#关闭swap</span></span><br><span class="line">swapoff -a   临时</span><br><span class="line"><span class="comment">#添加主机名与IP对应关系（记得设置主机名）</span></span><br><span class="line">vi /etc/hosts</span><br><span class="line">192.168.136.129 k8s-master</span><br><span class="line">192.168.136.128 k8s-node1</span><br><span class="line">192.168.136.130 k8s-node2</span><br><span class="line"><span class="comment">#将桥接的IPv4流量传递到iptables的链</span></span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="comment">#使配置生效</span></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><h2 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新yum</span></span><br><span class="line">yum update</span><br><span class="line"><span class="comment">#安装需要的软件包</span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"><span class="comment">#设置yum源</span></span><br><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment">#安装docker</span></span><br><span class="line">yum install docker-ce-17.12.1.ce -y</span><br><span class="line"><span class="comment">#设置开机自启，启动docker</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><h2 id="添加阿里云yum软件源"><a href="#添加阿里云yum软件源" class="headerlink" title="添加阿里云yum软件源"></a>添加阿里云yum软件源</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="安装kubeadm、kubelet和kebectl"><a href="#安装kubeadm、kubelet和kebectl" class="headerlink" title="安装kubeadm、kubelet和kebectl"></a>安装kubeadm、kubelet和kebectl</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y kubelet-1.15.0 kubeadm-1.15.0 kubectl-1.15.0</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br></pre></td></tr></table></figure><h2 id="部署kubernetes-master"><a href="#部署kubernetes-master" class="headerlink" title="部署kubernetes master"></a>部署kubernetes master</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在master执行初始化</span></span><br><span class="line">kubeadm init \</span><br><span class="line">--apiserver-advertise-address=192.168.136.129 \</span><br><span class="line">--image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">--kubernetes-version v1.15.0 \</span><br><span class="line">--service-cidr=10.1.0.0/16 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure><h2 id="使用kubectl工具"><a href="#使用kubectl工具" class="headerlink" title="使用kubectl工具"></a>使用kubectl工具</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="comment">#查看节点</span></span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><h2 id="安装pod网络插件CNI"><a href="#安装pod网络插件CNI" class="headerlink" title="安装pod网络插件CNI"></a>安装pod网络插件CNI</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><h2 id="将node加入集群"><a href="#将node加入集群" class="headerlink" title="将node加入集群"></a>将node加入集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.136.129:6443 --token 1w09k0.ugs74mxzljn7yk72 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:cac0b9e628461383dde738b184111c6b735b2010a6eb637b1a9b7ffc297a7537 </span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#当节点都是Ready状态，表示集群初始化成功</span></span><br><span class="line">kubectl get nodes</span><br><span class="line"><span class="comment">#查看kube-system名称空间pod状态,全部运行为成功</span></span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker Compose（四）</title>
      <link href="2019/10/05/Docker-Compose%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
      <url>2019/10/05/Docker-Compose%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本章主要介绍Docker Compose的基础概念，以及如何编写Docker Compose文件</p><a id="more"></a><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Docker Compose是一个工具，它可以通过yml文件定义多容器的docker应用，通过一条命令就可以根据yml文件去创建或者管理多个应用</p><h2 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h2><p>docker-compose.yml由Services、Networks、volumes三个部分组成。<br>一个Services代表一个container，这个container可以从dockerhub的image来创建，也可以从本地的Dockerfile build出来的image来创建<br>Servides的启动类似于docker run，我们可以给其指定network和volume，所以可以给service指定network和volume的引用</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">services:</span><br><span class="line">  db:</span><br><span class="line">    image: postgres:9.4</span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="string">&quot;db-data:/var/lib/postgresql/data&quot;</span></span><br><span class="line">    networks:</span><br><span class="line">      - back-tier</span><br><span class="line">volumes:</span><br><span class="line">  db-date:</span><br><span class="line">networks:</span><br><span class="line">  front-tier:</span><br><span class="line">    driver: bridge</span><br><span class="line">  back-tier: </span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">services:</span><br><span class="line">  worker:</span><br><span class="line">    build: ./worker</span><br><span class="line">    links:</span><br><span class="line">      - db</span><br><span class="line">      - redis</span><br><span class="line">    networks:</span><br><span class="line">      - back-tier</span><br><span class="line">networks:</span><br><span class="line">  back-tier: </span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure><h2 id="编写一个docker-compose-yml"><a href="#编写一个docker-compose-yml" class="headerlink" title="编写一个docker-compose.yml"></a>编写一个docker-compose.yml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">version: <span class="string">&#x27;3&#x27;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  </span><br><span class="line">  wordpress:</span><br><span class="line">    image: wordpress</span><br><span class="line">    ports:</span><br><span class="line">      - 8080:80</span><br><span class="line">    environment:</span><br><span class="line">      WORDPRESS_DB_HOST: mysql</span><br><span class="line">      WORDPRESS_DB_PASSWORD: root</span><br><span class="line">    networks:</span><br><span class="line">      - my-bridge</span><br><span class="line">  </span><br><span class="line">  mysql:</span><br><span class="line">    image: mysql</span><br><span class="line">    environment:</span><br><span class="line">      MYSQL_ROOT_PASSWORD: root</span><br><span class="line">      MYSQL_DATABASE: wordpress</span><br><span class="line">    volumes:</span><br><span class="line">      - mysql-data:/var/lib/mysql</span><br><span class="line">    networks:</span><br><span class="line">      - my-bridge</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  mysql-data:</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  my-bridge:</span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure><h2 id="docker-compose安装"><a href="#docker-compose安装" class="headerlink" title="docker-compose安装"></a>docker-compose安装</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载docker-compose到/usr/local/bin目录下</span></span><br><span class="line">curl -L https://get.daocloud.io/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"><span class="comment">#授予docke-compose可执行权限</span></span><br><span class="line">chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"><span class="comment">#查看版本</span></span><br><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure><h2 id="docker-compose常用命令"><a href="#docker-compose常用命令" class="headerlink" title="docker-compose常用命令"></a>docker-compose常用命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动docker-compose.yml文件</span></span><br><span class="line">docker-compose -f docker-compose.yml up -d</span><br><span class="line"><span class="comment">#查看正在运行的docker-compose容器</span></span><br><span class="line">docker-compose ps</span><br><span class="line"><span class="comment">#停止docker-compose运行的容器</span></span><br><span class="line">docker-compose stop</span><br><span class="line"><span class="comment">#停止并删除正在运行的容器</span></span><br><span class="line">docker-compose down</span><br><span class="line"><span class="comment">#进入docker-compose中的一个容器</span></span><br><span class="line">docker-compose <span class="built_in">exec</span> mysql bash</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker的持久化存储（三）</title>
      <link href="2019/09/21/Docker%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%EF%BC%88%E4%B8%89%EF%BC%89/"/>
      <url>2019/09/21/Docker%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本章主要介绍一下Docker的持久化存储</p><a id="more"></a><p>对于Docker Container layer来说，我们在容器里面写数据，这个数据仅限于这个创建的容器，当我们把容器删掉，意味着我们的数据也会被删除，这种情况是我们不能接受的，所以Docker就引入了持久化机制。</p><p>Docker持久化数据的方案：<br>（1）基于本地文件系统的Volume：可以在执行Docker create或者Docker run时，通过-v参数将宿主机的目录作为容器的数据卷。这部分功能便是基于本地文件系统的volume管理<br>（2）基于plugin的Volume：支持第三方存储方案，比如NAS，AWS</p><p>Volume的类型<br>（1）收管理的data Volume，由docker后台自动创建<br>（2）绑定挂载的Volume，具体挂载位置可以由用户指定</p><h2 id="Data-Volume"><a href="#Data-Volume" class="headerlink" title="Data Volume"></a>Data Volume</h2><p>需要在Docker file中指定volume持久化路径</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建mysql容器</span></span><br><span class="line">docker run -d --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD mysql</span><br><span class="line"><span class="comment">#查看刚刚创建的mysql容器默认创建的volume</span></span><br><span class="line">docker volume ls</span><br><span class="line"><span class="comment">#查看volume详细信息</span></span><br><span class="line">docker inspect 11e7434f01b8764f33d6ce0298c15ea49890e43f0e93a265ddb0f8d487b0b9aa</span><br><span class="line"><span class="comment">#删除mysql1容器</span></span><br><span class="line">docker rm mysql1</span><br><span class="line"><span class="comment">#再次查看volume，发现还在</span></span><br><span class="line">docker volume ls</span><br></pre></td></tr></table></figure><h2 id="Bind-Mouting"><a href="#Bind-Mouting" class="headerlink" title="Bind Mouting"></a>Bind Mouting</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-v表示将容器/etc/nginx目录映射到宿主机home/n1</span></span><br><span class="line">docker run -d --name nginx -v /home/n1:/etc/nginx nginx</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker网络（二）</title>
      <link href="2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前言已经介绍了Docker的镜像和容器，下面主要涉及Docker网络相关知识</p><a id="more"></a><h2 id="Linux网络命名空间"><a href="#Linux网络命名空间" class="headerlink" title="Linux网络命名空间"></a>Linux网络命名空间</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#进入一个已经运行的容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it 61512b362534 bash</span><br><span class="line"><span class="comment">#执行ip a</span></span><br><span class="line">ip a</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a1.png"><br>会发现有一些接口，这就是这个容器自己的network namespace<br>退出容器，在宿主机执行ip a<br><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a2.png"><br>显示出来的是宿主机的network namespace，这2个network namespace是不一样的<br>再创建第二个容器，2个docker容器的network namespace也是不一样的，他们之前是隔离开的。并且2个容器是可以ping通的</p><h3 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h3><p><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a3.png"><br>（1）创建network namespace</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建2个network namespace</span></span><br><span class="line">ip netns add test1</span><br><span class="line">ip netns add test2</span><br><span class="line"><span class="comment">#删除network namespace</span></span><br><span class="line">ip netns delete test1</span><br><span class="line"><span class="comment">#查看创建network namespace</span></span><br><span class="line">ip netns list</span><br></pre></td></tr></table></figure><p>（2）查看test1、test2的network namespace信息</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip netns <span class="built_in">exec</span> test1 ip a</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ip a</span><br></pre></td></tr></table></figure><p>（3） 使lo端口up起来</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip netns <span class="built_in">exec</span> test1 ip link <span class="built_in">set</span> dev lo</span><br></pre></td></tr></table></figure><p>（4） 添加一对veth接口</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip link add veth-test1 <span class="built_in">type</span> veth peer name veth-test2</span><br></pre></td></tr></table></figure><p>（5） 将veth-test1添加到test1中，veth-test2添加到test2</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip link <span class="built_in">set</span> veth-test1 netns test1</span><br><span class="line">ip link <span class="built_in">set</span> veth-test2 netns test2</span><br><span class="line"><span class="comment">#查看是否添加成功</span></span><br><span class="line">ip netns <span class="built_in">exec</span> test1 ip link</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ip link</span><br></pre></td></tr></table></figure><p>（6）给veth-test1、veth-test2分配端口</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip netns <span class="built_in">exec</span> test1 ip addr add 192.168.1.1/24 dev veth-test1</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ip addr add 192.168.1.2/24 dev veth-test2</span><br></pre></td></tr></table></figure><p>（7）将veth-test1、veth-test2端口up,并查看ip</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#up端口</span></span><br><span class="line">ip netns <span class="built_in">exec</span> test1 ip link <span class="built_in">set</span> dev veth-test1</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ip link <span class="built_in">set</span> dev veth-test2</span><br><span class="line"><span class="comment">#查看ip</span></span><br><span class="line">ip netns <span class="built_in">exec</span> test1 ip a</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ip a</span><br></pre></td></tr></table></figure><p>（8）查看互相是否可以通信</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip netns <span class="built_in">exec</span> test1 ping 192.168.1.2</span><br><span class="line">ip netns <span class="built_in">exec</span> test2 ping 192.168.1.1</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a4.png"><br>其实docker容器之间的通信也是通过这种技术实现的</p><h2 id="Docker-Bridge0"><a href="#Docker-Bridge0" class="headerlink" title="Docker Bridge0"></a>Docker Bridge0</h2><p>Container Test1容器通过自己端口与宿主机的docker0的veth端口相连，Container Test2容器通过自己的端口与宿主机另外一个veth端口相连，这样就保证了2个容器可以互相通信<br><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a5.png"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看docker的network</span></span><br><span class="line">docker network ls</span><br><span class="line"><span class="comment">#查看bridge中有哪些容器</span></span><br><span class="line">docker network inspect &lt;network ID&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip a</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a6.png"></p><h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><p>与其他容器通信时，通过ip来访问的。创建容器时使用–link <name>来实现容器连接，这样通过name也可以访问了,但是link这种方式是单向的<br>除非2个容器都是连接在用户自己创建的network上，可以使用name来访问</name></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name test2 --link test1 container1</span><br><span class="line">docker <span class="built_in">exec</span> -it test2 bash</span><br><span class="line">ping test1 </span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建network</span></span><br><span class="line">docker network create net3</span><br><span class="line"><span class="comment">#删除network</span></span><br><span class="line">docker network rm net3</span><br><span class="line"><span class="comment">#新建容器，使用net3，使用--network</span></span><br><span class="line">docker run -d --name test2 --network net3 container1</span><br><span class="line"><span class="comment">#将已经存在的容器连接到net3上</span></span><br><span class="line">docker network connect net3 container1</span><br></pre></td></tr></table></figure><h2 id="端口映射"><a href="#端口映射" class="headerlink" title="端口映射"></a>端口映射</h2><p>我们pull了一个nginx镜像，创建nginx容器，但是我们在外面无法访问nginx容器的80端口，这时就要将nginx服务暴露给外面，可以将nginx的80端口映射到本地</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -p表示端口映射</span></span><br><span class="line">docker run --name nginx -d -p 80:80</span><br></pre></td></tr></table></figure><h2 id="none和host-network"><a href="#none和host-network" class="headerlink" title="none和host network"></a>none和host network</h2><p>当容器连接到none时，不存在ip和mac地址，none是与外界隔绝的network<br>当容器连接到host时，他没有独立的network，他与宿主机的network共享一套network（如果创建2个nginx都绑定在80端口，容易端口冲突）</p><h2 id="多机通信"><a href="#多机通信" class="headerlink" title="多机通信"></a>多机通信</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/09/01/Docker%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/a7.png"><br>docker提供了overlay来实现2台linux主机之间的通信<br>2台linux主机通信，必须保证2个主机上的docker容器的ip不一样，我们使用etcd来实现</p><h3 id="下载etcd"><a href="#下载etcd" class="headerlink" title="下载etcd"></a>下载etcd</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载</span></span><br><span class="line">wget https://github.com/coreos/etcd/releases/download/v3.0.12/etcd-v3.0.12-linux-amd64.tar.gz</span><br><span class="line"><span class="comment">#解压缩</span></span><br><span class="line">tar zxvf etcd-v3.0.12-linux-amd64.tar.gz</span><br><span class="line"><span class="comment">#进入etcd-v3.0.12-linux-amd64目录下</span></span><br><span class="line"><span class="built_in">cd</span> etcd-v3.0.12-linux-amd64</span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动第一台node1主机etcd服务</span></span><br><span class="line">nohup ./etcd --name docker-node1 --initial-advertise-peer-urls http://192.168.186.129:2380 \</span><br><span class="line">--listen-peer-urls http://192.168.186.129:2380 \</span><br><span class="line">--listen-client-urls http://192.168.186.129:2379,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls http://192.168.186.129:2379 \</span><br><span class="line">--initial-cluster-token etcd-cluster \</span><br><span class="line">--initial-cluster docker-node1=http://192.168.186.129:2380,docker-node2=http://192.168.186.130:2380 \</span><br><span class="line">--initial-cluster-state new&amp;</span><br><span class="line"><span class="comment">#启动另一台node2主机etcd服务</span></span><br><span class="line">nohup ./etcd --name docker-node2 --initial-advertise-peer-urls http://192.168.186.130:2380 \</span><br><span class="line">--listen-peer-urls http://192.168.186.130:2380 \</span><br><span class="line">--listen-client-urls http://192.168.186.130:2379,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls http://192.168.186.130:2379 \</span><br><span class="line">--initial-cluster-token etcd-cluster \</span><br><span class="line">--initial-cluster docker-node1=http://192.168.186.129:2380,docker-node2=http://192.168.186.130:2380 \</span><br><span class="line">--initial-cluster-state new&amp;</span><br></pre></td></tr></table></figure><h3 id="查看cluster是否建立"><a href="#查看cluster是否建立" class="headerlink" title="查看cluster是否建立"></a>查看cluster是否建立</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./etcdctl cluster-health</span><br></pre></td></tr></table></figure><h3 id="重启docker"><a href="#重启docker" class="headerlink" title="重启docker"></a>重启docker</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#node1</span></span><br><span class="line">service docker stop</span><br><span class="line">sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.186.129:2379 --cluster-advertise=192.168.186.129:2375&amp;</span><br><span class="line"><span class="comment">#node2</span></span><br><span class="line">service docker stop</span><br><span class="line">sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.186.130:2379 --cluster-advertise=192.168.186.130:2375&amp;</span><br></pre></td></tr></table></figure><h3 id="创建overlay"><a href="#创建overlay" class="headerlink" title="创建overlay"></a>创建overlay</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在node1上创建overlay</span></span><br><span class="line">docker network create -d overlay demo</span><br><span class="line"><span class="comment">#查看node1上的network</span></span><br><span class="line">docker network ls</span><br><span class="line"><span class="comment">#再查看node2主机上的network，会发现存在名叫demo的overlay</span></span><br><span class="line">docker network ls</span><br></pre></td></tr></table></figure><h3 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在node1主机上创建busybox容器</span></span><br><span class="line">docker run -d --name test1 --net demo busybox sh -c <span class="string">&quot;while true; do sleep 3600; done&quot;</span></span><br><span class="line"><span class="comment">#在node2上再次创建，会发现报错，提示test1已经存在</span></span><br><span class="line">docker run -d --name test1 --net demo busybox sh -c <span class="string">&quot;while true; do sleep 3600; done&quot;</span></span><br><span class="line"><span class="comment">#创建test2</span></span><br><span class="line">docker run -d --name test2 --net demo busybox sh -c <span class="string">&quot;while true; do sleep 3600; done&quot;</span></span><br></pre></td></tr></table></figure><h3 id="查看2个容器的ip，是不一致的"><a href="#查看2个容器的ip，是不一致的" class="headerlink" title="查看2个容器的ip，是不一致的"></a>查看2个容器的ip，是不一致的</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it test1 ip a</span><br><span class="line">docker <span class="built_in">exec</span> -it test2 ip a</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker的镜像与容器（一）</title>
      <link href="2019/08/31/Docker%E7%9A%84%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>2019/08/31/Docker%E7%9A%84%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文主要涉及Docker镜像、容器相关知识</p><a id="more"></a><h2 id="Docker架构和底层技术"><a href="#Docker架构和底层技术" class="headerlink" title="Docker架构和底层技术"></a>Docker架构和底层技术</h2><p>Docker提供了一个开发、打包、运行应用的平台<br>Docker Engine将应用和infrastructure分离开<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/31/Docker%E7%9A%84%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%EF%BC%88%E4%B8%80%EF%BC%89/a1.png"></p><h3 id="Docker-Engine"><a href="#Docker-Engine" class="headerlink" title="Docker Engine"></a>Docker Engine</h3><p>Docker Engine由后台进程（dockerd）、REST API Server、CLI接口（docker）组成</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看Client、Server、Engine版本</span></span><br><span class="line">docker version</span><br><span class="line"><span class="comment">#查看docker进程</span></span><br><span class="line">ps -ef | grep docker</span><br></pre></td></tr></table></figure><h3 id="底层技术支持"><a href="#底层技术支持" class="headerlink" title="底层技术支持"></a>底层技术支持</h3><p>（1）Namespaces：做隔离pid，net，ipc，mnt，uts<br>（2）Control groups：做资源限制<br>（3）Union file systems：Container和image的分层</p><h2 id="Docker-Image"><a href="#Docker-Image" class="headerlink" title="Docker Image"></a>Docker Image</h2><p>Image里面是一层层的文件系统，即UnionFS（联合文件系统）。每一层文件系统我们都叫一层layer，Image本身是read-only的。构建镜像的时候，每个构建操作都是对一层修改，增加一层文件系统，当你使用Image的时候，你看到的是一个整体，不知道Image到底含有多少文件系统。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看image</span></span><br><span class="line">docker images</span><br><span class="line"><span class="comment">#删除镜像</span></span><br><span class="line">docker rmi 镜像名称</span><br><span class="line"><span class="comment">#使用Dockerfile创建镜像,其中“.”表示指向当前目录下的dockerdile，也可以使用“-f 文件目录” </span></span><br><span class="line">docker build -t 镜像名称 .</span><br></pre></td></tr></table></figure><h3 id="获取Image方式"><a href="#获取Image方式" class="headerlink" title="获取Image方式"></a>获取Image方式</h3><p>（1）Dockerfile<br>（2）Pull from Registry</p><h2 id="Docker-Container"><a href="#Docker-Container" class="headerlink" title="Docker Container"></a>Docker Container</h2><h3 id="Container概念"><a href="#Container概念" class="headerlink" title="Container概念"></a>Container概念</h3><p>（1）通过Image创建的<br>（2）在Image layer之上建立一个可读写的Container<br>（3）Image和Container的关系好比类和实例的关系<br>（4）Image负责application的存储和分发，Container负责运行application</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#运行容器</span></span><br><span class="line">docker run 镜像名称</span><br><span class="line"><span class="comment">#交互式运行容器</span></span><br><span class="line">docker run -it 镜像名称</span><br><span class="line"><span class="comment">#查看正在运行容器</span></span><br><span class="line">docker ps</span><br><span class="line"><span class="comment">#查看已经停止的容器</span></span><br><span class="line">docker ps -a</span><br><span class="line"><span class="comment">#删除容器</span></span><br><span class="line">docker rm 容器名称</span><br><span class="line"><span class="comment">#批量删除停止的容器</span></span><br><span class="line">docker rm $(docker ps -aq)</span><br><span class="line"><span class="comment">#批量删除status是exited的容器</span></span><br><span class="line">docker rm $(docker ps -f <span class="string">&quot;status=exited&quot;</span> -q)</span><br><span class="line"><span class="comment">#运行停止的容器/停止运行的容器</span></span><br><span class="line">docker start 容器名称  /   docker stop 容器名称</span><br><span class="line"><span class="comment">#进入容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it 容器ID bash</span><br><span class="line"><span class="comment">#从容器中创建新的镜像</span></span><br><span class="line">docker commit 容器名称 镜像名称</span><br></pre></td></tr></table></figure><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p>尽量使用官方的base image</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#制作base image</span></span><br><span class="line">FROM scratch</span><br><span class="line"><span class="comment">#使用base image</span></span><br><span class="line">FROM centos</span><br><span class="line">FROM ubuntu:14.04</span><br></pre></td></tr></table></figure><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p>定义一个image的Metadata,帮助信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LABEL maintainer=“1335402049@qq.com”</span><br><span class="line">LABEL version=<span class="string">&quot;1.0&quot;</span></span><br><span class="line">LABEL description=<span class="string">&quot;This is a dscription&quot;</span></span><br></pre></td></tr></table></figure><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p>为了美观、负杂的RUN，使用反斜线换行；避免无用分层，合成多条命令成一行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RUN yum update &amp;&amp; yum install -y vim \</span><br><span class="line">    python-dev</span><br></pre></td></tr></table></figure><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p>使用WORKDIR，不要使用RUN cd，尽量使用绝对目录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">WORKDIR /<span class="built_in">test</span>  <span class="comment">#如果没有会自动创建test目录</span></span><br><span class="line">WORKDIR demo</span><br><span class="line">RUN <span class="built_in">pwd</span>        <span class="comment">#输出结果：/test/demo</span></span><br></pre></td></tr></table></figure><h3 id="ADD和COPY"><a href="#ADD和COPY" class="headerlink" title="ADD和COPY"></a>ADD和COPY</h3><p>大部分情况，COPY优先于ADD；ADD除了COPY以外还有解压功能；添加远程文件/目录使用curl或者wget</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ADD hello /</span><br><span class="line">ADD test.tar.gz / <span class="comment">#添加到根目录并解压</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">WORKDIR /root</span><br><span class="line">ADD hello <span class="built_in">test</span>/   <span class="comment"># /root/test/hello</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">WORKDIR /root</span><br><span class="line">COPY hello <span class="built_in">test</span>/ </span><br></pre></td></tr></table></figure><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p>尽量使用ENV</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV MYSQL_VERSION 5.6  <span class="comment">#设置常量</span></span><br><span class="line">RUN apt-get install -y mysql-server=<span class="string">&quot;<span class="variable">$&#123;MYSQL_VERSION&#125;</span>&quot;</span> \</span><br><span class="line">    &amp;&amp; rm -rf /var/lib/apt/list/*   <span class="comment">#引用常量</span></span><br></pre></td></tr></table></figure><h3 id="RUN-CMD-ENTRYPOINT"><a href="#RUN-CMD-ENTRYPOINT" class="headerlink" title="RUN CMD ENTRYPOINT"></a>RUN CMD ENTRYPOINT</h3><p>RUN:执行命令并创建新的Image Layer<br>CMD：设置容器启动后默认执行的命令和参数<br>ENTRYPOINT：设置容器启动时运行的命令</p><p>CMD与ENTRYPOINT区别？<br>（1）CMD<br>容器启动时默认执行的命令;<br>如果docker run指定了其他命令，CMD命令会被忽略；<br>如果定义了多个CMD，只有最后一个会执行<br>（2）ENTRYPOINT<br>让容器以应用程序或者服务的形式运行；<br>不会被忽略，一定会执行</p><h2 id="资源限制"><a href="#资源限制" class="headerlink" title="资源限制"></a>资源限制</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#内存限制</span></span><br><span class="line">docker run --memory=200M 镜像名称</span><br><span class="line"><span class="comment">#cpu限制（相对）</span></span><br><span class="line">docker run --cpu-shares=10 镜像名称</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keepalived+Nginx双机热备</title>
      <link href="2019/08/24/Keepalived-Nginx%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"/>
      <url>2019/08/24/Keepalived-Nginx%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Keepalived实现nginx双机热备，实现高可用</p><a id="more"></a><h2 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker pull nginx</span></span><br></pre></td></tr></table></figure><h2 id="创建nginx配置文件"><a href="#创建nginx配置文件" class="headerlink" title="创建nginx配置文件"></a>创建nginx配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /home/n1/nginx.conf</span></span><br></pre></td></tr></table></figure><h2 id="nginx-conf配置文件"><a href="#nginx-conf配置文件" class="headerlink" title="nginx.conf配置文件"></a>nginx.conf配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">user  nginx;</span><br><span class="line">worker_processes  1;</span><br><span class="line"> </span><br><span class="line">error_log  /var/<span class="built_in">log</span>/nginx/error.log warn;</span><br><span class="line">pid        /var/run/nginx.pid;</span><br><span class="line"> </span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">http &#123;</span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"> </span><br><span class="line">    log_format  main  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span>;</span><br><span class="line"> </span><br><span class="line">    access_log  /var/<span class="built_in">log</span>/nginx/access.log  main;</span><br><span class="line"> </span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"> </span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line">    </span><br><span class="line">    proxy_redirect          off;</span><br><span class="line">    proxy_set_header        Host <span class="variable">$host</span>;</span><br><span class="line">    proxy_set_header        X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">    proxy_set_header        X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">    client_max_body_size    10m;</span><br><span class="line">    client_body_buffer_size   128k;</span><br><span class="line">    proxy_connect_timeout   5s;</span><br><span class="line">    proxy_send_timeout      5s;</span><br><span class="line">    proxy_read_timeout      5s;</span><br><span class="line">    proxy_buffer_size        4k;</span><br><span class="line">    proxy_buffers           4 32k;</span><br><span class="line">    proxy_busy_buffers_size  64k;</span><br><span class="line">    proxy_temp_file_write_size 64k;</span><br><span class="line">    </span><br><span class="line">    upstream tomcat &#123;</span><br><span class="line">        server 192.168.186.129:6001;</span><br><span class="line">        server 192.168.186.129:6002;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       6101;</span><br><span class="line">        server_name  192.168.186.129; </span><br><span class="line">        location / &#123;  </span><br><span class="line">            proxy_pass   http://tomcat;</span><br><span class="line">            index  index.html index.htm;  </span><br><span class="line">        &#125;  </span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -it -d --name n1 -v /home/n1/nginx.conf:/etc/nginx/nginx.conf --net=host --privileged nginx</span></span><br></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker exec -it n1 bash</span></span><br></pre></td></tr></table></figure><h2 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get update</span></span><br><span class="line"><span class="comment"># apt-get install keepalived</span></span><br><span class="line"><span class="comment"># apt-get install vim</span></span><br></pre></td></tr></table></figure><h2 id="创建keepalived配置文件"><a href="#创建keepalived配置文件" class="headerlink" title="创建keepalived配置文件"></a>创建keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/keepalived/keepalived.conf</span></span><br></pre></td></tr></table></figure><h2 id="keepalived配置文件"><a href="#keepalived配置文件" class="headerlink" title="keepalived配置文件"></a>keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">  vrrp_instance VI_1&#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface  ens33</span><br><span class="line">    virtual_router_id  51</span><br><span class="line">    priority  100</span><br><span class="line">    advert_int  1</span><br><span class="line">    authentication&#123;</span><br><span class="line">        auth_type  PASS</span><br><span class="line">        auth_pass  123456</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress&#123;</span><br><span class="line">        192.168.186.151</span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">virtual_server 192.168.186.151 6201 &#123;</span><br><span class="line">    delay_loop 3</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind NAT</span><br><span class="line">    persistence_timeout 50</span><br><span class="line">    protocol TCP</span><br><span class="line">    real_server 192.168.186.129 6101 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动keepalived"><a href="#启动keepalived" class="headerlink" title="启动keepalived"></a>启动keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># service keepalived start</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Keepalived </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keepalived </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker部署RedisCluster集群</title>
      <link href="2019/08/24/Docker%E9%83%A8%E7%BD%B2RedisCluster%E9%9B%86%E7%BE%A4/"/>
      <url>2019/08/24/Docker%E9%83%A8%E7%BD%B2RedisCluster%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前言我们已经搭建好了数据库集群，下面我们来部署Redis集群。</p><a id="more"></a><h2 id="安装Redis镜像"><a href="#安装Redis镜像" class="headerlink" title="安装Redis镜像"></a>安装Redis镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker pull yyyyttttwwww/redis</span></span><br></pre></td></tr></table></figure><h2 id="重命名"><a href="#重命名" class="headerlink" title="重命名"></a>重命名</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker tag yyyyttttwwww/redis redis</span></span><br><span class="line"><span class="comment"># docker rmi yyyyttttwwww/redis</span></span><br></pre></td></tr></table></figure><h2 id="创建Redis集群net2网段"><a href="#创建Redis集群net2网段" class="headerlink" title="创建Redis集群net2网段"></a>创建Redis集群net2网段</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker network create --subnet=172.19.0.0/16 net2</span></span><br></pre></td></tr></table></figure><h2 id="运行Redis容器-并进入容器"><a href="#运行Redis容器-并进入容器" class="headerlink" title="运行Redis容器,并进入容器"></a>运行Redis容器,并进入容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -it -d --name r1 -p 5001:6379 --net=net2 --ip 172.19.0.2 redis bash</span></span><br><span class="line"><span class="comment"># docker exec -it r1 bash</span></span><br></pre></td></tr></table></figure><h2 id="配置Redis节点"><a href="#配置Redis节点" class="headerlink" title="配置Redis节点"></a>配置Redis节点</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /usr/redis/redis.conf</span></span><br></pre></td></tr></table></figure><p>修改配置文件中如下信息</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以后台程序运行</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="comment">#开启集群</span></span><br><span class="line">cluster-enabled yes</span><br><span class="line"><span class="comment">#集群配置文件</span></span><br><span class="line">cluster-config-file nodes.conf</span><br><span class="line"><span class="comment">#设置超时时间</span></span><br><span class="line">cluster-node-timeout 15000</span><br><span class="line"><span class="comment">#开启AOF模式，日志功能</span></span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><h2 id="进入目录-开启Redis服务"><a href="#进入目录-开启Redis服务" class="headerlink" title="进入目录,开启Redis服务"></a>进入目录,开启Redis服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd /usr/redis/src</span></span><br><span class="line"><span class="comment"># ./redis-server ../redis.conf</span></span><br></pre></td></tr></table></figure><p>这样就创建了一个Redis节点了，依照上面操作创建其他Redis节点</p><h2 id="安装redis-trib-rb"><a href="#安装redis-trib-rb" class="headerlink" title="安装redis-trib.rb"></a>安装redis-trib.rb</h2><p>redis-trib.rb是基于Ruby的Redis集群命令行工具，下载地址<a href="https://cache.ruby-lang.org/pub/ruby/2.5/ruby-2.5.1.tar.gz">https://cache.ruby-lang.org/pub/ruby/2.5/ruby-2.5.1.tar.gz</a><br>docker pull yyyyttttwwww/redis拉取的镜像，在容器的usr/redis/src目录下已经事先下载好了redis-trib.rb</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir /usr/redis/cluster</span></span><br><span class="line"><span class="comment"># cp /usr/redis/src/redis-trib.rb /usr/redis/cluster</span></span><br><span class="line"><span class="comment"># apt-get install ruby</span></span><br><span class="line"><span class="comment"># apt-get install rubygems</span></span><br><span class="line"><span class="comment"># gem install redis</span></span><br></pre></td></tr></table></figure><h2 id="创建Redis集群"><a href="#创建Redis集群" class="headerlink" title="创建Redis集群"></a>创建Redis集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ./redis-trib.rb create --replicas 1 172.19.0.2:6379 172.19.0.3:6379 172.19.0.4:6379 172.19.0.5:6379 172.19.0.6:6379 172.19.0.7:6379</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/24/Docker%E9%83%A8%E7%BD%B2RedisCluster%E9%9B%86%E7%BE%A4/a1.png"></p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#进入r1节点</span></span><br><span class="line">docker <span class="built_in">exec</span> -it r1 bash</span><br><span class="line"><span class="comment">#使用redis-cli连接redis客户端</span></span><br><span class="line">/usr/redis/src/redis-cli -c</span><br><span class="line"><span class="comment">#写入数据</span></span><br><span class="line"><span class="built_in">set</span> a 10</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/24/Docker%E9%83%A8%E7%BD%B2RedisCluster%E9%9B%86%E7%BE%A4/a2.png"><br>这个数据最终是存到172.19.0.4这个节点了</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PXC热备份方案</title>
      <link href="2019/08/24/PXC%E7%83%AD%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88/"/>
      <url>2019/08/24/PXC%E7%83%AD%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>对数据库文件备份是工作中必不可少的环节，常见的数据库备份方式主要是冷备份和热备份方案</p><a id="more"></a><h2 id="冷备份"><a href="#冷备份" class="headerlink" title="冷备份"></a>冷备份</h2><p>冷备份就是关闭数据库时候的备份方式，通常是拷贝数据文件<br>冷备份是最简单的最安全的一种备份方式<br>但是一般运营过程中不能停止数据库服务来进行数据备份</p><h2 id="热备份"><a href="#热备份" class="headerlink" title="热备份"></a>热备份</h2><p>热备份是在系统运行的状态下备份数据<br>MySQL常见热备份方式是LVM和XtraBackup两种备份方案<br>LVM:linux的分区备份命令,可以备份任何数据库；但是会对数据库加锁,只能读取;而且命令复杂<br>XtraBackup:不需要锁表就可以实现数据备份,而且免费</p><h2 id="XtraBackup"><a href="#XtraBackup" class="headerlink" title="XtraBackup"></a>XtraBackup</h2><p>XtraBackup是由percona提供的一款基于InnoDB的开源免费数据库热备份软件，它支持在线热备份，占用磁盘空间小，能够非常快速地备份与恢复MySQL数据库<br>1.备份过程中不锁表，快速可靠<br>2.备份过程中不会打断正在执行地事务<br>3.备份数据经过压缩，占用磁盘空间小</p><h2 id="全量备份和增量备份"><a href="#全量备份和增量备份" class="headerlink" title="全量备份和增量备份"></a>全量备份和增量备份</h2><p>1.全量备份：备份全部数据。备份时间长，占用空间大。第一次备份要使用全量备份<br>2.增量备份：只备份变化的那部分数据。备份的时间短，占用空间小。后续建议使用增量备份</p><h2 id="PXC全量备份"><a href="#PXC全量备份" class="headerlink" title="PXC全量备份"></a>PXC全量备份</h2><h3 id="创建数据卷"><a href="#创建数据卷" class="headerlink" title="创建数据卷"></a>创建数据卷</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker volume create backup</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/24/PXC%E7%83%AD%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88/a1.png"></p><h3 id="挑选一个PXC节点node1，将其停止并删除，然后重新创建一个增加backup目录映射node1容器"><a href="#挑选一个PXC节点node1，将其停止并删除，然后重新创建一个增加backup目录映射node1容器" class="headerlink" title="挑选一个PXC节点node1，将其停止并删除，然后重新创建一个增加backup目录映射node1容器"></a>挑选一个PXC节点node1，将其停止并删除，然后重新创建一个增加backup目录映射node1容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker stop node1</span></span><br><span class="line"><span class="comment"># docker rm node1</span></span><br><span class="line"><span class="comment"># docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -v v1:/var/lib/mysql -v backup:/data --privileged -e CLUSTER_JOIN=node2 --name=node1 --net=net1 --ip 172.18.0.2 pxc</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/24/PXC%E7%83%AD%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88/a2.png"></p><h3 id="PXC容器中安装XtraBackup，并执行备份"><a href="#PXC容器中安装XtraBackup，并执行备份" class="headerlink" title="PXC容器中安装XtraBackup，并执行备份"></a>PXC容器中安装XtraBackup，并执行备份</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker exec -it node1 bash</span></span><br><span class="line"><span class="comment"># apt-get update</span></span><br><span class="line"><span class="comment"># apt-get install percona-xtrabackup-24</span></span><br><span class="line"><span class="comment"># innobackupex --user=root --password=tang1611 /data/back/full</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/24/PXC%E7%83%AD%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88/a3.png"></p><h2 id="PXC全量还原"><a href="#PXC全量还原" class="headerlink" title="PXC全量还原"></a>PXC全量还原</h2><p>数据库可以热备份，但是不能热还原，否则会造成业务数据和还原数据的冲突。<br>对于PXC集群为了避免还原过程中各节点数据同步冲突的问题，我们要先解散原来的集群，删除节点。然后新建节点空白数据库，执行还原，最后再建立起其他集群节点。<br>还原前还要将热备份保存的未提交的事务回滚，还原之后重启MySQL</p><h3 id="停止并删除PXC所有节点"><a href="#停止并删除PXC所有节点" class="headerlink" title="停止并删除PXC所有节点"></a>停止并删除PXC所有节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker stop node1 node2 node3 node4 node5</span></span><br><span class="line"><span class="comment"># docker rm node1 node2 node3 node4 node5</span></span><br><span class="line"><span class="comment"># docker volume rm v1 v2 v3 v4 v5</span></span><br></pre></td></tr></table></figure><h3 id="按之前程序创建v1数据卷和node1容器，进入容器，进行全量还原"><a href="#按之前程序创建v1数据卷和node1容器，进入容器，进行全量还原" class="headerlink" title="按之前程序创建v1数据卷和node1容器，进入容器，进行全量还原"></a>按之前程序创建v1数据卷和node1容器，进入容器，进行全量还原</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker volume create v1</span></span><br><span class="line"><span class="comment"># docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -v v1:/var/lib/mysql -v backup:/data --privileged --name=node1 --net=net1 --ip 172.18.0.2 pxc</span></span><br><span class="line"><span class="comment"># docker exec -it -u root node bash</span></span><br><span class="line"><span class="comment"># rm -rf /var/lib/mysql/*</span></span><br><span class="line"><span class="comment"># innobackupex --user=root --password=tang1611 --apply-back /data/back/full/2019-06-28_03-36-59</span></span><br><span class="line"><span class="comment"># innobackupex --user=root --password=tang1611 --copy-back /data/back/full/2019-06-28_03-36-59</span></span><br><span class="line"><span class="comment"># chown -R mysql:mysql /var/lib/mysql</span></span><br><span class="line"><span class="comment"># docker stop node1</span></span><br><span class="line"><span class="comment"># docker start node1</span></span><br></pre></td></tr></table></figure><p>最后重新创建其他数据卷和其他节点，同步node1节点即可。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PXC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker部署高可用MySQL负载均衡、双机热备</title>
      <link href="2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"/>
      <url>2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在之前的文章我们已经搭建好了PXC集群，所有的PXC集群节点都是可读可写的，在程序发送请求给数据库时，我们不能把所有的请求全发送给一个PXC节点，对于这种情况，就形成了一个节点负载特别高、性能差，其他节点就显得很空闲，这种情况是我们不希望的。我们希望所有的PXC节点都参与到请求的处理，所以我们就要用到数据库负载均衡技术。</p><a id="more"></a><p>这里我们使用Haproxy来做负载均衡，Haproxy是作为一个请求的转发器，将各个请求均匀分给不同的节点，这样就保证了单个节点负载低、性能好。</p><p>然而单点的Haproxy又不具备高可用，一旦Haproxy出现故障，整个程序就无法正常工作了，所以我们必须要做多个Haproxy节点，一个节点挂掉，必须要有其他Haproxy来顶替。因此这里我们使用Keepalived来实现双机热备。</p><h2 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker pull haproxy</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a1.png"></p><h2 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a2.png"></p><h2 id="创建Haproxy配置文件"><a href="#创建Haproxy配置文件" class="headerlink" title="创建Haproxy配置文件"></a>创建Haproxy配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># touch /home/soft/haproxy/haproxy.cfg</span></span><br></pre></td></tr></table></figure><h2 id="Haproxy配置"><a href="#Haproxy配置" class="headerlink" title="Haproxy配置"></a>Haproxy配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">global</span><br><span class="line">    <span class="comment">#工作目录</span></span><br><span class="line">    chroot /usr/<span class="built_in">local</span>/etc/haproxy</span><br><span class="line">    <span class="comment">#日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info</span></span><br><span class="line">    <span class="built_in">log</span> 127.0.0.1 local5 info</span><br><span class="line">    <span class="comment">#守护进程运行</span></span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    <span class="built_in">log</span>    global</span><br><span class="line">    mode    http</span><br><span class="line">    <span class="comment">#日志格式</span></span><br><span class="line">    option    httplog</span><br><span class="line">    <span class="comment">#日志中不记录负载均衡的心跳检测记录</span></span><br><span class="line">    option    dontlognull</span><br><span class="line">    <span class="comment">#连接超时（毫秒）</span></span><br><span class="line">    timeout connect 5000</span><br><span class="line">    <span class="comment">#客户端超时（毫秒）</span></span><br><span class="line">    timeout client  50000</span><br><span class="line">    <span class="comment">#服务器超时（毫秒）</span></span><br><span class="line">    timeout server  50000</span><br><span class="line"></span><br><span class="line"><span class="comment">#监控界面</span></span><br><span class="line">listen  admin_stats</span><br><span class="line">    <span class="comment">#监控界面的访问的IP和端口</span></span><br><span class="line">    <span class="built_in">bind</span>  0.0.0.0:8888</span><br><span class="line">    <span class="comment">#访问协议</span></span><br><span class="line">    mode        http</span><br><span class="line">    <span class="comment">#URI相对地址</span></span><br><span class="line">    stats uri   /dbs</span><br><span class="line">    <span class="comment">#统计报告格式</span></span><br><span class="line">    stats realm     Global\ statistics</span><br><span class="line">    <span class="comment">#登陆帐户信息</span></span><br><span class="line">    stats auth  admin:tang1611</span><br><span class="line"><span class="comment">#数据库负载均衡</span></span><br><span class="line">listen  proxy-mysql</span><br><span class="line">    <span class="comment">#访问的IP和端口</span></span><br><span class="line">    <span class="built_in">bind</span>  0.0.0.0:3306</span><br><span class="line">    <span class="comment">#网络协议</span></span><br><span class="line">    mode  tcp</span><br><span class="line">    <span class="comment">#负载均衡算法（轮询算法）</span></span><br><span class="line">    <span class="comment">#轮询算法：roundrobin</span></span><br><span class="line">    <span class="comment">#权重算法：static-rr</span></span><br><span class="line">    <span class="comment">#最少连接算法：leastconn</span></span><br><span class="line">    <span class="comment">#请求源IP算法：source</span></span><br><span class="line">    balance  roundrobin</span><br><span class="line">    <span class="comment">#日志格式</span></span><br><span class="line">    option  tcplog</span><br><span class="line">    <span class="comment">#在MySQL中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL数据库心跳检测</span></span><br><span class="line">    option  mysql-check user haproxy</span><br><span class="line">    server  MySQL_1 172.18.0.2:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_2 172.18.0.3:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_3 172.18.0.4:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_4 172.18.0.5:3306 check weight 1 maxconn 2000</span><br><span class="line">    server  MySQL_5 172.18.0.6:3306 check weight 1 maxconn 2000</span><br><span class="line">    <span class="comment">#使用keepalive检测死链</span></span><br><span class="line">    option  tcpka</span><br></pre></td></tr></table></figure><h2 id="创建Haproxy容器"><a href="#创建Haproxy容器" class="headerlink" title="创建Haproxy容器"></a>创建Haproxy容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -it -d -p 4001:8888 -p 4002:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h1 --privileged --net=net1 haproxy</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a3.png"></p><h2 id="进入后台运行的Haproxy容器"><a href="#进入后台运行的Haproxy容器" class="headerlink" title="进入后台运行的Haproxy容器"></a>进入后台运行的Haproxy容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker exec -it h1 bash</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a4.png"></p><h2 id="指明配置文件路径"><a href="#指明配置文件路径" class="headerlink" title="指明配置文件路径"></a>指明配置文件路径</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># haproxy -f /usr/local/etc/haproxy/haproxy.cfg</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a5.png"></p><h2 id="创建haproxy数据库账号"><a href="#创建haproxy数据库账号" class="headerlink" title="创建haproxy数据库账号"></a>创建haproxy数据库账号</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CREATE USER &#x27;haproxy&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;&#x27;;</span></span><br></pre></td></tr></table></figure><h2 id="进入haproxy监控页面"><a href="#进入haproxy监控页面" class="headerlink" title="进入haproxy监控页面"></a>进入haproxy监控页面</h2><p>浏览器访问 服务器ip:4001/dbs<br>其中4001是我们启动容器映射的宿主机的端口,dbs是配置文件里面配置的URL相对地址<br>例如我的访问地址是<a href="http://192.168.186.129:4001/dbs">http://192.168.186.129:4001/dbs</a><br>进入后输入用户名和密码，也是在配置文件内配置的，我这里用户名是admin，密码也是tang1611<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a6.png"></p><h2 id="验证haproxy是否转发请求"><a href="#验证haproxy是否转发请求" class="headerlink" title="验证haproxy是否转发请求"></a>验证haproxy是否转发请求</h2><p>（1）创建连接<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a7.png"><br>（2）更新数据<br>在刚刚创建的连接的表中增加一行数据，haproxy不处理任何数据，它会将这个请求发送给其他1个PXC节点，而PXC具备强一致性，就会将数据同步到其他节点<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a8.png"></p><h2 id="进入haproxy容器，更新apt-get"><a href="#进入haproxy容器，更新apt-get" class="headerlink" title="进入haproxy容器，更新apt-get"></a>进入haproxy容器，更新apt-get</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get update</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a9.png"></p><h2 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get install keepalived</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a10.png"></p><h2 id="安装vim编译器"><a href="#安装vim编译器" class="headerlink" title="安装vim编译器"></a>安装vim编译器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get install vim</span></span><br></pre></td></tr></table></figure><h2 id="创建keepalived配置文件"><a href="#创建keepalived配置文件" class="headerlink" title="创建keepalived配置文件"></a>创建keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/keepalived/keepalived.conf</span></span><br></pre></td></tr></table></figure><h2 id="keepalived配置文件"><a href="#keepalived配置文件" class="headerlink" title="keepalived配置文件"></a>keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> vrrp_instance VI_1&#123;</span><br><span class="line">   state MASTER</span><br><span class="line">interface  eth0</span><br><span class="line">virtual_router_id  51</span><br><span class="line">priority  100</span><br><span class="line">advert_int  1</span><br><span class="line">authentication&#123;</span><br><span class="line">  auth_type  PASS</span><br><span class="line">  auth_pass  123456</span><br><span class="line">&#125;</span><br><span class="line">virtual_ipaddress&#123;</span><br><span class="line">  172.18.0.201</span><br><span class="line">&#125;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="启动keepalived"><a href="#启动keepalived" class="headerlink" title="启动keepalived"></a>启动keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># service keepalived start</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/19/Docker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8MySQL%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/a11.png"></p><h2 id="创建第二个Haproxy容器"><a href="#创建第二个Haproxy容器" class="headerlink" title="创建第二个Haproxy容器"></a>创建第二个Haproxy容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -it -d -p 4003:8888 -p 4004:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h2 --privileged --net=net1 haproxy</span></span><br></pre></td></tr></table></figure><h2 id="进入容器，并指定配置文件"><a href="#进入容器，并指定配置文件" class="headerlink" title="进入容器，并指定配置文件"></a>进入容器，并指定配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker -it h2 bash</span></span><br><span class="line"><span class="comment"># docker -f /usr/local/etc/haproxy/haproxy.cfg</span></span><br></pre></td></tr></table></figure><h2 id="更新apt-get"><a href="#更新apt-get" class="headerlink" title="更新apt-get"></a>更新apt-get</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get update</span></span><br></pre></td></tr></table></figure><h2 id="安装keepalived-1"><a href="#安装keepalived-1" class="headerlink" title="安装keepalived"></a>安装keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get install keepalived</span></span><br></pre></td></tr></table></figure><h2 id="安装vim编译器-1"><a href="#安装vim编译器-1" class="headerlink" title="安装vim编译器"></a>安装vim编译器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get install vim</span></span><br></pre></td></tr></table></figure><h2 id="创建keepalived配置文件-1"><a href="#创建keepalived配置文件-1" class="headerlink" title="创建keepalived配置文件"></a>创建keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/keepalived/keepalived.conf</span></span><br></pre></td></tr></table></figure><h2 id="keepalived配置文件-1"><a href="#keepalived配置文件-1" class="headerlink" title="keepalived配置文件"></a>keepalived配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> vrrp_instance VI_1&#123;</span><br><span class="line">   state MASTER</span><br><span class="line">interface  eth0</span><br><span class="line">virtual_router_id  51</span><br><span class="line">priority  100</span><br><span class="line">advert_int  1</span><br><span class="line">authentication&#123;</span><br><span class="line">  auth_type  PASS</span><br><span class="line">  auth_pass  123456</span><br><span class="line">&#125;</span><br><span class="line">virtual_ipaddress&#123;</span><br><span class="line">  172.18.0.201</span><br><span class="line">&#125;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="启动keepalived-1"><a href="#启动keepalived-1" class="headerlink" title="启动keepalived"></a>启动keepalived</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># service keepalived start</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker搭建MySQL高可用方案PXC集群</title>
      <link href="2019/08/18/Docker%E6%90%AD%E5%BB%BAMySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88PXC%E9%9B%86%E7%BE%A4/"/>
      <url>2019/08/18/Docker%E6%90%AD%E5%BB%BAMySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88PXC%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>PXC全称Percona XtraDB Cluster，它提供了MySQL高可用的一种实现方案。PXC集群是以节点组成，推荐奇数个节点（至少3个以上），集群中的每个节点都包含完整的数据，并且所有节点都是可读可写的。PXC集群方案能够保证数据的强一致性，当程序向PXC的一个节点提交数据时，该节点先同步其他的节点，如果其他节点同步失败，那么这个提交数据的行为就算失败，只有所有节点都同步成功才返回程序提交数据成功。</p><a id="more"></a><h2 id="下载镜像文件"><a href="#下载镜像文件" class="headerlink" title="下载镜像文件"></a>下载镜像文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker pull percona/percona-xtradb-cluster:5.7.20</span></span><br></pre></td></tr></table></figure><h2 id="查看镜像文件"><a href="#查看镜像文件" class="headerlink" title="查看镜像文件"></a>查看镜像文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br></pre></td></tr></table></figure><h2 id="修改镜像文件名称"><a href="#修改镜像文件名称" class="headerlink" title="修改镜像文件名称"></a>修改镜像文件名称</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker tag percona/percona-xtradb-cluster:5.7.20 pxc</span></span><br></pre></td></tr></table></figure><h2 id="删除原来镜像文件"><a href="#删除原来镜像文件" class="headerlink" title="删除原来镜像文件"></a>删除原来镜像文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker rmi percona/percona-xtradb-cluster:5.7.20</span></span><br></pre></td></tr></table></figure><h2 id="创建pxc集群内部网络"><a href="#创建pxc集群内部网络" class="headerlink" title="创建pxc集群内部网络"></a>创建pxc集群内部网络</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker network create --subnet=172.18.0.0/24 net1</span></span><br></pre></td></tr></table></figure><h2 id="查看内部网络信息"><a href="#查看内部网络信息" class="headerlink" title="查看内部网络信息"></a>查看内部网络信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker inspect net1</span></span><br></pre></td></tr></table></figure><h2 id="创建docker卷"><a href="#创建docker卷" class="headerlink" title="创建docker卷"></a>创建docker卷</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker volume create v1</span></span><br><span class="line"><span class="comment"># docker volume create v2</span></span><br><span class="line"><span class="comment"># docker volume create v3</span></span><br><span class="line"><span class="comment"># docker volume create v4</span></span><br><span class="line"><span class="comment"># docker volume create v5</span></span><br></pre></td></tr></table></figure><h2 id="查看docker卷信息"><a href="#查看docker卷信息" class="headerlink" title="查看docker卷信息"></a>查看docker卷信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker inspect v1</span></span><br><span class="line"><span class="comment"># docker inspect v2</span></span><br><span class="line"><span class="comment"># docker inspect v3</span></span><br><span class="line"><span class="comment"># docker inspect v4</span></span><br><span class="line"><span class="comment"># docker inspect v5</span></span><br></pre></td></tr></table></figure><h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -v v1:/var/lib/mysql --privileged --name=node1 --net=net1 --ip 172.18.0.2 pxc</span></span><br><span class="line"><span class="comment"># docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -e CLUSTER_JOIN=node1 -v v2:/var/lib/mysql --privileged --name=node2 --net=net1 --ip 172.18.0.3 pxc</span></span><br><span class="line"><span class="comment"># docker run -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -e CLUSTER_JOIN=node1 -v v3:/var/lib/mysql --privileged --name=node3 --net=net1 --ip 172.18.0.4 pxc</span></span><br><span class="line"><span class="comment"># docker run -d -p 3309:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -e CLUSTER_JOIN=node1 -v v4:/var/lib/mysql --privileged --name=node4 --net=net1 --ip 172.18.0.5 pxc</span></span><br><span class="line"><span class="comment"># docker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=tang1611 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=tang1611 -e CLUSTER_JOIN=node1 -v v5:/var/lib/mysql --privileged --name=node5 --net=net1 --ip 172.18.0.6 pxc</span></span><br></pre></td></tr></table></figure><h2 id="查看正在运行的容器"><a href="#查看正在运行的容器" class="headerlink" title="查看正在运行的容器"></a>查看正在运行的容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker ps</span></span><br></pre></td></tr></table></figure><h2 id="使用本地navicate连接PXC集群节点"><a href="#使用本地navicate连接PXC集群节点" class="headerlink" title="使用本地navicate连接PXC集群节点"></a>使用本地navicate连接PXC集群节点</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/18/Docker%E6%90%AD%E5%BB%BAMySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88PXC%E9%9B%86%E7%BE%A4/a1.png"></p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Github-Pages和Hexo搭建自己的博客</title>
      <link href="2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
      <url>2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这是一篇使用Github Pages和Hexo搭建博客的详细教程。这是我搭建好自己博客的的第一篇文章，搭建的时候也是通过百度，经过千辛万苦完成的，希望通过我的教程，使更多的同学能够搭建自己的博客。</p><a id="more"></a><h2 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h2><p>（1）Node.js下载地址：<a href="https://nodejs.org/en/%E3%80%82">https://nodejs.org/en/。</a><br>（2）检验Node.js是否安装成功<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a1.png"></p><h2 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h2><p>（1）Git下载地址：<a href="https://git-scm.com/">https://git-scm.com/</a><br>（2）检验Git是否安装成功，鼠标右键菜单会出现Git GUI Here和Git Bash Here<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a2.png"></p><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>首先选择一个磁盘，新建一个文件夹（我这里新建了一个weifeng_blog文件夹），用来存储博客相关的文件。进入刚创建的文件夹，鼠标右击，点击Git Bash Here。<br>（1）安装hexo-cli<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a3.png"><br>（2）安装hexo部署到git page和deployer<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a4.png"></p><h2 id="Hexo初始化配置"><a href="#Hexo初始化配置" class="headerlink" title="Hexo初始化配置"></a>Hexo初始化配置</h2><p>在刚刚创建的文件夹下，再新建一个hexo的文件夹。进入hexo文件夹，鼠标右击，点击Git Bash Here。初始化的过程会比较慢，耐心等待。成功后会发现hexo目录下出现很多文件。<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a5.png"></p><h2 id="本地查看效果"><a href="#本地查看效果" class="headerlink" title="本地查看效果"></a>本地查看效果</h2><p>执行hexo g和hexo s,当你执行hexo g时，一直报错cannot find module。<br>例如：<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a6.png"><br>解决方案：npm install –save htmlparser2，这边的htmlparser2就是图片上说的缺失的module。再次执行hexo -g 和 hexo -s指令<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a7.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a8.png"><br>最后访问<a href="http://localhost:4000/%E3%80%82">http://localhost:4000/。</a><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a9.png"></p><h2 id="登录Github账户"><a href="#登录Github账户" class="headerlink" title="登录Github账户"></a>登录Github账户</h2><p>Github官网：<a href="https://github.com/">https://github.com/</a></p><h2 id="创建项目代码库"><a href="#创建项目代码库" class="headerlink" title="创建项目代码库"></a>创建项目代码库</h2><p>点击头像，create a new repository。Repository name必须要以你的用户名.github.io命名，勾选Initialize this repository with a README，最后Create repository。<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a10.png"></p><h2 id="配置SSH密钥"><a href="#配置SSH密钥" class="headerlink" title="配置SSH密钥"></a>配置SSH密钥</h2><p>在第一次创建的文件夹下（如我的文件夹weifeng_blog）,Git Bash Here。<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a11.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a12.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a13.png"><br>进入github个人主页，点击右上角，Settings。<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a14.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a15.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a16.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a17.png"></p><h2 id="配置Git个人信息"><a href="#配置Git个人信息" class="headerlink" title="配置Git个人信息"></a>配置Git个人信息</h2><p>把名称和邮箱替换成你自己的，名字可以不是GitHub的昵称，但为了方便记忆，建议与GitHub一致。<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a18.png"></p><h2 id="将本地hexo文件更新到Github库中"><a href="#将本地hexo文件更新到Github库中" class="headerlink" title="将本地hexo文件更新到Github库中"></a>将本地hexo文件更新到Github库中</h2><p><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a19.png"><br>打开创建的hexo文件夹，编辑_config.yml文件<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a20.png"><br>在hexo文件夹下，Git Bash Here。执行hexo g -d。若出现下面问题，则说明deployer没有安装成功。执行npm install hexo-deployer-git –save，然后再次执行hexo g -d<br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a21.png"><br><img src= "/img/loading.gif" data-lazy-src="/2019/08/17/%E4%BD%BF%E7%94%A8Github-Pages%E5%92%8CHexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/a22.png"><br>最后就可以通过https://你的用户名.github.io来访问你的博客了。</p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
